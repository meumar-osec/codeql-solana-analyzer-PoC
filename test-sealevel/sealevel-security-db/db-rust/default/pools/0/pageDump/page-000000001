/// may be passed in as long as it evaluates to a value of the expected type, e.g. `owner = token_program.key()`. If `target_account`/// used, the `target_account` must exist in the struct and the `.key()` is implicit, e.g. `payer = authority`./// - [Normal Constraints](#normal-constraints)/// - [SPL Constraints](#spl-constraints)/// # Normal Constraints/// <table>///     <thead>///         <tr>///             <th>Attribute</th>///             <th>Description</th>///         </tr>///     </thead>///     <tbody>///             <td>///                 <code>#[account(signer)]</code> <br><br><code>#[account(signer @ &lt;custom_error&gt;)]</code>///             </td>///                 Checks the given account signed the transaction.<br>///                 Custom errors are supported via <code>@</code>.<br>///                 Consider using the <code>Signer</code> type if you would only have this constraint on the account.<br><br>///                 Example:///                 <pre><code>/// #[account(signer)]/// pub authority: AccountInfo<'info>,/// #[account(signer @ MyError::MyErrorCode)]/// pub payer: AccountInfo<'info>///                 </code></pre>///                 <code>#[account(mut)]</code> <br><br><code>#[account(mut @ &lt;custom_error&gt;)]</code>///                 Checks the given account is mutable.<br>///                 Makes anchor persist any state changes.<br>///                 Custom errors are supported via <code>@</code>.<br><br>/// #[account(mut)]/// pub data_account: Account<'info, MyData>,/// #[account(mut @ MyError::MyErrorCode)]/// pub data_account_two: Account<'info, MyData>///                 <code>#[account(init, payer = &lt;target_account&gt;, space = &lt;num_bytes&gt;)]</code>///                 Creates the account via a CPI to the system program and///                 initializes it (sets its account discriminator).<br>///                 Marks the account as mutable and is mutually exclusive with <code>mut</code>.<br>///                 Makes the account rent exempt unless skipped with <code>rent_exempt = skip</code>.<br><br>///                 Use <code>#[account(zero)]</code> for accounts larger than 10 Kibibyte.<br><br>///                 <code>init</code> has to be used with additional constraints:///                 <ul>///                     <li>///                         Requires the <code>payer</code> constraint to also be on the account.///                         The <code>payer</code> account pays for the///                         account creation.///                     </li>///                         Requires the system program to exist on the struct///                         and be called <code>system_program</code>.///                         Requires that the <code>space</code> constraint is specified.///                         When using the <code>space</code> constraint, one must remember to add 8 to it///                         which is the size of the account discriminator. This only has to be done///                         for accounts owned by anchor programs.<br>///                         The given space number is the size of the account in bytes, so accounts that hold///                         a variable number of items such as a <code>Vec</code> should allocate sufficient space for all items that may///                         be added to the data structure because account size is fixed.///                         Check out the <a href = "https://www.anchor-lang.com/docs/space" target = "_blank" rel = "noopener noreferrer">space reference</a>///                         and the <a href = "https://borsh.io/" target = "_blank" rel = "noopener noreferrer">borsh library</a>///                         (which anchor uses under the hood for serialization) specification to learn how much///                         space different data structures require.///                 <br>///                 <pre>/// #[account]/// pub struct MyData {/// &nbsp;&nbsp;&nbsp;&nbsp;pub data: u64/// }&#10;/// &nbsp;&nbsp;&nbsp;&nbsp;#[account(init, payer = payer, space = 8 + 8)]/// &nbsp;&nbsp;&nbsp;&nbsp;pub data_account_two: Account<'info, MyData>,/// &nbsp;&nbsp;&nbsp;&nbsp;#[account(mut)]/// &nbsp;&nbsp;&nbsp;&nbsp;pub payer: Signer<'info>,/// &nbsp;&nbsp;&nbsp;&nbsp;pub system_program: Program<'info, System>,///                 </pre>///                 </ul>///                 <code>init</code> can be combined with other constraints (at the same time):///                         By default <code>init</code> sets the owner field of the created account to the///                         currently executing program. Add the <code>owner</code> constraint to specify a///                         different program owner.///                         Use the <code>seeds</code> constraint together with <code>bump</code>to create PDAs.<br>///                         <code>init</code> uses <code>find_program_address</code> to calculate the pda so the///                         bump value can be left empty.<br>///                         However, if you want to use the bump in your instruction,///                         you can pass it in as instruction data and set the bump value like shown in the example,///                         using the <code>instruction_data</code> attribute.///                         Anchor will then check that the bump returned by <code>find_program_address</code> equals///                         the bump in the instruction data.<br>///                         <code>seeds::program</code> cannot be used together with init because the creation of an///                         account requires its signature which for PDAs only the currently executing program can provide./// &nbsp;&nbsp;&nbsp;&nbsp;#[account(/// &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;init, payer = payer, space = 8 + 8/// &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;seeds = [b"example_seed"], bump = bump/// &nbsp;&nbsp;&nbsp;&nbsp;)]/// &nbsp;&nbsp;&nbsp;&nbsp;pub pda_data_account: Account<'info, MyData>,/// &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;init, payer = payer,/// &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;space = 8 + 8, owner = other_program.key()/// &nbsp;&nbsp;&nbsp;&nbsp;pub account_for_other_program: AccountInfo<'info>,/// &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;init, payer = payer, space = 8 + 8,/// &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;owner = other_program.key(),/// &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;seeds = [b"other_seed"], bump/// &nbsp;&nbsp;&nbsp;&nbsp;pub pda_for_other_program: AccountInfo<'info>,/// &nbsp;&nbsp;&nbsp;&nbsp;pub other_program: Program<'info, OtherProgram>///                 <code>#[account(init_if_needed, payer = &lt;target_account&gt;)]</code><br><br>///                 <code>#[account(init_if_needed, payer = &lt;target_account&gt;, space = &lt;num_bytes&gt;)]</code>///                 Exact same functionality as the <code>init</code> constraint but only runs if the account does not exist yet.<br>///                 If the account does exist, it still checks whether the given init constraints are correct,///                 e.g. that the account has the expected amount of space and, if it's a PDA, the correct seeds etc.<br><br>///                 This feature should be used with care and is therefore behind a feature flag.///                 You can enable it by importing <code>anchor-lang</code> with the <code>init-if-needed</code> cargo feature.<br>///                 When using <code>init_if_needed</code>, you need to make sure you properly protect yourself///                 against re-initialization attacks. You need to include checks in your code that check///                 that the initialized account cannot be reset to its initial settings after the first time it was///                 initialized (unless that it what you want).<br>///                 Because of the possibility of re-initialization attacks and the general guideline that instructions///                 should avoid having multiple execution flows (which is important so they remain easy to understand),///                 consider breaking up your instruction into two instructions - one for initializing and one for using///                 the account - unless you have a good reason not to do so.///                 <br><br>/// #[derive(Default)]/// pub struct OtherData {/// &nbsp;&nbsp;&nbsp;&nbsp;#[account(init_if_needed, payer = payer)]/// &nbsp;&nbsp;&nbsp;&nbsp;pub data_account: Account<'info, MyData>,/// &nbsp;&nbsp;&nbsp;&nbsp;#[account(init_if_needed, payer = payer, space = 8 + 8)]/// &nbsp;&nbsp;&nbsp;&nbsp;pub data_account_two: Account<'info, OtherData>,/// &nbsp;&nbsp;&nbsp;&nbsp;pub system_program: Program<'info, System>///                 <code>#[account(seeds = &lt;seeds&gt;, bump)]</code><br><br>///                 <code>#[account(seeds = &lt;seeds&gt;, bump, seeds::program = &lt;expr&gt;)]<br><br>///                 <code>#[account(seeds = &lt;seeds&gt;, bump = &lt;expr&gt;)]</code><br><br>///                 <code>#[account(seeds = &lt;seeds&gt;, bump = &lt;expr&gt;, seeds::program = &lt;expr&gt;)]</code><br><br>///                 Checks that given account is a PDA derived from the currently executing program,///                 the seeds, and if provided, the bump. If not provided, anchor uses the canonical///                 bump. <br>///                 Add <code>seeds::program = &lt;expr&gt;</code> to derive the PDA from a different///                 program than the currently executing one.<br>///                 This constraint behaves slightly differently when used with <code>init</code>.///                 See its description./// #[instruction(first_bump: u8, second_bump: u8)]/// pub struct Example {///     #[account(seeds = [b"example_seed"], bump)]///     pub canonical_pda: AccountInfo<'info>,///     #[account(///         seeds = [b"example_seed"],///         bump,///         seeds::program = other_program.key()///     )]///     pub canonical_pda_two: AccountInfo<'info>,///     #[account(seeds = [b"other_seed"], bump = first_bump)]///     pub arbitrary_pda: AccountInfo<'info>///         seeds = [b"other_seed"],///         bump = second_bump,///     pub arbitrary_pda_two: AccountInfo<'info>,///     pub other_program: Program<'info, OtherProgram>///                 <code>#[account(has_one = &lt;target_account&gt;)]</code><br><br>///                 <code>#[account(has_one = &lt;target_account&gt; @ &lt;custom_error&gt;)]</code>///                 Checks the <code>target_account</code> field on the account matches the///                 key of the <code>target_account</code> field in the Accounts struct.<br>/// #[account(mut, has_one = authority)]/// pub data: Account<'info, MyData>,/// pub authority: Signer<'info>///                 In this example <code>has_one</code> checks that <code>data.authority = authority.key()</code>///                 <code>#[account(address = &lt;expr&gt;)]</code><br><br>///                 <code>#[account(address = &lt;expr&gt; @ &lt;custom_error&gt;)]</code>///                 Checks the account key matches the pubkey.<br>/// #[account(address = crate::ID)]/// #[account(address = crate::ID @ MyError::MyErrorCode)]/// pub data_two: Account<'info, MyData>///                 <code>#[account(owner = &lt;expr&gt;)]</code><br><br>///                 <code>#[account(owner = &lt;expr&gt; @ &lt;custom_error&gt;)]</code>///                 Checks the account owner matches <code>expr</code>.<br>/// #[account(owner = Token::ID @ MyError::MyErrorCode)]/// #[account(owner = token_program.key())]/// pub data_two: Account<'info, MyData>,/// pub token_program: Program<'info, Token>///                 <code>#[account(executable)]</code>///                 Checks the account is executable (i.e. the account is a program).<br>///                 You may want to use the <code>Program</code> type instead.<br><br>/// #[account(executable)]/// pub my_program: AccountInfo<'info>///                 <code>#[account(rent_exempt = skip)]</code><br><br>///                 <code>#[account(rent_exempt = enforce)]</code>///                 Enforces rent exemption with <code>= enforce</code>.<br>///                 Skips rent exemption check that would normally be done///                 through other constraints with <code>= skip</code>,///                 e.g. when used with the <code>zero</code> constraint<br><br>/// #[account(zero, rent_exempt = skip)]/// pub skipped_account: Account<'info, MyData>,/// #[account(rent_exempt = enforce)]/// pub enforced_account: AccountInfo<'info>///                 <code>#[account(zero)]</code>///                 Checks the account discriminator is zero.<br>///                 Enforces rent exemption unless skipped with <code>rent_exempt = skip</code>.<br><br>///                 Use this constraint if you want to create an account in a previous instruction///                 and then initialize it in your instruction instead of using <code>init</code>.///                 This is necessary for accounts that are larger than 10 Kibibyte because those///                 accounts cannot be created via a CPI (which is what <code>init</code> would do).<br><br>///                 Anchor adds internal data to the account when using <code>zero</code> just like it///                 does with <code>init</code> which is why <code>zero</code> implies <code>mut</code>./// #[account(zero)]/// pub my_account: Account<'info, MyData>///                 <code>#[account(close = &lt;target_account&gt;)]</code>///                 Closes the account by:<br>///                 &nbsp;&nbsp;&nbsp;&nbsp;- Sending the lamports to the specified account<br>///                 &nbsp;&nbsp;&nbsp;&nbsp;- Assigning the owner to the System Program<br>///                 &nbsp;&nbsp;&nbsp;&nbsp;- Resetting the data of the account<br><br>///                 Requires <code>mut</code> to exist on the account./// #[account(mut, close = receiver)]/// pub receiver: SystemAccount<'info>///                 <code>#[account(constraint = &lt;expr&gt;)]</code><br><br><code>#[account(constraint = &lt;expr&gt; @ &lt;custom_error&gt;)]</code>///                 Constraint that checks whether the given expression evaluates to true.<br>///                 Use this when no other constraint fits your use case./// #[account(constraint = one.keys[0].age == two.apple.age)]/// pub one: Account<'info, MyData>,/// pub two: Account<'info, OtherData>///                 <code>#[account(realloc = &lt;space&gt;, realloc::payer = &lt;target&gt;, realloc::zero = &lt;bool&gt;)]</code>///                 Used to <a href="https://docs.rs/solana-program/latest/solana_program/account_info/struct.AccountInfo.html#method.realloc" target = "_blank" rel = "noopener noreferrer">realloc</a>///                 program account space at the beginning of an instruction.///                 The account must be marked as <code>mut</code> and applied to either <code>Account</code> or <code>AccountLoader</code> types.///                 If the change in account data length is additive, lamports will be transferred from the <code>realloc::payer</code> into the///                 program account in order to maintain rent exemption. Likewise, if the change is subtractive, lamports will be transferred from///                 the program account back into the <code>realloc::payer</code>.///                 The <code>realloc::zero</code> constraint is required in order to determine whether the new memory should be zero initialized after///                 reallocation. Please read the documentation on the <code>AccountInfo::realloc</code> function linked above to understand the///                 caveats regarding compute units when providing <code>true</code or <code>false</code> to this flag.///                 The manual use of `AccountInfo::realloc` is discouraged in favor of the `realloc` constraint group due to the lack of native runtime checks///                 to prevent reallocation over the `MAX_PERMITTED_DATA_INCREASE` limit (which can unintentionally cause account data overwrite other accounts).///                 The constraint group also ensure account reallocation idempotency but checking and restricting duplicate account reallocation within a single ix.///     #[account(mut)]///     pub payer: Signer<'info>,///         mut,///         seeds = [b"example"],///         realloc = 8 + std::mem::size_of::<MyType>() + 100,///         realloc::payer = payer,///         realloc::zero = false,///     pub acc: Account<'info, MyType>,///     pub system_program: Program<'info, System>,///     </tbody>/// </table>/// # SPL Constraints/// Anchor provides constraints that make verifying SPL accounts easier.///                 <code>#[account(token::mint = &lt;target_account&gt;, token::authority = &lt;target_account&gt;)]</code>///             <br><br>///                 <code>#[account(token::mint = &lt;target_account&gt;, token::authority = &lt;target_account&gt;, token::token_program = &lt;target_account&gt;)]</code>///                 Can be used as a check or with <code>init</code> to create a token///                 account with the given mint address and authority.<br>///                  When used as a check, it's possible to only specify a subset of the constraints./// use anchor_spl::{mint, token::{TokenAccount, Mint, Token}};/// ...&#10;/// #[account(///     init,///     payer = payer,///     token::mint = mint,///     token::authority = payer,/// )]/// pub token: Account<'info, TokenAccount>,/// #[account(address = mint::USDC)]/// pub mint: Account<'info, Mint>,/// pub payer: Signer<'info>,/// pub token_program: Program<'info, Token>,/// pub system_program: Program<'info, System>///                 <code>#[account(mint::authority = &lt;target_account&gt;, mint::decimals = &lt;expr&gt;)]</code>///                 <code>#[account(mint::authority = &lt;target_account&gt;, mint::decimals = &lt;expr&gt;, mint::freeze_authority = &lt;target_account&gt;)]</code>///                 Can be used as a check or with <code>init</code> to create a mint///                 account with the given mint decimals and mint authority.<br>///                 The freeze authority is optional when used with <code>init</code>.<br>///                 When used as a check, it's possible to only specify a subset of the constraints./// use anchor_spl::token::{Mint, Token};///     mint::decimals = 9,///     mint::authority = payer,/// pub mint_one: Account<'info, Mint>,///     mint::freeze_authority = payer/// pub mint_two: Account<'info, Mint>,///                 <code>#[account(associated_token::mint = &lt;target_account&gt;, associated_token::authority = &lt;target_account&gt;)]</code>///                <br><br>///                 <code>#[account(associated_token::mint = &lt;target_account&gt;, associated_token::authority = &lt;target_account&gt;, associated_token::token_program = &lt;target_account&gt;)]</code>///                 Can be used as a standalone as a check or with <code>init</code> to create an associated token///                 account with the given mint address and authority./// use anchor_spl::{///     associated_token::AssociatedToken,///     mint,///     token::{TokenAccount, Mint, Token}///     associated_token::mint = mint,///     associated_token::authority = payer,/// pub second_token: Account<'info, TokenAccount>,/// pub associated_token_program: Program<'info, AssociatedToken>,///         </tr><tr>///                 <code>#[account(*::token_program = &lt;target_account&gt;)]</code>///                 The <code>token_program</code> can optionally be overridden./// use anchor_spl::token_interface::{TokenInterface, TokenAccount, Mint};///     mint::token_program = token_a_token_program,/// pub token_a_mint: InterfaceAccount<'info, Mint>,///     mint::token_program = token_b_token_program,/// pub token_b_mint: InterfaceAccount<'info, Mint>,///     token::mint = token_a_mint,///     token::token_program = token_a_token_program,/// pub token_a_account: InterfaceAccount<'info, TokenAccount>,///     token::mint = token_b_mint,///     token::token_program = token_b_token_program,/// pub token_b_account: InterfaceAccount<'info, TokenAccount>,/// pub token_a_token_program: Interface<'info, TokenInterface>,/// pub token_b_token_program: Interface<'info, TokenInterface>,TokenStream2gen_borsh_serializeanchor_serializegen_borsh_deserializeborsh_deserializequote_spannedparse2AttributeDeriveInputFieldsGenericArgumentLitIntPathArgumentsTypeArrayderive_init_space/// Implements a [`Space`](./trait.Space.html) trait on the given/// struct or enum./// For types that have a variable size like String and Vec, it is necessary to indicate the size by the `max_len` attribute./// For nested types, it is necessary to specify a size for each variable type (see example)./// #[derive(InitSpace)]/// pub struct ExampleAccount {///     #[max_len(50)]///     pub string_one: String,///     #[max_len(10, 5)]///     pub nested: Vec<Vec<u8>>,///    #[account(mut)]///    pub payer: Signer<'info>,///    pub system_program: Program<'info, System>,///    #[account(init, payer = payer, space = 8 + ExampleAccount::INIT_SPACE)]///    pub data: Account<'info, ExampleAccount>,gen_maxlen_from_typeget_first_ty_argparse_len_argget_max_len_argsget_next_argToAccountMetasinstructionAccountMetato_account_metasbpf_writerBpfWriterErrorCodeAccountDeserializeAccountSerializeAccountsAccountsCloseAccountsExitOwnerToAccountInfoToAccountInfosaccount_infoAccountInfosystem_programinfo'infoAccount/// Wrapper around [`AccountInfo`](crate::solana_program::account_info::AccountInfo)/// that verifies program ownership and deserializes underlying data into a Rust type./// - [Basic Functionality](#basic-functionality)/// - [Using Account with non-anchor types](#using-account-with-non-anchor-types)/// - [Out of the box wrapper types](#out-of-the-box-wrapper-types)/// # Basic Functionality/// Account checks that `Account.info.owner == T::owner()`./// This means that the data type that Accounts wraps around (`=T`) needs to/// implement the [Owner trait](crate::Owner)./// The `#[account]` attribute implements the Owner trait for/// a struct using the `crate::ID` declared by [`declare_id`](crate::declare_id)/// in the same program. It follows that Account can also be used/// with a `T` that comes from a different program./// Checks:/// - `Account.info.owner == T::owner()`/// - `!(Account.info.owner == SystemProgram && Account.info.lamports() == 0)`/// use other_program::Auth;/// declare_id!("Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS");/// mod hello_anchor {///     pub fn set_data(ctx: Context<SetData>, data: u64) -> Result<()> {///         if (*ctx.accounts.auth_account).authorized {///             (*ctx.accounts.my_account).data = data;///         Ok(())///     pub data: u64/// pub struct SetData<'info> {///     pub my_account: Account<'info, MyData> // checks that my_account.info.owner == Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS///     pub auth_account: Account<'info, Auth> // checks that auth_account.info.owner == FEZGUxNhZWpYPj9MJCrZJvUo1iF9ys34UHx52y4SzVW9/// // In a different program/// declare_id!("FEZGUxNhZWpYPj9MJCrZJvUo1iF9ys34UHx52y4SzVW9");/// pub struct Auth {///     pub authorized: bool/// # Using Account with non-anchor programs/// Account can also be used with non-anchor programs. The data types from/// those programs are not annotated with `#[account]` so you have to/// - create a wrapper type around the structs you want to wrap with Account/// - implement the functions required by Account yourself/// instead of using `#[account]`. You only have to implement a fraction of the/// functions `#[account]` generates. See the example below for the code you have/// to write./// The mint wrapper type that Anchor provides out of the box for the token program ([source](https://github.com/coral-xyz/anchor/blob/master/spl/src/token.rs))/// #[derive(Clone)]/// pub struct Mint(spl_token::state::Mint);/// // This is necessary so we can use "anchor_spl::token::Mint::LEN"/// // because rust does not resolve "anchor_spl::token::Mint::LEN" to/// // "spl_token::state::Mint::LEN" automatically/// impl Mint {///     pub const LEN: usize = spl_token::state::Mint::LEN;/// // You don't have to implement the "try_deserialize" function/// // from this trait. It delegates to/// // "try_deserialize_unchecked" by default which is what we want here/// // because non-anchor accounts don't have a discriminator to check/// impl anchor_lang::AccountDeserialize for Mint {///     fn try_deserialize_unchecked(buf: &mut &[u8]) -> Result<Self> {///         spl_token::state::Mint::unpack(buf).map(Mint)/// // AccountSerialize defaults to a no-op which is what we want here/// // because it's a foreign program, so our program does not/// // have permission to write to the foreign program's accounts anyway/// impl anchor_lang::AccountSerialize for Mint {}/// impl anchor_lang::Owner for Mint {///     fn owner() -> Pubkey {///         // pub use spl_token::ID is used at the top of the file///         ID/// // Implement the "std::ops::Deref" trait for better user experience/// impl Deref for Mint {///     type Target = spl_token::state::Mint;///     fn deref(&self) -> &Self::Target {///         &self.0/// ## Out of the box wrapper types/// ### Accessing BPFUpgradeableLoader Data/// Anchor provides wrapper types to access data stored in programs owned by the BPFUpgradeableLoader/// such as the upgrade authority. If you're interested in the data of a program account, you can use/// Account<'info, BpfUpgradeableLoaderState>/// and then match on its contents inside your instruction function./// Alternatively, you can use/// Account<'info, ProgramData>/// to let anchor do the matching for you and return the ProgramData variant of BpfUpgradeableLoaderState./// use crate::program::MyProgram;/// declare_id!("Cum9tTyj5HwcEiAmhgaS7Bbj4UczCwsucrCkxRECzM4e");/// pub mod my_program {///     pub fn set_initial_admin(///         ctx: Context<SetInitialAdmin>,///         admin_key: Pubkey///     ) -> Result<()> {///         ctx.accounts.admin_settings.admin_key = admin_key;///     pub fn set_admin(...){...}///     pub fn set_settings(...){...}/// #[derive(Default, Debug)]/// pub struct AdminSettings {///     admin_key: Pubkey/// pub struct SetInitialAdmin<'info> {///     #[account(init, payer = authority, seeds = [b"admin"], bump)]///     pub admin_settings: Account<'info, AdminSettings>,///     pub authority: Signer<'info>,///     #[account(constraint = program.programdata_address()? == Some(program_data.key()))]///     pub program: Program<'info, MyProgram>,///     #[account(constraint = program_data.upgrade_authority_address == Some(authority.key()))]///     pub program_data: Account<'info, ProgramData>,/// This example solves a problem you may face if your program has admin settings: How do you set the/// admin key for restricted functionality after deployment? Setting the admin key itself should/// be a restricted action but how do you restrict it without having set an admin key?/// You're stuck in a loop./// One solution is to use the upgrade authority of the program as the initial/// (or permanent) admin key./// ### SPL Types/// Anchor provides wrapper types to access accounts owned by the token program. Use/// use anchor_spl::token::TokenAccount;///     pub my_acc: Account<'info, TokenAccount>/// to access token accounts and/// use anchor_spl::token::Mint;///     pub my_acc: Account<'info, Mint>/// to access mint accounts.fmt_with_nameexit_with_expected_ownerreload/// Reloads the account from storage. This is useful, for example, when/// observing side effects after CPI.set_inner/// Sets the inner account./// Instead of this:/// pub fn new_user(ctx: Context<CreateUser>, new_user:User) -> Result<()> {///     (*ctx.accounts.user_to_create).name = new_user.name;///     (*ctx.accounts.user_to_create).age = new_user.age;///     (*ctx.accounts.user_to_create).address = new_user.address;/// You can do this:///     ctx.accounts.user_to_create.set_inner(new_user);/// Deserializes the given `info` into a `Account`.try_from_unchecked/// Deserializes the given `info` into a `Account` without checking/// the account discriminator. Be careful when using this and avoid it if/// possible.try_accountsexitcloseto_account_infos//! Account container that checks ownership on deserialization.//! AccountInfo can be used as a type but//! [Unchecked Account](crate::accounts::unchecked_account::UncheckedAccount)//! should be used instead.ZeroCopyarray_refcellRefRefMutPhantomDataacc_infophantomAccountLoader/// Type facilitating on demand zero copy deserialization./// Note that using accounts in this way is distinctly different from using,/// for example, the [`Account`](crate::accounts::account::Account). Namely,/// one must call/// - `load_init` after initializing an account (this will ignore the missing/// account discriminator that gets added only after the user's instruction code)/// - `load` when the account is not mutable/// - `load_mut` when the account is mutable/// For more details on zero-copy-deserialization, see the/// [`account`](crate::account) attribute./// <p style=";padding:0.75em;border: 1px solid #ee6868">/// <strong>⚠️ </strong> When using this type it's important to be mindful/// of any calls to the <code>load</code> functions so as not to/// induce a <code>RefCell</code> panic, especially when sharing accounts across CPI/// boundaries. When in doubt, one should make sure all refs resulting from/// a call to a <code>load</code> function are dropped before CPI./// This can be done explicitly by calling <code>drop(my_var)</code> or implicitly/// by wrapping the code using the <code>Ref</code> in braces <code>{..}</code> or/// moving it into its own function./// </p>/// pub mod bar {///     pub fn create_bar(ctx: Context<CreateBar>, data: u64) -> Result<()> {///         let bar = &mut ctx.accounts.bar.load_init()?;///         bar.authority = ctx.accounts.authority.key();///         bar.data = data;///     pub fn update_bar(ctx: Context<UpdateBar>, data: u64) -> Result<()> {///         (*ctx.accounts.bar.load_mut()?).data = data;/// pub struct Bar {///     authority: Pubkey,///     data: u64/// pub struct CreateBar<'info> {///         init,///         payer = authority///     bar: AccountLoader<'info, Bar>,///     authority: Signer<'info>,///     system_program: AccountInfo<'info>,/// pub struct UpdateBar<'info> {///         has_one = authority,///     pub bar: AccountLoader<'info, Bar>,/// Constructs a new `Loader` from a previously initialized account./// Constructs a new `Loader` from an uninitialized account./// Returns a Ref to the account data structure for reading.load_mut/// Returns a `RefMut` to the account data structure for reading or writing.load_init/// Should only be called once, when the account is being initialized.// The account *cannot* be loaded when this is called.//! Type facilitating on demand zero copy deserialization.//! Box<T> type to save stack space.//! Sometimes accounts are too large for the stack,//! leading to stack violations.//! Boxing the account can help.//! #[derive(Accounts)]//! pub struct Example {//!     pub my_acc: Box<Account<'info, MyData>>//! }ProgramCheckIdInterface/// Type validating that the account is one of a set of given Programs/// The `Interface` wraps over the [`Program`](crate::Program), allowing for/// multiple possible program ids. Useful for any program that implements an/// instruction interface. For example, spl-token and spl-token-2022 both implement/// the spl-token interface./// - [Out of the Box Types](#out-of-the-box-types)/// - `expected_programs.contains(account_info.key)`/// - `account_info.executable == true`/// mod my_program {///     fn set_admin_settings(...){...}/// pub struct SetAdminSettings<'info> {///     #[account(mut, seeds = [b"admin"], bump)]///     pub program: Interface<'info, MyProgram>,/// The given program has a function with which the upgrade authority can set admin settings./// The required constraints are as follows:/// - `program` is the account of the program itself./// Its constraint checks that `program_data` is the account that contains the program's upgrade authority./// Implicitly, this checks that `program` is a BPFUpgradeable program (`program.programdata_address()?`/// will be `None` if it's not)./// - `program_data`'s constraint checks that its upgrade authority is the `authority` account./// - Finally, `authority` needs to sign the transaction./// # Out of the Box Types/// Between the [`anchor_lang`](https://docs.rs/anchor-lang/latest/anchor_lang) and [`anchor_spl`](https://docs.rs/anchor_spl/latest/anchor_spl) crates,/// the following `Interface` types are provided out of the box:/// - [`TokenInterface`](https://docs.rs/anchor-spl/latest/anchor_spl/token_interface/struct.TokenInterface.html)programdata_address/// Deserializes the given `info` into a `Program`.//! Type validating that the account is one of a set of given ProgramsCheckOwnerOwnersowner// The owner here is used to make sure that changes aren't incorrectly propagated// to an account with a modified ownerInterfaceAccount/// - [Using InterfaceAccount with non-anchor types](#using-interface-account-with-non-anchor-types)/// InterfaceAccount checks that `T::owners().contains(Account.info.owner)`./// implement the [Owners trait](crate::Owners)./// The `#[account]` attribute implements the Owners trait for/// a struct using multiple `crate::ID`s declared by [`declareId`](crate::declare_id)/// in the same program. It follows that InterfaceAccount can also be used/// - `T::owners().contains(InterfaceAccount.info.owner)`/// - `!(InterfaceAccount.info.owner == SystemProgram && InterfaceAccount.info.lamports() == 0)`///     pub my_account: InterfaceAccount<'info, MyData> // checks that my_account.info.owner == Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS///     pub auth_account: InterfaceAccount<'info, Auth> // checks that auth_account.info.owner == FEZGUxNhZWpYPj9MJCrZJvUo1iF9ys34UHx52y4SzVW9/// # Using InterfaceAccount with non-anchor programs/// InterfaceAccount can also be used with non-anchor programs. The data types from/// - create a wrapper type around the structs you want to wrap with InterfaceAccount/// - implement the functions required by InterfaceAccount yourself/// Anchor provides wrapper types to access accounts owned by the token programs. Use/// use anchor_spl::token_interface::TokenAccount;///     pub my_acc: InterfaceAccount<'info, TokenAccount>/// use anchor_spl::token_interface::Mint;///     pub my_acc: InterfaceAccount<'info, Mint>/// Deserializes the given `info` into a `InterfaceAccount`./// Deserializes the given `info` into a `InterfaceAccount` without checkingaccount_loaderinterfaceinterface_accountsignersystem_accountsysvarunchecked_account//! Account types that can be used in the account validation struct.//! Option<T> type for optional accounts.//!     pub my_acc: Option<Account<'info, MyData>>bpf_loader_upgradeableUpgradeableLoaderState_phantom/// Type validating that the account is the given Program/// The type has a `programdata_address` function that will return `Option::Some`/// if the program is owned by the [`BPFUpgradeableLoader`](https://docs.rs/solana-program/latest/solana_program/bpf_loader_upgradeable/index.html)/// which will contain the `programdata_address` property of the `Program` variant of the [`UpgradeableLoaderState`](https://docs.rs/solana-program/latest/solana_program/bpf_loader_upgradeable/enum.UpgradeableLoaderState.html) enum./// - `account_info.key == expected_program`/// the following `Program` types are provided out of the box:/// - [`System`](https://docs.rs/anchor-lang/latest/anchor_lang/struct.System.html)/// - [`AssociatedToken`](https://docs.rs/anchor-spl/latest/anchor_spl/associated_token/struct.AssociatedToken.html)/// - [`Token`](https://docs.rs/anchor-spl/latest/anchor_spl/token/struct.Token.html)//! Type validating that the account is the given ProgramSigner/// Type validating that the account signed the transaction. No other ownership/// or type checks are done. If this is used, one should not try to access the/// underlying account data./// - `Signer.info.is_signer == true`/// pub struct Example<'info> {///     #[account(init, payer = payer)]///     pub my_acc: Account<'info, MyData>,///     pub system_program: Program<'info, System>/// When creating an account with `init`, the `payer` needs to sign the transaction./// Deserializes the given `info` into a `Signer`.//! Type validating that the account signed the transactionSystemAccount/// Type validating that the account is owned by the system program/// - `SystemAccount.info.owner == SystemProgram`//! Type validating that the account is owned by the system programSysvar/// Type validating that the account is a sysvar and deserializing it./// If possible, sysvars should not be used via accounts/// but by using the [`get`](https://docs.rs/solana-program/latest/solana_program/sysvar/trait.Sysvar.html#method.get)/// function on the desired sysvar. This is because using `get`/// does not run the risk of Anchor having a bug in its `Sysvar` type/// and using `get` also decreases tx size, making space for other/// accounts that cannot be requested via syscall./// // OK - via account in the account validation struct///     pub clock: Sysvar<'info, Clock>/// // BETTER - via syscall in the instruction function/// fn better(ctx: Context<Better>) -> Result<()> {///     let clock = Clock::get()?;from_account_info//! Type validating that the account is a sysvar and deserializing itUncheckedAccount/// Explicit wrapper for AccountInfo types to emphasize/// that no checks are performed//! Explicit wrapper for AccountInfo types to emphasize//! that no checks are performedprogram_errorProgramErrorslotupgrade_authority_addressProgramDatatry_deserializetry_deserialize_uncheckedtry_serializeprogram_memorysol_memcpyinnerposwrite_allflushpreludeSystemis_closedBumpsprogram_id/// Currently executing program id./// Deserialized accounts.remaining_accounts'c/// Remaining accounts given but not deserialized or validated./// Be very careful when using this directly.bumps/// Bump seeds found during constraint validation. This is provided as a/// convenience so that handlers don't have to recalculate bump seeds or/// pass them in as arguments./// Type is the bumps struct generated by #[derive(Accounts)]Context/// Provides non-argument inputs to the program./// pub fn set_data(ctx: Context<SetData>, age: u64, other_data: u32) -> Result<()> {///     // Set account data like this///     (*ctx.accounts.my_account).age = age;///     (*ctx.accounts.my_account).other_data = other_data;///     // or like this///     let my_account = &mut ctx.account.my_account;///     my_account.age = age;///     my_account.other_data = other_data;signer_seedsCpiContext/// Context specifying non-argument inputs for cross-program-invocations./// # Example with and without PDA signature/// // Callee Program/// pub mod callee {///     pub fn init(ctx: Context<Init>) -> Result<()> {///         (*ctx.accounts.data).authority = ctx.accounts.authority.key();///         (*ctx.accounts.data_acc).data = data;/// pub struct Data {///     data: u64,/// pub struct Init<'info> {///     pub data: Account<'info, Data>,///     pub authority: UncheckedAccount<'info>,///     #[account(mut, has_one = authority)]///     pub data_acc: Account<'info, Data>,/// // Caller Program/// use callee::{self, program::Callee};/// declare_id!("Sxg7dBh5VLT8S1o6BqncZCPq9nhHHukjfVd6ohQJeAk");/// pub mod caller {///     pub fn do_cpi(ctx: Context<DoCpi>, data: u64) -> Result<()> {///         let callee_id = ctx.accounts.callee.to_account_info();///         let callee_accounts = callee::cpi::accounts::SetData {///             data_acc: ctx.accounts.data_acc.to_account_info(),///             authority: ctx.accounts.callee_authority.to_account_info(),///         };///         let cpi_ctx = CpiContext::new(callee_id, callee_accounts);///         callee::cpi::set_data(cpi_ctx, data)///     pub fn do_cpi_with_pda_authority(ctx: Context<DoCpiWithPDAAuthority>, bump: u8, data: u64) -> Result<()> {///         let seeds = &[&[b"example_seed", bytemuck::bytes_of(&bump)][..]];///         let cpi_ctx = CpiContext::new_with_signer(callee_id, callee_accounts, seeds);/// // We can use "UncheckedAccount"s here because/// // the callee program does the checks./// // We use "mut" so the autogenerated clients know/// // that this account should be mutable./// pub struct DoCpi<'info> {///     pub data_acc: UncheckedAccount<'info>,///     pub callee_authority: UncheckedAccount<'info>,///     pub callee: Program<'info, Callee>,/// pub struct DoCpiWithPDAAuthority<'info> {must_usenew_with_signerwith_signerwith_remaining_accounts//! Data structures that are used to provide non-argument inputs to program endpointsmaybestdBorshIoErrorTryFromIntErrorERROR_CODE_OFFSET/// The starting point for user defined error codes." Error codes that can be returned by internal framework code."""" - &gt;= 100 Instruction error codes"" - &gt;= 1000 IDL error codes"" - &gt;= 2000 constraint error codes"" - &gt;= 3000 account error codes"" - &gt;= 4100 misc error codes"" - = 5000 deprecated error code"" The starting point for user-defined errors is defined"" by the [ERROR_CODE_OFFSET](crate::error::ERROR_CODE_OFFSET)."" 100 - 8 byte instruction identifier not provided"100InstructionMissing" 101 - Fallback functions are not supported"InstructionFallbackNotFound" 102 - The program could not deserialize the given instruction"InstructionDidNotDeserialize" 103 - The program could not serialize the given instruction"InstructionDidNotSerialize" 1000 - The program was compiled without idl instructions"1000IdlInstructionStub" 1001 - Invalid program given to the IDL instruction"IdlInstructionInvalidProgram" 1002 - IDL Account must be empty in order to resize"IdlAccountNotEmpty" 1500 - The program was compiled without `event-cpi` feature"1500EventInstructionStub" 2000 - A mut constraint was violated"2000ConstraintMut" 2001 - A has one constraint was violated"ConstraintHasOne" 2002 - A signer constraint was violated"ConstraintSigner" 2003 - A raw constraint was violated"ConstraintRaw" 2004 - An owner constraint was violated"ConstraintOwner" 2005 - A rent exemption constraint was violated"ConstraintRentExempt" 2006 - A seeds constraint was violated"ConstraintSeeds" 2007 - An executable constraint was violated"ConstraintExecutable" 2008 - Deprecated Error, feel free to replace with something else"ConstraintState" 2009 - An associated constraint was violated"ConstraintAssociated" 2010 - An associated init constraint was violated"ConstraintAssociatedInit" 2011 - A close constraint was violated"ConstraintClose" 2012 - An address constraint was violated"ConstraintAddress" 2013 - Expected zero account discriminant"ConstraintZero" 2014 - A token mint constraint was violated"ConstraintTokenMint" 2015 - A token owner constraint was violated"ConstraintTokenOwner" The mint mint is intentional -> a mint authority for the mint."" 2016 - A mint mint authority constraint was violated"ConstraintMintMintAuthority" 2017 - A mint freeze authority constraint was violated"ConstraintMintFreezeAuthority" 2018 - A mint decimals constraint was violated"ConstraintMintDecimals" 2019 - A space constraint was violated"ConstraintSpace" 2020 - A required account for the constraint is None"ConstraintAccountIsNone" The token token is intentional -> a token program for the token account."" 2021 - A token account token program constraint was violated"ConstraintTokenTokenProgram" 2022 - A mint token program constraint was violated"ConstraintMintTokenProgram" 2023 - A mint token program constraint was violated"ConstraintAssociatedTokenTokenProgram" Extension constraints"" 2024 - A group pointer extension constraint was violated"ConstraintMintGroupPointerExtension" 2025 - A group pointer extension authority constraint was violated"ConstraintMintGroupPointerExtensionAuthority" 2026 - A group pointer extension group address constraint was violated"ConstraintMintGroupPointerExtensionGroupAddress" 2027 - A group member pointer extension constraint was violated"ConstraintMintGroupMemberPointerExtension" 2028 - A group member pointer extension authority constraint was violated"ConstraintMintGroupMemberPointerExtensionAuthority" 2029 - A group member pointer extension member address constraint was violated"ConstraintMintGroupMemberPointerExtensionMemberAddress" 2030 - A metadata pointer extension constraint was violated"ConstraintMintMetadataPointerExtension" 2031 - A metadata pointer extension authority constraint was violated"ConstraintMintMetadataPointerExtensionAuthority" 2032 - A metadata pointer extension metadata address constraint was violated"ConstraintMintMetadataPointerExtensionMetadataAddress" 2033 - A close authority extension constraint was violated"ConstraintMintCloseAuthorityExtension" 2034 - A close authority extension authority constraint was violated"ConstraintMintCloseAuthorityExtensionAuthority" 2035 - A permanent delegate extension constraint was violated"ConstraintMintPermanentDelegateExtension" 2036 - A permanent delegate extension authority constraint was violated"ConstraintMintPermanentDelegateExtensionDelegate" 2037 - A transfer hook extension constraint was violated"ConstraintMintTransferHookExtension" 2038 - A transfer hook extension authority constraint was violated"ConstraintMintTransferHookExtensionAuthority" 2039 - A transfer hook extension transfer hook program id constraint was violated"ConstraintMintTransferHookExtensionProgramId" 2500 - A require expression was violated"2500RequireViolated" 2501 - A require_eq expression was violated"RequireEqViolated" 2502 - A require_keys_eq expression was violated"RequireKeysEqViolated" 2503 - A require_neq expression was violated"RequireNeqViolated" 2504 - A require_keys_neq expression was violated"RequireKeysNeqViolated" 2505 - A require_gt expression was violated"RequireGtViolated" 2506 - A require_gte expression was violated"RequireGteViolated" 3000 - The account discriminator was already set on this account"3000AccountDiscriminatorAlreadySet" 3001 - No 8 byte discriminator was found on the account"AccountDiscriminatorNotFound" 3002 - 8 byte discriminator did not match what was expected"AccountDiscriminatorMismatch" 3003 - Failed to deserialize the account"AccountDidNotDeserialize" 3004 - Failed to serialize the account"AccountDidNotSerialize" 3005 - Not enough account keys given to the instruction"AccountNotEnoughKeys" 3006 - The given account is not mutable"AccountNotMutable" 3007 - The given account is owned by a different program than expected"AccountOwnedByWrongProgram" 3008 - Program ID was not as expected"InvalidProgramId" 3009 - Program account is not executable"InvalidProgramExecutable" 3010 - The given account did not sign"AccountNotSigner" 3011 - The given account is not owned by the system program"AccountNotSystemOwned" 3012 - The program expected this account to be already initialized"AccountNotInitialized" 3013 - The given account is not a program data account"AccountNotProgramData" 3014 - The given account is not the associated token account"AccountNotAssociatedTokenAccount" 3015 - The given public key does not match the required sysvar"AccountSysvarMismatch" 3016 - The account reallocation exceeds the MAX_PERMITTED_DATA_INCREASE limit"AccountReallocExceedsLimit" 3017 - The account was duplicated for more than one reallocation"AccountDuplicateReallocs" 4100 - The declared program id does not match actual program id"4100DeclaredProgramIdMismatch" 4101 - You cannot/should not initialize the payer account as a program account"4101TryingToInitPayerAsProgramAccount" 4102 - Invalid numeric conversion error"4102InvalidNumericConversion" 5000 - The API being used is deprecated and should no longer be used"5000Deprecatedr" Gets the name of this [#enum_name]."AnchorErrorProgramErrorWithOriginwith_account_namewith_sourceSourcewith_pubkeyswith_valueserror_originErrorOrigincompared_valuesComparedValues// Two ProgramErrors are equal when they have the same error codeValuesAccountNameerror_nameerror_code_numbererror_msg/// Two `AnchorError`s are equal when they have the same error codefilenamelineEVENT_IX_TAG// Sha256(anchor:event)[..8]EVENT_IX_TAG_LEIDL_IX_TAG// The first 8 bytes of an instruction to create or modify the IDL account. This// instruction is defined outside the main program's instruction enum, so that// the enum variant tags can align with function source order.// Sha256(anchor:idl)[..8];IDL_IX_TAG_LEERASED_AUTHORITY// The Pubkey that is stored as the 'authority' on the IdlAccount when the authority// is "erased".IdlInstructiondata_lenCreate// One time initializer for creating the program's idl account.CreateBuffer// Creates a new IDL account buffer. Can be called several times.data// Appends the given data to the end of the idl account buffer.SetBuffer// Sets a new data buffer for the IdlAccount.new_authoritySetAuthority// Sets a new authority on the IdlAccount.CloseResize// Increases account size for accounts that need over 10kb.BorshSerializedeserialize_readerBorshDeserializedeserialize_variantEnumExtauthorityIdlAccountautomatically_derivedDISCRIMINATORDiscriminatoraddressseed//! Defines the instructions and account state used to store a program's//! IDL on-chain at a canonical account address, which can be derived as a//! function of nothing other than the program's ID.//! It can be upgraded in a way similar to a BPF upgradeable program. That is,//! one may invoke the `IdlInstruction::CreateBuffer` instruction to create//! a buffer, `IdlInstruction::Write` to write a new IDL into it, and then//! `IdlInstruction::SetBuffer` to copy the IDL into the program's canonical//! IDL account. In order to perform this upgrade, the buffer's `authority`//! must match the canonical IDL account's authority.//! Because the IDL can be larger than the max transaction size, the transaction//! must be broken up into several pieces and stored into the IDL account with//! multiple transactions via the `Write` instruction to continuously append to//! the account's IDL data buffer.//! Note that IDL account instructions are automatically inserted into all//! Anchor programs. To remove them, one can use the `no-idl` feature.PodZeroableaccount_metabpf_upgradeable_statecontextAnchorDeserializeAnchorSerializeInitSpace/// Borsh is the default serialization format for instructions and accounts./// Returns the validated accounts struct. What constitutes "valid" is/// program dependent. However, users of these types should never have to/// worry about account substitution attacks. For example, if a program/// expects a `Mint` account from the SPL token program  in a particular/// field, then it should be impossible for this method to return `Ok` if/// any other account type is given--from the SPL token program or elsewhere./// `program_id` is the currently executing program. `accounts` is the/// set of accounts to construct the type from. For every account used,/// the implementation should mutate the slice, consuming the used entry/// so that it cannot be used again./// A data structure of validated accounts that can be deserialized from the/// input to a Solana program. Implementations of this trait should perform any/// and all requisite constraint checks on accounts to ensure the accounts/// maintain any invariants required for the program to run securely. In most/// cases, it's recommended to use the [`Accounts`](./derive.Accounts.html)/// derive macro to implement this trait./// Generics:/// -   `B`: the type of the PDA bumps cache struct generated by the `Accounts` struct.///     For example,///         seeds = [...],///     pub pda_1: UncheckedAccount<'info>,///     pub not_pda: UncheckedAccount<'info>,///    generates:/// pub struct ExampleBumps {///     pub pda_1: u8,/// Struct to hold account bump seeds./// Associated bump seeds for `Accounts`./// `program_id` is the currently executing program./// The exit procedure for an account. Any cleanup or persistence to storage/// should be done here./// The close procedure to initiate garabage collection of an account, allowing/// one to retrieve the rent exemption./// `is_signer` is given as an optional override for the signer meta field./// This covers the edge case when a program-derived-address needs to relay/// a transaction from a client to another program but sign the transaction/// before the relay. The client cannot mark the field as a signer, and so/// we have to override the is_signer meta field given by the client./// Transformation to/// [`AccountMeta`](../solana_program/instruction/struct.AccountMeta.html)/// structs./// [`AccountInfo`](../solana_program/account_info/struct.AccountInfo.html)to_account_info/// Transformation to an `AccountInfo` struct.get_lamports/// Get the lamports of the account.add_lamports/// Add lamports to the account./// This method is useful for transferring lamports from a PDA./// # Requirements/// 1. The account must be marked `mut`./// 2. The total lamports **before** the transaction must equal to total lamports **after**/// the transaction./// 3. `lamports` field of the account info should not currently be borrowed./// See [`Lamports::sub_lamports`] for subtracting lamports.sub_lamports/// Subtract lamports from the account./// 1. The account must be owned by the executing program./// 2. The account must be marked `mut`./// 3. The total lamports **before** the transaction must equal to total lamports **after**/// 4. `lamports` field of the account info should not currently be borrowed./// See [`Lamports::add_lamports`] for adding lamports.Lamports/// Lamports related utility methods for accounts./// Serializes the account data into `writer`./// A data structure that can be serialized and stored into account storage,/// i.e. an/// [`AccountInfo`](../solana_program/account_info/struct.AccountInfo.html#structfield.data)'s/// mutable data slice./// Implementors of this trait should ensure that any subsequent usage of the/// `AccountDeserialize` trait succeeds if and only if the account is of the/// correct type./// In most cases, one can use the default implementation provided by the/// [`#[account]`](./attr.account.html) attribute./// Deserializes previously initialized account data. Should fail for all/// uninitialized accounts, where the bytes are zeroed. Implementations/// should be unique to a particular account type so that one can never/// successfully deserialize the data of one account type into another./// For example, if the SPL token program were to implement this trait,/// it should be impossible to deserialize a `Mint` account into a token/// `Account`./// Deserializes account data without checking the account discriminator./// This should only be used on account initialization, when the bytes of/// the account are zeroed./// A data structure that can be deserialized and stored into account storage,/// An account data structure capable of zero copy deserialization.write_to/// Clears `data` and writes instruction data to it./// We use a `Vec<u8>`` here because of the additional flexibility of re-allocation (only if/// necessary), and because the data field in `Instruction` expects a `Vec<u8>`.InstructionData/// Calculates the data for an instruction invocation, where the data is/// `Sha256(<namespace>:<method_name>)[..8] || BorshSerialize(args)`./// `args` is a borsh serialized struct of named fields for each argument given/// to an instruction.Event/// An event that can be emitted via a Solana log. See [`emit!`](crate::prelude::emit) for an example.deprecatedEventData// The serialized event data to be emitted via a Solana log.// TODO: remove this on the next major version upgrade.discriminator/// 8 byte unique identifier for a type.INIT_SPACESpace/// Defines the space of an account for initialization.Bump/// Bump seed for program derived addresses./// Defines an address expected to own an account.owners/// Defines a list of addresses expected to own an account.check_owner/// Defines a trait for checking the owner of a program./// Defines the id of a program.Ids/// Defines the possible ids of a program.check_id/// Defines a trait for checking the id of a program./// Defines the Pubkey of an account.errrequirerequire_eqrequire_gtrequire_gterequire_keys_eqrequire_keys_neqrequire_neqsourcenext_account_infoclockClockepoch_scheduleEpochScheduleinstructionsInstructionsrentRentrewardsRewardsslot_hashesSlotHashesslot_historySlotHistorystake_historyStakeHistorySolanaSysvar/// The prelude contains all commonly used components of the crate./// All programs should include it via `anchor_lang::prelude::*;`.ZeroCopyAccessorEventIndex// Used to calculate the maximum between two expressions.// It is necessary for the calculation of the enum space.Ty// Very experimental trait.__private/// Internal module used by macros and unstable apis./// Ensures a condition is true, otherwise returns with the given error./// Use this with or without a custom error type./// // Instruction function/// pub fn set_data(ctx: Context<SetData>, data: u64) -> Result<()> {///     require!(ctx.accounts.data.mutation_allowed, MyError::MutationForbidden);///     ctx.accounts.data.data = data;/// // An enum for custom error codes///     MutationForbidden/// // An account definition///     mutation_allowed: bool,/// // An account validation struct///     pub data: Account<'info, MyData>/// Ensures two NON-PUBKEY values are equal./// Use [require_keys_eq](crate::prelude::require_keys_eq)/// to compare two pubkeys./// Can be used with or without a custom error code.///     require_eq!(ctx.accounts.data.data, 0);/// Ensures two NON-PUBKEY values are not equal./// Use [require_keys_neq](crate::prelude::require_keys_neq)///     require_neq!(ctx.accounts.data.data, 0);///     Ok(());/// Ensures two pubkeys values are equal./// Use [require_eq](crate::prelude::require_eq)/// to compare two non-pubkey values.///     require_keys_eq!(ctx.accounts.data.authority.key(), ctx.accounts.authority.key());/// Ensures two pubkeys are not equal./// Use [require_neq](crate::prelude::require_neq)///     require_keys_neq!(ctx.accounts.data.authority.key(), ctx.accounts.other.key());/// Ensures the first NON-PUBKEY value is greater than the second/// NON-PUBKEY value./// To include an equality check, use [require_gte](crate::require_gte).///     require_gt!(ctx.accounts.data.data, 0);/// Ensures the first NON-PUBKEY value is greater than or equal/// to the second NON-PUBKEY value.///     require_gte!(ctx.accounts.data.data, 1);/// Returns with the given error./// Use this with a custom error type./// pub fn example(ctx: Context<Example>) -> Result<()> {///     err!(MyError::SomeError)///     SomeError/// Creates a [`Source`](crate::error::Source)//! Anchor ⚓ is a framework for Solana's Sealevel runtime providing several//! convenient developer tools.//! - Rust eDSL for writing safe, secure, and high level Solana programs//! - [IDL](https://en.wikipedia.org/wiki/Interface_description_language) specification//! - TypeScript package for generating clients from IDL//! - CLI and workspace management for developing complete applications//! If you're familiar with developing in Ethereum's//! [Solidity](https://docs.soliditylang.org/en/v0.7.4/),//! [Truffle](https://www.trufflesuite.com/),//! [web3.js](https://github.com/ethereum/web3.js) or Parity's//! [Ink!](https://github.com/paritytech/ink), then the experience will be//! familiar. Although the syntax and semantics are targeted at Solana, the high//! level workflow of writing RPC request handlers, emitting an IDL, and//! generating clients from IDL is the same.//! For detailed tutorials and examples on how to use Anchor, see the guided//! [tutorials](https://anchor-lang.com) or examples in the GitHub//! [repository](https://github.com/coral-xyz/anchor).//! Presented here are the Rust primitives for building on Solana.IDadvance_nonce_accountAdvanceNonceAccountauthorizedrecent_blockhashesAdvanceNonceAccountBumpsr" An internal, Anchor generated module. This is used (as an"r" implementation detail), to generate a struct for a given"r" `#[derive(Accounts)]` implementation, where each field is a Pubkey,"r" instead of an `AccountInfo`. This is useful for clients that want"r" to generate a list of accounts, without explicitly knowing the"r" order all the fields should be in."r" To access the struct in this module, one should use the sibling"r" `accounts` module (also generated), which re-exports this."" Generated client accounts for [`AdvanceNonceAccount`]."__client_accounts_advance_nonce_accountr" implementation detail), to generate a CPI struct for a given"r" `#[derive(Accounts)]` implementation, where each field is an"r" AccountInfo."r" [`cpi::accounts`] module (also generated), which re-exports this."" Generated CPI struct of the accounts for [`AdvanceNonceAccount`]."__cpi_client_accounts_advance_nonce_accountallocateAllocateaccount_to_allocateAllocateBumps" Generated client accounts for [`Allocate`]."__client_accounts_allocate" Generated CPI struct of the accounts for [`Allocate`]."__cpi_client_accounts_allocateallocate_with_seedAllocateWithSeedbaseAllocateWithSeedBumps" Generated client accounts for [`AllocateWithSeed`]."__client_accounts_allocate_with_seed" Generated CPI struct of the accounts for [`AllocateWithSeed`]."__cpi_client_accounts_allocate_with_seedassignAssignaccount_to_assignAssignBumps" Generated client accounts for [`Assign`]."__client_accounts_assign" Generated CPI struct of the accounts for [`Assign`]."__cpi_client_accounts_assignassign_with_seedAssignWithSeedAssignWithSeedBumps" Generated client accounts for [`AssignWithSeed`]."__client_accounts_assign_with_seed" Generated CPI struct of the accounts for [`AssignWithSeed`]."__cpi_client_accounts_assign_with_seedauthorize_nonce_accountAuthorizeNonceAccountAuthorizeNonceAccountBumps" Generated client accounts for [`AuthorizeNonceAccount`]."__client_accounts_authorize_nonce_account" Generated CPI struct of the accounts for [`AuthorizeNonceAccount`]."__cpi_client_accounts_authorize_nonce_accountcreate_accountCreateAccounttoCreateAccountBumps" Generated client accounts for [`CreateAccount`]."__client_accounts_create_account" Generated CPI struct of the accounts for [`CreateAccount`]."__cpi_client_accounts_create_accountcreate_account_with_seedCreateAccountWithSeedCreateAccountWithSeedBumps" Generated client accounts for [`CreateAccountWithSeed`]."__client_accounts_create_account_with_seed" Generated CPI struct of the accounts for [`CreateAccountWithSeed`]."__cpi_client_accounts_create_account_with_seedcreate_nonce_accountCreateNonceAccountCreateNonceAccountBumps" Generated client accounts for [`CreateNonceAccount`]."__client_accounts_create_nonce_account" Generated CPI struct of the accounts for [`CreateNonceAccount`]."__cpi_client_accounts_create_nonce_accountcreate_nonce_account_with_seedCreateNonceAccountWithSeedCreateNonceAccountWithSeedBumps" Generated client accounts for [`CreateNonceAccountWithSeed`]."__client_accounts_create_nonce_account_with_seed" Generated CPI struct of the accounts for [`CreateNonceAccountWithSeed`]."__cpi_client_accounts_create_nonce_account_with_seedtransferTransferTransferBumps" Generated client accounts for [`Transfer`]."__client_accounts_transfer" Generated CPI struct of the accounts for [`Transfer`]."__cpi_client_accounts_transfertransfer_with_seedTransferWithSeedTransferWithSeedBumps" Generated client accounts for [`TransferWithSeed`]."__client_accounts_transfer_with_seed" Generated CPI struct of the accounts for [`TransferWithSeed`]."__cpi_client_accounts_transfer_with_seedwithdraw_nonce_accountWithdrawNonceAccountWithdrawNonceAccountBumps" Generated client accounts for [`WithdrawNonceAccount`]."__client_accounts_withdraw_nonce_account" Generated CPI struct of the accounts for [`WithdrawNonceAccount`]."__cpi_client_accounts_withdraw_nonce_accountEpochTestTestBumps" Generated client accounts for [`Test`]."__client_accounts_test" Generated CPI struct of the accounts for [`Test`]."__cpi_client_accounts_testtest_accounts_trait_for_vectest_accounts_trait_for_vec_emptypathPathBufprocessCommandStdioRegexIdlEventcreate_type/// Create an IDL type definition for the type./// The type is only included in the IDL if this method returns `Some`.insert_types/// Insert all types that are included in the current type definition to the given map.get_full_path/// Get the full module path of the type./// The full path will be used in the case of a conflicting type definition, e.g. when there/// are multiple structs with the same name./// The default implementation covers most cases.IdlBuild/// A trait that types must implement in order to include the type in the IDL definition./// This trait is automatically implemented for Anchor all types that use the `AnchorSerialize`/// proc macro. Note that manually implementing the `AnchorSerialize` trait does **NOT** have the/// same effect./// Types that don't implement this trait will cause a compile error during the IDL generation./// The default implementation of the trait allows the program to compile but the type does **NOT**/// get included in the IDL.program_pathresolutionskip_lintno_docscargo_argsIdlBuilder/// IDL builder using builder pattern./// let idl = IdlBuilder::new().program_path(path).skip_lint(true).build()?;/// Create a new [`IdlBuilder`] instance./// Set the program path (default: current directory)/// Set whether to include account resolution information in the IDL (default: true)./// Set whether to skip linting (default: false)./// Set whether to skip generating docs in the IDL (default: false)./// Set the `cargo` args that will get passed to the underlying `cargo` command when building/// IDLs (default: empty)./// Build the IDL with the current configuration.build_idl/// Generate IDL via compilation./// Build IDL.install_toolchain_if_needed/// Install the given toolchain if it's not already installed.convert_module_paths/// Convert paths to name if there are no conflicts.sort/// Alphabetically sort fields for consistency./// Verify IDL is valid./// Create an [`Idl`] value with additional support for older specs based on the/// `idl.metadata.spec` field./// If `spec` field is not specified, the conversion will fallback to the legacy IDL spec/// (pre Anchor v0.30)./// **Note:** For legacy IDLs, `idl.metadata.address` field is required to be populated with/// program's address otherwise an error will be returned.SnakeCaseversiondocsIdlConstIdlTypeDefinitionIdlErrorCodemetadataValuetyvaluestrctmethodsIdlStateIdlAccountItemargsreturnsIdlAccountsis_mutis_signeris_optionalpdaIdlPdarelationsseedsIdlSeedIdlSeedConstConstIdlSeedArgArgIdlSeedAccount// account_ty points to the entry in the "accounts" section.// Some only if the `Account<T>` type is used.fieldsIdlEventField/// - `idl-parse`: always the name of the type/// - `idl-build`: full path if there is a name conflict, otherwise the name of the type/// Documentation commentsgenerics/// Generics, only supported with `idl-build`IdlTypeDefinitionTy/// Type definition, `struct` or `enum`StructvariantsIdlEnumVariantEnumAliasEnumFieldsNamedTupleBoolI16F32F64U128I128U256I256BytesPublicKeyDefinedArrayGenericLenArrayGenericIdlDefinedTypeArgDefinedWithTypeArgscodeget_disclegacy/// Legacy IDL spec (pre Anchor v0.30)//! Anchor IDL.FromStrIDL_SPEC/// IDL specification Semantic VersionIdlMetadataspecdescriptionrepositorydependenciesIdlDependencycontactdeploymentsIdlDeploymentsmainnettestnetdevnetlocalnetIdlDiscriminatorIdlInstructionAccountsCompositeIdlInstructionAccountSinglewritableoptionalserializationBorshBytemuckBytemuckUnsafeCustomIdlReprModifierRustCTransparentalignaliasErrfrom_str// TODO: Move to utils crateis_default/// Get whether the given data is the default of its type.arrayarray_with_underscored_lengthmultidimensional_arraydefineddefined_with_genericsget_associated_token_addressget_associated_token_address_with_program_idcreatecreate_idempotentCreateIdempotentpayerassociated_tokenminttoken_programCreateBumps" Generated client accounts for [`Create`]."__client_accounts_create" Generated CPI struct of the accounts for [`Create`]."__cpi_client_accounts_createAssociatedTokenserum_dexSelfTradeBehaviormatchingOrderTypeSideNonZeroU64new_order_v3NewOrderV3cancel_order_v2CancelOrderV2settle_fundsSettleFundsinit_open_ordersInitOpenOrdersclose_open_ordersCloseOpenOrderssweep_feesSweepFeesinitialize_marketInitializeMarketmarketopen_ordersrequest_queueevent_queuemarket_bidsmarket_asksorder_payer_token_account// Token account where funds are transferred from for the order. If// posting a bid market A/B, then this is the SPL token account for B.open_orders_authoritycoin_vault// Also known as the "base" currency. For a given A/B market,// this is the vault for the A mint.pc_vault// Also known as the "quote" currency. For a given A/B market,// this is the vault for the B mint.coin_walletpc_walletvault_signer/// To use an (optional) market authority, add it as the first account of the/// CpiContext's `remaining_accounts` Vec.destinationsweep_authoritysweep_receivercoin_mintpc_mintbidsasksreq_qevent_qDexvote_weight_record/// A macro is exposed so that we can embed the program ID.impl_idl_build/// Crate a default [`anchor_lang::IdlBuild`] implementation for the given type./// This is used in order to make wrapper accounts of `anchor-spl` work with `idl-build` feature.token_2022token_2022_extensionstoken_interface//! Anchor CPI wrappers for popular programs in the Solana ecosystem.build_memoBuildMemoMemompl_token_metadataapprove_collection_authorityApproveCollectionAuthoritybubblegum_set_collection_sizeBubblegumSetCollectionSizeburn_edition_nftBurnEditionNftburn_nftBurnNft/// Burn an NFT by closing its token, metadata and edition accounts./// The lamports of the closed accounts will be transferred to the owner./// This instruction takes an optional `collection_metadata` argument, if this argument is/// `Some`, the `ctx` argument should also include the `collection_metadata` account in its/// remaining accounts, otherwise the CPI will fail because [`BurnNft`] only includes required/// accounts./// CpiContext::new(program, BurnNft { .. })///     .with_remaining_accounts(vec![ctx.accounts.collection_metadata]);create_metadata_accounts_v3CreateMetadataAccountsV3DataV2CollectionDetailsupdate_metadata_accounts_v2UpdateMetadataAccountsV2create_master_edition_v3CreateMasterEditionV3mint_new_edition_from_master_edition_via_tokenMintNewEditionFromMasterEditionViaTokenrevoke_collection_authorityRevokeCollectionAuthorityset_collection_sizeSetCollectionSizeverify_collectionVerifyCollectionverify_sized_collection_itemVerifySizedCollectionItemset_and_verify_collectionSetAndVerifyCollectionset_and_verify_sized_collection_itemSetAndVerifySizedCollectionItemfreeze_delegated_accountFreezeDelegatedAccountthaw_delegated_accountThawDelegatedAccountupdate_primary_sale_happened_via_tokenUpdatePrimarySaleHappenedViaTokenset_token_standardSetTokenStandardsign_metadataSignMetadataremove_creator_verificationRemoveCreatorVerificationutilizeUtilizeunverify_collectionUnverifyCollectionunverify_sized_collection_itemUnverifySizedCollectionItemcollection_authority_recordnew_collection_authorityupdate_authoritymetadata_accountbubblegum_signerprint_edition_mintmaster_edition_mintprint_edition_tokenmaster_edition_tokenmaster_editionprint_editionedition_markereditionmint_authoritynew_metadatanew_editionnew_mintedition_mark_pdanew_mint_authoritytoken_account_ownertoken_accountnew_metadata_update_authoritymetadata_mint// Not actually used by the program but still needed because it's needed// for the pda calculation in the helper. :/// The better thing to do would be to remove this and have the instruction// helper pass in the `edition_mark_pda` directly.delegate_authorityrevoke_authoritymint_accountcollection_authoritycollection_mintcollection_metadatacollection_master_editiondelegatecreatoruse_authoritycollectioncollection_master_edition_accountMetadataMetadataAccountMasterEditionMasterEditionAccountTokenRecordTokenRecordAccountLENsrmSRMr" The static program ID"r" Const version of `ID`"ID_CONSTr" Confirms that a given pubkey is equivalent to the program ID"r" Returns the program ID"id_consttest_idusdcUSDCstakeStakeAuthorizeStakeStateauthorizeAuthorizewithdrawWithdrawdeactivate_stakeDeactivateStake/// The stake account to be updated/// The existing authoritynew_authorized/// The new authority to replace the existing authority/// Clock sysvarwithdrawer/// The stake account's withdraw authority/// Account to send withdrawn lamports to/// StakeHistory sysvar/// The stake account to be deactivatedstaker/// The stake account's stake authorityStakeAccountStake// CPI functions// CPI accounts// Stateprogram_packPacktransfer_checkedTransferCheckedmint_toMintToburnBurnapproveApproveapprove_checkedApproveCheckedrevokeRevokeinitialize_accountInitializeAccountinitialize_account3InitializeAccount3close_accountCloseAccountfreeze_accountFreezeAccountthaw_accountThawAccountinitialize_mintInitializeMintinitialize_mint2InitializeMint2set_authorityAuthorityTypesync_nativeSyncNativeTransferCheckedBumps" Generated client accounts for [`TransferChecked`]."__client_accounts_transfer_checked" Generated CPI struct of the accounts for [`TransferChecked`]."__cpi_client_accounts_transfer_checkedMintToBumps" Generated client accounts for [`MintTo`]."__client_accounts_mint_to" Generated CPI struct of the accounts for [`MintTo`]."__cpi_client_accounts_mint_toBurnBumps" Generated client accounts for [`Burn`]."__client_accounts_burn" Generated CPI struct of the accounts for [`Burn`]."__cpi_client_accounts_burnApproveBumps" Generated client accounts for [`Approve`]."__client_accounts_approve" Generated CPI struct of the accounts for [`Approve`]."__cpi_client_accounts_approveApproveCheckedBumps" Generated client accounts for [`ApproveChecked`]."__client_accounts_approve_checked" Generated CPI struct of the accounts for [`ApproveChecked`]."__cpi_client_accounts_approve_checkedRevokeBumps" Generated client accounts for [`Revoke`]."__client_accounts_revoke" Generated CPI struct of the accounts for [`Revoke`]."__cpi_client_accounts_revokeInitializeAccountBumps" Generated client accounts for [`InitializeAccount`]."__client_accounts_initialize_account" Generated CPI struct of the accounts for [`InitializeAccount`]."__cpi_client_accounts_initialize_accountInitializeAccount3Bumps" Generated client accounts for [`InitializeAccount3`]."__client_accounts_initialize_account3" Generated CPI struct of the accounts for [`InitializeAccount3`]."__cpi_client_accounts_initialize_account3CloseAccountBumps" Generated client accounts for [`CloseAccount`]."__client_accounts_close_account" Generated CPI struct of the accounts for [`CloseAccount`]."__cpi_client_accounts_close_accountFreezeAccountBumps" Generated client accounts for [`FreezeAccount`]."__client_accounts_freeze_account" Generated CPI struct of the accounts for [`FreezeAccount`]."__cpi_client_accounts_freeze_accountThawAccountBumps" Generated client accounts for [`ThawAccount`]."__client_accounts_thaw_account" Generated CPI struct of the accounts for [`ThawAccount`]."__cpi_client_accounts_thaw_accountInitializeMintBumps" Generated client accounts for [`InitializeMint`]."__client_accounts_initialize_mint" Generated CPI struct of the accounts for [`InitializeMint`]."__cpi_client_accounts_initialize_mintInitializeMint2Bumps" Generated client accounts for [`InitializeMint2`]."__client_accounts_initialize_mint2" Generated CPI struct of the accounts for [`InitializeMint2`]."__cpi_client_accounts_initialize_mint2current_authorityaccount_or_mintSetAuthorityBumps" Generated client accounts for [`SetAuthority`]."__client_accounts_set_authority" Generated CPI struct of the accounts for [`SetAuthority`]."__cpi_client_accounts_set_authoritySyncNativeBumps" Generated client accounts for [`SyncNative`]."__client_accounts_sync_native" Generated CPI struct of the accounts for [`SyncNative`]."__cpi_client_accounts_sync_nativeTokenAccountMintamountaccessor// Field parsers to save compute. All account validation is assumed to be done// outside of these methods.get_account_data_sizeGetAccountDataSizeextensionExtensionTypeinitialize_mint_close_authorityInitializeMintCloseAuthorityinitialize_immutable_ownerInitializeImmutableOwneramount_to_ui_amountAmountToUiAmountui_amount_to_amountUiAmountToAmountGetAccountDataSizeBumps" Generated client accounts for [`GetAccountDataSize`]."__client_accounts_get_account_data_size" Generated CPI struct of the accounts for [`GetAccountDataSize`]."__cpi_client_accounts_get_account_data_sizeInitializeMintCloseAuthorityBumps" Generated client accounts for [`InitializeMintCloseAuthority`]."__client_accounts_initialize_mint_close_authority" Generated CPI struct of the accounts for [`InitializeMintCloseAuthority`]."__cpi_client_accounts_initialize_mint_close_authorityInitializeImmutableOwnerBumps" Generated client accounts for [`InitializeImmutableOwner`]."__client_accounts_initialize_immutable_owner" Generated CPI struct of the accounts for [`InitializeImmutableOwner`]."__cpi_client_accounts_initialize_immutable_ownerAmountToUiAmountBumps" Generated client accounts for [`AmountToUiAmount`]."__client_accounts_amount_to_ui_amount" Generated CPI struct of the accounts for [`AmountToUiAmount`]."__cpi_client_accounts_amount_to_ui_amountUiAmountToAmountBumps" Generated client accounts for [`UiAmountToAmount`]."__client_accounts_ui_amount_to_amount" Generated CPI struct of the accounts for [`UiAmountToAmount`]."__cpi_client_accounts_ui_amount_to_amountToken2022// waiting for labs to mergecpi_guard_enableCpiGuardcpi_guard_disabletoken_program_idCpiGuardBumps" Generated client accounts for [`CpiGuard`]."__client_accounts_cpi_guard" Generated CPI struct of the accounts for [`CpiGuard`]."__cpi_client_accounts_cpi_guardAccountStatedefault_account_state_initializeDefaultAccountStateInitializeDefaultAccountStateInitializeBumps" Generated client accounts for [`DefaultAccountStateInitialize`]."__client_accounts_default_account_state_initialize" Generated CPI struct of the accounts for [`DefaultAccountStateInitialize`]."__cpi_client_accounts_default_account_state_initializedefault_account_state_updateDefaultAccountStateUpdatefreeze_authorityDefaultAccountStateUpdateBumps" Generated client accounts for [`DefaultAccountStateUpdate`]."__client_accounts_default_account_state_update" Generated CPI struct of the accounts for [`DefaultAccountStateUpdate`]."__cpi_client_accounts_default_account_state_updategroup_member_pointer_initializeGroupMemberPointerInitializeGroupMemberPointerInitializeBumps" Generated client accounts for [`GroupMemberPointerInitialize`]."__client_accounts_group_member_pointer_initialize" Generated CPI struct of the accounts for [`GroupMemberPointerInitialize`]."__cpi_client_accounts_group_member_pointer_initializegroup_member_pointer_updateGroupMemberPointerUpdateGroupMemberPointerUpdateBumps" Generated client accounts for [`GroupMemberPointerUpdate`]."__client_accounts_group_member_pointer_update" Generated CPI struct of the accounts for [`GroupMemberPointerUpdate`]."__cpi_client_accounts_group_member_pointer_updategroup_pointer_initializeGroupPointerInitializeGroupPointerInitializeBumps" Generated client accounts for [`GroupPointerInitialize`]."__client_accounts_group_pointer_initialize" Generated CPI struct of the accounts for [`GroupPointerInitialize`]."__cpi_client_accounts_group_pointer_initializegroup_pointer_updateGroupPointerUpdateGroupPointerUpdateBumps" Generated client accounts for [`GroupPointerUpdate`]."__client_accounts_group_pointer_update" Generated CPI struct of the accounts for [`GroupPointerUpdate`]."__cpi_client_accounts_group_pointer_updateimmutable_owner_initializeImmutableOwnerInitializeImmutableOwnerInitializeBumps" Generated client accounts for [`ImmutableOwnerInitialize`]."__client_accounts_immutable_owner_initialize" Generated CPI struct of the accounts for [`ImmutableOwnerInitialize`]."__cpi_client_accounts_immutable_owner_initializeinterest_bearing_mint_initializeInterestBearingMintInitializeInterestBearingMintInitializeBumps" Generated client accounts for [`InterestBearingMintInitialize`]."__client_accounts_interest_bearing_mint_initialize" Generated CPI struct of the accounts for [`InterestBearingMintInitialize`]."__cpi_client_accounts_interest_bearing_mint_initializeinterest_bearing_mint_update_rateInterestBearingMintUpdateRaterate_authorityInterestBearingMintUpdateRateBumps" Generated client accounts for [`InterestBearingMintUpdateRate`]."__client_accounts_interest_bearing_mint_update_rate" Generated CPI struct of the accounts for [`InterestBearingMintUpdateRate`]."__cpi_client_accounts_interest_bearing_mint_update_ratememo_transfer_initializeMemoTransfermemo_transfer_disableMemoTransferBumps" Generated client accounts for [`MemoTransfer`]."__client_accounts_memo_transfer" Generated CPI struct of the accounts for [`MemoTransfer`]."__cpi_client_accounts_memo_transfermetadata_pointer_initializeMetadataPointerInitializeMetadataPointerInitializeBumps" Generated client accounts for [`MetadataPointerInitialize`]."__client_accounts_metadata_pointer_initialize" Generated CPI struct of the accounts for [`MetadataPointerInitialize`]."__cpi_client_accounts_metadata_pointer_initializemint_close_authority_initializeMintCloseAuthorityInitializeMintCloseAuthorityInitializeBumps" Generated client accounts for [`MintCloseAuthorityInitialize`]."__client_accounts_mint_close_authority_initialize" Generated CPI struct of the accounts for [`MintCloseAuthorityInitialize`]."__cpi_client_accounts_mint_close_authority_initializeconfidential_transferconfidential_transfer_feecpi_guarddefault_account_stategroup_member_pointergroup_pointerimmutable_ownerinterest_bearing_mintmemo_transfermetadata_pointermint_close_authoritynon_transferablepermanent_delegatetoken_grouptoken_metadatatransfer_feetransfer_hooknon_transferable_mint_initializeNonTransferableMintInitializeNonTransferableMintInitializeBumps" Generated client accounts for [`NonTransferableMintInitialize`]."__client_accounts_non_transferable_mint_initialize" Generated CPI struct of the accounts for [`NonTransferableMintInitialize`]."__cpi_client_accounts_non_transferable_mint_initializepermanent_delegate_initializePermanentDelegateInitializePermanentDelegateInitializeBumps" Generated client accounts for [`PermanentDelegateInitialize`]."__client_accounts_permanent_delegate_initialize" Generated CPI struct of the accounts for [`PermanentDelegateInitialize`]."__cpi_client_accounts_permanent_delegate_initializetoken_group_initializeTokenGroupInitializegroupTokenGroupInitializeBumps" Generated client accounts for [`TokenGroupInitialize`]."__client_accounts_token_group_initialize" Generated CPI struct of the accounts for [`TokenGroupInitialize`]."__cpi_client_accounts_token_group_initializetoken_member_initializeTokenMemberInitializemembermember_mintmember_mint_authoritygroup_update_authorityTokenMemberInitializeBumps" Generated client accounts for [`TokenMemberInitialize`]."__client_accounts_token_member_initialize" Generated CPI struct of the accounts for [`TokenMemberInitialize`]."__cpi_client_accounts_token_member_initializeoptional_keysOptionalNonZeroPubkeyFieldtoken_metadata_initializeTokenMetadataInitializeTokenMetadataInitializeBumps" Generated client accounts for [`TokenMetadataInitialize`]."__client_accounts_token_metadata_initialize" Generated CPI struct of the accounts for [`TokenMetadataInitialize`]."__cpi_client_accounts_token_metadata_initializetoken_metadata_update_authorityTokenMetadataUpdateAuthorityTokenMetadataUpdateAuthorityBumps" Generated client accounts for [`TokenMetadataUpdateAuthority`]."__client_accounts_token_metadata_update_authority" Generated CPI struct of the accounts for [`TokenMetadataUpdateAuthority`]."__cpi_client_accounts_token_metadata_update_authoritytoken_metadata_update_fieldTokenMetadataUpdateFieldTokenMetadataUpdateFieldBumps" Generated client accounts for [`TokenMetadataUpdateField`]."__client_accounts_token_metadata_update_field" Generated CPI struct of the accounts for [`TokenMetadataUpdateField`]."__cpi_client_accounts_token_metadata_update_fieldtransfer_fee_initializeTransferFeeInitializeTransferFeeInitializeBumps" Generated client accounts for [`TransferFeeInitialize`]."__client_accounts_transfer_fee_initialize" Generated CPI struct of the accounts for [`TransferFeeInitialize`]."__cpi_client_accounts_transfer_fee_initializetransfer_fee_setTransferFeeSetTransferFeeTransferFeeSetTransferFeeBumps" Generated client accounts for [`TransferFeeSetTransferFee`]."__client_accounts_transfer_fee_set_transfer_fee" Generated CPI struct of the accounts for [`TransferFeeSetTransferFee`]."__cpi_client_accounts_transfer_fee_set_transfer_feetransfer_checked_with_feeTransferCheckedWithFeeTransferCheckedWithFeeBumps" Generated client accounts for [`TransferCheckedWithFee`]."__client_accounts_transfer_checked_with_fee" Generated CPI struct of the accounts for [`TransferCheckedWithFee`]."__cpi_client_accounts_transfer_checked_with_feeharvest_withheld_tokens_to_mintHarvestWithheldTokensToMintHarvestWithheldTokensToMintBumps" Generated client accounts for [`HarvestWithheldTokensToMint`]."__client_accounts_harvest_withheld_tokens_to_mint" Generated CPI struct of the accounts for [`HarvestWithheldTokensToMint`]."__cpi_client_accounts_harvest_withheld_tokens_to_mintwithdraw_withheld_tokens_from_mintWithdrawWithheldTokensFromMintWithdrawWithheldTokensFromMintBumps" Generated client accounts for [`WithdrawWithheldTokensFromMint`]."__client_accounts_withdraw_withheld_tokens_from_mint" Generated CPI struct of the accounts for [`WithdrawWithheldTokensFromMint`]."__cpi_client_accounts_withdraw_withheld_tokens_from_minttransfer_hook_initializeTransferHookInitializeTransferHookInitializeBumps" Generated client accounts for [`TransferHookInitialize`]."__client_accounts_transfer_hook_initialize" Generated CPI struct of the accounts for [`TransferHookInitialize`]."__cpi_client_accounts_transfer_hook_initializetransfer_hook_updateTransferHookUpdateTransferHookUpdateBumps" Generated client accounts for [`TransferHookUpdate`]."__client_accounts_transfer_hook_update" Generated CPI struct of the accounts for [`TransferHookUpdate`]."__cpi_client_accounts_transfer_hook_updateBaseStateWithExtensionsExtensionStateWithExtensionsIDSTokenInterfaceExtensionsVecfind_mint_account_sizeget_mint_extension_dataAccountFieldgenerate// Generates the private `__client_accounts` mod implementation, containing// a generated struct mapping 1-1 to the `Accounts` struct, except with// `Pubkey`s as the types. This is generated for Rust *clients*.// Generates the private `__cpi_client_accounts` mod implementation, containing// `AccountInfo`s as the types. This is generated for CPI clients.ParsedGenericsconstraintsgenerate_bumps_namegenerate_compositeCompositeFieldlinearizeConstraintGroupConstraint// Linearizes the constraint group so that constraints with dependencies// run after those without.generate_constraintgenerate_constraint_compositegenerate_constraint_addressgenerate_constraint_initConstraintInitGroupgenerate_constraint_zeroedConstraintZeroedgenerate_constraint_closegenerate_constraint_mutgenerate_constraint_has_onegenerate_constraint_signergenerate_constraint_rawgenerate_constraint_ownergenerate_constraint_rent_exemptgenerate_constraint_reallocConstraintReallocGroupgenerate_constraint_init_groupgenerate_constraint_seedsConstraintSeedsGroupgenerate_constraint_associated_tokenConstraintAssociatedTokengenerate_constraint_token_accountConstraintTokenAccountGroupgenerate_constraint_mintConstraintTokenMintGroupseenOptionalCheckScopenew_with_fieldgenerate_checkgenerate_get_token_account_spacegenerate_create_account// Generated code to create an account with with system program with the// given `space` amount of data, owned by `owner`.// `seeds_with_nonce` should be given for creating PDAs. Otherwise it's an// empty stream.// This should only be run within scopes where `system_program` is not Optionalgenerate_constraint_executablegenerate_custom_errorgenerate_account_refaccounts_codegen// Generates the `Exit` trait implementation.ConstParamLifetimeDefTypeParamGenericParamPredicateLifetimeWhereClauseWherePredicatecombined_genericsCommatrait_genericsstruct_genericswhere_clause// Generates the `ToAccountInfos` trait implementation.// Generates the `ToAccountMetas` trait implementation.// Generates the `Accounts` trait implementation.generate_constraintsgenerate_accounts_instanceis_initIxArgSIGHASH_GLOBAL_NAMESPACE// Namespace for calculating instruction sighash signatures for any instruction// not affecting program state.sighash// We don't technically use sighash, because the input arguments aren't given.// Rust doesn't have method overloading so no need to use the arguments.// However, we do namespace methods in the preeimage so that we can use// different traits with the same method name.generate_ix_variantgenerate_accountsgen_fallbackgenerate_event_cpi_handler/// Generate the event-cpi instruction handler based on whether the `event-cpi` feature is enabled.program_codegendispatchidl_accounts_and_functions// Generate non-inlined wrappers for each instruction handler, since Solana's// BPF max stack size can't handle reasonable sized dispatch trees without doing// so.generate_ix_variant_namegenerate_event_cpi_mod/// Generate the event module based on whether the `event-cpi` feature is enabled.entryhandlersDigestSha256HASH_BYTEShasherhashvParseHashErrorWrongSizeInvalidto_bytes/// Return a Sha256 hash for the given data.// Utility hashing module copied from `solana_program::program::hash`, since we// can't import solana_program for compile time hashing for some reason.get_idl_module_pathget_no_docsInitKindgen_idl_build_impl_accounts_struct/// Generate the IDL build impl for the Accounts struct.get_addressget_pdaparse_seed/// Parse a seeds constraint, extracting the `IdlSeed` types./// Note: This implementation makes assumptions about the types that can be used (e.g., no/// program-defined function calls in seeds)./// This probably doesn't cover all cases. If you see a warning log, you can add a new case here./// In the worst case, we miss a seed and the parser will treat the given seeds as empty and so/// clients will simply fail to automatically populate the PDA accounts./// # Seed assumptions/// Seeds must be of one of the following forms:/// - Constant/// - Instruction argument/// - Account key or field/// Seed namesubfields/// All path components for the subfields accessed on this seedSeedPath/// SeedPath represents the deconstructed syntax of a single pda seed,/// consisting of a variable name and a vec of all the sub fields accessed/// on that variable name. For example, if a seed is `my_field.my_data.as_ref()`,/// then the field name is `my_field` and the vec of sub fields is `[my_data]`./// Extract the seed path from a single seed expression./// Get the full path to the data this seed represents.get_relationsgen_print_sectiongen_idl_print_fn_addressfind_pathget_serde_json_module_pathgen_idl_typegen_idl_print_fn_constantItemConstimpl_idl_build_structItemStruct/// Generate `IdlBuild` impl for a struct.impl_idl_build_enumItemEnum/// Generate `IdlBuild` impl for an enum.impl_idl_build_unionItemUnion/// Generate `IdlBuild` impl for a union./// Unions are not currently supported in the IDL.GenericsTypePath/// Generate `IdlBuild` implementation.gen_idl_type_def_structgen_idl_type_def_enumgen_idl_type_defget_attr_strgen_idl_fieldget_first_segmentPathSegmentgen_idl_print_fn_errorgen_idl_print_fn_eventimpl_idl_build_event/// Generate IDL build impl for an event.fscargo_tomlManifestCrateContextget_external_typerecursively_find_typeget_registry_pathparse_lock_fileget_usesflatten_usesUseTreeexternalgen_idl_print_fn_program/// Generate the IDL build print function for the program module.check_safety_comments/// Check safety comments.accounts_parserprogram_parserIdentExtParseErrorParseResultspannedSpannedItemFnItemModPatTypeixsIxprogram_modfallback_fnFallbackFnraw_methodidentIxReturnanchor_ident// The ident for the struct deriving Accounts.interface_discriminator// The discriminator based on the `#[interface]` attribute.raw_arg// Name of the accounts struct.// Generics + lifetimes on the accounts struct.// Fields on the accounts struct.instruction_api// Instruction data api expression.instruction_args// Return value maps instruction name to type.// E.g. if we have `#[instruction(data: u64)]` then returns// { "data": "u64"}.field_nameshas_optionalis_field_optionalty_name/// IDL Doc commenttyped_identty_decl// Ignores optional accounts. Optional account checks and handing should be done prior to this// function being called.container_tyaccount_ty// Returns the inner account struct type.symbolraw_fieldAccountLoaderTySysvarTyAccountTyProgramTyInterfaceTyInterfaceAccountTy// A type of an account field.FeesRecentBlockhashesaccount_type_path// The struct type of the account.// True if the account has been boxed via `Box<T>`.raw_enumcodesinitzeroedmutablerent_exemptexecutablehas_onerawrealloc// All well formed constraints on a single `Accounts` field.is_zeroedis_mutableis_closeInitZeroedMutHasOneRawRentExemptSeedsExecutableAddressRealloc// A single account constraint *after* merging all tokens into a well formed// constraint. Some constraints like "seeds" are defined by multiple// tokens, so a merging phase is required.ConstraintTokenConstraintInitConstraintPayerPayerTokenMintConstraintTokenAuthorityTokenAuthorityConstraintTokenProgramTokenTokenProgramAssociatedTokenMintAssociatedTokenAuthorityAssociatedTokenTokenProgramConstraintMintAuthorityMintAuthorityMintFreezeAuthorityMintDecimalsMintTokenProgramConstraintTokenBumpConstraintProgramSeedProgramSeedConstraintReallocConstraintReallocPayerReallocPayerConstraintReallocZeroReallocZeroConstraintExtensionAuthorityExtensionGroupPointerAuthority// extensionsConstraintExtensionGroupPointerGroupAddressExtensionGroupPointerGroupAddressExtensionGroupMemberPointerAuthorityConstraintExtensionGroupMemberPointerMemberAddressExtensionGroupMemberPointerMemberAddressExtensionMetadataPointerAuthorityConstraintExtensionMetadataPointerMetadataAddressExtensionMetadataPointerMetadataAddressExtensionCloseAuthorityExtensionTokenHookAuthorityConstraintExtensionTokenHookProgramIdExtensionTokenHookProgramIdConstraintExtensionPermanentDelegateExtensionPermanentDelegate// Constraint token is a single keyword in a `#[account(<TOKEN>)]` attribute.if_neededConstraintInitIfNeededspacetargetjoin_targetowner_addressEnforceSkipbumpprogram_seed// None => bump was given without a target.// None => use the current program's program_id.// extension constraintsgroup_addressmember_addressmetadata_address// Owner for token and mint represents the authority. Not to be confused// with the owner of the AccountInfo.decimalsgroup_pointer_authoritygroup_pointer_group_addressgroup_member_pointer_authoritygroup_member_pointer_member_addressmetadata_pointer_authoritymetadata_pointer_metadata_addressclose_authoritytransfer_hook_authoritytransfer_hook_program_idsol_destconfidential_transfer_dataConstraintMintConfidentialTransferDataConstraintMintMetadatatoken_group_dataConstraintMintTokenGroupDatatoken_group_member_dataConstraintMintTokenGroupMemberDatametadata_pointer_dataConstraintMintMetadataPointerDatagroup_pointer_dataConstraintMintGroupPointerDatagroup_member_pointer_dataConstraintMintGroupMemberPointerDataConstraintMintCloseAuthorityauthmint_authmint_freeze_authwallet// Syntaxt context object for preserving metadata about the inner item.is_accountparse_token// Parses a single constraint from a parse stream for `#[account(<STREAM>)]`.parse_optional_custom_errorf_ty'tytoken_minttoken_authoritytoken_token_programassociated_token_mintassociated_token_authorityassociated_token_token_programmint_freeze_authoritymint_decimalsmint_token_programextension_group_pointer_authorityextension_group_pointer_group_addressextension_group_member_pointer_authorityextension_group_member_pointer_member_addressextension_metadata_pointer_authorityextension_metadata_pointer_metadata_addressextension_close_authorityextension_transfer_hook_authorityextension_transfer_hook_program_idextension_permanent_delegaterealloc_payerrealloc_zeroConstraintGroupBuilderadd_initadd_zeroedadd_reallocadd_realloc_payeradd_realloc_zeroadd_closeadd_addressadd_token_mintadd_associated_token_mintadd_bumpadd_program_seedadd_token_authorityadd_associated_token_authorityadd_token_token_programadd_associated_token_token_programadd_mint_authorityadd_mint_freeze_authorityadd_mint_decimalsadd_mint_token_programadd_mutadd_signeradd_has_oneadd_rawadd_owneradd_rent_exemptadd_seedsadd_executableadd_payeradd_spaceadd_extension_group_pointer_authorityadd_extension_group_pointer_group_addressadd_extension_group_member_pointer_authorityadd_extension_group_member_pointer_member_addressadd_extension_metadata_pointer_authorityadd_extension_metadata_pointer_metadata_addressadd_extension_close_authorityadd_extension_authorityadd_extension_transfer_hook_program_idadd_extension_permanent_delegate/// Account name of the event authority/// Seeds expression of the event authorityEventAuthority/// This struct is used to keep the authority account information in sync./// Returns the account name and the seeds expression of the event authority.name_token_stream/// Returns the name without surrounding quotes.add_event_cpi_accounts/// Add necessary event CPI accounts to the given accounts struct.constraints_cross_checksparse_account_fieldis_field_primitiveparse_tyoption_to_inner_pathident_stringparse_program_account_loaderparse_account_typarse_interface_account_typarse_program_typarse_interface_typarse_account// TODO: this whole method is a hack. Do something more idiomatic.parse_sysvarImplItemImplItemConstmodulesParsedModule/// Crate parse context/// Keeps track of modules defined within a crate.impl_constsstructsenumstype_aliasesItemTypeModuleContextroot_modulesafety_checks// Perform Anchor safety checks on the parsed createdetail'krate/// Module parse context/// Keeps track of items defined within a module.itemsfileitemUnparsedModuleparse_recursivefrom_item_modunparsed_submodulessubmodulesunsafe_struct_fieldsLitStrMetaNameValue// returns vec of doc strings// Removes any internal #[msg] attributes, as they are inert.parse_error_attributeVariantspl_interfacetts_to_stringctx_accounts_ident// Parse all non-state ix handlers from the program mod definition.parse_argsparse_returnffiOsStringcompile_errorcompile_proberustc_minor_versioncargo_env_varbacktraceBacktraceBacktraceStatusimpl_backtracebacktrace_if_absent_assert_send_syncChainStateStdErrorChainLinkedrestBufferedsize_hintnext_backDoubleEndedIteratorContextErrorInfalliblenightlyRequestext_contextEwith_contextFnOnce/// # type T = ();/// #/// use anyhow::{Context, Result};/// fn maybe_get() -> Option<T> {///     # const IGNORE: &str = stringify! {///     # };///     # unimplemented!()/// fn demo() -> Result<()> {///     let t = maybe_get().context("there is no T")?;provideQuotedwrite_strMaybeUninit__dispatch_ensureBothDebugNotBothDebug40writtenBufas_strrender__parse_ensure// low precedence control flow constructs// unary operators// control flow constructs// atomic expressions// path expressions// trailer expressions// types// path types// qualified paths// trait objects// angle bracketed generic arguments// patterns// comparison binary operators// high precedence binary operators// low precedence binary operators// unrecognized expression__fancy_ensure__fallback_ensurechainOwnNonNull/// Create a new error object from any error type./// The error type must be threadsafe and `'static`, so that the `Error`/// will be as well./// If the error type does not provide a backtrace, a backtrace will be/// created here to ensure that a backtrace exists.M/// Create a new error object from a printable error message./// If the argument implements std::error::Error, prefer `Error::new`/// instead which preserves the underlying error's cause chain and/// backtrace. If the argument may or may not implement std::error::Error/// now or in the future, use `anyhow!(err)` which handles either way/// correctly./// `Error::msg("...")` is equivalent to `anyhow!("...")` but occasionally/// convenient in places where a function is preferable over a macro, such/// as iterator or stream combinators:/// # mod ffi {/// #     pub struct Input;/// #     pub struct Output;/// #     pub async fn do_some_work(_: Input) -> Result<Output, &'static str> {/// #         unimplemented!()/// #     }/// # use ffi::{Input, Output};/// use anyhow::{Error, Result};/// use futures::stream::{Stream, StreamExt, TryStreamExt};/// async fn demo<S>(stream: S) -> Result<Vec<Output>>/// where///     S: Stream<Item = Input>,/// {///     stream///         .then(ffi::do_some_work) // returns Result<Output, &str>///         .map_err(Error::msg)///         .try_collect()///         .awaitfrom_boxed/// Construct an error object from a type-erased standard library error./// This is mostly useful for interop with other error libraries./// Here is a skeleton of a library that provides its own error abstraction./// The pair of `From` impls provide bidirectional support for `?`/// conversion between `Report` and `anyhow::Error`./// use std::error::Error as StdError;/// pub struct Report {/* ... */}/// impl<E> From<E> for Report///     E: Into<anyhow::Error>,///     Result<(), E>: anyhow::Context<(), E>,///     fn from(error: E) -> Self {///         let anyhow_error: anyhow::Error = error.into();///         let boxed_error: Box<dyn StdError + Send + Sync + 'static> = anyhow_error.into();///         Report::from_boxed(boxed_error)/// impl From<Report> for anyhow::Error {///     fn from(report: Report) -> Self {///         let boxed_error: Box<dyn StdError + Send + Sync + 'static> = report.into_boxed();///         anyhow::Error::from_boxed(boxed_error)/// impl Report {///     fn from_boxed(boxed_error: Box<dyn StdError + Send + Sync + 'static>) -> Self {///         todo!()///     fn into_boxed(self) -> Box<dyn StdError + Send + Sync + 'static> {/// // Example usage: can use `?` in both directions./// fn a() -> anyhow::Result<()> {///     b()?;/// fn b() -> Result<(), Report> {///     a()?;construct_from_stdconstruct_from_adhocconstruct_from_displayconstruct_from_contextconstruct_from_boxedconstructErrorVTable// Takes backtrace as argument rather than capturing it here so that the// user sees one fewer layer of wrapping noise in the backtrace.// Unsafe because the given vtable must have sensible behavior on the error// value of type E./// Wrap the error value with additional context./// For attaching context to a `Result` as it is propagated, the/// [`Context`][crate::Context] extension trait may be more convenient than/// this function./// The primary reason to use `error.context(...)` instead of/// `result.context(...)` via the `Context` trait would be if the context/// needs to depend on some data held by the underlying error:/// # use std::fmt::{self, Debug, Display};/// # impl std::error::Error for ParseError {}/// # impl Debug for ParseError {/// #     fn fmt(&self, formatter: &mut fmt::Formatter) -> fmt::Result {/// # impl Display for ParseError {/// use anyhow::Result;/// use std::fs::File;/// use std::path::Path;/// struct ParseError {///     line: usize,///     column: usize,/// fn parse_impl(file: File) -> Result<T, ParseError> {/// pub fn parse(path: impl AsRef<Path>) -> Result<T> {///     let file = File::open(&path)?;///     parse_impl(file).map_err(|error| {///         let context = format!(///             "only the first {} lines of {} are valid",///             error.line, path.as_ref().display(),///         );///         anyhow::Error::new(error).context(context)///     })/// Get the backtrace for this Error./// In order for the backtrace to be meaningful, one of the two environment/// variables `RUST_LIB_BACKTRACE=1` or `RUST_BACKTRACE=1` must be defined/// and `RUST_LIB_BACKTRACE` must not be `0`. Backtraces are somewhat/// expensive to capture in Rust, so we don't necessarily want to be/// capturing them all over the place all the time./// - If you want panics and errors to both have backtraces, set///   `RUST_BACKTRACE=1`;/// - If you want only errors to have backtraces, set///   `RUST_LIB_BACKTRACE=1`;/// - If you want only panics to have backtraces, set `RUST_BACKTRACE=1` and///   `RUST_LIB_BACKTRACE=0`./// # Stability/// Standard library backtraces are only available when using Rust &ge;/// 1.65. On older compilers, this function is only available if the crate's/// "backtrace" feature is enabled, and will use the `backtrace` crate as/// the underlying backtrace implementation. The return type of this/// function on old compilers is `&(impl Debug + Display)`./// ```toml/// [dependencies]/// anyhow = { version = "1.0", features = ["backtrace"] }/// An iterator of the chain of source errors contained by this Error./// This iterator will visit every error in the cause chain of this error/// object, beginning with the error that this error object was created/// use anyhow::Error;/// use std::io;/// pub fn underlying_io_error_kind(error: &Error) -> Option<io::ErrorKind> {///     for cause in error.chain() {///         if let Some(io_error) = cause.downcast_ref::<io::Error>() {///             return Some(io_error.kind());///     Noneroot_cause/// The lowest level cause of this error &mdash; this error's cause's/// cause's cause etc./// The root cause is the last error in the iterator produced by/// [`chain()`][Error::chain].is/// Returns true if `E` is the type held by this error object./// For errors with context, this method returns true if `E` matches the/// type of the context `C` **or** the type of the error on which the/// context has been attached. For details about the interaction between/// context and downcasting, [see here]./// [see here]: crate::Context#effect-on-downcastingdowncast/// Attempt to downcast the error object to a concrete type.downcast_ref/// Downcast this error object by reference./// # use anyhow::anyhow;/// # use std::fmt::{self, Display};/// # use std::task::Poll;/// # #[derive(Debug)]/// # enum DataStoreError {/// #     Censored(()),/// # impl Display for DataStoreError {/// # impl std::error::Error for DataStoreError {}/// # const REDACTED_CONTENT: () = ();/// # let error = anyhow!("...");/// # let root_cause = &error;/// # let ret =/// // If the error was caused by redaction, then return a tombstone instead/// // of the content./// match root_cause.downcast_ref::<DataStoreError>() {///     Some(DataStoreError::Censored(_)) => Ok(Poll::Ready(REDACTED_CONTENT)),///     None => Err(error),/// # ;downcast_mut/// Downcast this error object by mutable reference.into_boxed_dyn_error/// Convert to a standard library error trait object./// This is implemented as a cheap pointer cast that does not allocate or/// deallocate memory. Like [`anyhow::Error::from_boxed`], it's useful for/// interop with other error libraries./// The same conversion is also available as/// <code style="display:inline;white-space:normal;">impl From&lt;anyhow::Error&gt;/// for Box&lt;dyn Error + Send + Sync + &apos;static&gt;</code>./// If a backtrace was collected during construction of the `anyhow::Error`,/// that backtrace remains accessible using the standard library `Error`/// trait's provider API, but as a consequence, the resulting boxed error/// can no longer be downcast to its original underlying type./// #![feature(error_generic_member_access)]/// use anyhow::anyhow;/// use std::backtrace::Backtrace;/// use thiserror::Error;/// #[derive(Error, Debug)]/// #[error("...")]/// struct MyError;/// let anyhow_error = anyhow!(MyError);/// println!("{}", anyhow_error.backtrace());  // has Backtrace/// assert!(anyhow_error.downcast_ref::<MyError>().is_some());  // can downcast/// let boxed_dyn_error = anyhow_error.into_boxed_dyn_error();/// assert!(std::error::request_ref::<Backtrace>(&*boxed_dyn_error).is_some());  // has Backtrace/// assert!(boxed_dyn_error.downcast_ref::<MyError>().is_none());  // can no longer downcast/// [`anyhow::Error::from_boxed`]: Self::from_boxedreallocate_into_boxed_dyn_error_without_backtrace/// Unlike `self.into_boxed_dyn_error()`, this method relocates the/// underlying error into a new allocation in order to make it downcastable/// to `&E` or `Box<E>` for its original underlying error type. Any/// backtrace collected during construction of the `anyhow::Error` is/// discarded./// let boxed_dyn_error = anyhow_error.reallocate_into_boxed_dyn_error_without_backtrace();/// assert!(std::error::request_ref::<Backtrace>(&*boxed_dyn_error).is_none());  // Backtrace lost/// assert!(boxed_dyn_error.downcast_ref::<MyError>().is_some());  // can downcast to &MyError/// assert!(boxed_dyn_error.downcast::<MyError>().is_ok());  // can downcast to Box<MyError>thiserror_provide// Called by thiserror when you have `#[source] anyhow::Error`. This provide// implementation includes the anyhow::Error's Backtrace if any, unlike// deref'ing to dyn Error where the provide implementation would include// only the original error's Backtrace from before it got wrapped into an// anyhow::Error.dropDropobject_dropErrorImplobject_refobject_boxedobject_reallocate_boxedobject_downcastobject_drop_rest// Safety: requires layout of *e to match ErrorImpl<E>.object_drop_frontcontext_downcast// Safety: requires layout of *e to match ErrorImpl<ContextError<C, E>>.context_drop_restcontext_chain_downcast// Safety: requires layout of *e to match ErrorImpl<ContextError<C, Error>>.context_chain_drop_restvtable_object// NOTE: Don't use directly. Use only through vtable. Erased type may have// different alignment.// NOTE: If working with `ErrorImpl<()>`, references should be avoided in favor// of raw pointers and `NonNull`.// repr C to ensure that E remains in the final position.// Reads the vtable out of `p`. This is the same as `p.as_ref().vtable`, but// avoids converting `p` into a reference.// repr C to ensure that ContextError<C, E> has the same layout as// ContextError<ManuallyDrop<C>, E> and ContextError<C, ManuallyDrop<E>>.eraseerror_mutdisplaynumberstartedIndentedone_digittwo_digitsno_digitsAdhocanyhow_kindAdhocKindTraitTraitKindBoxedBoxedKind// Tagged dispatch mechanism for resolving the behavior of `anyhow!($expr)`.// When anyhow! is given a single expr argument to turn into anyhow::Error, we// want the resulting Error to pick up the input's implementation of source()// and backtrace() if it has a std::error::Error impl, otherwise require nothing// more than Display and Debug.// Expressed in terms of specialization, we want something like://     trait AnyhowNew {//         fn new(self) -> Error;//     impl<T> AnyhowNew for T//     where//         T: Display + Debug + Send + Sync + 'static,//     {//         default fn new(self) -> Error {//             /* no std error impl *///         T: std::error::Error + Send + Sync + 'static,//         fn new(self) -> Error {//             /* use std error's source() and backtrace() */// Since specialization is not stable yet, instead we rely on autoref behavior// of method resolution to perform tagged dispatch. Here we have two traits// AdhocKind and TraitKind that both have an anyhow_kind() method. AdhocKind is// implemented whether or not the caller's type has a std error impl, while// TraitKind is implemented only when a std error impl does exist. The ambiguity// is resolved by AdhocKind requiring an extra autoref so that it has lower// precedence.// The anyhow! macro will set up the call in this form://     #[allow(unused_imports)]//     use $crate::__private::{AdhocKind, TraitKind};//     let error = $msg;//     (&error).anyhow_kind().new(error)ensurewrapperformat_err/// The `Error` type, a wrapper around a dynamic error type./// `Error` works a lot like `Box<dyn std::error::Error>`, but with these/// differences:/// - `Error` requires that the error is `Send`, `Sync`, and `'static`./// - `Error` guarantees that a backtrace is available, even if the underlying///   error type does not provide one./// - `Error` is represented as a narrow pointer &mdash; exactly one word in///   size instead of two./// <br>/// # Display representations/// When you print an error object using "{}" or to_string(), only the outermost/// underlying error or context is printed, not any of the lower level causes./// This is exactly as if you had called the Display impl of the error from/// which you constructed your anyhow::Error./// ```console/// Failed to read instrs from ./path/to/instrs.json/// To print causes as well using anyhow's default formatting of causes, use the/// alternate selector "{:#}"./// Failed to read instrs from ./path/to/instrs.json: No such file or directory (os error 2)/// The Debug format "{:?}" includes your backtrace if one was captured. Note/// that this is the representation you get by default if you return an error/// from `fn main` instead of printing it explicitly yourself./// Error: Failed to read instrs from ./path/to/instrs.json/// Caused by:///     No such file or directory (os error 2)/// and if there is a backtrace available:/// Stack backtrace:///    0: <E as anyhow::context::ext::StdError>::ext_context///              at /git/anyhow/src/backtrace.rs:26///    1: core::result::Result<T,E>::map_err///              at /git/rustc/src/libcore/result.rs:596///    2: anyhow::context::<impl anyhow::Context<T,E> for core::result::Result<T,E>>::with_context///              at /git/anyhow/src/context.rs:58///    3: testing::main///              at src/main.rs:5///    4: std::rt::lang_start///              at /git/rustc/src/libstd/rt.rs:61///    5: main///    6: __libc_start_main///    7: _start/// To see a conventional struct-style Debug representation, use "{:#?}"./// Error {///     context: "Failed to read instrs from ./path/to/instrs.json",///     source: Os {///         code: 2,///         kind: NotFound,///         message: "No such file or directory",/// If none of the built-in representations are appropriate and you would prefer/// to render the error and its cause chain yourself, it can be done something/// like this:/// fn main() {///     if let Err(err) = try_main() {///         eprintln!("ERROR: {}", err);///         err.chain().skip(1).for_each(|cause| eprintln!("because: {}", cause));///         std::process::exit(1);/// fn try_main() -> Result<()> {///     # Ok(())/// Iterator of a chain of source errors./// This type is the iterator returned by [`Error::chain`]./// `Result<T, Error>`/// This is a reasonable return type to use throughout your application but also/// for `fn main`; if you do, failures will be printed along with any/// [context][Context] and a backtrace if one was captured./// `anyhow::Result` may be used with one *or* two type parameters./// ```rust/// # const IGNORE: &str = stringify! {/// fn demo1() -> Result<T> {...}///            // ^ equivalent to std::result::Result<T, anyhow::Error>/// fn demo2() -> Result<T, OtherError> {...}///            // ^ equivalent to std::result::Result<T, OtherError>/// # };/// # pub trait Deserialize {}/// # mod serde_json {/// #     use super::Deserialize;/// #     use std::io;/// #     pub fn from_str<T: Deserialize>(json: &str) -> io::Result<T> {/// # struct ClusterMap;/// # impl Deserialize for ClusterMap {}/// fn main() -> Result<()> {///     # return Ok(());///     let config = std::fs::read_to_string("cluster.json")?;///     let map: ClusterMap = serde_json::from_str(&config)?;///     println!("cluster info: {:#?}", map);/// Wrap the error value with additional context that is evaluated lazily/// only once an error does occur./// Provides the `context` method for `Result`./// This trait is sealed and cannot be implemented for types outside of/// `anyhow`./// use std::fs;/// use std::path::PathBuf;/// pub struct ImportantThing {///     path: PathBuf,/// impl ImportantThing {///     # const IGNORE: &'static str = stringify! {///     pub fn detach(&mut self) -> Result<()> {...}///     # fn detach(&mut self) -> Result<()> {///     #     unimplemented!()///     # }/// pub fn do_it(mut it: ImportantThing) -> Result<Vec<u8>> {///     it.detach().context("Failed to detach the important thing")?;///     let path = &it.path;///     let content = fs::read(path)///         .with_context(|| format!("Failed to read instrs from {}", path.display()))?;///     Ok(content)/// When printed, the outermost context would be printed first and the lower/// level underlying causes would be enumerated below./// Refer to the [Display representations] documentation for other forms in/// which this context chain can be rendered./// [Display representations]: Error#display-representations/// # Effect on downcasting/// After attaching context of type `C` onto an error of type `E`, the resulting/// `anyhow::Error` may be downcast to `C` **or** to `E`./// That is, in codebases that rely on downcasting, Anyhow's context supports/// both of the following use cases:///   - **Attaching context whose type is insignificant onto errors whose type///     is used in downcasts.**///     In other error libraries whose context is not designed this way, it can///     be risky to introduce context to existing code because new context might///     break existing working downcasts. In Anyhow, any downcast that worked///     before adding context will continue to work after you add a context, so///     you should freely add human-readable context to errors wherever it would///     be helpful.///     ```///     # use anyhow::bail;///     # use thiserror::Error;///     #///     # #[derive(Error, Debug)]///     # #[error("???")]///     # struct SuspiciousError;///     # fn helper() -> Result<()> {///     #     bail!(SuspiciousError);///     use anyhow::{Context, Result};///     fn do_it() -> Result<()> {///         helper().context("Failed to complete the work")?;///         # const IGNORE: &str = stringify! {///         ...///         # };///         # unreachable!()///     fn main() {///         let err = do_it().unwrap_err();///         if let Some(e) = err.downcast_ref::<SuspiciousError>() {///             // If helper() returned SuspiciousError, this downcast will///             // correctly succeed even with the context in between.///             # return;///         # panic!("expected downcast to succeed");///   - **Attaching context whose type is used in downcasts onto errors whose///     type is insignificant.**///     Some codebases prefer to use machine-readable context to categorize///     lower level errors in a way that will be actionable to higher levels of///     the application.///     # struct HelperFailed;///     #     bail!("no such file or directory");///         helper().context(HelperFailed)?;///         if let Some(e) = err.downcast_ref::<HelperFailed>() {///             // If helper failed, this downcast will succeed because///             // HelperFailed is the context that has been attached to///             // that error./// Equivalent to `Ok::<_, anyhow::Error>(value)`./// This simplifies creation of an `anyhow::Result` in places where type/// inference cannot deduce the `E` type of the result &mdash; without needing/// to write`Ok::<_, anyhow::Error>(value)`./// One might think that `anyhow::Result::Ok(value)` would work in such cases/// but it does not./// error[E0282]: type annotations needed for `std::result::Result<i32, E>`///   --> src/main.rs:11:13///    |/// 11 |     let _ = anyhow::Result::Ok(1);///    |         -   ^^^^^^^^^^^^^^^^^^ cannot infer type for type parameter `E` declared on the enum `Result`///    |         |///    |         consider giving this pattern the explicit type `std::result::Result<i32, E>`, where the type parameter `E` is specifiednotArgumentsconcatformat_argsstringify// Not public API. Referenced by macro-generated code.//! [![github]](https://github.com/dtolnay/anyhow)&ensp;[![crates-io]](https://crates.io/crates/anyhow)&ensp;[![docs-rs]](https://docs.rs/anyhow)//! [github]: https://img.shields.io/badge/github-8da0cb?style=for-the-badge&labelColor=555555&logo=github//! [crates-io]: https://img.shields.io/badge/crates.io-fc8d62?style=for-the-badge&labelColor=555555&logo=rust//! [docs-rs]: https://img.shields.io/badge/docs.rs-66c2a5?style=for-the-badge&labelColor=555555&logo=docs.rs//! <br>//! This library provides [`anyhow::Error`][Error], a trait object based error//! type for easy idiomatic error handling in Rust applications.//! # Details//! - Use `Result<T, anyhow::Error>`, or equivalently `anyhow::Result<T>`, as//!   the return type of any fallible function.//!   Within the function, use `?` to easily propagate any error that implements//!   the [`std::error::Error`] trait.//!   ```//!   # pub trait Deserialize {}//!   #//!   # mod serde_json {//!   #     use super::Deserialize;//!   #     use std::io;//!   #     pub fn from_str<T: Deserialize>(json: &str) -> io::Result<T> {//!   #         unimplemented!()//!   #     }//!   # }//!   # struct ClusterMap;//!   # impl Deserialize for ClusterMap {}//!   use anyhow::Result;//!   fn get_cluster_info() -> Result<ClusterMap> {//!       let config = std::fs::read_to_string("cluster.json")?;//!       let map: ClusterMap = serde_json::from_str(&config)?;//!       Ok(map)//!   }//!   # fn main() {}//! - Attach context to help the person troubleshooting the error understand//!   where things went wrong. A low-level error like "No such file or//!   directory" can be annoying to debug without more context about what higher//!   level step the application was in the middle of.//!   # struct It;//!   # impl It {//!   #     fn detach(&self) -> Result<()> {//!   use anyhow::{Context, Result};//!   fn main() -> Result<()> {//!       # return Ok(());//!       #//!       # const _: &str = stringify! {//!       ...//!       # };//!       # let it = It;//!       # let path = "./path/to/instrs.json";//!       it.detach().context("Failed to detach the important thing")?;//!       let content = std::fs::read(path)//!           .with_context(|| format!("Failed to read instrs from {}", path))?;//!       # Ok(())//!   ```console//!   Error: Failed to read instrs from ./path/to/instrs.json//!   Caused by://!       No such file or directory (os error 2)//! - Downcasting is supported and can be by value, by shared reference, or by//!   mutable reference as needed.//!   # use anyhow::anyhow;//!   # use std::fmt::{self, Display};//!   # use std::task::Poll;//!   # #[derive(Debug)]//!   # enum DataStoreError {//!   #     Censored(()),//!   # impl Display for DataStoreError {//!   #     fn fmt(&self, formatter: &mut fmt::Formatter) -> fmt::Result {//!   # impl std::error::Error for DataStoreError {}//!   # const REDACTED_CONTENT: () = ();//!   # let error = anyhow!("...");//!   # let root_cause = &error;//!   # let ret =//!   // If the error was caused by redaction, then return a//!   // tombstone instead of the content.//!   match root_cause.downcast_ref::<DataStoreError>() {//!       Some(DataStoreError::Censored(_)) => Ok(Poll::Ready(REDACTED_CONTENT)),//!       None => Err(error),//!   # ;//! - If using Rust &ge; 1.65, a backtrace is captured and printed with the//!   error if the underlying error type does not already provide its own. In//!   order to see backtraces, they must be enabled through the environment//!   variables described in [`std::backtrace`]://!   - If you want panics and errors to both have backtraces, set//!     `RUST_BACKTRACE=1`;//!   - If you want only errors to have backtraces, set `RUST_LIB_BACKTRACE=1`;//!   - If you want only panics to have backtraces, set `RUST_BACKTRACE=1` and//!     `RUST_LIB_BACKTRACE=0`.//!   [`std::backtrace`]: std::backtrace#environment-variables//! - Anyhow works with any error type that has an impl of `std::error::Error`,//!   including ones defined in your crate. We do not bundle a `derive(Error)`//!   macro but you can write the impls yourself or use a standalone macro like//!   [thiserror].//!   [thiserror]: https://github.com/dtolnay/thiserror//!   use thiserror::Error;//!   #[derive(Error, Debug)]//!   pub enum FormatError {//!       #[error("Invalid header (expected {expected:?}, got {found:?})")]//!       InvalidHeader {//!           expected: String,//!           found: String,//!       },//!       #[error("Missing attribute: {0}")]//!       MissingAttribute(String),//! - One-off error messages can be constructed using the `anyhow!` macro, which//!   supports string interpolation and produces an `anyhow::Error`.//!   # use anyhow::{anyhow, Result};//!   # fn demo() -> Result<()> {//!   #     let missing = "...";//!   return Err(anyhow!("Missing attribute: {}", missing));//!   #     Ok(())//!   A `bail!` macro is provided as a shorthand for the same early return.//!   # use anyhow::{bail, Result};//!   bail!("Missing attribute: {}", missing);//! # No-std support//! In no_std mode, almost all of the same API is available and works the same//! way. To depend on Anyhow in no_std mode, disable our default enabled "std"//! feature in Cargo.toml. A global allocator is required.//! ```toml//! [dependencies]//! anyhow = { version = "1.0", default-features = false }//! With versions of Rust older than 1.81, no_std mode may require an additional//! `.map_err(Error::msg)` when working with a non-Anyhow error type inside a//! function that returns Anyhow's error type, as the trait that `?`-based error//! conversions are defined by is only available in std in those old versions.bail/// Return early with an error./// This macro is equivalent to/// <code>return Err([anyhow!($args\...)][anyhow!])</code>./// The surrounding function's or closure's return value is required to be/// <code>Result&lt;_, [anyhow::Error][crate::Error]&gt;</code>./// [anyhow!]: crate::anyhow/// # use anyhow::{bail, Result};/// # fn has_permission(user: usize, resource: usize) -> bool {/// #     true/// # fn main() -> Result<()> {/// #     let user = 0;/// #     let resource = 0;/// if !has_permission(user, resource) {///     bail!("permission denied for accessing {}", resource);/// #     Ok(())/// # use thiserror::Error;/// # const MAX_DEPTH: usize = 1;/// enum ScienceError {///     #[error("recursion limit exceeded")]///     RecursionLimitExceeded,///     # #[error("...")]///     # More = (stringify! {///     # }, 1).1,/// #     let depth = 0;/// if depth > MAX_DEPTH {///     bail!(ScienceError::RecursionLimitExceeded);__ensurer" Return early with an error if a condition is not satisfied."r" This macro is equivalent to"r" <code>if !$cond { return Err([anyhow!($args\...)][anyhow!]); }</code>."r" The surrounding function's or closure's return value is required to be"r" <code>Result&lt;_, [anyhow::Error][crate::Error]&gt;</code>."r" Analogously to `assert!`, `ensure!` takes a condition and exits the function"r" if the condition fails. Unlike `assert!`, `ensure!` returns an `Error`"r" rather than panicking."r" [anyhow!]: crate::anyhow"r" # Example"r" ```"r" # use anyhow::{ensure, Result};"r" #"r" # fn main() -> Result<()> {"r" #     let user = 0;"r#" ensure!(user == 0, "only user 0 is allowed");"#r" #     Ok(())"r" # }"r" # use thiserror::Error;"r" # const MAX_DEPTH: usize = 1;"r" #[derive(Error, Debug)]"r" enum ScienceError {"r#"     #[error("recursion limit exceeded")]"#r"     RecursionLimitExceeded,"r#"     # #[error("...")]"#r"     # More = (stringify! {"r"     ..."r"     # }, 1).1,"r" }"r" #     let depth = 0;"r" ensure!(depth <= MAX_DEPTH, ScienceError::RecursionLimitExceeded);"/// Construct an ad-hoc error from a string or existing non-`anyhow` error/// value./// This evaluates to an [`Error`][crate::Error]. It can take either just a/// string, or a format string with arguments. It also can take any custom type/// which implements `Debug` and `Display`./// If called with a single argument whose type implements `std::error::Error`/// (in addition to `Debug` and `Display`, which are always required), then that/// Error impl's `source` is preserved as the `source` of the resulting/// `anyhow::Error`./// # type V = ();/// use anyhow::{anyhow, Result};/// fn lookup(key: &str) -> Result<V> {///     if key.len() != 16 {///         return Err(anyhow!("key length must be 16 characters, got {:?}", key));///     // ...__anyhow// Not public API. This is used in the implementation of some of the other// macros, in which the must_use call is not needed because the value is known// to be used.request_ref_backtracerequest_refprovide_ref_backtrace// This code exercises the surface area that we expect of the Error generic// member access API. If the current toolchain is able to compile it, then// anyhow is able to provide backtrace support.UCastTocastby_refby_mutlifetimefrom_rawas_ptr// Force turbofish on all calls of `.cast::<U>()`.MessageErrorDisplayErrorBoxedErrormodelsshort_weierstrassSWCurveConfigCurveConfigAffineMontFpZeroFqFrG1AffineBaseFieldScalarFieldCOFACTOR/// COFACTOR = 1COFACTOR_INV/// COFACTOR_INV = COFACTOR^{-1} mod r = 1COEFF_A/// COEFF_A = 0COEFF_B/// COEFF_B = 3GENERATOR/// AFFINE_GENERATOR_COEFFS = (G1_GENERATOR_X, G1_GENERATOR_Y)mul_by_aG1_GENERATOR_X/// G1_GENERATOR_X = 1G1_GENERATOR_Y/// G1_GENERATOR_Y = 2Fq2G2Affine/// COFACTOR = (36 * X^4) + (36 * X^3) + (30 * X^2) + 6*X + 1/// 21888242871839275222246405745257275088844257914179612981679871602714643921549/// COFACTOR_INV = COFACTOR^{-1} mod r/// COEFF_A = [0, 0]/// COEFF_B = 3/(u+9)/// (19485874751759354771024239261021720505790618469301721065564631296452457478373, 266929791119991161246907387137283842545076965332900288569378510910307636690)/// AFFINE_GENERATOR_COEFFS = (G2_GENERATOR_X, G2_GENERATOR_Y)G2_GENERATOR_XG2_GENERATOR_YG2_GENERATOR_X_C0/// G2_GENERATOR_X_C0 =/// 10857046999023057135944570762232829481370756359578518086990519993285655852781G2_GENERATOR_X_C1/// G2_GENERATOR_X_C1 =/// 11559732032986387107991004021392285783925812861821192530917403151452391805634G2_GENERATOR_Y_C0/// G2_GENERATOR_Y_C0 =/// 8495653923123431417604973247489272438418190587263600148770280649306958101930G2_GENERATOR_Y_C1/// G2_GENERATOR_Y_C1 =/// 4082367875863433681332203403145435568316851327593401208105741076214120093531bnBnBnConfigTwistTypeg1g2XX_IS_NEGATIVE/// `x` is positive.ATE_LOOP_COUNTTWIST_MUL_BY_Q_XTWIST_MUL_BY_Q_YTWIST_TYPEFpFp2ConfigFq2ConfigFp6ConfigFq6ConfigFp12ConfigFq12ConfigG1ConfigG2ConfigBn254G1ProjectiveG2Projectiveark_algebra_test_templatestest_grouptest_pairingFp256MontBackendMontConfig"21888242871839275222246405745257275088696311157297823662689037894645226208583"modulus"3"generatorFqConfigfqconfig___Fq12Fp12NONRESIDUEFq6FROBENIUS_COEFF_FP12_C1Fp2/// NONRESIDUE = -1FROBENIUS_COEFF_FP2_C1/// Coefficients for the Frobenius automorphism.mul_fp_by_nonresidue_in_placeFp6/// NONRESIDUE = U+9FROBENIUS_COEFF_FP6_C1FROBENIUS_COEFF_FP6_C2mul_fp2_by_nonresidue_in_place"21888242871839275222246405745257275088548364400416034343698204186575808495617""5"FrConfigfrconfig___frfqfq2fq6fq12bigintegerBigIntBigIntegerBigInteger256FftFieldPrimeFieldUniformRandMulAssigntest_fieldtest_fq_repr_fromtest_fq_repr_is_oddtest_fq_repr_is_zerotest_fq_repr_num_bitstest_fq_num_bitstest_fq_root_of_unitytest_fq_orderingtest_fq_legendretest_fq2_orderingtest_fq2_basicstest_fq2_legendretest_fq6_mul_by_1test_fq6_mul_by_01test_fq12_mul_by_014test_fq12_mul_by_034curves//! This library implements the BN254 curve that was sampled as part of the [\[BCTV14\]](https://eprint.iacr.org/2013/879.pdf) paper .//! The name denotes that it is a Barreto--Naehrig curve of embedding degree 12,//! defined over a 254-bit (prime) field. The scalar field is highly 2-adic.//! This curve is also implemented in [libff](https://github.com/scipr-lab/libff/tree/master/libff/algebra/curves/alt_bn128) under the name `bn128`.//! It is the same as the `bn256` curve used in Ethereum (eg: [go-ethereum](https://github.com/ethereum/go-ethereum/tree/master/crypto/bn254/cloudflare)).//! #CAUTION//! **This curve does not satisfy the 128-bit security level anymore.**//! Curve information://! * Base field: q =//!   21888242871839275222246405745257275088696311157297823662689037894645226208583//! * Scalar field: r =//!   21888242871839275222246405745257275088548364400416034343698204186575808495617//! * valuation(q - 1, 2) = 1//! * valuation(r - 1, 2) = 28//! * G1 curve equation: y^2 = x^3 + 3//! * G2 curve equation: y^2 = x^3 + B, where//!    * B = 3/(u+9) where Fq2 is represented as Fq\[u\]/(u^2+1) =//!      Fq2(19485874751759354771024239261021720505790618469301721065564631296452457478373,//!      266929791119991161246907387137283842545076965332900288569378510910307636690)swuwbhashingmap_to_curve_hasherMapToCurveHashToCurveErrorProjectiveZETA/// An element of the base field that is not a square root see \[WB2019, Section 4\]./// It is also convenient to have $g(b/ZETA * a)$ to be square. In general/// we use a `ZETA` with low absolute value coefficients when they are/// represented as integers.SWUConfig/// Trait defining the necessary parameters for the SWU hash-to-curve method/// for the curves of Weierstrass form of:/// y^2 = x^3 + a*x + b where ab != 0. From [\[WB2019\]]/// - [\[WB2019\]] <https://eprint.iacr.org/2019/403>SWUMap/// Represents the SWU hash-to-curve map defined by `P`.parity/// Trait defining a parity method on the Field elements based on [\[1\]] Section 4.1/// - [\[1\]] <https://datatracker.ietf.org/doc/draft-irtf-cfrg-hash-to-curve/>/// Constructs a new map if `P` represents a valid map.map_to_curve/// Map an arbitrary base field element to a curve point./// Based on/// <https://github.com/zcash/pasta_curves/blob/main/src/hashtocurve.rs>.MapToCurveBasedHasherHashToCurvefield_hashersDefaultFieldHasherFp64"127""6"F127Configf127config___F127F127_ONETestSWUMapToCurveConfig/// COEFF_A = 1/// COEFF_B = 63/// just because not defining another field/// from itertools import product/// p = 127/// FF = GF(p)/// for a,b in product(range(0,p), range(0,p)):///     try:///         E = EllipticCurve([FF(a),FF(b)])///         if E.order() == p:///             print(E)///     except:///         pass/// y^2 = x^3 + x + 63test_field_element_construction/// test that MontFp make a none zero element out of 1test_field_divisionhash_arbitary_string_to_curve_swu/// The point of the test is to get a simple SWU compatible curve and make/// simple hashmap_field_to_curve_swu/// Use a simple SWU compatible curve and map the whole field to it. We observe/// the map behaviour. Specifically, the map should be non-constant, all/// elements should be mapped to curve successfully. everything can be mappedbatch_inversionunivariateDensePolynomialDenseUVPolynomialPolynomialAffineReprMPx_map_numeratorDomainx_map_denominatorCodomainy_map_numeratory_map_denominatorIsogenyMap/// [`IsogenyMap`] defines an isogeny between curves of/// form `Phi(x, y) := (a(x), b(x)*y)./// The `x` coordinate of the codomain point only depends on the/// `x`-coordinate of the domain point, and the/// `y`-coordinate of the codomain point is a multiple of the `y`-coordinate of the domain point./// The multiplier depends on the `x`-coordinate of the domain point./// All isogeny maps of curves of short Weierstrass form can be written in this way. See/// [\[Ga18]\]. Theorem 9.7.5 for details./// We assume that `Domain` and `Codomain` have the same `BaseField` but we use both/// `BaseField<Domain>` and `BaseField<Codomain>` in our fields' definitions to avoid/// using `PhantomData`/// - [\[Ga18]\] Galbraith, S. D. (2018). Mathematics of public key cryptography.applyIsogenousCurve// The isogenous curve should be defined over the same base field but it can have// different scalar field type IsogenousCurveScalarField :ISOGENY_MAPWBConfig/// Trait defining the necessary parameters for the WB hash-to-curve method/// of y^2 = x^3 + a*x + b where b != 0 but `a` can be zero like BLS-381 curve./// From [\[WB2019\]]/// - [\[WB2019\]] <http://dx.doi.org/10.46586/tches.v2019.i4.154-179>swu_field_curve_hashercurve_paramsWBMap/// Map random field point to a random curve point/// inspired from/// <https://github.com/zcash/pasta_curves/blob/main/src/hashtocurve.rs>curve_mapsF127_ZEROTestWBF127MapToCurveConfig/// The struct defining our parameters for the target curve of hashing/// E: Elliptic Curve defined by y^2 = x^3 + 3 over Finite/// Field of size 127TestSWU127MapToIsogenousCurveConfig/// Testing WB19 hashing on a small curve/// E_isogenous : Elliptic Curve defined by y^2 = x^3 + 109*x + 124 over Finite/// Isogenous to E : y^2 = x^3 + 3/// First we define the isogenous curve/// sage: E_isogenous.order()/// 127/// COEFF_A = 109/// COEFF_B = 124/// NON-SQUARE = - 1/// SWU parameters for E_isogenousISOGENY_MAP_TESTWBF127/// With psi: E_isogenous -> E/// psi = (psi_x(x,y), psi_y(x,y))/// psi_x: (-57*x^13 - 21*x^12 + 10*x^11 + 34*x^10 + 40*x^9 -/// 13*x^8 + 32*x^7 - 32*x^6 + 23*x^5 - 14*x^4 + 39*x^3 + 23*x^2 + 63*x +/// 4)/(x^12 - 13*x^11 + 11*x^10 - 33*x^9 - 30*x^8 + 30*x^7 + 34*x^6 - 44*x^5 +/// 63*x^4 - 20*x^3 - 10*x^2 + 31*x + 2)/// psi_y: (10*x^18*y + 59*x^17*y + 41*x^16*y + 48*x^15*y - 7*x^14*y + 6*x^13*y +/// 5*x^12*y + 62*x^11*y + 12*x^10*y + 36*x^9*y - 49*x^8*y - 18*x^7*y - 63*x^6*y/// - 43*x^5*y - 60*x^4*y - 18*x^3*y + 30*x^2*y - 57*x*y - 34*y)/(x^18 + 44*x^17/// - 63*x^16 + 52*x^15 + 3*x^14 + 38*x^13 - 30*x^12 + 11*x^11 - 42*x^10 - 13*x^9/// - 46*x^8 - 61*x^7 - 16*x^6 - 55*x^5 + 18*x^4 + 23*x^3 - 24*x^2 - 18*x + 32)hash_arbitrary_string_to_curve_wb/// The point of the test is to get a simple WB compatible curve/// and make simple hashCurveGroupHashToField/// Constructs a new mapping./// Map an arbitary field element to a corresponding curve point./// Trait for mapping a random field element to a random curve point.field_hasherH2Fcurve_mapperM2C_params_t/// Helper struct that can be used to construct elements on the elliptic curve/// from arbitrary messages, by first hashing the message onto a field element/// and then mapping it to the elliptic curve defined over that field.// Produce a hash of the message, using the hash to field and map to curve// traits. This uses the IETF hash to curve's specification for Random// oracle encoding (hash_to_curve) defined by combining these components.// See https://tools.ietf.org/html/draft-irtf-cfrg-hash-to-curve-09#section-3/// Create a new hash to curve instance, with a given domain./// Produce a hash of the message, which also depends on the domain./// The output of the hash is a curve point in the prime order subgroup/// of the given elliptic curve./// Trait for hashing arbitrary data to a group element on an elliptic curveUnsupportedCurveError/// Curve choice is unsupported by the given HashToCurve method.MapToCurveError/// Error with map to curve/// This is an error that could occur during the hash to curve processark_test_curvesbls12_381test_parity_of_prime_field_elementstest_parity_of_quadratic_extension_elementstest_parity_of_cubic_extension_elementsinclude_strCanonicalDeserializeCanonicalSerializeAddMulNegSubAssignscalar_mulvariable_baseVariableBaseMSMScalarMul/// Provides a `HashToCurve` trait and implementations of this trait via/// different hashing strategies.pairing/// The scalar field `F_r`, where `r` is the order of this group./// Returns a fixed generator of this group.double/// Doubles `self`.double_in_place/// Double `self` in place.mul_bigint/// Performs scalar multiplication of this element.mul_bits_be/// Computes `other * self`, where `other` is a *big-endian*/// bit representation of some integer.GroupSum/// Represents (elements of) a group of prime order `r`./// The field over which this curve is defined./// The affine representation of this element.FullGroup/// Type representing an element of the full elliptic curve group, not just the/// prime order subgroup.normalize_batch/// Normalizes a slice of group elements into affine.into_affine/// Converts `self` into the affine representation.MulBase// + for<'a> Add<&'a Self::Affine, Output = Self>// + for<'a> AddAssign<&'a Self::Affine>/// An opaque representation of an elliptic curve group element that is suitable/// for efficient group arithmetic./// The point is guaranteed to be in the correct prime order subgroup./// The finite field over which this curve is defined./// The projective representation of points on this curve.xy/// Returns the x and y coordinates of this affine point.x/// Returns the x coordinate of this affine point.y/// Returns the y coordinate of this affine point./// Returns the point at infinity./// Is `self` the point at infinity?/// Returns a fixed generator of unknown exponent.into_group/// Converts self into the projective representation.from_random_bytes/// Returns a group element if the set of bytes forms a valid group element,/// otherwise returns None. This function is primarily intended for sampling/// random group elements from a hash-function or RNG output./// Performs scalar multiplication of this element with mixed addition.clear_cofactor/// Performs cofactor clearing./// The default method is simply to multiply by the cofactor./// For some curve families more efficient methods exist.mul_by_cofactor_to_group/// Multiplies this element by the cofactor and output the/// resulting projective element.mul_by_cofactor/// Multiplies this element by the cofactor.mul_by_cofactor_inv/// Multiplies this element by the inverse of the cofactor in/// `Self::ScalarField`.// needed due to https://github.com/rust-lang/rust/issues/69640/// The canonical representation of an elliptic curve group element./// This should represent the affine coordinates of the point corresponding/// to this group element.E1E2CurveCycle/// Wrapper trait representing a cycle of elliptic curves (E1, E2) such that/// the base field of E1 is the scalar field of E2, and the scalar field of E1/// is the base field of E2.Engine1G1PairingEngine2PairingFriendlyCycle/// A cycle of curves where both curves are pairing-friendly.bls12Bls12ConfigG1Preparedserialize_with_modeCompressSerializationErrorserialized_sizedeserialize_with_modeValidatebatch_checkValidBitIteratorBEell_coeffsEllCoeff// Stores the coefficients of the line evaluations as calculated in// https://eprint.iacr.org/2013/722.pdfinfinityG2PreparedzG2HomProjectiveadd_in_placeMillerLoopOutputPairingOutputfp12_2over3over2fp2fp6_3over2CyclotomicMultSubgroup/// A particular BLS12 group can have G2 being either a multiplicative or a/// divisive twist./// Parameterizes the BLS12 family./// Is `Self::X` negative?/// What kind of twist is this?multi_miller_loopBls12final_exponentiationell// Evaluate the line function at point p.exp_by_x// Exponentiates `f` by `Self::X`, and stores the result in `result`.G2TargetFieldmul_by_charItertools/// The absolute value of the BN curve parameter `X`/// (as in `q = 36 X^4 + 36 X^3 + 24 X^2 + 6 X + 1`)./// Whether or not `X` is negative./// The absolute value of `6X + 2`./// Evaluates the line function at point p.exp_by_neg_xbw6BW6Configell_coeffs_1ell_coeffs_2fp3Fp3Configfp6_2over3ATE_LOOP_COUNT_1ATE_LOOP_COUNT_1_IS_NEGATIVEATE_LOOP_COUNT_2ATE_LOOP_COUNT_2_IS_NEGATIVEBW6final_exponentiation_first_chunkfinal_exponentiation_last_chunkmnt4MNT4Configx_twisty_twistMNT4x_over_twisty_over_twistdouble_coefficientsAteDoubleCoefficientsaddition_coefficientsAteAdditionCoefficientsG2ProjectiveExtendedc_hc_4cc_jc_lc_l1c_rzfp4Fp4Fp4ConfigGTTWISTTWIST_COEFF_AATE_IS_LOOP_COUNT_NEGFINAL_EXPONENT_LAST_CHUNK_1FINAL_EXPONENT_LAST_CHUNK_W0_IS_NEGFINAL_EXPONENT_LAST_CHUNK_ABS_OF_W0doubling_for_flipped_miller_loopmixed_addition_for_flipped_miller_loopate_miller_loopmnt6MNT6ConfigFp3MNT6mixed_addition_for_flipper_miller_looptwisted_edwards/// Base field that the curve is defined over./// Finite prime field corresponding to an appropriate prime-order subgroup/// of the curve group./// The cofactor of this curve, represented as a sequence of little-endian limbs.cofactor_is_one/// Elliptic curves can be represented via different "models" with varying/// efficiency properties./// `CurveConfig` bundles together the types that are common/// to all models of the given curve, namely the `BaseField` over which the/// curve is defined, and the `ScalarField` defined by the appropriate/// prime-order subgroup of the curve.FmtResultdistributionsDistributionRngToConstraintFieldSWFlags/// Affine coordinates for a point on an elliptic curve in short Weierstrass/// form, over the base field `P::BaseField`./// Constructs a group element from x and y coordinates./// Performs checks to ensure that the point is on the curve and is in the right subgroup./// # Warning/// Does *not* perform any checks to ensure the point is in the curve or/// is in the right subgroup.identityget_point_from_x_unchecked/// Attempts to construct an affine point given an x-coordinate. The/// point is not guaranteed to be in the prime order subgroup./// If and only if `greatest` is set will the lexicographically/// largest y-coordinate be selected.get_ys_from_x_unchecked/// Returns the two possible y-coordinates corresponding to the given x-coordinate./// The corresponding points are not guaranteed to be in the prime-order subgroup,/// but are guaranteed to be on the curve. That is, this method returns `None`/// if the x-coordinate corresponds to a non-curve point./// The results are sorted by lexicographical order./// This means that, if `P::BaseField: PrimeField`, the results are sorted as integers.is_on_curve/// Checks if `self` is a valid point on the curve.to_flagsis_in_correct_subgroup_assuming_on_curve/// Checks if `self` is in the subgroup having order that equaling that of/// `P::ScalarField`.// DISCUSS Maybe these function names are too verbose?// The phantom data does not contain element-specific data// and thus does not need to be zeroized.sample/// Generates a uniformly random instance of the curve./// Some curves can implement a more efficient algorithm.neg/// If `self.is_zero()`, returns `self` (`== Self::zero()`)./// Else, returns `(x, -y)`, where `self = (x, y)`.mul// The projective point X, Y, Z is represented in the affine// coordinates as X/Z^2, Y/Z^3.to_field_elementsConstraintF/// `X / Z` projection of the affine `X`/// `Y / Z` projection of the affine `Y`/// Projective multiplicative inverse. Will be `0` only at infinity./// Jacobian coordinates for a point on an elliptic curve in short Weierstrass/// form, over the base field `P::BaseField`. This struct implements arithmetic/// via the Jacobian formulae/// Constructs a new group element without checking whether the coordinates/// specify a point in the subgroup./// Constructs a new group element in a way while enforcing that points are in/// the prime-order subgroup./// Returns the point at infinity, which always has Z = 0./// Checks whether `self.z.is_zero()`./// Sets `self = 2 * self`. Note that Jacobian formulae are incomplete, and/// so doubling cannot be computed as `self + self`. Instead, this/// implementation uses the following specialized doubling formulae:/// * [`P::A` is zero](http://www.hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html#doubling-dbl-2009-l)/// * [`P::A` is not zero](https://www.hyperelliptic.org/EFD/g1p/auto-shortw-jacobian.html#doubling-dbl-2007-bl)/// Normalizes a slice of projective elements so that/// conversion to affine is cheap./// In more detail, this method converts a curve point in Jacobian/// coordinates (x, y, z) into an equivalent representation (x/z^2,/// y/z^3, 1)./// For `N = v.len()`, this costs 1 inversion + 6N field multiplications + N/// field squarings./// (Where batch inversion comprises 3N field multiplications + 1 inversion/// of these operations)add_assign/// Using http://www.hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html#addition-madd-2007-blsub_assignimpl_additive_ops_from_refmul_assign// The affine point X, Y is represented in the Jacobian// coordinates with Z = 1.NEGATION_IS_CHEAPbatch_convert_to_mul_basemsmCanonicalDeserializeWithFlagsCanonicalSerializeWithFlagsaffineserialization_flags/// Coefficient `a` of the curve equation./// Coefficient `b` of the curve equation./// Generator of the prime-order subgroup./// Helper method for computing `elem * Self::COEFF_A`./// The default implementation should be overridden only if/// the product can be computed faster than standard field multiplication/// (eg: via doubling if `COEFF_A == 2`, or if `COEFF_A.is_zero()`).add_b/// Helper method for computing `elem + Self::COEFF_B`./// the sum can be computed faster than standard field addition (eg: via/// doubling)./// Check if the provided curve point is in the prime-order subgroup./// The default implementation multiplies `item` by the order `r` of the/// prime-order subgroup, and checks if the result is one./// Implementors can choose to override this default impl/// if the given curve has faster methods/// for performing this check (for example, via leveraging curve/// isomorphisms).mul_projective/// Default implementation of group multiplication for projective/// coordinatesmul_affine/// Default implementation of group multiplication for affine/// coordinates./// Default implementation for multi scalar multiplication/// If uncompressed, serializes both x and y coordinates as well as a bit for whether it is/// infinity. If compressed, serializes x coordinate with two bits to encode whether y is/// positive, negative, or infinity./// If `validate` is `Yes`, calls `check()` to make sure the element is valid./// Constants and convenience functions that collectively define the [Short Weierstrass model](https://www.hyperelliptic.org/EFD/g1p/auto-shortw.html)/// of the curve. In this model, the curve equation is `y² = x³ + a * x + b`,/// for constants `a` and `b`.Flags0YIsPositive/// Represents a point with positive y-coordinate by setting the MSB to 1.6<<PointAtInfinity/// Represents the point at infinity by setting the setting the last-but-one bit to 1.7YIsNegative/// Represents a point with negative y-coordinate by setting all bits to 0./// Flags to be encoded into the serialization./// The default flags (empty) should not change the binary representation.from_y_coordinateis_infinityis_positiveBIT_SIZEu8_bitmaskfrom_u8TECurveConfigTEFlags/// X coordinate of the point represented as a field element/// Y coordinate of the point represented as a field element/// Affine coordinates for a point on a twisted Edwards curve, over the/// base field `P::BaseField`./// Construct a new group element without checking whether the coordinates/// Construct a new group element in a way while enforcing that points are in/// Construct the identity of the group/// Is this point the identity?get_point_from_y_unchecked/// Attempts to construct an affine point given an y-coordinate. The/// largest x-coordinate be selected./// a * X^2 + Y^2 = 1 + d * X^2 * Y^2/// a * X^2 - d * X^2 * Y^2 = 1 - Y^2/// X^2 * (a - d * Y^2) = 1 - Y^2/// X^2 = (1 - Y^2) / (a - d * Y^2)get_xs_from_y_unchecked/// Attempts to recover the x-coordinate given an y-coordinate. The/// resulting point is not guaranteed to be in the prime order subgroup./// Checks that the current point is on the elliptic curve./// Checks if `self` is in the subgroup having order equaling that of/// `P::ScalarField` given it is on the curve.// The projective point X, Y, T, Z is represented in the affine// coordinates as X/Z, Y/Z.MontCurveConfig/// `Projective` implements Extended Twisted Edwards Coordinates/// as described in [\[HKCD08\]](https://eprint.iacr.org/2008/522.pdf)./// This implementation uses the unified addition formulae from that paper (see/// Section 3.1).// The affine point (X, Y) is represented in the Extended Projective coordinates// with Z = 1.MontgomeryAffineCOEFF_D/// Coefficient `d` of the curve equation./// Model parameters for the Montgomery curve that is birationally/// equivalent to this curve./// Checks that the current point is in the prime order subgroup given/// the point on the curve./// For some curve families though, it is sufficient to multiply/// by a smaller scalar./// If uncompressed, serializes both x and y coordinates./// If compressed, serializes y coordinate with a bit to encode whether x is positive./// Uses `Affine::get_xs_from_y_unchecked()` for the compressed version./// Constants and convenience functions that collectively define the [Twisted Edwards model](https://www.hyperelliptic.org/EFD/g1p/auto-twisted.html)/// of the curve. In this model, the curve equation is/// `a * x² + y² = 1 + d * x² * y²`, for constants `a` and `d`./// Model parameters for the Twisted Edwards curve that is birationally/// Constants and convenience functions that collectively define the [Montgomery model](https://www.hyperelliptic.org/EFD/g1p/auto-montgom.html)/// `b * y² = x³ + a * x² + x`, for constants `a` and `b`.//////////////////////////////////////////////////////////////////////////////XIsPositiveXIsNegativefrom_x_coordinateis_negative/// This is the base field of the G1 group and base prime field of G2./// This is the scalar field of the G1/G2 groups./// An element in G1./// A G1 element that has been preprocessed for use in a pairing./// An element of G2./// The affine representation of an element in G2./// A G2 element that has been preprocessed for use in a pairing./// The extension field that hosts the target group of the pairing./// Computes the product of Miller loops for some number of (G1, G2) pairs.miller_loop/// Computes the Miller loop over `a` and `b`./// Performs final exponentiation of the result of a `Self::multi_miller_loop`.multi_pairing/// Computes a "product" of pairings./// Performs multiple pairing operations/// Collection of types (mainly fields and curves) that together describe/// how to compute a pairing over a pairing-friendly curve./// Represents the target group of a pairing. This struct is a/// wrapper around the field that the target group is embedded in./// The identity element, or "zero", of the group is the identity element of the multiplicative group of the underlying field, i.e., `P::TargetField::one()`./// Represents the output of the Miller loop of the pairing.prepare_g1/// Preprocesses a G1 element for use in a pairing.prepare_g2/// Preprocesses a G2 element for use in a pairing.cfg_itercfg_iter_mutFixedBaseget_mul_window_sizeget_window_tablewindowed_mul// TODO use const-generics for the scalar size and window// TODO use iterators of iterators of T::Affine instead of taking owned VecCurve/// A representation of curve points that enables efficient arithmetic by/// avoiding inversions.COEFF_A1/// Coefficient `a_1` of `f(y) = a_1 * (y + a_2) * (y + a_3)`.COEFF_A2/// Coefficient `a_2` of `f(y) = a_1 * (y + a_2) * (y + a_3)`.COEFF_A3/// Coefficient `a_3` of `f(y) = a_1 * (y + a_2) * (y + a_3)`.COEFF_B1/// Coefficient `b_1` of `g(y) = b_1 * (y + b_2) * (y + b_3)`.COEFF_B2/// Coefficient `b_2` of `g(y) = b_1 * (y + b_2) * (y + b_3)`.COEFF_B3/// Coefficient `b_3` of `g(y) = b_1 * (y + b_2) * (y + b_3)`.COEFF_C1/// Coefficient `c_1` of `h(y) = (y + c_1) * (y + c_2)`.COEFF_C2/// Coefficient `c_2` of `h(y) = (y + c_1) * (y + c_2)`.COEFF_N11/// The first element of the matrix for scalar decomposition.COEFF_N12/// The second element of the matrix for scalar decomposition.COEFF_N21/// The third element of the matrix for scalar decomposition.COEFF_N22/// The forth element of the matrix for the scalar decomposition.endomorphism/// Maps a point G to phi(G):= lambda G where psi is the endomorphism.// On an affine curve, the function takes the following steps://  f(y) = a_1 * (y + a_2) * (y + a_3)//  g(y) = b_1 * (y + b_2) * (y + b_3)//  h(y) = (y + c_1) * (y + c_2)//  return (x',y') where//  x' = x * f(y) / y//  y' = g(y) / h(y)scalar_decomposition/// Decomposes a scalar s into k1, k2, s.t. s = k1 + lambda k2,glv_mul/// Performs GLV multiplication.// Constants that are used to calculate `phi(G) := lambda*G`.// Constants for scalar decomposition.// This is a 2x2 matrix, which is practically the LLL-reduced bases.GLVConfig/// The GLV parameters for computing the endomorphism and scalar decomposition.glvwnaffixed_baseln_without_floats/// The result of this function is only approximately `ln(a)`/// [`Explanation of usage`]/// [`Explanation of usage`]: https://github.com/scipr-lab/zexe/issues/79#issue-556220473iterableIterablestream_pippengermsm_unchecked/// Computes an inner product between the [`PrimeField`] elements in `scalars`/// and the corresponding group elements in `bases`./// If the elements have different length, it will chop the slices to the/// shortest length between `scalars.len()` and `bases.len()`./// Reference: [`VariableBaseMSM::msm`]/// Performs multi-scalar multiplication, without checking that `bases.len() == scalars.len()`./// This method checks that `bases` and `scalars` have the same length./// If they are unequal, it returns an error containing/// the shortest length over which the MSM can be performed.msm_bigint/// Optimized implementation of multi-scalar multiplication.Jmsm_chunks/// Streaming multi-scalar multiplication algorithm with hard-coded chunk/// size.msm_bigint_wnaf// Compute msm using windowed non-adjacent formmake_digits// From: https://github.com/arkworks-rs/gemini/blob/main/src/kzg/msm/variable_base.rs#L20scalars_bufferGbases_bufferbuf_sizeChunkedPippenger/// Struct for the chunked Pippenger algorithm./// Initialize a chunked Pippenger instance with default parameters.with_size/// Initialize a chunked Pippenger instance with the given buffer size./// Add a new (base, scalar) pair into the instance.finalize/// Output the final Pippenger algorithm result.HashMapPippenger/// Hash map struct for Pippenger algorithm./// Produce a new hash map with the maximum msm buffer size./// Add a new (base, scalar) pair into the hash map./// Update the final result with (base, scalar) pairs in the hash map.//! A space-efficient implementation of Pippenger's algorithm.window_sizeWnafContext/// A helper type that contains all the context required for computing/// a window NAF multiplication of a group element by a scalar./// Constructs a new context for a window of size `window_size`./// This function will panic if not `2 <= window_size < 64`table/// Computes scalar multiplication of a group element `g` by `scalar`./// This method uses the wNAF algorithm to perform the scalar/// multiplication; first, it uses `Self::table` to calculate an/// appropriate table of multiples of `g`, and then uses the wNAF/// algorithm to compute the scalar multiple.mul_with_table/// Computes scalar multiplication of a group element by `scalar`./// `base_table` holds precomputed multiples of the group element; it can be/// generated using `Self::table`. `scalar` is an element of/// `G::ScalarField`./// Returns `None` if the table is too small.adc/// Sets a = a + b + carry, and returns the new carry.adc_for_add_with_carryadc_no_carry/// Calculate a + b + carry, returning the sumsbb/// Sets a = a - b - borrow, and returns the borrow.sbb_for_sub_with_borrowmac/// Calculate a + b * c, returning the lower 64 bits of the result and setting/// `carry` to the upper 64 bits.mac_discard/// Calculate a + b * c, discarding the lower 64 bits of the result and settingmac_with_carry/// Calculate a + (b * c) + carry, returning the least significant digit/// and setting carry to the most significant digit.find_naf/// Compute the NAF (non-adjacent form) of numfind_relaxed_naf/// We define relaxed NAF as a variant of NAF with a very small tweak./// Note that the cost of scalar multiplication grows with the length of the sequence (for doubling)/// plus the Hamming weight of the sequence (for addition, or subtraction)./// NAF is optimizing for the Hamming weight only and therefore can be suboptimal./// For example, NAF may generate a sequence (in little-endian) of the form ...0 -1 0 1./// This can be rewritten as ...0 1 1 to avoid one doubling, at the cost that we are making an/// exception of non-adjacence for the most significant bit./// Since this representation is no longer a strict NAF, we call it "relaxed NAF".test_find_relaxed_naf_usefulnesstest_find_relaxed_naf_correctnessBitIteratorLEconst_forunroll_for_loopsUpperHexBigUintarithmetic/// Construct a [`struct@BigInt<N>`] element from a literal string./// If the integer represented by the string cannot fit in the number/// of limbs of the `BigInt`, this macro results in a/// * compile-time error if used in a const context/// * run-time error otherwise./// # use ark_ff::BigInt;/// const ONE: BigInt<6> = BigInt!("1");/// fn check_correctness() {///     assert_eq!(ONE, BigInt::from(1u8));const_moduloconst_is_evenconst_is_oddmod_4const_shr/// Compute a right shift of `self`/// This is equivalent to a (saturating) division by 2.const_geqtwo_adic_valuation/// Compute the largest integer `s` such that `self = 2**s * t + 1` for odd `t`.two_adic_coefficient/// Compute the smallest odd integer `t` such that `self = 2**s * t + 1` for some/// integer `s = self.two_adic_valuation()`.divide_by_2_round_down/// Divide `self` by 2, rounding down if necessary./// That is, if `self.is_odd()`, compute `(self - 1)/2`./// Else, compute `self/2`.const_num_bits/// Find the number of bits in the binary decomposition of `self`.const_sub_with_borrowconst_add_with_carryconst_mul2_with_carryconst_is_zeromontgomery_r/// Computes the Montgomery R constant modulo `self`.montgomery_r2/// Computes the Montgomery R2 constant modulo `self`.NUM_LIMBSadd_with_carrysub_with_borrowmul2mulndiv2divnis_oddis_evennum_bitsget_bitfrom_bits_befrom_bits_leto_bytes_beto_bytes_leas_mut/// Returns `Err(())` if the bit size of `val` is more than `N * 64`.signed_mod_reduction/// Compute the signed modulo operation on a u64 representation, returning the result./// If n % modulus > modulus / 2, return modulus - n/// use ark_ff::signed_mod_reduction;/// let res = signed_mod_reduction(6u64, 8u64);/// assert_eq!(res, -2i64);BigInteger64BigInteger128BigInteger3205BigInteger384BigInteger448BigInteger76812BigInteger832/// Number of 64-bit limbs representing `Self`./// Add another [`BigInteger`] to `self`. This method stores the result in `self`,/// and returns a carry bit./// use ark_ff::{biginteger::BigInteger64 as B, BigInteger as _};/// // Basic/// let (mut one, mut x) = (B::from(1u64), B::from(2u64));/// let carry = x.add_with_carry(&one);/// assert_eq!(x, B::from(3u64));/// assert_eq!(carry, false);/// // Edge-Case/// let mut x = B::from(u64::MAX);/// assert_eq!(x, B::from(0u64));/// assert_eq!(carry, true)/// Subtract another [`BigInteger`] from this one. This method stores the result in/// `self`, and returns a borrow./// let (mut one_sub, two, mut three_sub) = (B::from(1u64), B::from(2u64), B::from(3u64));/// let borrow = three_sub.sub_with_borrow(&two);/// assert_eq!(three_sub, one_sub);/// assert_eq!(borrow, false);/// let borrow = one_sub.sub_with_borrow(&two);/// assert_eq!(one_sub, B::from(u64::MAX));/// assert_eq!(borrow, true);/// Performs a leftwise bitshift of this number, effectively multiplying/// it by 2. Overflow is ignored./// let mut two_mul = B::from(2u64);/// two_mul.mul2();/// assert_eq!(two_mul, B::from(4u64));/// // Edge-Cases/// let mut zero = B::from(0u64);/// zero.mul2();/// assert_eq!(zero, B::from(0u64));/// let mut arr: [bool; 64] = [false; 64];/// arr[0] = true;/// let mut mul = B::from_bits_be(&arr);/// mul.mul2();/// assert_eq!(mul, B::from(0u64));/// Performs a leftwise bitshift of this number by n bits, effectively multiplying/// it by 2^n. Overflow is ignored./// let mut one_mul = B::from(1u64);/// one_mul.muln(5);/// assert_eq!(one_mul, B::from(32u64));/// zero.muln(5);/// arr[4] = true;/// mul.muln(5);/// Performs a rightwise bitshift of this number, effectively dividing/// it by 2./// let (mut two, mut four_div) = (B::from(2u64), B::from(4u64));/// four_div.div2();/// assert_eq!(two, four_div);/// zero.div2();/// let mut one = B::from(1u64);/// one.div2();/// assert_eq!(one, B::from(0u64));/// Performs a rightwise bitshift of this number by some amount./// let (mut one, mut thirty_two_div) = (B::from(1u64), B::from(32u64));/// thirty_two_div.divn(5);/// assert_eq!(one, thirty_two_div);/// let mut div = B::from_bits_le(&arr);/// div.divn(5);/// assert_eq!(div, B::from(0u64));/// Returns true iff this number is odd./// assert!(one.is_odd());/// Returns true iff this number is even./// let mut two = B::from(2u64);/// assert!(two.is_even());/// Returns true iff this number is zero./// assert!(zero.is_zero());/// Compute the minimum number of bits needed to encode this number./// let zero = B::from(0u64);/// assert_eq!(zero.num_bits(), 0);/// let one = B::from(1u64);/// assert_eq!(one.num_bits(), 1);/// let max = B::from(u64::MAX);/// assert_eq!(max.num_bits(), 64);/// let u32_max = B::from(u32::MAX as u64);/// assert_eq!(u32_max.num_bits(), 32);/// Compute the `i`-th bit of `self`./// assert!(one.get_bit(0));/// assert!(!one.get_bit(1));/// Returns the big integer representation of a given big endian boolean/// array./// arr[63] = true;/// assert_eq!(B::from_bits_be(&arr), one);/// ```   /// Returns the big integer representation of a given little endian boolean/// assert_eq!(B::from_bits_le(&arr), one);to_bits_be/// Returns the bit representation in a big endian boolean array,/// with leading zeroes./// let arr = one.to_bits_be();/// let mut vec = vec![false; 64];/// vec[63] = true;/// assert_eq!(arr, vec);/// ```  to_bits_le/// Returns the bit representation in a little endian boolean array,/// with trailing zeroes./// let arr = one.to_bits_le();/// vec[0] = true;/// Returns the byte representation in a big endian byte array,/// with leading zeros./// let arr = one.to_bytes_be();/// let mut vec = vec![0; 8];/// vec[7] = 1;/// Returns the byte representation in a little endian byte array,/// with trailing zeros./// let arr = one.to_bytes_le();/// vec[0] = 1;find_wnaf/// Returns the windowed non-adjacent form of `self`, for a window of size `w`./// This defines a `BigInteger`, a smart wrapper around a/// sequence of `u64` limbs, least-significant limb first.// TODO: get rid of this trait once we can use associated constants in const generics.biginteger_arithmetic_test// Test elementary math operations for BigInteger.biginteger_bits_test// Test correctness of BigInteger's bit valuesbiginteger_conversion_test// Test conversion from BigInteger to BigUinttest_biginteger// Wrapper test function for BigIntegertest_biginteger64test_biginteger128test_biginteger256test_biginteger384test_biginteger448test_biginteger768test_biginteger832sSlicen/// Iterates over a slice of `u64` in *big-endian* order.without_leading_zeros/// Construct an iterator that automatically skips any leading zeros./// That is, it skips all zeros before the most-significant one.max_len/// Iterates over a slice of `u64` in *little-endian* order.without_trailing_zeros/// Construct an iterator that automatically skips any trailing zeros./// That is, it skips all zeros after the most-significant one./// A helper macro for emulating `for` loops in a `const` context./// # use ark_ff::const_for;/// const fn for_in_const() {///     let mut array = [0usize; 4];///     const_for!((i in 0..(array.len())) { // We need to wrap the `array.len()` in parenthesis.///         array[i] = i;///     assert!(array[0] == 0);///     assert!(array[1] == 1);///     assert!(array[2] == 2);///     assert!(array[3] == 3);b0b1MulBuffer/// A buffer to hold values of size 2 * N. This is mostly/// a hack that's necessary until `generic_const_exprs` is stable.bufferslastSerBuffer/// A buffer to hold values of size 8 * N + 1 bytes. This is mostlyas_slicelast_n_plus_1_bytes_mutcopy_from_u8_slicecopy_from_u64_sliceto_bigintwrite_up_to/// Write up to `num_bytes` bytes from `self` to `other`./// `num_bytes` is allowed to range from `8 * (N - 1) + 1` to `8 * N + 1`.read_exact_up_to/// Read up to `num_bytes` bytes from `other` to `self`./// `num_bytes` is allowed to range from `8 * (N - 1)` to `8 * N + 1`.RBuffer/// Returns the `i`-th bit where bit 0 is the least significant one./// In other words, the bit with weight `2^i`.R2Buffertest_mul_buffer_correctnesstest_mul_buffer_soundness// Implements AddAssign on Self by deferring to an implementation on &Selfimpl_multiplicative_ops_from_ref// Implements `MulAssign` and `DivAssign` by deferring to an implementation on &SelfINVERSE_IS_FAST/// Is the inverse fast to compute? For example, in quadratic extensions, the inverse/// can be computed at the cost of negating one coordinate, which is much faster than/// standard inversion./// By default this is `false`, but should be set to `true` for quadratic extensions.cyclotomic_square/// Compute a square in the cyclotomic subgroup. By default this is computed using [`Field::square`](crate::Field::square), but for/// degree 12 extensions, this can be computed faster than normal squaring./// This method should be invoked only when `self` is in the cyclotomic subgroup.cyclotomic_square_in_place/// Square `self` in place. By default this is computed using/// [`Field::square_in_place`](crate::Field::square_in_place), but for degree 12 extensions,/// this can be computed faster than normal squaring.cyclotomic_inverse/// Compute the inverse of `self`. See [`Self::INVERSE_IS_FAST`] for details./// Returns [`None`] if `self.is_zero()`, and [`Some`] otherwise.cyclotomic_inverse_in_placecyclotomic_exp/// Compute a cyclotomic exponentiation of `self` with respect to `e`.cyclotomic_exp_in_place/// Set `self` to be the result of exponentiating `self` by `e`,/// using efficient cyclotomic algorithms./// Fields that have a cyclotomic multiplicative subgroup, and which can/// leverage efficient inversion and squaring algorithms for elements in this subgroup./// If a field has multiplicative order p^d - 1, the cyclotomic subgroups refer to subgroups of order φ_n(p),/// for any n < d, where φ_n is the [n-th cyclotomic polynomial](https://en.wikipedia.org/wiki/Cyclotomic_polynomial)./// ## Note/// Note that this trait is unrelated to the `Group` trait from the `ark_ec` crate. That trait/// denotes an *additive* group, while this trait denotes a *multiplicative* group.exp_loop/// Helper function to calculate the double-and-add loop for exponentiation./// The generator of the multiplicative group of the fieldTWO_ADICITY/// Let `N` be the size of the multiplicative group defined by the field./// Then `TWO_ADICITY` is the two-adicity of `N`, i.e. the integer `s`/// such that `N = 2^s * t` for some odd integer `t`.TWO_ADIC_ROOT_OF_UNITY/// 2^s root of unity computed by GENERATOR^tSMALL_SUBGROUP_BASE/// An integer `b` such that there exists a multiplicative subgroup/// of size `b^k` for some integer `k`.SMALL_SUBGROUP_BASE_ADICITY/// The integer `k` such that there exists a multiplicative subgroup/// of size `Self::SMALL_SUBGROUP_BASE^k`.LARGE_SUBGROUP_ROOT_OF_UNITY/// GENERATOR^((MODULUS-1) / (2^s */// SMALL_SUBGROUP_BASE^SMALL_SUBGROUP_BASE_ADICITY)) Used for mixed-radix/// FFT.get_root_of_unity/// Returns the root of unity of order n, if one exists./// If no small multiplicative subgroup is defined, this is the 2-adic root/// of unity of order n (for n a power of 2)./// If a small multiplicative subgroup is defined, this is the root of unity/// of order n for the larger subgroup generated by/// `FftConfig::LARGE_SUBGROUP_ROOT_OF_UNITY`/// (for n = 2^i * FftConfig::SMALL_SUBGROUP_BASE^j for some i, j)./// The interface for fields that are able to be used in FFTs.DynDigestExtendableOutputUpdateconstruct_dst_primeExpanderMAX_DST_LENGTHLONG_DST_PREFIX17xoferdstkExpanderXofblock_sizeExpanderXmd// The below implementation is a rework of https://github.com/armfazh/h2c-rust-ref// With some optimisationslibtest_mimicrunFailedTrialSha384Sha512Shake128Shake256read_dirFileBufReadervectorsTestExpanderExpanderVectordst_primelen_in_bytesmsg_primeuniform_bytesexpanderExpIDHashIDXMDXofIDXOFSHA256SHA384SHA512SHAKE128SHAKE256do_testget_expander/// Initialises a new hash-to-field helper struct./// # Arguments/// * `domain` - bytes that get concatenated with the `msg` during hashing, in order to separate potentially interfering instantiations of the hasher.hash_to_field/// Hash an arbitrary `msg` to #`count` elements from field `F`./// Trait for hashing messages to field elements.len_per_base_elem128SEC_PARAM/// This field hasher constructs a Hash-To-Field based on a fixed-output hash function,/// like SHA2, SHA3 or Blake2./// The implementation aims to follow the specification in [Hashing to Elliptic Curves (draft)](https://tools.ietf.org/pdf/draft-irtf-cfrg-hash-to-curve-13.pdf)./// use ark_ff::fields::field_hashers::{DefaultFieldHasher, HashToField};/// use ark_test_curves::bls12_381::Fq;/// use sha2::Sha256;/// let hasher = <DefaultFieldHasher<Sha256> as HashToField<Fq>>::new(&[1, 2, 3]);/// let field_elements: Vec<Fq> = hasher.hash_to_field(b"Hello, World!", 2);/// assert_eq!(field_elements.len(), 2);get_len_per_elem/// This function computes the length in bytes that a hash function should output/// for hashing an element of type `Field`./// See section 5.1 and 5.3 of the/// [IETF hash standardization draft](https://datatracker.ietf.org/doc/draft-irtf-cfrg-hash-to-curve/14/)EmptyFlagsDivDivAssignprimefft_friendlycyclotomicsqrtBasePrimeFieldBasePrimeFieldIterSQRT_PRECOMPSqrtPrecomputation/// Determines the algorithm for computing square roots./// The additive identity of the field.ONE/// The multiplicative identity of the field.characteristic/// Returns the characteristic of the field,/// in little-endian representation.extension_degree/// Returns the extension degree of this field with respect/// to `Self::BasePrimeField`.to_base_prime_field_elementsfrom_base_prime_field_elems/// Convert a slice of base prime field elements into a field element./// If the slice length != Self::extension_degree(), must return None.from_base_prime_field/// Constructs a field element from a single base prime field elements./// # use ark_ff::Field;/// # use ark_test_curves::bls12_381::Fq as F;/// # use ark_test_curves::bls12_381::Fq2 as F2;/// # use ark_std::One;/// assert_eq!(F2::from_base_prime_field(F::one()), F2::one());/// Returns `self + self`./// Doubles `self` in place.neg_in_place/// Negates `self` in place./// Attempt to deserialize a field element. Returns `None` if the/// deserialization fails./// This function is primarily intended for sampling random field elements/// from a hash-function or RNG output.from_random_bytes_with_flags/// Attempt to deserialize a field element, splitting the bitflags metadata/// according to `F` specification. Returns `None` if the deserialization/// fails.legendreLegendreSymbol/// Returns a `LegendreSymbol`, which indicates whether this field element/// is  1 : a quadratic residue///  0 : equal to 0/// -1 : a quadratic non-residue/// Returns the square root of self, if it exists.sqrt_in_place/// Sets `self` to be the square root of `self`, if it exists.square/// Returns `self * self`.square_in_place/// Squares `self` in place.inverse/// Computes the multiplicative inverse of `self` if `self` is nonzero.inverse_in_place/// If `self.inverse().is_none()`, this just returns `None`. Otherwise, it sets/// `self` to `self.inverse().unwrap()`.sum_of_products/// Returns `sum([a_i * b_i])`.frobenius_map_in_place/// Sets `self` to `self^s`, where `s = Self::BasePrimeField::MODULUS^power`./// This is also called the Frobenius automorphism.frobenius_map/// Returns `self^s`, where `s = Self::BasePrimeField::MODULUS^power`.pow/// Returns `self^exp`, where `exp` is an integer represented with `u64` limbs,/// least significant limb first.pow_with_table/// Exponentiates a field element `f` by a number represented with `u64`/// limbs, using a precomputed table containing as many powers of 2 of/// `f` as the 1 + the floor of log2 of the exponent `exp`, starting/// from the 1st power. That is, `powers_of_2` should equal `&[p, p^2,/// p^4, ..., p^(2^n)]` when `exp` has at most `n` bits./// This returns `None` when a power is missing from the table.Product/// The interface for a generic field.  /// Types implementing [`Field`] support common field operations such as addition, subtraction, multiplication, and inverses./// ## Defining your own field/// To demonstrate the various field operations, we can first define a prime ordered field $\mathbb{F}_{p}$ with $p = 17$. When defining a field $\mathbb{F}_p$, we need to provide the modulus(the $p$ in $\mathbb{F}_p$) and a generator. Recall that a generator $g \in \mathbb{F}_p$ is a field element whose powers comprise the entire field: $\mathbb{F}_p =\\{g, g^1, \ldots, g^{p-1}\\}$./// We can then manually construct the field element associated with an integer with `Fp::from` and perform field addition, subtraction, multiplication, and inversion on it./// use ark_ff::fields::{Field, Fp64, MontBackend, MontConfig};/// #[derive(MontConfig)]/// #[modulus = "17"]/// #[generator = "3"]/// pub struct FqConfig;/// pub type Fq = Fp64<MontBackend<FqConfig, 1>>;/// # fn main() {/// let a = Fq::from(9);/// let b = Fq::from(10);/// assert_eq!(a, Fq::from(26));          // 26 =  9 mod 17/// assert_eq!(a - b, Fq::from(16));      // -1 = 16 mod 17/// assert_eq!(a + b, Fq::from(2));       // 19 =  2 mod 17/// assert_eq!(a * b, Fq::from(5));       // 90 =  5 mod 17/// assert_eq!(a.square(), Fq::from(13)); // 81 = 13 mod 17/// assert_eq!(b.double(), Fq::from(3));  // 20 =  3 mod 17/// assert_eq!(a / b, a * b.inverse().unwrap()); // need to unwrap since `b` could be 0 which is not invertible/// ## Using pre-defined fields/// In the following example, we’ll use the field associated with the BLS12-381 pairing-friendly group./// use ark_ff::Field;/// use ark_test_curves::bls12_381::Fq as F;/// use ark_std::{One, UniformRand, test_rng};/// let mut rng = test_rng();/// // Let's sample uniformly random field elements:/// let a = F::rand(&mut rng);/// let b = F::rand(&mut rng);/// let c = a + b;/// let d = a - b;/// assert_eq!(c + d, a.double());/// let e = c * d;/// assert_eq!(e, a.square() - b.square());         // (a + b)(a - b) = a^2 - b^2/// assert_eq!(a.inverse().unwrap() * a, F::one()); // Euler-Fermat theorem tells us: a * a^{-1} = 1 mod p// Given a vector of field elements {v_i}, compute the vector {v_i^(-1)}batch_inversion_and_mul// Given a vector of field elements {v_i}, compute the vector {coeff * v_i^(-1)}serial_batch_inversion_and_mul/// Given a vector of field elements {v_i}, compute the vector {coeff * v_i^(-1)}./// This method is explicitly single-threaded.test_rng// TODO: only Fr & FrConfig should need to be imported.// The rest of imports are caused by cargo not resolving the deps properly// from this crate and from ark_test_curvestest_batch_inversiontest_from_into_biguinttest_from_be_bytes_mod_orderno_std_tests/// The prime field that this cubic extension is eventually an extension of./// The base field that this field is a cubic extension of./// Note: while for simple instances of cubic extensions such as `Fp3`/// we might see `BaseField == BasePrimeField`, it won't always hold true./// E.g. for an extension tower: `BasePrimeField == Fp`, but `BaseField == Fp2`.FrobCoeff/// The type of the coefficients for an efficient implementation of the/// Frobenius endomorphism.CubicExtFieldDEGREE_OVER_BASE_PRIME_FIELD/// The degree of the extension over the base prime field./// The cubic non-residue used to construct the extension.FROBENIUS_COEFF_C1FROBENIUS_COEFF_C2mul_base_field_by_nonresidue_in_place/// A specializable method for multiplying an element of the base field by/// the quadratic non-residue. This is used in multiplication and squaring.mul_base_field_by_nonresidue/// A defaulted method for multiplying an element of the base field bymul_base_field_by_frob_coeff/// the appropriate Frobenius coefficient.CubicExtConfig/// Defines a Cubic extension field from a cubic non-residue.c0c1c2/// An element of a cubic extension field F_p\[X\]/(X^3 - P::NONRESIDUE) is/// represented as c0 + c1 * X + c2 * X^2, for c0, c1, c2 in `P::BaseField`./// Create a new field element from coefficients `c0`, `c1` and `c2`/// so that the result is of the form `c0 + c1 * X + c2 * X^2`./// # use ark_std::test_rng;/// # use ark_test_curves::bls12_381::{Fq2 as Fp2, Fq6 as Fp6};/// # use ark_test_curves::bls12_381::Fq6Config;/// # use ark_std::UniformRand;/// # use ark_ff::models::fp6_3over2::Fp6ConfigWrapper;/// use ark_ff::models::cubic_extension::CubicExtField;/// let c0: Fp2 = Fp2::rand(&mut test_rng());/// let c1: Fp2 = Fp2::rand(&mut test_rng());/// let c2: Fp2 = Fp2::rand(&mut test_rng());/// # type Config = Fp6ConfigWrapper<Fq6Config>;/// // `Fp6` a degree-3 extension over `Fp2`./// let c: CubicExtField<Config> = Fp6::new(c0, c1, c2);mul_assign_by_base_fieldnorm/// Calculate the norm of an element with respect to the base field/// `P::BaseField`. The norm maps an element `a` in the extension field/// `Fq^m` to an element in the BaseField `Fq`./// `Norm(a) = a * a^q * a^(q^2)`is_oneBaseFieldIter/// Returns the Legendre symbol./// `CubicExtField` elements are ordered lexicographically.divproductdiv_assignserialize_with_flagsserialized_size_with_flagsdeserialize_with_flagsmnt6_753Fq3test_norm_for_towerstest_from_base_prime_field_elementstest_from_base_prime_field_elementcube_ext_testsbuffer_byte_sizemontgomery_backendMODULUS/// The modulus of the field./// A multiplicative generator of the field./// `Self::GENERATOR` is an element having multiplicative order/// `Self::MODULUS - 1`./// Additive identity of the field, i.e. the element `e`/// such that, for all elements `f` of the field, `e + f = f`./// Multiplicative identity of the field, i.e. the element `e`/// such that, for all elements `f` of the field, `e * f = f`./// Precomputed material for use when computing square roots./// Currently uses the generic Tonelli-Shanks,/// which works for every modulus./// Set a += b./// Set a -= b./// Set a = a + a./// Set a = -a;/// Set a *= b./// Compute the inner product `<a, b>`./// Compute a^{-1} if `a` is not zero.from_bigint/// Construct a field element from an integer in the range/// `0..(Self::MODULUS - 1)`. Returns `None` if the integer is outside/// this range.into_bigint/// Convert a field element to an integer in the range `0..(Self::MODULUS -/// 1)`.FpConfig/// A trait that specifies the configuration of a prime field./// Also specifies how to perform arithmetic on field elements./// Represents an element of the prime field F_p, where `p == P::MODULUS`./// This type can represent elements in any field of size at most N * 64 bits.Fp128Fp192Fp320Fp384Fp448Fp512Fp5769Fp640Fp704Fp768Fp832is_geq_modulussubtract_modulussubtract_modulus_with_carrynum_bits_to_shaveOnce/// The Frobenius map has no effect in a prime field.MODULUS_MINUS_ONE_DIV_TWOMODULUS_BIT_SIZETRACETRACE_MINUS_ONE_DIV_TWO/// Note that this implementation of `Ord` compares field elements viewing/// them as integers in the range 0, 1, ..., P::MODULUS - 1. However, other/// implementations of `PrimeField` might choose a different ordering, and/// as such, users should use this `Ord` for applications where/// any ordering suffices (like in a BTreeMap), and not in applications/// where a particular ordering is required./// Note that this implementation of `PartialOrd` compares field elements/// viewing them as integers in the range 0, 1, ..., `P::MODULUS` - 1. However,/// other implementations of `PrimeField` might choose a different ordering, and/// as such, users should use this `PartialOrd` for applications where// Let `m = 8 * n` for some `n` be the smallest multiple of 8 greater// than `P::MODULUS_BIT_SIZE`.// If `(m - P::MODULUS_BIT_SIZE) >= F::BIT_SIZE` , then this method returns `n`;// otherwise, it returns `n + 1`./// Interpret a string of numbers as a (congruent) prime field element./// Does not accept unnecessary leading zeroes or a blank string./// Outputs a string containing the value of `self`,/// represented as a decimal without leading zeroes./// Returns `self * other.inverse()` if `other.inverse()` is `Some`, and/// panics otherwise./// Computes `self *= other.inverse()` if `other.inverse()` is `Some`, and/// Converts `Self::BigInteger` into `Self`fa/// Let `M` be the power of 2^64 nearest to `Self::MODULUS_BITS`. Then/// `R = M % Self::MODULUS`.R2/// R2 = R^2 % Self::MODULUSINV/// INV = -MODULUS^{-1} mod 2^64CAN_USE_NO_CARRY_MUL_OPT/// Can we use the no-carry optimization for multiplication/// outlined [here](https://hackmd.io/@gnark/modular_multiplication)?/// This optimization applies if/// (a) `Self::MODULUS[N-1] < u64::MAX >> 1`, and/// (b) the bits of the modulus are not all 1.CAN_USE_NO_CARRY_SQUARE_OPT/// Can we use the no-carry optimization for squaring/// (a) `Self::MODULUS[N-1] < u64::MAX >> 2`, andMODULUS_HAS_SPARE_BIT/// Does the modulus have a spare unused bit/// This condition applies if/// (a) `Self::MODULUS[N-1] >> 63 == 0`/// SMALL_SUBGROUP_BASE^SMALL_SUBGROUP_BASE_ADICITY))./// Used for mixed-radix FFT./// The default is to use the standard Tonelli-Shanks algorithm.MODULUS_PLUS_ONE_DIV_FOUR/// (MODULUS + 1) / 4 when MODULUS % 4 == 3. Used for square root precomputations./// Sets `a = a + b`./// Sets `a = a - b`./// Sets `a = 2 * a`./// Sets `a = -a`." This modular multiplication algorithm uses Montgomery"" reduction for efficient implementation. It also additionally"" uses the \"no-carry optimization\" outlined"" [here](https://hackmd.io/@gnark/modular_multiplication) if"" `Self::MODULUS` has (a) a non-zero MSB, and (b) at least one"" zero bit in the rest of the modulus."/// A trait that specifies the constants and arithmetic procedures/// for Montgomery arithmetic over the prime field defined by `MODULUS`./// Manual implementation of this trait is not recommended unless one wishes/// to specialize arithmetic methods. Instead, the/// [`MontConfig`][`ark_ff_macros::MontConfig`] derive macro should be used.inv/// Compute -M^{-1} mod 2^64.can_use_no_carry_mul_optimizationmodulus_has_spare_bitcan_use_no_carry_square_optimizationsqrt_precomputation/// Construct a [`Fp<MontBackend<T, N>, N>`] element from a literal string. This/// should be used primarily for constructing constant field elements; in a/// non-const context, [`Fp::from_str`](`ark_std::str::FromStr::from_str`) is/// preferable./// of limbs of the `Fp`, this macro results in a/// # use ark_test_curves::{MontFp, One};/// # use ark_test_curves::bls12_381 as ark_bls12_381;/// # use ark_std::str::FromStr;/// use ark_bls12_381::Fq;/// const ONE: Fq = MontFp!("1");/// const NEG_ONE: Fq = MontFp!("-1");///     assert_eq!(ONE, Fq::one());///     assert_eq!(Fq::from_str("1").unwrap(), ONE);///     assert_eq!(NEG_ONE, -Fq::one());/// This modular multiplication algorithm uses Montgomery/// reduction for efficient implementation. It also additionally/// uses the "no-carry optimization" outlined/// [here](https://hackmd.io/@zkteam/modular_multiplication) if/// `P::MODULUS` has (a) a non-zero MSB, and (b) at least one/// zero bit in the rest of the modulus./// Construct a new field element from its underlying/// [`struct@BigInt`] data type./// Unlike [`Self::new`], this method does not perform Montgomery reduction./// Thus, this method should be used only when constructing/// an element from an integer that has already been put in/// Montgomery form.const_negfrom_sign_and_limbs/// Interpret a set of limbs (along with a sign) as a field element./// For *internal* use only; please use the `ark_ff::MontFp` macro instead/// of this methodmul_without_cond_subtractconst_is_validconst_subtract_modulusconst_subtract_modulus_with_carrysecp256k1Signtest_mont_macro_correctnessstr_to_limbs_u64quadratic_extensionFp2ConfigTraitNot/// This *must* equal (0, 1, 0);/// see [[DESD06, Section 6.1]](https://eprint.iacr.org/2006/471.pdf).mul_fp6_by_nonresidue_in_place/// Multiply by quadratic nonresidue v.Fp12ConfigWrapperQuadExtConfigQuadExtFieldmul_by_fpmul_by_034mul_by_014characteristic_square_mod_6_is_onetest_characteristic_square_mod_6_is_one/// Base prime field underlying this extension./// Quadratic non-residue in [`Self::Fp`] used to construct the extension/// field. That is, `NONRESIDUE` is such that the quadratic polynomial/// `f(X) = X^2 - Self::NONRESIDUE` in Fp\[X\] is irreducible in `Self::Fp`./// Return `fe * Self::NONRESIDUE`./// Intended for specialization when [`Self::NONRESIDUE`] has a special/// structure that can speed up multiplicationmul_fp_by_nonresidue_and_add/// A specializable method for setting `y = x + NONRESIDUE * y`./// This allows for optimizations when the non-residue is/// canonically negative in the field.mul_fp_by_nonresidue_plus_one_and_add/// A specializable method for computing x + mul_fp_by_nonresidue(y) + y/// This allows for optimizations when the non-residue is not -1.sub_and_mul_fp_by_nonresidue/// A specializable method for computing x - mul_fp_by_nonresidue(y)/// Trait that specifies constants and methods for defining degree-two extension fields.Fp2ConfigWrapper/// Wrapper for [`Fp2Config`], allowing combination of the [`Fp2Config`] and [`QuadExtConfig`] traits.mul_base_field_by_nonresidue_and_addmul_base_field_by_nonresidue_plus_one_and_addsub_and_mul_base_field_by_nonresidue/// Alias for instances of quadratic extension fields. Helpful for omitting verbose/// instantiations involving `Fp2ConfigWrapper`.mul_assign_by_fp/// In-place multiply both coefficients `c0` and `c1` of `self`/// by an element from [`Fp`](`Fp2Config::Fp`)./// # use ark_test_curves::bls12_381::{Fq as Fp, Fq2 as Fp2};/// let c0: Fp = Fp::rand(&mut test_rng());/// let c1: Fp = Fp::rand(&mut test_rng());/// let mut ext_element: Fp2 = Fp2::new(c0, c1);/// let base_field_element: Fp = Fp::rand(&mut test_rng());/// ext_element.mul_assign_by_fp(&base_field_element);/// assert_eq!(ext_element.c0, c0 * base_field_element);/// assert_eq!(ext_element.c1, c1 * base_field_element);cubic_extension/// Cubic non-residue in `Self::Fp` used to construct the extension/// field. That is, `NONRESIDUE` is such that the cubic polynomial/// `f(X) = X^3 - Self::NONRESIDUE` in Fp\[X\] is irreducible in `Self::Fp`.FROBENIUS_COEFF_FP3_C1FROBENIUS_COEFF_FP3_C2/// p^3 - 1 = 2^s * t, where t is odd.QUADRATIC_NONRESIDUE_TO_T/// t-th power of a quadratic nonresidue in Fp3./// The default implementation can be specialized if [`Self::NONRESIDUE`] has a special/// Trait that specifies constants and methods for defining degree-three extension fields.Fp3ConfigWrapper/// Wrapper for [`Fp3Config`], allowing combination of the [`Fp3Config`] and [`CubicExtConfig`] traits./// In-place multiply all coefficients `c0`, `c1`, and `c2` of `self`/// by an element from [`Fp`](`Fp3Config::Fp`)./// # use ark_test_curves::mnt6_753 as ark_mnt6_753;/// use ark_mnt6_753::{Fq as Fp, Fq3 as Fp3};/// let c2: Fp = Fp::rand(&mut test_rng());/// let mut ext_element: Fp3 = Fp3::new(c0, c1, c2);/// assert_eq!(ext_element.c2, c2 * base_field_element);// We just use the default algorithms; there don't seem to be any faster ones./// This *must* equal (0, 1);/// see [[DESD06, Section 5.1]](https://eprint.iacr.org/2006/471.pdf).FROBENIUS_COEFF_FP4_C1/// non_residue^((modulus^i-1)/4) for i=0,1,2,3Fp4ConfigWrappermul_by_fp2mul_fp3_by_nonresidue_in_placeFp6ConfigWrappermul_fp2_by_nonresiduemul_assign_by_fp2mul_by_1mul_by_01fp/// The prime field that this quadratic extension is eventually an extension of./// The base field that this field is a quadratic extension of./// Note: while for simple instances of quadratic extensions such as `Fp2`/// E.g. for an extension tower: `BasePrimeField == Fp`, but `BaseField == Fp3`./// The type of the coefficients for an efficient implemntation of the/// The quadratic non-residue used to construct the extension./// the quadratic non-residue. This is used in Karatsuba multiplication/// and in complex squaring./// A specializable method for computing x + mul_base_field_by_nonresidue(y) + y/// A specializable method for computing x - mul_base_field_by_nonresidue(y)/// Defines a Quadratic extension field from a quadratic non-residue./// Coefficient `c0` in the representation of the field element `c = c0 + c1 * X`/// Coefficient `c1` in the representation of the field element `c = c0 + c1 * X`/// An element of a quadratic extension field F_p\[X\]/(X^2 - P::NONRESIDUE) is/// represented as c0 + c1 * X, for c0, c1 in `P::BaseField`./// Create a new field element from coefficients `c0` and `c1`,/// so that the result is of the form `c0 + c1 * X`./// // `Fp2` a degree-2 extension over `Fp`./// let c: Fp2 = Fp2::new(c0, c1);conjugate_in_place/// This is only to be used when the element is *known* to be in the/// cyclotomic subgroup./// Norm of QuadExtField over `P::BaseField`:`Norm(a) = a * a.conjugate()`./// This simplifies to: `Norm(a) = a.x^2 - P::NON_RESIDUE * a.y^2`./// This is alternatively expressed as `Norm(a) = a^(1 + p)`./// # use ark_std::{UniformRand, Zero};/// # use ark_test_curves::{Field, bls12_381::Fq2 as Fp2};/// let c: Fp2 = Fp2::rand(&mut test_rng());/// let norm = c.norm();/// // We now compute the norm using the `a * a.conjugate()` approach./// // A Frobenius map sends an element of `Fp2` to one of its p_th powers:/// // `a.frobenius_map_in_place(1) -> a^p` and `a^p` is also `a`'s Galois conjugate./// let mut c_conjugate = c;/// c_conjugate.frobenius_map_in_place(1);/// let norm2 = c * c_conjugate;/// // Computing the norm of an `Fp2` element should result in an element/// // in BaseField `Fp`, i.e. `c1 == 0`/// assert!(norm2.c1.is_zero());/// assert_eq!(norm, norm2.c0);mul_assign_by_basefield/// In-place multiply both coefficients `c0` & `c1` of the quadratic/// extension field by an element from the base field./// `QuadExtField` elements are ordered lexicographically.quad_ext_tests/// A `BigInteger` type that can represent elements of this field./// The modulus `p`./// The value `(p - 1)/ 2`./// The size of the modulus in bits./// The trace of the field is defined as the smallest integer `t` such that by/// `2^s * t = p - 1`, and `t` is coprime to 2./// The value `(t - 1)/ 2`./// Construct a prime field element from an integer in the range 0..(p - 1)./// Converts an element of the prime field into an integer in the range 0..(p - 1).from_be_bytes_mod_order/// Reads bytes in big-endian, and converts them to a field element./// If the integer represented by `bytes` is larger than the modulus `p`, this method/// performs the appropriate reduction.from_le_bytes_mod_order/// Reads bytes in little-endian, and converts them to a field element./// The interface for a prime field, i.e. the field of integers modulo a prime $p$.  /// In the following example we'll use the prime field underlying the BLS12-381 G1 curve./// use ark_ff::{BigInteger, Field, PrimeField};/// use ark_std::{test_rng, One, UniformRand, Zero};/// // We can access the prime modulus associated with `F`:/// let modulus = <F as PrimeField>::MODULUS;/// assert_eq!(a.pow(&modulus), a); // the Euler-Fermat theorem tells us: a^{p-1} = 1 mod p/// // We can convert field elements to integers in the range [0, MODULUS - 1]:/// let one: num_bigint::BigUint = F::one().into();/// assert_eq!(one, num_bigint::BigUint::one());/// // We can construct field elements from an arbitrary sequence of bytes:/// let n = F::from_le_bytes_mod_order(&modulus.to_bytes_le());/// assert_eq!(n, F::zero());QuadraticResidue-QuadraticNonResidue/// Indication of the field element's quadratic residuosity/// # use ark_test_curves::{LegendreSymbol, Field, bls12_381::Fq as Fp};/// let a: Fp = Fp::rand(&mut test_rng());/// let b = a.square();/// assert_eq!(b.legendre(), LegendreSymbol::QuadraticResidue);/// Returns true if `self.is_zero()`./// let b: Fp = a.square();/// assert!(!b.legendre().is_zero());is_qnr/// Returns true if `self` is a quadratic non-residue./// # use ark_test_curves::{Fp2Config, Field, LegendreSymbol, bls12_381::{Fq, Fq2Config}};/// let a: Fq = Fq2Config::NONRESIDUE;/// assert!(a.legendre().is_qnr());is_qr/// Returns true if `self` is a quadratic residue./// # use ark_test_curves::bls12_381::Fq as Fp;/// # use ark_ff::{LegendreSymbol, Field};/// assert!(b.legendre().is_qr());two_adicityquadratic_nonresidue_to_tracetrace_of_modulus_minus_one_div_twoTonelliShanks// Tonelli-Shanks algorithm works for all elements, no matter what the modulus is.modulus_plus_one_div_fourCase3Mod4/// To be used when the modulus is 3 mod 4./// Precomputation that makes computing square roots faster/// A particular variant should only be instantiated if the modulus satisfies/// the corresponding condition.k_adicity/// Calculates the k-adicity of n, i.e., the number of trailing 0s in a base-kconst_helpersto_field_vec/// Types that can be converted to a vector of `F` elements. Useful for/// specifying how public inputs to a constraint system should be represented/// inside that constraint system.// Impl for base fieldAssemblyVarMemoryVariableFixedmemory_accessmemory_accessesDeclarationRegister/// Name of the assembly template variable declared by `self`.expr/// Rust expression whose value is declared in `self`.data_structuresassembly_instructionsdeclarationsused_registersRAXRSIRCXRDXappendinstructions_to_stringget_decl_nameget_declget_decl_with_fallbackadd_declarationadd_bufferadd_asmadd_clobbersadd_clobber"128"recursion_limitRefCellMAX_REGSnum_limbsabAsmMulInputx86_64_asm_mulAsmSquareInputx86_64_asm_squareconstruct_asm_mulgenerate_implexpand_mulsmontgomeryunrollto_sign_and_limbsmont_config/// Derive the `MontConfig` trait./// The attributes available to this macro are/// * `modulus`: Specify the prime modulus underlying this prime field./// * `generator`: Specify the generator of the multiplicative subgroup of this///   prime field. This value must be a quadratic non-residue in the field./// * `small_subgroup_base` and `small_subgroup_power` (optional): If the field///   has insufficient two-adicity, specify an additional subgroup of size///   `small_subgroup_base.pow(small_subgroup_power)`.// This code was adapted from the `PrimeField` Derive Macro in ff-derive.ARG_MSG/// Attribute used to unroll for loops found inside a function block.fetch_attr/// Fetch an attribute string from the derived struct.test_str_to_limbsadd_assign_impladd_with_carry_implsub_with_borrow_implsubtract_modulus_impldouble_in_place_implmont_config_helpermul_assign_implsquare_in_place_implsum_of_products_implparse_quoteBraceExprBlockExprForLoopExprIfExprLetExprRangePatPatIdentRangeLimitsStmtunroll_in_block/// Routine to unroll for loops within a block/// Routine to unroll a for loop statement, or return the statement unchanged if/// it's not a for loop.//! An attribute-like procedural macro for unrolling for loops with integer//! literal bounds.//! This crate provides the [`unroll_for_loops`](../attr.unroll_for_loops.html)//! attribute-like macro that can be applied to functions containing for-loops//! with integer bounds. This macro looks for loops to unroll and unrolls them//! at compile time.//! ## Usage//! Just add `#[unroll_for_loops]` above the function whose for loops you would//! like to unroll. Currently all for loops with integer literal bounds will be//! unrolled, although this macro currently can't see inside complex code (e.g.//! for loops within closures).//! ## Example//! The following function computes a matrix-vector product and returns the//! result as an array. Both of the inner for-loops are unrolled when//! `#[unroll_for_loops]` is applied.//! ```rust//! use ark_ff_macros::unroll_for_loops;//! #[unroll_for_loops(12)]//! fn mtx_vec_mul(mtx: &[[f64; 5]; 5], vec: &[f64; 5]) -> [f64; 5] {//!     let mut out = [0.0; 5];//!     for col in 0..5 {//!         for row in 0..5 {//!             out[row] += mtx[col][row] * vec[col];//!         }//!     }//!     out//! fn mtx_vec_mul_2(mtx: &[[f64; 5]; 5], vec: &[f64; 5]) -> [f64; 5] {//! let a = [[1.0, 2.0, 3.0, 4.0, 5.0]; 5];//! let b = [7.9, 4.8, 3.8, 4.22, 5.2];//! assert_eq!(mtx_vec_mul(&a, &b), mtx_vec_mul_2(&a, &b));//! This code was adapted from the [`unroll`](https://crates.io/crates/unroll) crate.parse_stringstr_to_limbsdomainElementsDomainCoeffEvaluationDomainMixedRadixEvaluationDomainRadix2EvaluationDomainGeneralEvaluationDomainRadix2/// Radix-2 domainMixedRadix/// Mixed-radix domain/// Defines a domain over which finite field (I)FFTs can be performed./// Generally tries to build a radix-2 domain and falls back to a mixed-radix/// domain if the radix-2 multiplicative subgroup is too small.GeneralElements/// Construct a domain that is large enough for evaluations of a polynomial/// having `num_coeffs` coefficients./// If the field specifies a small subgroup for a mixed-radix FFT and/// the radix-2 FFT cannot be constructed, this method tries/// constructing a mixed-radix FFT instead.get_cosetcompute_size_of_domainsizelog_size_of_groupsize_invgroup_gengroup_gen_invcoset_offsetcoset_offset_invcoset_offset_pow_sizefft_in_placeifft_in_placeevaluate_all_lagrange_coefficientsvanishing_polynomialSparsePolynomialevaluate_vanishing_polynomial/// Return an iterator over the elements of the domain./// A generalized version of an iterator over the elements of a domain.polynomialbn384_small_two_adicityBNFrvanishing_polynomial_evaluationvanishing_polynomial_vanishes_on_domainsize_of_elements//! This module contains a `GeneralEvaluationDomain` for//! performing various kinds of polynomial arithmetic on top of//! a FFT-friendly finite field.//! It is a wrapper around specific implementations of `EvaluationDomain` that//! automatically chooses the most efficient implementation//! depending on the number of coefficients and the two-adicity of the prime.best_fftbitreverse/// The size of the domain./// `log_2(self.size)`.size_as_field_element/// Size of the domain as a field element./// Inverse of the size in the field./// A generator of the subgroup./// Inverse of the generator of the subgroup./// Offset that specifies the coset.offset_inv/// Inverse of the offset that specifies the coset.offset_pow_size/// Constant coefficient for the vanishing polynomial./// Equals `self.offset^self.size`./// Defines a domain over which finite field (I)FFTs can be performed. Works/// only for fields that have a multiplicative subgroup of size that is/// a power-of-2 and another small subgroup over a different base defined.mixed_radix_fft_permutebest_mixed_domain_sizeserial_mixed_radix_fftnon_systematic_lagrange_coefficients_test/// Test that lagrange interpolation for a random polynomial at a random/// point works.systematic_lagrange_coefficients_test/// Test that lagrange coefficients for a point in the domain is correctelements_contents//! This module contains a `MixedRadixEvaluationDomain` for//! fields that are FFT-friendly but do not have high-enough//! two-adicity to perform the FFT efficiently, i.e. the multiplicative//! subgroup `G` generated by `F::TWO_ADIC_ROOT_OF_UNITY` is not large enough.//! `MixedRadixEvaluationDomain` resolves//! this issue by using a larger subgroup obtained by combining//! `G` with another subgroup of size//! `F::SMALL_SUBGROUP_BASE^(F::SMALL_SUBGROUP_BASE_ADICITY)`,//! to obtain a subgroup generated by `F::LARGE_SUBGROUP_ROOT_OF_UNITY`.generalmixed_radixradix2/// The type of the elements iterator.sample_element_outside_domain/// Sample an element that is *not* in the domain.new_coset/// Construct a coset domain that is large enough for evaluations of a polynomial/// Construct a coset domain from a subgroup domain/// Return the size of a domain that is large enough for evaluations of a/// polynomial having `num_coeffs` coefficients./// Return the size of `self`./// Return the size of `self` as a field element./// Return log_2(size) of `self`./// Return the inverse of `self.size_as_field_element()`./// Return the generator for the multiplicative subgroup that defines this domain./// Return the group inverse of `self.group_gen()`./// Return the group offset that defines this domain./// Return the inverse of `self.offset()`./// Return `offset^size`.fft/// Compute a FFT./// Compute a FFT, modifying the vector in place.ifft/// Compute a IFFT./// Compute a IFFT, modifying the vector in place.distribute_powers/// Multiply the `i`-th element of `coeffs` with `g^i`.distribute_powers_and_mul_by_const/// Multiply the `i`-th element of `coeffs` with `c*g^i`./// Evaluate all the lagrange polynomials defined by this domain at the/// point `tau`. This is computed in time O(|domain|)./// Then given the evaluations of a degree d polynomial P over this domain,/// where d < |domain|, `P(tau)` can be computed as/// `P(tau) = sum_{i in [|Domain|]} L_{i, Domain}(tau) * P(g^i)`./// `L_{i, Domain}` is the value of the i-th lagrange coefficient/// in the returned vector./// Return the sparse vanishing polynomial./// This evaluates the vanishing polynomial for this domain at tau.element/// Returns the `i`-th element of the domain.reindex_by_subdomain/// Given an index which assumes the first elements of this domain are the/// elements of another (sub)domain,/// this returns the actual index into this domain.mul_polynomials_in_evaluation_domain/// Perform O(n) multiplication of two polynomials that are presented by/// their evaluations in the domain./// Returns the evaluations of the product over the domain./// Assumes that the domain is large enough to allow for successful/// interpolation after multiplication./// Defines a domain over which finite field (I)FFTs can be performed. The/// size of the supported FFT depends on the size of the multiplicative/// subgroup. For efficiency, we recommend that the field has at least one large/// subgroup generated by a root of unity./// Types that can be FFT-ed must implement this trait.//! This module contains an `EvaluationDomain` abstraction for//! fields that are friendly to fast-fourier-transforms (FFTs).//! A field is FFT-friendly if it contains enough//! roots of unity to perform the FFT in O(n log n) time.//! These roots of unity comprise the domain over which//! polynomial arithmetic is performed.compute_powers_serialcfg_chunks_mutFFTOrderII/// Both the input and the output of the FFT must be in-order.IO/// The input of the FFT must be in-order, but the output does not have to/// be.OI/// The input of the FFT can be out of order, but the output must be/// in-order.degree_aware_fft_in_place/// Degree aware FFT that runs in O(n log d) instead of O(n log n)/// Implementation copied from libiop.in_order_fft_in_placein_order_ifft_in_placefft_helper_in_placeifft_helper_in_place// Handles doing an IFFT with handling of being in order and out of order.// The results here must all be divided by |x_s|,// which is left up to the caller to do.roots_of_unity/// Computes the first `self.size / 2` roots of unity for the entire domain./// e.g. for the domain [1, g, g^2, ..., g^{n - 1}], it computes// [1, g, g^2, ..., g^{(n/2) - 1}]butterfly_fn_iobutterfly_fn_oiapply_butterflyio_helperoi_helperMIN_NUM_CHUNKS_FOR_COMPACTION/// The minimum number of chunks at which root compaction/// is beneficial.MIN_GAP_SIZE_FOR_PARALLELISATION/// The minimum size of a chunk at which parallelization of `butterfly`s is/// beneficial. This value was chosen empirically.bitrevderange// The code below is a port of the excellent library of https://github.com/kwantam/fffft by Riad S. Wahby// to the arkworks APIsDEGREE_AWARE_FFT_THRESHOLD_FACTOR/// Factor that determines if a the degree aware FFT should be called./// only for fields that have a large multiplicative subgroup of size that is/// a power-of-2.test_fft_correctnessdegree_aware_fft_correctnesstest_roots_of_unity//! This module defines `Radix2EvaluationDomain`, an `EvaluationDomain`//! for performing various kinds of polynomial arithmetic on top of//! fields that are FFT-friendly. `Radix2EvaluationDomain` supports//! FFTs of size at most `2^F::TWO_ADICITY`.compute_powers_and_mul_by_const_serialcur_elemcur_pow/// An iterator over the elements of a domain.multivariatemultilinearDenseMultilinearExtensionMultilinearExtensionSparseMultilinearExtensionevaluationsswap_bits/// The evaluation over {0,1}^`num_vars`num_vars/// Number of variables/// Stores a multilinear polynomial in dense evaluation form.from_evaluations_slice/// Construct a new polynomial from a list of evaluations where the index/// represents a point in {0,1}^`num_vars` in little endian form. For/// example, `0b1011` represents `P(1,1,0,1)`from_evaluations_vecrelabel_in_place/// Relabel the point in place by switching `k` scalars from position `a` to/// position `b`, and from position `b` to position `a` in vector./// This function turns `P(x_1,...,x_a,...,x_{a+k - 1},...,x_b,...,x_{b+k - 1},...,x_n)`/// to `P(x_1,...,x_b,...,x_{b+k - 1},...,x_a,...,x_{a+k - 1},...,x_n)`/// Returns an iterator that iterates over the evaluations over {0,1}^`num_vars`iter_mut/// Returns a mutable iterator that iterates over the evaluations over {0,1}^`num_vars`evaluaterelabelfix_variablesto_evaluations/// Returns the evaluation of the polynomial at a point represented by index./// Index represents a vector in {0,1}^`num_vars` in little endian form. For/// For dense multilinear polynomial, `index` takes constant time.evaluate_data_array/// utility: evaluate multilinear extension (in form of data array) at a random pointevaluate_at_a_pointrelabel_polynomial//! Multilinear polynomial represented in dense evaluation form./// Returns the number of variables in `self`/// Evaluates `self` at the given the vector `point` in slice./// If the number of variables does not match, return `None`./// Outputs an `l`-variate multilinear extension where value of evaluations/// are sampled uniformly at random./// Relabel the point by swapping `k` scalars from positions `a..a+k` to/// positions `b..b+k`, and from position `b..b+k` to position `a..a+k`/// in vector./// Reduce the number of variables of `self` by fixing the/// `partial_point.len()` variables at `partial_point`./// Returns a list of evaluations over the domain, which is the boolean/// hypercube./// This trait describes an interface for the multilinear extension/// of an array./// The latter is a multilinear polynomial represented in terms of its/// evaluations over the domain {0,1}^`num_vars` (i.e. the Boolean hypercube)./// Index represents a point, which is a vector in {0,1}^`num_vars` in little/// endian form. For example, `0b1011` represents `P(1,1,0,1)`/// swap the bits of `x` from position `a..a+n` to `b..b+n` and from `b..b+n` to `a..a+n` in little endian order/// tuples of index and value/// number of variables/// Stores a multilinear polynomial in sparse evaluation form.from_evaluationsrand_with_config/// are sampled uniformly at random. The number of nonzero entries is/// `num_nonzero_entries` and indices of those nonzero entries are/// distributed uniformly at random./// Note that this function uses rejection sampling. As number of nonzero/// entries approach `2 ^ num_vars`, sampling will be very slow due to/// large number of collisions.to_dense_multilinear_extension/// Convert the sparse multilinear polynomial to dense form.precompute_eq/// utility: precompute f(x) = eq(g,x)/// `sqrt(2^num_vars)` and indices of those nonzero entries are distributed/// uniformly at random./// Returns the evaluation of the polynomial at a point represented by/// index./// For Sparse multilinear polynomial, Lookup_evaluation takes log time to/// the size of polynomial.tuples_to_treemap/// Utility: Convert tuples to hashmap.treemap_to_hashmaphashmap_to_treemaprandom_poly/// Some sanity test to ensure random sparse polynomial make sense./// Test if sparse multilinear polynomial evaluates correctly./// This function assumes dense multilinear polynomial functions correctly.evaluate_edge_cases//! multilinear polynomial represented in sparse evaluation form.evals/// The evaluations of a polynomial over the domain `D`Evaluations/// Stores a UV polynomial in evaluation form.from_vec_and_domain/// Construct `Self` from evaluations and a domain.interpolate_by_ref/// Interpolate a polynomial from a list of evaluationsinterpolate/// Return the domain `self` is defined over//! A univariate polynomial represented in evaluations form.DenseMVPolynomial//! This crate implements functions for manipulating polynomials over finite//! fields, including FFTs.Point/// The type of evaluation points for this polynomial.degree/// Returns the total degree of the polynomial/// Evaluates `self` at the given `point` in `Self::Point`./// Describes the common interface for univariate and multivariate polynomialsfrom_coefficients_slice/// Constructs a new polynomial from a list of coefficients.from_coefficients_veccoeffs/// Returns the coefficients of `self`/// Returns a univariate polynomial of degree `d` where each/// coefficient is sampled uniformly at random./// Describes the interface for univariate polynomialsTerm/// The type of the terms of `self`/// Constructs a new polynomial from a list of tuples of the form `(coeff, Self::Term)`terms/// Returns the terms of a `self` as a list of tuples of the form `(coeff, Self::Term)`/// Outputs an `l`-variate polynomial which is the sum of `l` `d`-degree univariate/// polynomials where each coefficient is sampled uniformly at random./// Describes the interface for multivariate polynomials//! Modules for working with univariate or multivariate polynomials./// Create a new `Term` from a list of tuples of the form `(variable, power)`/// Returns the total degree of `self`. This is the sum of all variable/// powers in `self`vars/// Returns a list of variables in `self`powers/// Returns a list of the powers of each variable in `self`is_constant/// Returns whether `self` is a constant/// Evaluates `self` at the point `p`./// Describes the interface for a term (monomial) of a multivariate polynomial.SparseTerm/// Stores a term (monomial) in a multivariate polynomial./// Each element is of the form `(variable, power)`.combine/// Sums the powers of any duplicated variables. Assumes `term` is sorted./// Returns the sum of all variable powers in `self`/// Returns a list of variable powers in `self`/// Evaluates `self` at the given `point` in the field./// Sort by total degree. If total degree is equal then ordering/// is given by exponent weight in lower-numbered variables/// ie. `x_1 > x_2`, `x_1^2 > x_1 * x_2`, etc.//! Work with sparse multivariate polynomials./// The number of variables the polynomial supports/// List of each term along with its coefficient/// Stores a sparse multivariate polynomial in coefficient form.remove_zeros/// use ark_poly::{///     polynomial::multivariate::{SparsePolynomial, SparseTerm},///     DenseMVPolynomial, Polynomial,/// use ark_std::test_rng;/// let rng = &mut test_rng();/// // Create a multivariate polynomial of degree 7/// let poly: SparsePolynomial<Fq, SparseTerm> = SparsePolynomial::rand(7, 2, rng);/// assert_eq!(poly.degree(), 7);/// use ark_ff::UniformRand;///     polynomial::multivariate::{SparsePolynomial, SparseTerm, Term},/// let poly = SparsePolynomial::rand(4, 3, rng);/// let random_point = vec![Fq::rand(rng); 3];/// // The result will be a single element in the field./// let result: Fq = poly.evaluate(&random_point);/// Outputs an `l`-variate polynomial which is the sum of `l` `d`-degree/// univariate polynomials where each coefficient is sampled uniformly at random./// // Create a multivariate polynomial in 3 variables, with 4 terms:/// // 2*x_0^3 + x_0*x_2 + x_1*x_2 + 5/// let poly = SparsePolynomial::from_coefficients_vec(///     3,///     vec![///         (Fq::from(2), SparseTerm::new(vec![(0, 3)])),///         (Fq::from(1), SparseTerm::new(vec![(0, 1), (2, 1)])),///         (Fq::from(1), SparseTerm::new(vec![(1, 1), (2, 1)])),///         (Fq::from(5), SparseTerm::new(vec![])),///     ],/// Returns the zero polynomial./// Checks if the given polynomial is zero.rand_poly/// Generate random `l`-variate polynomial of maximum individual degree `d`naive_mul/// Perform a naive n^2 multiplication of `self` by `other`.add_polynomialssub_polynomialsevaluate_polynomialsadd_and_evaluate_polynomialsmul_polynomials_fixed/// This is just to make sure naive_mul works as expected// TODO: Make tests generic over term type//! A sparse multivariate polynomial represented in coefficient form.DenseOrSparsePolynomial/// The coefficient of `x^i` is stored at location `i` in `self.coeffs`./// Stores a polynomial in coefficient form.horner_evaluate// Horner's method for polynomial evaluationinternal_evaluate/// Outputs a univariate polynomial of degree `d` where/// each coefficient is sampled uniformly at random.mul_by_vanishing_poly/// Multiply `self` by the vanishing polynomial for the domain `domain`./// Returns the result of the multiplication.divide_by_vanishing_poly/// Divide `self` by the vanishing polynomial for the domain `domain`./// Returns the quotient and remainder of the division.truncate_leading_zerosevaluate_over_domain_by_ref/// Evaluate `self` over `domain`.evaluate_over_domain/// Performs O(nlogn) multiplication of polynomials if F is smooth.rand_sparse_polydouble_polynomials_randomadd_sparse_polynomialsadd_assign_sparse_polynomialsadd_polynomials_with_mulsub_sparse_polynomialssub_assign_sparse_polynomialspolynomial_additive_identitydivide_polynomials_fixeddivide_polynomials_randommul_random_elementmul_polynomials_randomtest_leading_zeroevaluate_over_domain_test//! A dense univariate polynomial represented in coefficient form.CowSPolynomial/// Represents the case where `self` is a sparse polynomialDPolynomial/// Represents the case where `self` is a dense polynomial/// Represents either a sparse polynomial or a dense one.try_into/// Return the degree of `self.leading_coefficientiter_with_indexdivide_with_q_and_r/// Divide self by another (sparse or dense) polynomial, and returns the/// quotient and remainder./// Construct `Evaluations` by evaluating a polynomial over the domain/// `domain`.eval_over_domain_helper//! Work with sparse and dense polynomials./// The coefficient a_i of `x^i` is stored as (i, a_i) in `self.coeffs`./// the entries in `self.coeffs` *must*  be sorted in increasing order of/// `i`./// Stores a sparse polynomial in coefficient form./// Returns the degree of the polynomial.// TODO: Reduce number of clonesappend_coeffs// append append_coeffs to self.// Correctness relies on the lowest degree term in append_coeffs// being higher than self.degree()ZERO_COEFF_PROBABILITY// probability of rand sparse polynomial having a particular coefficient be 0evaluate_at_pointadd_polynomialmul_polynomialevaluate_over_small_domain//! A sparse polynomial represented in coefficient form.fft_composition// Test multiplying various (low degree) polynomials together and// comparing with naive evaluations.NotEnoughSpace/// During serialization, we didn't have enough space to write extra info.InvalidData/// During serialization, the data was invalid.UnexpectedFlags/// During serialization, non-empty flags were given where none were/// expected.IoError/// During serialization, we countered an I/O error./// This is an error that could occur during serialization/// The number of bits required to encode `Self`./// This should be at most 8.// Returns a bit mask corresponding to `self`.// For example, if `Self` contains two variants, there are just two possible// bit masks: `0` and `1 << 7`.// Tries to read `Self` from `value`. Should return `None` if the// `Self::BIT_SIZE` most-significant bits of `value` do not correspond to// those generated by `u8_bitmask`.// That is, this method ignores all but the top `Self::BIT_SIZE` bits, and// decides whether these top bits correspond to a bitmask output by// `u8_bitmask`.from_u8_remove_flags// Convenience method that reads `Self` from `value`, just like `Self::from_u8`,// but additionally zeroes out the bits corresponding to the resulting flag// in `value`. If `Self::from_u8(*value)` would return `None`, then this// method should *not* modify `value`./// Represents metadata to be appended to an object's serialization. For/// example, when serializing elliptic curve points, one can/// use a `Flag` to represent whether the serialization is the point/// at infinity, or whether the `y` coordinate is positive or not./// These bits will be appended to the end of the point's serialization,/// or included in a new byte, depending on space available./// This is meant to be provided to `CanonicalSerializeWithFlags` and/// `CanonicalDeserializeWithFlags`rcRcimpl_uint// No-opToOwnedOwnedimpl_tuple// Implement Serialization for tuples/// Serializes a `BTreeMap` as `len(map) || key 1 || value 1 || ... || key n || value n`./// Deserializes a `BTreeMap` from `len(map) || key 1 || value 1 || ... || key n || value n`./// Serializes a `BTreeSet` as `len(set) || value 1 || value 2 || ... || value n`./// Deserializes a `BTreeSet` from `len(map) || value 1 || ... || value n`.flagsimplsOutputSizeUser/// Whether to use a compressed version of the serialization algorithm. Specific behavior depends/// on implementation. If no compressed version exists (e.g. on `Fp`), mode is ignored./// Whether to validate the element after deserializing it. Specific behavior depends on/// implementation. If no validation algorithm exists (e.g. on `Fp`), mode is ignored./// The general serialize method that takes in customization flags.serialize_compressedcompressed_sizeserialize_uncompresseduncompressed_size/// Serializer in little endian format./// This trait can be derived if all fields of a struct implement/// `CanonicalSerialize` and the `derive` feature is enabled./// // The `derive` feature must be set for the derivation to work./// use ark_serialize::*;/// # #[cfg(feature = "derive")]/// #[derive(CanonicalSerialize)]/// struct TestStruct {///     a: u64,///     b: (u64, (u64, u64)),/// The general deserialize method that takes in customization flags.deserialize_compresseddeserialize_compressed_uncheckeddeserialize_uncompresseddeserialize_uncompressed_unchecked/// Deserializer in little endian format./// `CanonicalDeserialize` and the `derive` feature is enabled./// #[derive(CanonicalDeserialize)]/// Serializes `self` and `flags` into `writer`./// Serializer in little endian format allowing to encode flags./// Reads `Self` and `Flags` from `reader`./// Returns empty flags by default./// Deserializer in little endian format allowing flags to be encoded.HashMarshaller// This private struct works around Serialize taking the pre-existing// std::io::Write instance of most digest::Digest implementations by valueOutputSizehash_uncompressedCanonicalSerializeHashExt/// The CanonicalSerialize induces a natural way to hash the/// corresponding value, of which this is the convenience trait./// CanonicalSerializeHashExt is a (blanket) extension trait of/// CanonicalSerializebuffer_bit_byte_size/// Converts the number of bits required to represent a number/// into the number of bytes required to represent it.RngCoreDummytest_serializeensure_non_malleable_encoding// Serialize T, randomly mutate the data, and deserialize it.// Ensure it fails.// Up to the caller to provide a valid mutation criterion// to ensure that this test always fails.// This method requires a concrete instance of the data to be provided,// to get the serialized size.test_arraytest_vectest_uinttest_stringtest_tupletest_tuple_vectest_optiontest_booltest_btreemaptest_btreesettest_phantomdatatest_sha2test_blake2test_sha3test_biguintIdentOrIndexDataimpl_valid_fieldimpl_validimpl_deserialize_field/// Returns a `TokenStream` for `deserialize_with_mode`./// uncompressed.impl_canonical_deserializederive_canonical_serializederive_canonical_deserializeimpl_serialize_fieldimpl_canonical_serializeRepr/// The error type for I/O operations of the [`Read`], [`Write`], [`Seek`], and/// associated traits./// Errors mostly originate from the underlying OS, but custom instances of/// `Error` can be created with crafted error messages and a particular value of/// [`ErrorKind`]./// [`Read`]: crate::io::Read/// [`Write`]: crate::io::Write/// [`Seek`]: crate::io::SeekSimpleNotFound/// An entity was not found, often a file.PermissionDenied/// The operation lacked the necessary privileges to complete.ConnectionRefused/// The connection was refused by the remote server.ConnectionReset/// The connection was reset by the remote server.ConnectionAborted/// The connection was aborted (terminated) by the remote server.NotConnected/// The network operation failed because it was not connected yet.AddrInUse/// A socket address could not be bound because the address is already in/// use elsewhere.AddrNotAvailable/// A nonexistent interface was requested or the requested address was not/// local.BrokenPipe/// The operation failed because a pipe was closed.AlreadyExists/// An entity already exists, often a file.WouldBlock/// The operation needs to block to complete, but the blocking operation was/// requested to not occur.InvalidInput/// A parameter was incorrect./// Data not valid for the operation were encountered./// Unlike [`InvalidInput`], this typically means that the operation/// parameters were valid, however the error was caused by malformed/// input data./// For example, a function that reads a file into a string will error with/// `InvalidData` if the file's contents are not valid UTF-8./// [`InvalidInput`]: ErrorKind::InvalidInputTimedOut/// The I/O operation's timeout expired, causing it to be canceled.WriteZero/// An error returned when an operation could not be completed because a/// call to [`write`] returned [`Ok(0)`]./// This typically means that an operation could only succeed if it wrote a/// particular number of bytes but only a smaller number of bytes could be/// written./// [`write`]: crate::io::Write::write/// [`Ok(0)`]: OkInterrupted/// This operation was interrupted./// Interrupted operations can typically be retried.Other/// Any I/O error not part of this list./// Errors that are `Other` now may move to a different or a new/// [`ErrorKind`] variant in the future. It is not recommended to match/// an error against `Other` and to expect any additional characteristics,/// e.g., a specific [`Error::raw_os_error`] return value.UnexpectedEof/// An error returned when an operation could not be completed because an/// "end of file" was reached prematurely./// This typically means that an operation could only succeed if it read a/// read./// A list specifying general categories of I/O error./// This list is intended to grow over time and it is not recommended to/// exhaustively match against it./// It is used with the [`io::Error`] type./// [`io::Error`]: Error/// Converts an [`ErrorKind`] into an [`Error`]./// This conversion allocates a new error with a simple representation of error kind./// use ark_std::io::{Error, ErrorKind};/// let not_found = ErrorKind::NotFound;/// let error = Error::from(not_found);/// assert_eq!("entity not found", format!("{}", error));/// Intended for use for errors not exposed to the user, where allocating onto/// the heap (for normal construction via Error::new) is too costly./// Creates a new I/O error from a known kind of error as well as an/// arbitrary error payload./// This function is used to generically create I/O errors which do not/// originate from the OS itself. The `error` argument is an arbitrary/// payload which will be contained in this [`Error`]./// // errors can be created from strings/// let custom_error = Error::new(ErrorKind::Other, "oh no!");/// // errors can also be created from other errors/// let custom_error2 = Error::new(ErrorKind::Interrupted, custom_error);_newget_ref/// Consumes the `Error`, returning its inner error (if any)./// If this [`Error`] was constructed via [`new`] then this function will/// return [`Some`], otherwise it will return [`None`]./// [`new`]: Error::new/// Returns the corresponding [`ErrorKind`] for this error._assert_error_is_sync_send/// Pull some bytes from this source into the specified buffer, returning/// how many bytes were read./// This function does not provide any guarantees about whether it blocks/// waiting for data, but if an object needs to block for a read but cannot/// it will typically signal this via an [`Err`] return value./// If the return value of this method is [`Ok(n)`], then it must be/// guaranteed that `0 <= n <= buf.len()`. A nonzero `n` value indicates/// that the buffer `buf` has been filled in with `n` bytes of data from this/// source. If `n` is `0`, then it can indicate that the the buffer/// specified was 0 bytes in length./// No guarantees are provided about the contents of `buf` when this/// function is called, implementations cannot rely on any property of the/// contents of `buf` being true. It is recommended that implementations/// only write data to `buf` instead of reading its contents./// If this function encounters any form of I/O or other error, an error/// variant will be returned. If an error is returned then it must be/// guaranteed that no bytes were read./// An error of the [`ErrorKind::Interrupted`] kind is non-fatal and the read/// operation should be retried if there is nothing else to do.read_exact/// Read the exact number of bytes required to fill `buf`./// This function reads as many bytes as necessary to completely fill the/// specified buffer `buf`./// If this function encounters an error of the kind/// [`ErrorKind::Interrupted`] then the error is ignored and the operation/// will continue./// If any other read error is encountered then this function immediately/// returns. The contents of `buf` are unspecified in this case./// If this function returns an error, it is unspecified how many bytes it/// has read, but it will never read more than would be necessary to/// completely fill the buffer./// Creates a "by reference" adaptor for this instance of `Read`./// The returned adaptor also implements `Read` and will simply borrow this/// current reader./// The `Read` trait allows for reading bytes from a source./// Implementors of the `Read` trait are called 'readers'./// Readers are defined by one required method, [`read()`]. Each call to [`read()`]/// will attempt to pull bytes from this source into a provided buffer. A/// number of other methods are implemented in terms of [`read()`], giving/// implementors a number of ways to read bytes while only needing to implement/// a single method./// Readers are intended to be composable with one another. Many implementors/// throughout [`ark_std::io`] take and provide types which implement the `Read`/// Please note that each call to [`read()`] may involve a system call, and/// therefore, using something that implements [`BufRead`], such as/// [`BufReader`], will be more efficient./// Read from [`&str`] because [`&[u8]`][slice] implements `Read`:/// ```no_run/// # use ark_std::io;/// use ark_std::io::prelude::*;///     let mut b = "This string will be read".as_bytes();///     let mut buffer = [0; 10];///     // read up to 10 bytes///     b.read(&mut buffer)?;/// [`read()`]: trait.Read.html#tymethod.read/// [`ark_std::io`]: ../../std/io/index.html/// [`BufRead`]: trait.BufRead.html/// [`BufReader`]: struct.BufReader.html/// [`&str`]: ../../std/primitive.str.html/// [slice]: ../../std/primitive.slice.html/// Write a buffer into this writer, returning how many bytes were written./// This function will attempt to write the entire contents of `buf`, but/// the entire write may not succeed, or the write may also generate an/// error. A call to `write` represents *at most one* attempt to write to/// any wrapped object./// Calls to `write` are not guaranteed to block waiting for data to be/// written, and a write which would otherwise block can be indicated through/// an [`Err`] variant./// If the return value is [`Ok(n)`] then it must be guaranteed that/// `0 <= n <= buf.len()`. A return value of `0` typically means that the/// underlying object is no longer able to accept bytes and will likely not/// be able to in the future as well, or that the buffer provided is empty./// Each call to `write` may generate an I/O error indicating that the/// operation could not be completed. If an error is returned then no bytes/// in the buffer were written to this writer./// It is **not** considered an error if the entire buffer could not be/// written to this writer./// An error of the [`ErrorKind::Interrupted`] kind is non-fatal and the/// write operation should be retried if there is nothing else to do./// [`Err`]: ../../std/result/enum.Result.html#variant.Err/// [`Ok(n)`]:  ../../std/result/enum.Result.html#variant.Ok/// [`ErrorKind::Interrupted`]: ../../std/io/enum.ErrorKind.html#variant.Interrupted/// Flush this output stream, ensuring that all intermediately buffered/// contents reach their destination./// It is considered an error if not all bytes could be written due to/// I/O errors or EOF being reached./// Attempts to write an entire buffer into this writer./// This method will continuously call [`write`] until there is no more data/// to be written or an error of non-[`ErrorKind::Interrupted`] kind is/// returned. This method will not return until the entire buffer has been/// successfully written or such an error occurs. The first error that is/// not of [`ErrorKind::Interrupted`] kind generated from this method will be/// This function will return the first error of/// non-[`ErrorKind::Interrupted`] kind that [`write`] returns./// [`write`]: #tymethod.write/// Creates a "by reference" adaptor for this instance of `Write`./// The returned adaptor also implements `Write` and will simply borrow this/// current writer.Cursor/// This data structure is used as a workaround for current design of `ToBytes`/// which does not allow multiple writes to `&mut [u8]`./// Creates a new cursor wrapping the provided underlying in-memory buffer./// Cursor initial position is `0` even if underlying buffer (e.g., `Vec`)/// is not empty. So writing to cursor starts with overwriting `Vec`/// content, not with appending to it./// use ark_std::io::Cursor;/// let buff = Cursor::new(Vec::new());/// # fn force_inference(_: &Cursor<Vec<u8>>) {}/// # force_inference(&buff);/// Consumes this cursor, returning the underlying value./// let vec = buff.into_inner();/// Gets a reference to the underlying value in this cursor./// let reference = buff.get_ref();/// Gets a mutable reference to the underlying value in this cursor./// Care should be taken to avoid modifying the internal I/O state of the/// underlying value as it may corrupt this cursor's position./// let mut buff = Cursor::new(Vec::new());/// let reference = buff.get_mut();position/// Returns the current position of this cursor.set_position/// Sets the position of this cursor./// let mut buff = Cursor::new(vec![1, 2, 3, 4, 5]);/// assert_eq!(buff.position(), 0);/// buff.set_position(2);/// assert_eq!(buff.position(), 2);/// buff.set_position(4);/// assert_eq!(buff.position(), 4);get_bufslice_write// Non-resizing write implementationvec_write//! no-std io replacement/////////////////////////////////////////////////////////////////////////////////revReverse/// The type of the element being streamed./// The type of the iterator being generated.///  Return the iterator associated to the current instance./// In the so-called _streaming model_ [BCHO22], this is equivalent to/// instantiating a new stream tape./// For base types, this acts in the same way as the `.iter()` method.///  ```/// use ark_std::iterable::Iterable;/// let x = &[1, 2, 4];/// let mut iterator = x.iter();/// Return a hint on the length of the stream./// Careful: different objects might have different indications of what/// _length_ means; this might not be the actual size in terms of/// elements./// Return `true` if the stream is empty, else `false`./// The trait [`Iterable`] represents a streamable object that can produce/// an arbitrary number of streams of length [`Iterable::len`](Iterable::len)./// An Iterable is pretty much like an [`IntoIterator`] that can be copied over/// and over, and has an hint of the length.  Copies are meant to be shared/// across threads safely./// use ark_std::borrow::Borrow;/// // Relying only on standard library/// fn f(xs: impl IntoIterator<Item=impl Borrow<u32>> + Clone) -> u32 {///     xs.clone().into_iter().fold(1, |x, y| x.borrow() * y.borrow()) +///     xs.clone().into_iter().fold(0, |x, y| x.borrow() + y.borrow()) +///     xs.into_iter().size_hint().0 as u32/// // Relying on the trait below/// fn g(xs: impl Iterable<Item=impl Borrow<u32>>) -> u32 {///     xs.iter().fold(1, |x, y| x.borrow() * y.borrow()) +///     xs.iter().fold(0, |x, y| x.borrow() + y.borrow()) +///     xs.len() as u32/// // Test over a slice (which implements both traits)./// let xs = &[1, 2, 3, 4];/// assert_eq!(f(xs), g(xs));/// # Efficency/// For efficiency, functions using iterables are often times relying on/// [`Borrow`](std::borrow::Borrow) in order to avoid copying the contents of/// the iterator../// The `Iter` associated type has a lifetime that is independent from that of/// the [`Iterable`] object. This means that implicitly a copy of the relevant/// contents of the object will happen whenever/// [`Iterable::iter`](crate::iterable::Iterable::iter) is called. This might/// change in the future as associated type constructors/// [[RFC1598](https://github.com/rust-lang/rfcs/blob/master/text/1598-generic_associated_types.md#declaring--assigning-an-associated-type-constructor)]/// stabilize./// # Future implementation/// A lot of stream operations must be performed symbolically./// We expect that, in the future, this trait will accommodate for additional/// streaming function, e.g. `Iterable::hadamard(&self, other: &Iterable)` to/// perform the Hadamard product of two streams, or `Iterable::add(&self, other:/// &Iterable)` to perform the addition of two streams.//! A base library for interfacing with streams of vectors and matrices.//! This library presents the abstraction layer for the _streaming model_.//! Essentially, it provides a set of handy utilities as a wrapper around//! iterators.Rev/// Stream that goes over an `[ExactSizeIterator]` in reverse order./// This stream allows to switch fast from little endian ordering used in/// time-efficient algorithms, e.g. in slices `&[T]` into big endia ordering/// (used in space-efficient algorithms./// use ark_std::iterable::{Iterable, Reverse};/// let le_v = &[1, 2, 3];/// let be_v = Reverse(le_v);/// let mut be_v_iter = be_v.iter();/// assert_eq!(be_v_iter.next(), Some(&3));/// assert_eq!(be_v_iter.next(), Some(&2));/// assert_eq!(be_v_iter.next(), Some(&1));rand_helperperf_tracelog2/// Returns the ceiling of the base-2 logarithm of `x`./// use ark_std::log2;/// assert_eq!(log2(16), 4);/// assert_eq!(log2(17), 5);/// assert_eq!(log2(1), 0);/// assert_eq!(log2(0), 0);/// assert_eq!(log2(usize::MAX), (core::mem::size_of::<usize>() * 8) as u32);/// assert_eq!(log2(1 << 15), 15);/// assert_eq!(log2(2usize.pow(18)), 18);/// Creates parallel iterator over refs if `parallel` feature is enabled./// Additionally, if the object being iterated implements/// `IndexedParallelIterator`, then one can specify a minimum size for/// iteration./// Creates parallel iterator over mut refs if `parallel` feature is enabled.cfg_into_iter/// Creates parallel iterator if `parallel` feature is enabled.cfg_chunks/// Returns an iterator over `chunk_size` elements of the slice at a/// Returns an iterator over `chunk_size` mutable elements of the slice at atest_cfg_macrosTimerInfostart_timeradd_to_traceend_timerprint_start_endprint_add//! This module contains macros for logging to stdout a trace of wall-clock time required//! to execute annotated code. One can use this code as follows://! use ark_std::{start_timer, end_timer};//! let start = start_timer!(|| "Addition of two integers");//! let c = 5 + 7;//! end_timer!(start);//! The foregoing code should log the following to stdout.//! Start: Addition of two integers//! End: Addition of two integers... 1ns//! These macros can be arbitrarily nested, and the nested nature is made apparent//! in the output. For example, the following snippet://! let start2 = start_timer!(|| "Inner");//! end_timer!(start2);//! should print out the following://!     Start: Inner//!     End: Inner               ... 1ns//! Additionally, one can use the `add_to_trace` macro to log additional context//! in the output.StdRngtest_rng_helper/// Should be used only for tests, not for any real world usage./// You can use `array_ref` to generate an array reference to a subset/// of a sliceable bit of data (which could be an array, or a slice,/// or a Vec)./// **Panics** if the slice is out of bounds./// #[macro_use]/// extern crate arrayref;/// fn read_u16(bytes: &[u8; 2]) -> u16 {///      bytes[0] as u16 + ((bytes[1] as u16) << 8)/// // .../// let data = [0,1,2,3,4,0,6,7,8,9];/// assert_eq!(256, read_u16(array_ref![data,0,2]));/// assert_eq!(4, read_u16(array_ref![data,4,2]));array_refs/// You can use `array_refs` to generate a series of array references/// to an input array reference.  The idea is if you want to break an/// array into a series of contiguous and non-overlapping arrays./// `array_refs` is a bit funny in that it insists on slicing up the/// *entire* array.  This is intentional, as I find it handy to make/// me ensure that my sub-arrays add up to the entire array.  This/// macro will *never* panic, since the sizes are all checked at/// compile time./// Note that unlike `array_ref!`, `array_refs` *requires* that the/// first argument be an array reference.  The following arguments are/// the lengths of each subarray you wish a reference to.  The total/// of these arguments *must* equal the size of the array itself./// let data = [0,1,2,3,4,0,6,7];/// let (a,b,c) = array_refs![&data,2,2,4];/// assert_eq!(read_u16(a), 256);/// assert_eq!(read_u16(b), 3*256+2);/// assert_eq!(*c, [4,0,6,7]);mut_array_refs/// You can use `mut_array_refs` to generate a series of mutable array/// references to an input mutable array reference.  The idea is if/// you want to break an array into a series of contiguous and/// non-overlapping mutable array references.  Like `array_refs!`,/// `mut_array_refs!` is a bit funny in that it insists on slicing up/// the *entire* array.  This is intentional, as I find it handy to/// make me ensure that my sub-arrays add up to the entire array./// This macro will *never* panic, since the sizes are all checked at/// Note that unlike `array_mut_ref!`, `mut_array_refs` *requires*/// that the first argument be a mutable array reference.  The/// following arguments are the lengths of each subarray you wish a/// reference to.  The total of these arguments *must* equal the size/// of the array itself.  Also note that this macro allows you to take/// out multiple mutable references to a single object, which is both/// weird and powerful./// fn write_u16(bytes: &mut [u8; 2], num: u16) {///      bytes[0] = num as u8;///      bytes[1] = (num >> 8) as u8;/// fn write_u32(bytes: &mut [u8; 4], num: u32) {///      bytes[1] = (num >> 8) as u8; // this is buggy to save space.../// let mut data = [0,1,2,3,4,0,6,7];/// let (a,b,c) = mut_array_refs![&mut data,2,2,4];/// // let's write out some nice prime numbers!/// write_u16(a, 37);/// write_u16(b, 73);/// write_u32(c, 137); // approximate inverse of the fine structure constant!array_mut_ref/// You can use `array_mut_ref` to generate a mutable array reference/// to a subset of a sliceable bit of data (which could be an array,/// or a slice, or a Vec)./// let mut data = [0,1,2,3,4,0,6,7,8,9];/// write_u16(array_mut_ref![data,0,2], 1);/// write_u16(array_mut_ref![data,2,2], 5);/// assert_eq!(*array_ref![data,0,4], [1,0,5,0]);/// *array_mut_ref![data,4,5] = [4,3,2,1,0];/// assert_eq!(data, [1,0,5,0,4,3,2,1,0,9]);quickcheckchecks_boundssimple_case_workscheck_array_ref_5check_array_ref_out_of_bounds_5check_array_mut_ref_7check_array_mut_ref_out_of_bounds_32test_5_array_refstest_5_array_refs_dotdottest_5_mut_xarray_refstest_5_mut_xarray_refs_with_dotdotforbidden_clippy_lints_do_not_firesingle_arg_refs// use super::*;//! This package contains just four macros, which enable the creation//! of array references to portions of arrays or slices (or things//! that can be sliced).//! # Examples//! Here is a simple example of slicing and dicing a slice into array//! references with these macros.  Here we implement a simple//! little-endian conversion from bytes to `u16`, and demonstrate code//! that uses `array_ref!` to extract an array reference from a larger//! array.  Note that the documentation for each macro also has an//! example of its use.//! #[macro_use]//! extern crate arrayref;//! fn read_u16(bytes: &[u8; 2]) -> u16 {//!      bytes[0] as u16 + ((bytes[1] as u16) << 8)//! // ...//! # fn main() {//! let data = [0,1,2,3,4,0,6,7,8,9];//! assert_eq!(256, read_u16(array_ref![data,0,2]));//! assert_eq!(4, read_u16(array_ref![data,4,2]));// mod testBorrowMutUtf8ErrorCapacityErrorLenUintcharencode_utf8MakeMaybeUninit// the `len` first elements of the array are initializedxsCAPArrayString/// A string with a fixed capacity./// The `ArrayString` is a string backed by a fixed size array. It keeps track/// of its length, and is parameterized by `CAP` for the maximum capacity./// `CAP` is of type `usize` but is range limited to `u32::MAX`; attempting to create larger/// arrayvecs with larger capacity will panic./// The string is a contiguous value that you can store directly on the stack/// if needed./// Return an empty `ArrayString`/// Create a new empty `ArrayString`./// Capacity is inferred from the type parameter./// use arrayvec::ArrayString;/// let mut string = ArrayString::<16>::new();/// string.push_str("foo");/// assert_eq!(&string[..], "foo");/// assert_eq!(string.capacity(), 16);new_const/// Create a new empty `ArrayString` (const fn)./// static ARRAY: ArrayString<1024> = ArrayString::new_const();/// Return the length of the string./// Returns whether the string is empty./// Create a new `ArrayString` from a `str`./// **Errors** if the backing array is not large enough to fit the string./// let mut string = ArrayString::<3>::from("foo").unwrap();/// assert_eq!(string.len(), 3);/// assert_eq!(string.capacity(), 3);from_byte_string/// Create a new `ArrayString` from a byte string literal./// **Errors** if the byte string literal is not valid UTF-8./// let string = ArrayString::from_byte_string(b"hello world").unwrap();zero_filled/// Create a new `ArrayString` value fully filled with ASCII NULL characters (`\0`). Useful/// to be used as a buffer to collect external data or as a buffer for intermediate processing./// let string = ArrayString::<16>::zero_filled();/// assert_eq!(string.len(), 16);capacity/// Return the capacity of the `ArrayString`./// let string = ArrayString::<3>::new();is_full/// Return if the `ArrayString` is completely filled./// let mut string = ArrayString::<1>::new();/// assert!(!string.is_full());/// string.push_str("A");/// assert!(string.is_full());remaining_capacity/// Returns the capacity left in the `ArrayString`./// let mut string = ArrayString::<3>::from("abc").unwrap();/// string.pop();/// assert_eq!(string.remaining_capacity(), 1);track_callerpush/// Adds the given char to the end of the string./// ***Panics*** if the backing array is not large enough to fit the additional char./// let mut string = ArrayString::<2>::new();/// string.push('a');/// string.push('b');/// assert_eq!(&string[..], "ab");try_push/// Returns `Ok` if the push succeeds./// **Errors** if the backing array is not large enough to fit the additional char./// string.try_push('a').unwrap();/// string.try_push('b').unwrap();/// let overflow = string.try_push('c');/// assert_eq!(overflow.unwrap_err().element(), 'c');push_str/// Adds the given string slice to the end of the string./// ***Panics*** if the backing array is not large enough to fit the string./// string.push_str("a");/// string.push_str("d");/// assert_eq!(&string[..], "ad");try_push_str/// string.try_push_str("a").unwrap();/// let overflow1 = string.try_push_str("bc");/// string.try_push_str("d").unwrap();/// let overflow2 = string.try_push_str("ef");/// assert_eq!(overflow1.unwrap_err().element(), "bc");/// assert_eq!(overflow2.unwrap_err().element(), "ef");pop/// Removes the last character from the string and returns it./// Returns `None` if this `ArrayString` is empty./// /// let mut s = ArrayString::<3>::from("foo").unwrap();/// assert_eq!(s.pop(), Some('o'));/// assert_eq!(s.pop(), Some('f'));/// assert_eq!(s.pop(), None);/// Shortens this `ArrayString` to the specified length./// If `new_len` is greater than the string’s current length, this has no/// effect./// ***Panics*** if `new_len` does not lie on a `char` boundary./// let mut string = ArrayString::<6>::from("foobar").unwrap();/// string.truncate(3);/// string.truncate(4);/// Removes a `char` from this `ArrayString` at a byte position and returns it./// This is an `O(n)` operation, as it requires copying every element in the/// ***Panics*** if `idx` is larger than or equal to the `ArrayString`’s length,/// or if it does not lie on a `char` boundary./// assert_eq!(s.remove(0), 'f');/// assert_eq!(s.remove(1), 'o');/// assert_eq!(s.remove(0), 'o');clear/// Make the string empty.set_len/// Set the strings’s length./// This function is `unsafe` because it changes the notion of the/// number of “valid” bytes in the string. Use with care./// This method uses *debug assertions* to check the validity of `length`/// and may use other debug assertions./// Return a string slice of the whole `ArrayString`.as_mut_str/// Return a mutable string slice of the whole `ArrayString`./// Return a raw pointer to the string's buffer.as_mut_ptr/// Return a raw mutable pointer to the string's buffer.borrow_mutwrite_char/// `Write` appends written data to the end of the string.clone_fromltlegtgeBound// extra traitsarrayvec_implArrayVecImplArrayVec/// A vector with a fixed capacity./// The `ArrayVec` is a vector backed by a fixed size array. It keeps track of/// the number of initialized elements. The `ArrayVec<T, CAP>` is parameterized/// by `T` for the element type and `CAP` for the maximum capacity./// The vector is a contiguous value (storing the elements inline) that you can store directly on/// the stack if needed./// It offers a simple API but also dereferences to a slice, so that the full slice API is/// available. The ArrayVec can be converted into a by value iterator.panic_oobCAPACITY/// Capacity/// Create a new empty `ArrayVec`./// The maximum capacity is given by the generic parameter `CAP`./// use arrayvec::ArrayVec;/// let mut array = ArrayVec::<_, 16>::new();/// array.push(1);/// array.push(2);/// assert_eq!(&array[..], &[1, 2]);/// assert_eq!(array.capacity(), 16);/// Create a new empty `ArrayVec` (const fn)./// static ARRAY: ArrayVec<u8, 1024> = ArrayVec::new_const();/// Return the number of elements in the `ArrayVec`./// let mut array = ArrayVec::from([1, 2, 3]);/// array.pop();/// assert_eq!(array.len(), 2);/// Returns whether the `ArrayVec` is empty./// let mut array = ArrayVec::from([1]);/// assert_eq!(array.is_empty(), true);/// Return the capacity of the `ArrayVec`./// let array = ArrayVec::from([1, 2, 3]);/// assert_eq!(array.capacity(), 3);/// Return true if the `ArrayVec` is completely filled to its capacity, false otherwise./// let mut array = ArrayVec::<_, 1>::new();/// assert!(!array.is_full());/// assert!(array.is_full());/// Returns the capacity left in the `ArrayVec`./// assert_eq!(array.remaining_capacity(), 1);/// Push `element` to the end of the vector./// ***Panics*** if the vector is already full./// let mut array = ArrayVec::<_, 2>::new();/// Return `Ok` if the push succeeds, or return an error if the vector/// is already full./// let push1 = array.try_push(1);/// let push2 = array.try_push(2);/// assert!(push1.is_ok());/// assert!(push2.is_ok());/// let overflow = array.try_push(3);/// assert!(overflow.is_err());push_unchecked/// Push `element` to the end of the vector without checking the capacity./// It is up to the caller to ensure the capacity of the vector is/// sufficiently large./// This method uses *debug assertions* to check that the arrayvec is not full./// if array.len() + 2 <= array.capacity() {///     unsafe {///         array.push_unchecked(1);///         array.push_unchecked(2);/// Shortens the vector, keeping the first `len` elements and dropping/// the rest./// If `len` is greater than the vector’s current length this has no/// let mut array = ArrayVec::from([1, 2, 3, 4, 5]);/// array.truncate(3);/// assert_eq!(&array[..], &[1, 2, 3]);/// array.truncate(4);/// Remove all elements in the vector.get_unchecked_ptr/// Get pointer to where element at `index` would be/// Insert `element` at position `index`./// Shift up all elements after `index`./// It is an error if the index is greater than the length or if the/// arrayvec is full./// ***Panics*** if the array is full or the `index` is out of bounds. See/// `try_insert` for fallible version./// array.insert(0, "x");/// array.insert(0, "y");/// assert_eq!(&array[..], &["y", "x"]);try_insert/// Shift up all elements after `index`; the `index` must be less than/// or equal to the length./// Returns an error if vector is already at full capacity./// ***Panics*** `index` is out of bounds./// assert!(array.try_insert(0, "x").is_ok());/// assert!(array.try_insert(0, "y").is_ok());/// assert!(array.try_insert(0, "z").is_err());/// Remove the last element in the vector and return it./// Return `Some(` *element* `)` if the vector is non-empty, else `None`./// assert_eq!(array.pop(), Some(1));/// assert_eq!(array.pop(), None);swap_remove/// Remove the element at `index` and swap the last element into its place./// This operation is O(1)./// Return the *element* if the index is in bounds, else panic./// ***Panics*** if the `index` is out of bounds./// assert_eq!(array.swap_remove(0), 1);/// assert_eq!(&array[..], &[3, 2]);/// assert_eq!(array.swap_remove(1), 2);/// assert_eq!(&array[..], &[3]);swap_pop/// This is a checked version of `.swap_remove`.  /// Return `Some(` *element* `)` if the index is in bounds, else `None`./// assert_eq!(array.swap_pop(0), Some(1));/// assert_eq!(array.swap_pop(10), None);/// Remove the element at `index` and shift down the following elements./// The `index` must be strictly less than the length of the vector./// let removed_elt = array.remove(0);/// assert_eq!(removed_elt, 1);/// assert_eq!(&array[..], &[2, 3]);pop_at/// This is a checked version of `.remove(index)`. Returns `None` if there/// is no element at `index`. Otherwise, return the element inside `Some`./// assert!(array.pop_at(0).is_some());/// assert!(array.pop_at(2).is_none());/// assert!(array.pop_at(10).is_none());retain/// Retains only the elements specified by the predicate./// In other words, remove all elements `e` such that `f(&mut e)` returns false./// This method operates in place and preserves the order of the retained/// let mut array = ArrayVec::from([1, 2, 3, 4]);/// array.retain(|x| *x & 1 != 0 );/// assert_eq!(&array[..], &[1, 3]);/// Set the vector’s length without dropping or moving out elements/// This method is `unsafe` because it changes the notion of the/// number of “valid” elements in the vector. Use with care./// This method uses *debug assertions* to check that `length` is/// not greater than the capacity.try_extend_from_slice/// Copy all elements from the slice and append to the `ArrayVec`./// let mut vec: ArrayVec<usize, 10> = ArrayVec::new();/// vec.push(1);/// vec.try_extend_from_slice(&[2, 3]).unwrap();/// assert_eq!(&vec[..], &[1, 2, 3]);/// This method will return an error if the capacity left (see/// [`remaining_capacity`]) is smaller then the length of the provided/// slice./// [`remaining_capacity`]: #method.remaining_capacitydrainDrain/// Create a draining iterator that removes the specified range in the vector/// and yields the removed items from start to end. The element range is/// removed even if the iterator is not consumed until the end./// Note: It is unspecified how many elements are removed from the vector,/// if the `Drain` value is leaked./// **Panics** if the starting point is greater than the end point or if/// the end point is greater than the length of the vector./// let mut v1 = ArrayVec::from([1, 2, 3]);/// let v2: ArrayVec<_, 3> = v1.drain(0..2).collect();/// assert_eq!(&v1[..], &[3]);/// assert_eq!(&v2[..], &[1, 2]);drain_range/// Return the inner fixed size array, if it is full to its capacity./// Return an `Ok` value with the array if length equals capacity,/// return an `Err` with self otherwise.into_inner_unchecked/// Return the inner fixed size array./// Safety:/// This operation is safe if and only if length equals capacity.take/// Returns the ArrayVec, replacing the original with a new empty ArrayVec./// let mut v = ArrayVec::from([0, 1, 2, 3]);/// assert_eq!([0, 1, 2, 3], v.take().into_inner().unwrap());/// assert!(v.is_empty());/// Return a slice containing all elements of the vector.as_mut_slice/// Return a mutable slice containing all elements of the vector./// Return a raw pointer to the vector's buffer./// Return a raw mutable pointer to the vector's buffer./// Create an `ArrayVec` from an array./// assert_eq!(array.len(), 3);/// Try to create an `ArrayVec` from a slice. This will return an error if the slice was too big to/// fit./// use std::convert::TryInto as _;/// let array: ArrayVec<_, 4> = (&[1, 2, 3] as &[_]).try_into().unwrap();/// assert_eq!(array.capacity(), 4);/// Iterate the `ArrayVec` with references to each element./// for elt in &array {/// Iterate the `ArrayVec` with mutable references to each element./// for elt in &mut array {/// Iterate the `ArrayVec` with each element by value./// The vector is consumed by this operation./// for elt in ArrayVec::from([1, 2, 3]) {v/// By-value iterator for `ArrayVec`./// Returns the remaining items of this iterator as a slice./// Returns the remaining items of this iterator as a mutable slice.tail_start/// Index of tail to preservetail_len/// Length of tail/// Current remaining range to remove/// A draining iterator for `ArrayVec`.fScopeExitGuard/// Extend the `ArrayVec` with an iterator./// ***Panics*** if extending the vector exceeds its capacity.extend_panicCHECKextend_from_iter/// Extend the arrayvec from the iterable./// ## Safety/// Unsafe because if CHECK is false, the length of the input is not checked./// The caller must ensure the length of the input fits in the capacity./// Extend the ArrayVec with clones of elements from the slice;/// the length of the slice must be <= the remaining capacity in the arrayvec.raw_ptr_add/// Rawptr add but uses arithmetic distance for ZST/// Create an `ArrayVec` from an iterator./// ***Panics*** if the number of elements in the iterator exceeds the arrayvec's capacity./// Return an empty array/// Implements basic arrayvec methods - based on a few required methods/// for length and element access.TAG_CONT// UTF-8 ranges and tags for encoding charactersTAG_TWO_BTAG_THREE_BTAG_FOUR_BMAX_ONE_BMAX_TWO_BMAX_THREE_BEncodeUtf8Error/// Placeholder/// Encode a char into buf using UTF-8./// On success, return the byte length of the encoding (1, 2, 3 or 4).<br>/// On error, return `EncodeUtf8Error` if the buffer was too short for the char./// Safety: `ptr` must be writable for `len` bytes.test_encode_utf8// Miri is too slowtest_encode_utf8_oob// Copyright 2012-2016 The Rust Project Developers. See the COPYRIGHT// file at the top-level directory of this distribution and at// http://rust-lang.org/COPYRIGHT.// Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or// http://www.apache.org/licenses/LICENSE-2.0> or the MIT license// <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your// option. This file may not be copied, modified, or distributed// except according to those terms.// Original authors: alexchrichton, bluss/// Error value indicating insufficient capacity/// Create a new `CapacityError` from `element`./// Extract the overflowing elementsimplify/// Convert into a `CapacityError` that does not carry an element.CAPERRORassert_capacity_limitassert_capacity_limit_constarray_string//! **arrayvec** provides the types [`ArrayVec`] and [`ArrayString`]: //! array-backed vector and string types, which store their contents inline.//! The arrayvec package has the following cargo features://! - `std`//!   - Optional, enabled by default//!   - Use libstd; disable to use `no_std` instead.//! - `serde`//!   - Optional//!   - Enable serialization for ArrayVec and ArrayString using serde 1.x//! - `zeroize`//!   - Implement `Zeroize` for ArrayVec and ArrayString//! ## Rust Version//! This version of arrayvec requires Rust 1.51 or later.VALUEARRAY/// Asserts that an expression matches a given pattern./// A guard expression may be supplied to add further restrictions to the/// expected value of the expression./// A `match` arm may be supplied to perform additional assertions or to yield/// a value from the macro invocation./// #[macro_use] extern crate assert_matches;/// #[derive(Debug)]/// enum Foo {///     A(i32),///     B(&'static str),/// let a = Foo::A(1);/// // Assert that `a` matches the pattern `Foo::A(_)`./// assert_matches!(a, Foo::A(_));/// // Assert that `a` matches the pattern and/// // that the contained value meets the condition `i > 0`./// assert_matches!(a, Foo::A(i) if i > 0);/// let b = Foo::B("foobar");/// // Assert that `b` matches the pattern `Foo::B(_)`./// assert_matches!(b, Foo::B(s) => {///     // Perform additional assertions on the variable binding `s`.///     assert!(s.starts_with("foo"));///     assert!(s.ends_with("bar"));/// // Assert that `b` matches the pattern and yield the string `s`./// let s = assert_matches!(b, Foo::B(s) => s);/// // Perform an assertion on the value `s`./// assert_eq!(s, "foobar");debug_assert_matches/// Unlike [`assert_matches!`], `debug_assert_matches!` statements are only enabled/// in non-optimized builds by default. An optimized build will omit all/// `debug_assert_matches!` statements unless `-C debug-assertions` is passed/// to the compiler./// See the macro [`assert_matches!`] documentation for more information./// [`assert_matches!`]: macro.assert_matches.html_assert_matches_cfgcatch_unwindFootest_assert_succeedtest_assert_panic_0test_assert_panic_1test_assert_panic_2test_assert_panic_3test_assert_panic_4test_assert_panic_5test_assert_panic_6test_assert_no_moveassert_with_messagepanic_messagetest_panic_message//! Provides a macro, `assert_matches!`, which tests whether a value//! matches a given pattern, causing a panic if the match fails.//! See the macro [`assert_matches!`] documentation for more information.//! Also provides a debug-only counterpart, [`debug_assert_matches!`].//! See the macro [`debug_assert_matches!`] documentation for more information//! about this macro.//! [`assert_matches!`]: macro.assert_matches.html//! [`debug_assert_matches!`]: macro.debug_assert_matches.htmlStreamStdoutStderrStdin/// possible stream sources/// returns true if this is a ttyisnt/// returns true if this is _not_ a ttyis_erris_outis_in//! atty is a simple utility that answers one question//! > is this a tty?//! usage is just as simple//! if atty::is(atty::Stream::Stdout) {//!   println!("i'm a tty")//! if atty::isnt(atty::Stream::Stdout) {//!   println!("i'm not a tty")/// A common error type for the `autocfg` crate.causeIoParseIntErrorNumExitStatusProcessUtf8from_exitfrom_iofrom_numfrom_utf8try/// Local macro to avoid `std::try!`, deprecated in Rust 1.39.stderrATOMIC_USIZE_INITrustcRustcVersionout_dirrustflagsuuidAutoCfg/// Helper to detect compiler features for `cfg` output in build scripts./// Writes a config flag for rustc on standard out./// This looks like: `cargo:rustc-cfg=CFG`/// Cargo will use this in arguments to rustc, like `--cfg CFG`./// This does not automatically call [`emit_possibility`]/// so the compiler my generate an [`unexpected_cfgs` warning][check-cfg-flags]./// However, all the builtin emit methods on [`AutoCfg`] call [`emit_possibility`] automatically./// [check-cfg-flags]: https://blog.rust-lang.org/2024/05/06/check-cfg.htmlrerun_path/// Writes a line telling Cargo to rerun the build script if `path` changes./// This looks like: `cargo:rerun-if-changed=PATH`/// This requires at least cargo 0.7.0, corresponding to rustc 1.6.0.  Earlier/// versions of cargo will simply ignore the directive.rerun_env/// Writes a line telling Cargo to rerun the build script if the environment/// variable `var` changes./// This looks like: `cargo:rerun-if-env-changed=VAR`/// This requires at least cargo 0.21.0, corresponding to rustc 1.20.0.  Earlieremit_possibility/// Indicates to rustc that a config flag should not generate an [`unexpected_cfgs` warning][check-cfg-flags]/// This looks like `cargo:rustc-check-cfg=cfg(VAR)`/// As of rust 1.80, the compiler does [automatic checking of cfgs at compile time][check-cfg-flags]./// All custom configuration flags must be known to rustc, or they will generate a warning./// This is done automatically when calling the builtin emit methods on [`AutoCfg`],/// but not when calling [`autocfg::emit`](crate::emit) directly./// Versions before rust 1.80 will simply ignore this directive./// This function indicates to the compiler that the config flag never has a value./// If this is not desired, see [the blog post][check-cfg]./// Creates a new `AutoCfg` instance./// Panics if `AutoCfg::new()` returns an error./// # Common errors/// - `rustc` can't be executed, from `RUSTC` or in the `PATH`./// - The version output from `rustc` can't be parsed./// - `OUT_DIR` is not set in the environment, or is not a writable directory.with_dir/// Creates a new `AutoCfg` instance with the specified output directory./// - `dir` is not a writable directory./// Returns whether `AutoCfg` is using `#![no_std]` in its probes./// This is automatically detected during construction -- if an empty probe/// fails while one with `#![no_std]` succeeds, then the attribute will be/// used for all further probes. This is usually only necessary when the/// `TARGET` lacks `std` altogether. If neither succeeds, `no_std` is not/// set, but that `AutoCfg` will probably only work for version checks./// This attribute changes the implicit [prelude] from `std` to `core`,/// which may affect the paths you need to use in other probes. It also/// restricts some types that otherwise get additional methods in `std`,/// like floating-point trigonometry and slice sorting./// See also [`set_no_std`](#method.set_no_std)./// [prelude]: https://doc.rust-lang.org/reference/names/preludes.html#the-no_std-attributeset_no_std/// Sets whether `AutoCfg` should use `#![no_std]` in its probes./// See also [`no_std`](#method.no_std)./// Returns the `--edition` string that is currently being passed to `rustc`, if any,/// as configured by the [`set_edition`][Self::set_edition] method.set_edition/// Sets the `--edition` string that will be passed to `rustc`,/// or `None` to leave the compiler at its default edition./// See also [The Rust Edition Guide](https://doc.rust-lang.org/edition-guide/)./// **Warning:** Setting an unsupported edition will likely cause **all** subsequent probes to/// fail! As of this writing, the known editions and their minimum Rust versions are:/// | Edition | Version    |/// | ------- | ---------- |/// | 2015    | 1.27.0[^1] |/// | 2018    | 1.31.0     |/// | 2021    | 1.56.0     |/// | 2024    | 1.85.0     |/// [^1]: Prior to 1.27.0, Rust was effectively 2015 Edition by default, but the concept hadn't/// been established yet, so the explicit `--edition` flag wasn't supported either.probe_rustc_version/// Tests whether the current `rustc` reports a version greater than/// or equal to "`major`.`minor`".emit_rustc_version/// Sets a `cfg` value of the form `rustc_major_minor`, like `rustc_1_29`,/// if the current `rustc` is at least that version.new_crate_name/// Returns a new (hopefully unique) crate name for probes.probe_fmtprobeprobe_raw/// Tests whether the given code can be compiled as a Rust library./// This will only return `Ok` if the compiler ran and exited successfully,/// per `ExitStatus::success()`./// The code is passed to the compiler exactly as-is, notably not even/// adding the [`#![no_std]`][Self::no_std] attribute like other probes./// Raw probes are useful for testing functionality that's not yet covered/// by the rest of the `AutoCfg` API. For example, the following attribute/// **must** be used at the crate level, so it wouldn't work within the code/// templates used by other `probe_*` methods./// # extern crate autocfg;/// # // Normally, cargo will set `OUT_DIR` for build scripts./// # let exe = std::env::current_exe().unwrap();/// # std::env::set_var("OUT_DIR", exe.parent().unwrap());/// let ac = autocfg::new();/// assert!(ac.probe_raw("#![no_builtins]").is_ok());/// Rust nightly features could be tested as well -- ideally including a/// code sample to ensure the unstable feature still works as expected./// For example, `slice::group_by` was renamed to `chunk_by` when it was/// stabilized, even though the feature name was unchanged, so testing the/// `#![feature(..)]` alone wouldn't reveal that. For larger snippets,/// [`include_str!`] may be useful to load them from separate files./// let code = r#"///     #![feature(slice_group_by)]///     pub fn probe(slice: &[i32]) -> impl Iterator<Item = &[i32]> {///         slice.group_by(|a, b| a == b)/// "#;/// if ac.probe_raw(code).is_ok() {///     autocfg::emit("has_slice_group_by");probe_sysroot_crate/// Tests whether the given sysroot crate can be used./// The test code is subject to change, but currently looks like:/// extern crate CRATE as probe;emit_sysroot_crate/// Emits a config value `has_CRATE` if `probe_sysroot_crate` returns true.probe_path/// Tests whether the given path can be used./// pub use PATH;emit_has_path/// Emits a config value `has_PATH` if `probe_path` returns true./// Any non-identifier characters in the `path` will be replaced with/// `_` in the generated config value.emit_path_cfg/// Emits the given `cfg` value if `probe_path` returns true.probe_trait/// Tests whether the given trait can be used./// pub trait Probe: TRAIT + Sized {}emit_has_trait/// Emits a config value `has_TRAIT` if `probe_trait` returns true./// Any non-identifier characters in the trait `name` will be replaced withemit_trait_cfg/// Emits the given `cfg` value if `probe_trait` returns true.probe_type/// Tests whether the given type can be used./// pub type Probe = TYPE;emit_has_type/// Emits a config value `has_TYPE` if `probe_type` returns true./// Any non-identifier characters in the type `name` will be replaced withemit_type_cfg/// Emits the given `cfg` value if `probe_type` returns true.probe_expression/// Tests whether the given expression can be used./// pub fn probe() { let _ = EXPR; }emit_expression_cfg/// Emits the given `cfg` value if `probe_expression` returns true.probe_constant/// Tests whether the given constant expression can be used./// pub const PROBE: () = ((), EXPR).0;emit_constant_cfg/// Emits the given `cfg` value if `probe_constant` returns true.mangledir_contains_targetnew_uuid/// Generates a numeric ID to use in probe crate names./// This attempts to be random, within the constraints of Rust 1.0 and no dependencies.//! A Rust library for build scripts to automatically configure code based on//! compiler support.  Code snippets are dynamically tested to see if the `rustc`//! will accept them, rather than hard-coding specific version support.//! Add this to your `Cargo.toml`://! [build-dependencies]//! autocfg = "1"//! Then use it in your `build.rs` script to detect compiler features.  For//! example, to test for 128-bit integer support, it might look like://! extern crate autocfg;//! fn main() {//! #   // Normally, cargo will set `OUT_DIR` for build scripts.//! #   let exe = std::env::current_exe().unwrap();//! #   std::env::set_var("OUT_DIR", exe.parent().unwrap());//!     let ac = autocfg::new();//!     ac.emit_has_type("i128");//!     // (optional) We don't need to rerun for anything external.//!     autocfg::rerun_path("build.rs");//! If the type test succeeds, this will write a `cargo:rustc-cfg=has_i128` line//! for Cargo, which translates to Rust arguments `--cfg has_i128`.  Then in the//! rest of your Rust code, you can add `#[cfg(has_i128)]` conditions on code that//! should only be used when the compiler supports it.//! ## Caution//! Many of the probing methods of `AutoCfg` document the particular template they//! use, **subject to change**. The inputs are not validated to make sure they are//! semantically correct for their expected use, so it's _possible_ to escape and//! inject something unintended. However, such abuse is unsupported and will not//! be considered when making changes to the templates.// allow future warnings that can't be fixed while keeping 1.0 compatibilityrustc_wrapperrustc_workspace_wrappercommand/// Build the command with possible wrappers./// Try to get the `rustc` version.get_rustc_wrapperversion_cmpdir_does_not_contain_targetdir_does_contain_targetdir_does_not_contain_target_with_custom_target_dirdir_does_contain_target_with_custom_target_dirmajorminorpatch/// A version structure for making relative comparisons./// Creates a `Version` instance for a specific `major.minor.patch` version.from_commandencodeadd_paddingencode_to_slicewrite_encoded_bytes/// Handle a chunk of encoded base64 data (as UTF-8 bytes)Sink/// The output mechanism for ChunkedEncoder's encoded bytes.BUF_SIZEmax_input_chunk_lenChunkedEncoder/// A base64 encoder that emits encoded bytes in chunks without heap allocation.max_input_length/// Calculate the longest input that can be encoded for the given output buffer size./// If the config requires padding, two bytes of buffer space will be set aside so that the last/// chunk of input can be encoded safely./// The input length will always be a multiple of 3 so that no encoding state has to be carried over/// between chunks.StringSink// A really simple sink that just appends to a stringencode_config_bufrandom_configCharacterSetUniformFromEntropychunked_encode_emptychunked_encode_intermediate_fast_loopchunked_encode_fast_loopchunked_encode_slow_loop_onlychunked_encode_matches_normal_encode_random_string_sinkmax_input_length_no_padmax_input_length_with_pad_decrements_one_triplemax_input_length_with_pad_one_byte_shortmax_input_length_with_pad_fits_exactlymax_input_length_cant_use_extra_single_encoded_byteSinkTestHelperchunked_encode_matches_normal_encode_randomchunked_encode_strconfig_with_padencode_to_string// An abstraction around sinks so that we can have tests that easily to any sink implementationStringSinkTestHelpertablesINPUT_CHUNK_LEN// decode logic operates on chunks of 8 input bytes without paddingDECODED_CHUNK_LENDECODED_CHUNK_SUFFIX// we read a u64 and write a u64, but a u64 of input only yields 6 bytes of output, so the last// 2 bytes of any output u64 should not be counted as written to (but must be available in a// slice).CHUNKS_PER_FAST_LOOP_BLOCK// how many u64's of input to handle at a timeINPUT_BLOCK_LENDECODED_BLOCK_LEN// includes the trailing 2 bytes for the final u64 writeDecodeErrorInvalidByte/// An invalid byte was found in the input. The offset and offending byte are provided.InvalidLength/// The length of the input is invalid.InvalidLastSymbol/// The last non-padding input symbol's encoded 6 bits have nonzero bits that will be discarded./// This is indicative of corrupted or truncated Base64./// Unlike InvalidByte, which reports symbols that aren't in the alphabet, this error is for/// symbols that are in the alphabet but represent nonsensical encodings./// Errors that can occur while decoding.decode///Decode from string reference as octets.///Returns a Result containing a Vec<u8>.///Convenience `decode_config(input, base64::STANDARD);`.///# Example///```rust///extern crate base64;///fn main() {///    let bytes = base64::decode("aGVsbG8gd29ybGQ=").unwrap();///    println!("{:?}", bytes);///}///```decode_config///    let bytes = base64::decode_config("aGVsbG8gd29ybGR+Cg==", base64::STANDARD).unwrap();///    let bytes_url = base64::decode_config("aGVsbG8gaW50ZXJuZXR-Cg==", base64::URL_SAFE).unwrap();///    println!("{:?}", bytes_url);decode_config_buf///Writes into the supplied buffer to avoid allocation.///Returns a Result containing an empty tuple, aka ().///    let mut buffer = Vec::<u8>::new();///    base64::decode_config_buf("aGVsbG8gd29ybGR+Cg==", base64::STANDARD, &mut buffer).unwrap();///    println!("{:?}", buffer);///    buffer.clear();///    base64::decode_config_buf("aGVsbG8gaW50ZXJuZXR-Cg==", base64::URL_SAFE, &mut buffer)///        .unwrap();decode_config_slice/// Decode the input into the provided output slice./// This will not write any bytes past exactly what is decoded (no stray garbage bytes at the end)./// If you don't know ahead of time what the decoded length should be, size your buffer with a/// conservative estimate for the decoded length of an input: 3 bytes of output for every 4 bytes of/// input, rounded up, or in other words `(input_len + 3) / 4 * 3`./// If the slice is not large enough, this will panic.num_chunks/// Return the number of input chunks (including a possibly partial final chunk) in the inputdecode_helper/// Helper to avoid duplicating num_chunks calculation, which is costly on short inputs./// Returns the number of bytes written, or an error.// We're on the fragile edge of compiler heuristics here. If this is not inlined, slow. If this is// inlined(always), a different slow. plain ol' inline makes the benchmarks happiest at the moment,// but this is fragile and the best setting changes with only minor code modifications.decode_chunk/// Decode 8 bytes of input into 6 bytes of output. 8 bytes of output will be written, but only the/// first 6 of those contain meaningful data./// `input` is the bytes to decode, of which the first 8 bytes will be processed./// `index_at_start_of_input` is the offset in the overall input (used for reporting errors/// accurately)/// `decode_table` is the lookup table for the particular base64 alphabet./// `output` will have its first 8 bytes overwritten, of which only the first 6 are valid decoded/// data.// yes, really inline (worth 30-50% speedup)decode_chunk_precise/// Decode an 8-byte chunk, but only write the 6 bytes actually decoded instead of including 2/// trailing garbage bytes.encode_config_sliceassert_encode_sanitydecode_chunk_precise_writes_only_6_bytesdecode_chunk_writes_8_bytesdecode_into_nonempty_vec_doesnt_clobber_existing_prefixdecode_into_slice_doesnt_clobber_existing_prefix_or_suffixdecode_into_slice_fits_in_precisely_sized_slicedetect_invalid_last_symbol_two_bytesdetect_invalid_last_symbol_one_bytedetect_invalid_last_symbol_every_possible_three_symbolsdetect_invalid_last_symbol_every_possible_two_symbolsdecode_imapchunked_encoderBase64Display/// A convenience wrapper for base64'ing bytes into a format string without heap allocation.with_config/// Create a `Base64Display` with the provided config.FormatterSinkbasic_displaydisplay_encode_matches_normal_encodeDisplaySinkTestHelper//! Enables base64'd output anywhere you might use a `Display` implementation, like a format string.//! use base64::display::Base64Display;//! let data = vec![0x0, 0x1, 0x2, 0x3];//! let wrapper = Base64Display::with_config(&data, base64::STANDARD);//! assert_eq!("base64: AAECAw==", format!("base64: {}", wrapper));///Encode arbitrary octets as base64.///Returns a String.///Convenience for `encode_config(input, base64::STANDARD);`.///    let b64 = base64::encode(b"hello world");///    println!("{}", b64);encode_config///    let b64 = base64::encode_config(b"hello world~", base64::STANDARD);///    let b64_url = base64::encode_config(b"hello internet~", base64::URL_SAFE);///    println!("{}", b64_url);///Writes into the supplied output buffer, which will grow the buffer if needed.///    let mut buf = String::new();///    base64::encode_config_buf(b"hello world~", base64::STANDARD, &mut buf);///    println!("{}", buf);///    buf.clear();///    base64::encode_config_buf(b"hello internet~", base64::URL_SAFE, &mut buf);/// Encode arbitrary octets as base64./// Writes into the supplied output buffer./// This is useful if you wish to avoid allocation entirely (e.g. encoding into a stack-resident/// or statically-allocated buffer)./// If `output` is too small to hold the encoded version of `input`, a panic will result./// extern crate base64;///     let s = b"hello internet!";///     let mut buf = Vec::new();///     // make sure we'll have a slice big enough for base64 + padding///     buf.resize(s.len() * 4 / 3 + 4, 0);///     let bytes_written = base64::encode_config_slice(s,///                             base64::STANDARD, &mut buf);///     // shorten our vec down to just what was written///     buf.resize(bytes_written, 0);///     assert_eq!(s, base64::decode(&buf).unwrap().as_slice());encode_with_padding/// B64-encode and pad (if configured)./// This helper exists to avoid recalculating encoded_size, which is relatively expensive on short/// inputs./// `encoded_size` is the encoded size calculated for `input`./// `output` must be of size `encoded_size`./// All bytes in `output` will be written to since it is exactly the size of the output./// Encode input bytes to utf8 base64 bytes. Does not pad./// `output` must be long enough to hold the encoded `input` without padding./// Returns the number of bytes written.encoded_size/// calculate the base64 encoded string size, including padding if appropriate/// Write padding characters./// `output` is the slice where padding should be written, of length at least 2./// Returns the number of padding bytes written.URL_SAFE_NO_PADencoded_size_correct_standardencoded_size_correct_no_padencoded_size_overflowencode_config_buf_into_nonempty_buffer_doesnt_clobber_prefixencode_config_slice_into_nonempty_buffer_doesnt_clobber_suffixencode_config_slice_fits_into_precisely_sized_sliceencode_to_slice_random_valid_utf8encode_with_padding_random_valid_utf8add_padding_random_valid_utf8assert_encoded_lengthencode_imap/// The standard character set (uses `+` and `/`)./// See [RFC 3548](https://tools.ietf.org/html/rfc3548#section-3).UrlSafe/// The URL safe character set (uses `-` and `_`)./// See [RFC 3548](https://tools.ietf.org/html/rfc3548#section-4).Crypt/// The `crypt(3)` character set (uses `./0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz`)./// Not standardized, but folk wisdom on the net asserts that this alphabet is what crypt uses.Bcrypt/// The bcrypt character set (uses `./ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789`).ImapMutf7/// The character set used in IMAP-modified UTF-7 (uses `+` and `,`)./// See [RFC 3501](https://tools.ietf.org/html/rfc3501#section-5.1.3)BinHex/// The character set used in BinHex 4.0 files./// See [BinHex 4.0 Definition](http://files.stairways.com/other/binhex-40-specs-info.txt)/// Available encoding character setsencode_tabledecode_tablechar_set/// Character set to use/// True to pad output with `=` charactersdecode_allow_trailing_bits/// True to ignore excess nonzero bits in the last few symbols, otherwise an error is returned./// Contains configuration parameters for base64 encoding/// Create a new `Config`./// Sets whether to pad output with `=` characters./// Sets whether to emit errors for nonzero trailing bits./// This is useful when implementing/// [forgiving-base64 decode](https://infra.spec.whatwg.org/#forgiving-base64-decode)./// Standard character set with padding.STANDARD_NO_PAD/// Standard character set without padding.URL_SAFE/// URL-safe character set with padding/// URL-safe character set without paddingCRYPT/// As per `crypt(3)` requirementsBCRYPT/// Bcrypt character setIMAP_MUTF7/// IMAP modified UTF-7 requirementsBINHEX/// BinHex character set//! # Configs//! There isn't just one type of Base64; that would be too simple. You need to choose a character//! set (standard, URL-safe, etc) and padding suffix (yes/no).//! The `Config` struct encapsulates this info. There are some common configs included: `STANDARD`,//! `URL_SAFE`, etc. You can also make your own `Config` if needed.//! The functions that don't have `config` in the name (e.g. `encode()` and `decode()`) use the//! `STANDARD` config .//! The functions that write to a slice (the ones that end in `_slice`) are generally the fastest//! because they don't need to resize anything. If it fits in your workflow and you care about//! performance, keep using the same buffer (growing as need be) and use the `_slice` methods for//! the best performance.//! # Encoding//! Several different encoding functions are available to you depending on your desire for//! convenience vs performance.//! | Function                | Output                       | Allocates                      |//! | ----------------------- | ---------------------------- | ------------------------------ |//! | `encode`                | Returns a new `String`       | Always                         |//! | `encode_config`         | Returns a new `String`       | Always                         |//! | `encode_config_buf`     | Appends to provided `String` | Only if `String` needs to grow |//! | `encode_config_slice`   | Writes to provided `&[u8]`   | Never                          |//! All of the encoding functions that take a `Config` will pad as per the config.//! # Decoding//! Just as for encoding, there are different decoding functions available.//! | Function                | Output                        | Allocates                      |//! | ----------------------- | ----------------------------- | ------------------------------ |//! | `decode`                | Returns a new `Vec<u8>`       | Always                         |//! | `decode_config`         | Returns a new `Vec<u8>`       | Always                         |//! | `decode_config_buf`     | Appends to provided `Vec<u8>` | Only if `Vec` needs to grow    |//! | `decode_config_slice`   | Writes to provided `&[u8]`    | Never                          |//! Unlike encoding, where all possible input is valid, decoding can fail (see `DecodeError`).//! Input can be invalid because it has invalid characters or invalid padding. (No padding at all is//! valid, but excess padding is not.) Whitespace in the input is invalid.//! # `Read` and `Write`//! To map a `Read` of b64 bytes to the decoded bytes, wrap a reader (file, network socket, etc)//! with `base64::read::DecoderReader`. To write raw bytes and have them b64 encoded on the fly,//! wrap a writer with `base64::write::EncoderWriter`. There is some performance overhead (15% or//! so) because of the necessary buffer shuffling -- still fast enough that almost nobody cares.//! Also, these implementations do not heap allocate.//! # Panics//! If length calculations result in overflowing `usize`, a panic will result.//! The `_slice` flavors of encode or decode will panic if the provided output slice is too small,// This should be large, but it has to fit on the stack.BASE64_CHUNK_SIZE// 4 bytes of base64 data encode 3 bytes of raw data (modulo padding).DECODED_CHUNK_SIZEr/// Where b64 data is read fromb64_buffer// Holds b64 data read from the delegate reader.b64_offset// The start of the pending buffered data in b64_buffer.b64_len// The amount of buffered b64 data.decoded_buffer// Since the caller may provide us with a buffer of size 1 or 2 that's too small to copy a// decoded chunk in to, we have to be able to hang on to a few decoded bytes.// Technically we only need to hold 2 bytes but then we'd need a separate temporary buffer to// decode 3 bytes into and then juggle copying one byte into the provided read buf and the rest// into here, which seems like a lot of complexity for 1 extra byte of storage.decoded_offset// index of start of decoded datadecoded_len// length of decoded datatotal_b64_decoded// used to provide accurate offsets in errorsDecoderReader/// A `Read` implementation that decodes base64 data read from an underlying reader./// use std::io::Read;/// use std::io::Cursor;/// // use a cursor as the simplest possible `Read` -- in real code this is probably a file, etc./// let mut wrapped_reader = Cursor::new(b"YXNkZg==");/// let mut decoder = base64::read::DecoderReader::new(///     &mut wrapped_reader, base64::STANDARD);/// // handle errors as you normally would/// let mut result = Vec::new();/// decoder.read_to_end(&mut result).unwrap();/// assert_eq!(b"asdf", &result[..]);/// Create a new decoder that will read from the provided reader `r`.flush_decoded_buf/// Write as much as possible of the decoded buffer into the target buffer./// Must only be called when there is something to write and space to write into./// Returns a Result with the number of (decoded) bytes copied.read_from_delegate/// Read into the remaining space in the buffer after the current contents./// Must only be called when there is space to read into in the buffer./// Returns the number of bytes read.decode_to_buf/// Decode the requested number of bytes from the b64 buffer into the provided buffer. It's the/// caller's responsibility to choose the number of b64 bytes to decode correctly./// Returns a Result with the number of decoded bytes written to `buf`./// Decode input from the wrapped reader./// Under non-error circumstances, this returns `Ok` with the value being the number of bytes/// written in `buf`./// Where possible, this function buffers base64 to minimize the number of read() calls to the/// delegate reader./// Any errors emitted by the delegate reader are returned. Decoding errors due to invalid/// base64 are also possible, and will have `io::ErrorKind::InvalidData`.decodersimpletrailing_junk// Make sure we error out on trailing junk.handles_short_read_from_delegateread_in_short_incrementsread_in_short_increments_with_short_delegate_readsreports_invalid_last_symbol_correctlyreports_invalid_byte_correctlyconsume_with_short_reads_and_validaterngsThreadRngRandomShortRead/// Limits how many bytes a reader will provide in each read call./// Useful for shaking out code that may work fine only with typical input sources that always fill/// the buffer.decoder_tests//! Implementations of `io::Read` to transparently decode base64.INVALID_VALUESTANDARD_ENCODESTANDARD_DECODEURL_SAFE_ENCODEURL_SAFE_DECODECRYPT_ENCODECRYPT_DECODEBCRYPT_ENCODEBCRYPT_DECODEIMAP_MUTF7_ENCODEIMAP_MUTF7_DECODEBINHEX_ENCODEBINHEX_DECODEseqSliceRandomroundtrip_random_config_shortroundtrip_random_config_longroundtrip_random_configMAX_INPUT_LEN/// The most bytes whose encoding will fit in `BUF_SIZE`MIN_ENCODE_CHUNK_SIZE// 3 bytes of input = 4 bytes of base64, always (because we don't allow line wrapping)w/// Where encoded data is written toextra_input/// Holds a partial chunk, if any, after the last `write()`, so that we may then fill the chunk/// with the next `write()`, encode it, then proceed with the rest of the input normally.extra_input_occupied_len/// How much of `extra` is occupied, in `[0, MIN_ENCODE_CHUNK_SIZE]`.output/// Buffer to encode into. May hold leftover encoded bytes from a previous write call that the underlying writer/// did not write last time.output_occupied_len/// How much of `output` is occupied with encoded data that couldn't be written last timefinished/// True iff padding / partial last chunk has been written.panicked/// panic safety: don't write again in destructor if writer panicked while we were writing to itEncoderWriter/// A `Write` implementation that base64 encodes data before delegating to the wrapped writer./// Because base64 has special handling for the end of the input data (padding, etc), there's a/// `finish()` method on this type that encodes any leftover input bytes and adds padding if/// appropriate. It's called automatically when deallocated (see the `Drop` implementation), but/// any error that occurs when invoking the underlying writer will be suppressed. If you want to/// handle such errors, call `finish()` yourself./// // use a vec as the simplest possible `Write` -- in real code this is probably a file, etc./// let mut wrapped_writer = Vec::new();///     let mut enc = base64::write::EncoderWriter::new(///         &mut wrapped_writer, base64::STANDARD);///     // handle errors as you normally would///     enc.write_all(b"asdf").unwrap();///     // could leave this out to be called by Drop, if you don't care///     // about handling errors///     enc.finish().unwrap();/// // base64 was written to the writer/// assert_eq!(b"YXNkZg==", &wrapped_writer[..]);/// Calling `write()` after `finish()` is invalid and will panic./// Base64 encoding itself does not generate errors, but errors from the wrapped writer will be/// returned as per the contract of `Write`./// It has some minor performance loss compared to encoding slices (a couple percent)./// It does not do any heap allocation./// Create a new encoder that will write to the provided delegate writer `w`./// Encode all remaining buffered data and write it, including any trailing incomplete input/// triples and associated padding./// Once this succeeds, no further writes can be performed, as that would produce invalid/// base64./// This may write to the delegate writer multiple times if the delegate writer does not accept all input provided/// to its `write` each invocation./// The first error that is not of [`ErrorKind::Interrupted`] will be returned.write_to_delegate/// Write as much of the encoded output to the delegate writer as it will accept, and store the/// leftovers to be attempted at the next write() call. Updates `self.output_occupied_len`./// Errors from the delegate writer are returned. In the case of an error,/// `self.output_occupied_len` will not be updated, as errors from `write` are specified to mean/// that no write took place.write_all_encoded_output/// Write all buffered encoded output. If this returns `Ok`, `self.output_occupied_len` is `0`./// This is basically write_all for the remaining buffered data but without the undesirable/// abort-on-`Ok(0)` behavior./// Any error emitted by the delegate writer abort the write loop and is returned, unless it's/// `Interrupted`, in which case the error is ignored and writes will continue./// Encode input and then write to the delegate writer./// of `input` consumed. The value may be `0`, which interacts poorly with `write_all`, which/// interprets `Ok(0)` as an error, despite it being allowed by the contract of `write`. See/// https://github.com/rust-lang/rust/issues/56889 for more on that./// If the previous call to `write` provided more (encoded) data than the delegate writer could/// accept in a single call to its `write`, the remaining data is buffered. As long as buffered/// data is present, subsequent calls to `write` will try to write the remaining buffered data/// to the delegate and return either `Ok(0)` -- and therefore not consume any of `input` -- or/// Any errors emitted by the delegate writer are returned./// Because this is usually treated as OK to call multiple times, it will *not* flush any/// incomplete chunks of input or write padding.encode_three_bytesencode_nine_bytes_two_writesencode_one_then_two_bytesencode_one_then_five_bytesencode_1_2_3_bytesencode_with_padding_multiple_writesfinish_writes_extra_bytewrite_partial_chunk_encodes_partial_chunkwrite_1_chunk_encodes_complete_chunkwrite_1_chunk_and_partial_encodes_only_complete_chunkwrite_2_partials_to_exactly_complete_chunk_encodes_complete_chunkwrite_partial_then_enough_to_complete_chunk_but_not_complete_another_chunk_encodes_complete_chunk_without_consuming_remainingwrite_partial_then_enough_to_complete_chunk_and_another_chunk_encodes_complete_chunkswrite_partial_then_enough_to_complete_chunk_and_another_chunk_and_another_partial_chunk_encodes_only_complete_chunksdrop_calls_finish_for_youevery_possible_split_of_inputencode_random_config_matches_normal_encode_reasonable_input_lenencode_random_config_matches_normal_encode_tiny_input_lenretrying_writes_that_error_with_interrupted_workswrites_that_only_write_part_of_input_and_sometimes_interrupt_produce_correct_encoded_dataretry_interrupted_write_all/// Retry writes until all the data is written or an error that isn't Interrupted is returned.do_encode_random_config_matches_normal_encodefraction/// In [0, 1]. If a random number in [0, 1] is  `<= threshold`, `Write` methods will return/// an `Interrupted` errorInterruptingWriter/// A `Write` implementation that returns Interrupted some fraction of the time, randomly.full_input_fraction/// In [0, 1]. If a random number in [0, 1] is  `<= threshold`, `write()` will write all its/// input. Otherwise, it will write a random substringno_interrupt_fractionPartialInterruptingWriter/// A `Write` implementation that sometimes will only write part of its input.encoderencoder_tests//! Implementations of `io::Write` to transparently handle base64.PAD_BYTEALPHABET_SIZEsymbolsAlphabet/// An alphabet defines the 64 ASCII characters (symbols) used for base64./// Common alphabets are provided as constants, and custom alphabets/// can be made via `from_str` or the `TryFrom<str>` implementation./// Building and using a custom Alphabet:/// let custom = base64::alphabet::Alphabet::new("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/").unwrap();/// let engine = base64::engine::GeneralPurpose::new(///     &custom,///     base64::engine::general_purpose::PAD);/// Building a const:/// use base64::alphabet::Alphabet;/// static CUSTOM: Alphabet = {///     // Result::unwrap() isn't const yet, but panic!() is OK///     match Alphabet::new("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/") {///         Ok(x) => x,///         Err(_) => panic!("creation of alphabet failed"),/// Building lazily:/// use base64::{///     alphabet::Alphabet,///     engine::{general_purpose::GeneralPurpose, GeneralPurposeConfig},/// use once_cell::sync::Lazy;/// static CUSTOM: Lazy<Alphabet> = Lazy::new(||///     Alphabet::new("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/").unwrap()from_str_unchecked/// Performs no checks so that it can be const./// Used only for known-valid strings.ParseAlphabetError/// Create an `Alphabet` from a string of 64 unique printable ASCII bytes./// The `=` byte is not allowed as it is used for padding./// Create a `&str` from the symbols in the `Alphabet`/// Alphabets must be 64 ASCII bytesDuplicatedByte/// All bytes must be uniqueUnprintableByte/// All bytes must be printable (in the range `[32, 126]`).ReservedByte/// `=` cannot be used/// Possible errors when constructing an [Alphabet] from a `str`./// The standard alphabet (with `+` and `/`) specified in [RFC 4648][]./// [RFC 4648]: https://datatracker.ietf.org/doc/html/rfc4648#section-4/// The URL-safe alphabet (with `-` and `_`) specified in [RFC 4648][]./// [RFC 4648]: https://datatracker.ietf.org/doc/html/rfc4648#section-5/// The `crypt(3)` alphabet (with `.` and `/` as the _first_ two characters)./// The bcrypt alphabet./// The alphabet used in IMAP-modified UTF-7 (with `+` and `,`).BIN_HEX/// The alphabet used in BinHex 4.0 files.detects_duplicate_startdetects_duplicate_enddetects_duplicate_middledetects_lengthdetects_paddingdetects_unprintablesame_as_uncheckedstr_same_as_input//! Provides [Alphabet] and constants for alphabets commonly used in the wild.engineEngine'eSeedableRnggeneral_purposeGeneralPurposeGeneralPurposeConfigPADrandom_engineDecodeEstimate/// Padding characters (`=`) interspersed in the encoded form will be treated as invalid bytes./// A typical cause of this is stray trailing whitespace or other separator bytes./// In the case where excess trailing bytes have produced an invalid length *and* the last byte/// is also an invalid base64 symbol (as would be the case for whitespace, etc), `InvalidByte`/// will be emitted instead of `InvalidLength` to make the issue easier to debug./// Unlike `InvalidByte`, which reports symbols that aren't in the alphabet, this error is forInvalidPadding/// The nature of the padding was not as configured: absent or incorrect when it must be/// canonical, or present when it must be absent, etc.DecodeSliceError/// A [DecodeError] occurredOutputSliceTooSmall/// The provided slice _may_ be too small./// The check is conservative (assumes the last triplet of output bytes will all be needed)./// Errors that can occur while decoding into a slice./// Decode base64 using the [`STANDARD` engine](STANDARD)./// See [Engine::decode].decode_engine/// Decode from string reference as octets using the specified [Engine].///Returns a `Result` containing a `Vec<u8>`.decode_engine_vec/// Decode from string reference as octets./// See [Engine::decode_vec].decode_engine_slice/// See [Engine::decode_slice].decoded_len_estimate/// Returns a conservative estimate of the decoded size of `encoded_len` base64 symbols (rounded up/// to the next group of 3 decoded bytes)./// The resulting length will be a safe choice for the size of a decode buffer, but may have up to/// 2 trailing bytes that won't end up being needed./// use base64::decoded_len_estimate;/// assert_eq!(3, decoded_len_estimate(1));/// assert_eq!(3, decoded_len_estimate(2));/// assert_eq!(3, decoded_len_estimate(3));/// assert_eq!(3, decoded_len_estimate(4));/// // start of the next quad of encoded symbols/// assert_eq!(6, decoded_len_estimate(5));decode_slice_doesnt_clobber_existing_prefix_or_suffixdecode_slice_unchecked_doesnt_clobber_existing_prefix_or_suffixdecode_engine_estimation_works_for_various_lengthsdecode_slice_output_length_errorsdo_decode_slice_doesnt_clobber_existing_prefix_or_suffix/// Create a `Base64Display` with the provided engine.//! use base64::{display::Base64Display, engine::general_purpose::STANDARD};//! let wrapper = Base64Display::new(&data, &STANDARD);/// Encode arbitrary octets as base64 using the [`STANDARD` engine](STANDARD)./// See [Engine::encode].encode_engine///Encode arbitrary octets as base64 using the provided `Engine` into a new `String`.encode_engine_string///Encode arbitrary octets as base64 into a supplied `String`./// See [Engine::encode_string].encode_engine_sliceEncodeSliceError/// Encode arbitrary octets as base64 into a supplied slice./// See [Engine::encode_slice].encoded_len/// Calculate the base64 encoded length for a given input length, optionally including any/// appropriate padding bytes./// Returns `None` if the encoded length can't be represented in `usize`. This will happen for/// input lengths in approximately the top quarter of the range of `usize`./// `unpadded_output_len` is the size of the unpadded but base64 encoded data./// The provided slice is too small./// Errors that can occur while encoding into a slice.NO_PADURL_SAFE_NO_PAD_ENGINEencode_engine_string_into_nonempty_buffer_doesnt_clobber_prefixencode_engine_slice_into_nonempty_buffer_doesnt_clobber_suffixDecodeMetadataDecodePaddingMode/// Total number of decode chunks, including a possibly partial last chunkGeneralPurposeEstimate/// Returns the decode metadata, or an error.estimate_short_lengthsestimate_via_u128_inflationdecode_suffix/// Decode the last 1-8 bytes, checking for trailing set bits and padding per the provided/// parameters./// Returns the decode metadata representing the total number of bytes decoded, including the ones/// indicated as already written by `output_index`./// A general-purpose base64 engine./// - It uses no vector CPU instructions, so it will work on any system./// - It is reasonably fast (~2-3GiB/s)./// - It is not constant-time, though, so it is vulnerable to timing side-channel attacks. For loading cryptographic keys, etc, it is suggested to use the forthcoming constant-time implementation./// Create a `GeneralPurpose` engine from an [Alphabet]./// While not very expensive to initialize, ideally these should be cached/// if the engine will be used repeatedly.internal_encodeinternal_decoded_len_estimateinternal_decode/// Returns a table mapping a 6-bit index to the ASCII byte encoding of the index/// Returns a table mapping base64 bytes as the lookup index to either:/// - [INVALID_VALUE] for bytes that aren't members of the alphabet/// - a byte whose lower 6 bits are the value that was encoded into the index byteencode_paddingdecode_padding_mode/// Contains configuration parameters for base64 encoding and decoding./// # use base64::engine::GeneralPurposeConfig;/// let config = GeneralPurposeConfig::new()///     .with_encode_padding(false);///     // further customize using `.with_*` methods as needed/// The constants [PAD] and [NO_PAD] cover most use cases./// To specify the characters used, see [Alphabet]./// Create a new config with `padding` = `true`, `decode_allow_trailing_bits` = `false`, and/// `decode_padding_mode = DecodePaddingMode::RequireCanonicalPadding`./// This probably matches most people's expectations, but consider disabling padding to save/// a few bytes unless you specifically need it for compatibility with some legacy system.with_encode_padding/// Create a new config based on `self` with an updated `padding` setting./// If `padding` is `true`, encoding will append either 1 or 2 `=` padding characters as needed/// to produce an output whose length is a multiple of 4./// Padding is not needed for correct decoding and only serves to waste bytes, but it's in the/// [spec](https://datatracker.ietf.org/doc/html/rfc4648#section-3.2)./// For new applications, consider not using padding if the decoders you're using don't require/// padding to be present.with_decode_allow_trailing_bits/// Create a new config based on `self` with an updated `decode_allow_trailing_bits` setting./// Most users will not need to configure this. It's useful if you need to decode base64/// produced by a buggy encoder that has bits set in the unused space on the last base64/// character as per [forgiving-base64 decode](https://infra.spec.whatwg.org/#forgiving-base64-decode)./// If invalid trailing bits are present and this is `true`, those bits will/// be silently ignored, else `DecodeError::InvalidLastSymbol` will be emitted.with_decode_padding_mode/// Create a new config based on `self` with an updated `decode_padding_mode` setting./// Padding is not useful in terms of representing encoded data -- it makes no difference to/// the decoder if padding is present or not, so if you have some un-padded input to decode, it/// is perfectly fine to use `DecodePaddingMode::Indifferent` to prevent errors from being/// emitted./// However, since in practice/// [people who learned nothing from BER vs DER seem to expect base64 to have one canonical encoding](https://eprint.iacr.org/2022/361),/// the default setting is the stricter `DecodePaddingMode::RequireCanonicalPadding`./// Or, if "canonical" in your circumstance means _no_ padding rather than padding to the/// next multiple of four, there's `DecodePaddingMode::RequireNoPadding`./// Delegates to [GeneralPurposeConfig::new]./// A [GeneralPurpose] engine using the [alphabet::STANDARD] base64 alphabet and [PAD] config./// A [GeneralPurpose] engine using the [alphabet::STANDARD] base64 alphabet and [NO_PAD] config./// A [GeneralPurpose] engine using the [alphabet::URL_SAFE] base64 alphabet and [PAD] config./// A [GeneralPurpose] engine using the [alphabet::URL_SAFE] base64 alphabet and [NO_PAD] config./// Include padding bytes when encoding, and require that they be present when decoding./// This is the standard per the base64 RFC, but consider using [NO_PAD] instead as padding serves/// little purpose in practice./// Don't add padding when encoding, and require no padding when decoding.//! Provides the [GeneralPurpose] engine and associated config types.naive/// The config type used by this engine/// The decode estimate used by this engine/// This is not meant to be called directly; it is only for `Engine` implementors./// See the other `encode*` functions on this trait./// Encode the `input` bytes into the `output` buffer based on the mapping in `encode_table`./// `output` will be long enough to hold the encoded data./// No padding should be written; that is handled separately./// Must not write any bytes into the output slice other than the encoded data./// As an optimization to prevent the decoded length from being calculated twice, it is/// sometimes helpful to have a conservative estimate of the decoded size before doing the/// decoding, so this calculation is done separately and passed to [Engine::decode()] as needed./// See the other `decode*` functions on this trait./// Decode `input` base64 bytes into the `output` buffer./// `decode_estimate` is the result of [Engine::internal_decoded_len_estimate()], which is passed in to avoid/// calculating it again (expensive on short inputs).`/// Each complete 4-byte chunk of encoded data decodes to 3 bytes of decoded data, but this/// function must also handle the final possibly partial chunk./// If the input length is not a multiple of 4, or uses padding bytes to reach a multiple of 4,/// the trailing 2 or 3 bytes must decode to 1 or 2 bytes, respectively, as per the/// [RFC](https://tools.ietf.org/html/rfc4648#section-3.5)./// Decoding must not write any bytes into the output slice other than the decoded data./// Non-canonical trailing bits in the final tokens or non-canonical padding must be reported as/// errors unless the engine is configured otherwise./// Panics if `output` is too small./// Returns the config for this engine./// Encode arbitrary octets as base64 using the provided `Engine`./// Returns a `String`./// use base64::{Engine as _, engine::{self, general_purpose}, alphabet};/// let b64 = general_purpose::STANDARD.encode(b"hello world~");/// println!("{}", b64);/// const CUSTOM_ENGINE: engine::GeneralPurpose =///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::NO_PAD);/// let b64_url = CUSTOM_ENGINE.encode(b"hello internet~");encode_string/// Encode arbitrary octets as base64 into a supplied `String`./// Writes into the supplied `String`, which may allocate if its internal buffer isn't big enough.///     let mut buf = String::new();///     general_purpose::STANDARD.encode_string(b"hello world~", &mut buf);///     println!("{}", buf);///     buf.clear();///     CUSTOM_ENGINE.encode_string(b"hello internet~", &mut buf);encode_slice/// use base64::{Engine as _, engine::general_purpose};/// let s = b"hello internet!";/// let mut buf = Vec::new();/// // make sure we'll have a slice big enough for base64 + padding/// buf.resize(s.len() * 4 / 3 + 4, 0);/// let bytes_written = general_purpose::STANDARD.encode_slice(s, &mut buf).unwrap();/// // shorten our vec down to just what was written/// buf.truncate(bytes_written);/// assert_eq!(s, general_purpose::STANDARD.decode(&buf).unwrap().as_slice());/// Decode the input into a new `Vec`./// use base64::{Engine as _, alphabet, engine::{self, general_purpose}};/// let bytes = general_purpose::STANDARD///     .decode("aGVsbG8gd29ybGR+Cg==").unwrap();/// println!("{:?}", bytes);/// // custom engine setup/// let bytes_url = engine::GeneralPurpose::new(///              &alphabet::URL_SAFE,///              general_purpose::NO_PAD)///     .decode("aGVsbG8gaW50ZXJuZXR-Cg").unwrap();/// println!("{:?}", bytes_url);decode_vec/// Decode the `input` into the supplied `buffer`./// Writes into the supplied `Vec`, which may allocate if its internal buffer isn't big enough./// Returns a `Result` containing an empty tuple, aka `()`.///     engine::GeneralPurpose::new(&alphabet::URL_SAFE, general_purpose::PAD);///     use base64::Engine;///     let mut buffer = Vec::<u8>::new();///     // with the default engine///     general_purpose::STANDARD///         .decode_vec("aGVsbG8gd29ybGR+Cg==", &mut buffer,).unwrap();///     println!("{:?}", buffer);///     buffer.clear();///     // with a custom engine///     CUSTOM_ENGINE.decode_vec(///         "aGVsbG8gaW50ZXJuZXR-Cg==",///         &mut buffer,///     ).unwrap();decode_slice/// Returns the number of bytes written to the slice, or an error if `output` is smaller than/// the estimated decoded length./// See [crate::decoded_len_estimate] for calculating buffer sizes./// See [Engine::decode_slice_unchecked] for a version that panics instead of returning an error/// if the output buffer is too small.decode_slice_unchecked/// Returns the number of bytes written to the slice./// See [Engine::decode_slice] for a version that returns an error instead of panicking if the output/// buffer is too small./// Panics if the provided output buffer is too small for the decoded data./// An `Engine` provides low-level encoding and decoding operations that all other higher-level parts of the API use. Users of the library will generally not need to implement this./// Different implementations offer different characteristics. The library currently ships with/// [GeneralPurpose] that offers good speed and works on any CPU, with more choices/// coming later, like a constant-time one when side channel resistance is called for, and vendor-specific vectorized ones for more speed./// See [general_purpose::STANDARD_NO_PAD] if you just want standard base64. Otherwise, when possible, it's/// recommended to store the engine in a `const` so that references to it won't pose any lifetime/// issues, and to avoid repeating the cost of engine setup./// Since almost nobody will need to implement `Engine`, docs for internal methods are hidden.// When adding an implementation of Engine, include them in the engine test suite:// - add an implementation of [engine::tests::EngineWrapper]// - add the implementation to the `all_engines` macro// All tests run on all engines listed in the macro./// Returns `true` if padding should be added after the encoded output./// Padding is added outside the engine's encode() since the engine may be used/// to encode only a chunk of the overall output, so it can't always know when/// the output is "done" and would therefore need padding (if configured).// It could be provided as a separate parameter when encoding, but that feels like// leaking an implementation detail to the user, and it's hopefully more convenient// to have to only pass one thing (the engine) to any part of the API./// The minimal level of configuration that engines must support./// Returns a conservative (err on the side of too big) estimate of the decoded length to use/// for pre-allocating buffers, etc./// The estimate must be no larger than the next largest complete triple of decoded bytes./// That is, the final quad of tokens to decode may be assumed to be complete with no padding./// The decode estimate used by an engine implementation. Users do not need to interact with this;/// it is only for engine implementors./// Implementors may store relevant data here when constructing this to avoid having to calculate/// them again during actual decoding.Indifferent/// Canonical padding is allowed, but any fewer padding bytes than that is also allowed.RequireCanonical/// Padding must be canonical (0, 1, or 2 `=` as needed to produce a 4 byte suffix).RequireNone/// Padding must be absent -- for when you want predictable padding, without any wasted bytes./// Controls how pad bytes are handled when decoding./// Each [Engine] must support at least the behavior indicated by/// [DecodePaddingMode::RequireCanonical], and may support other modes./// Number of decoded bytes outputpadding_offset/// Offset of the first padding byte in the input, if any/// Metadata about the result of a decode operation//! Provides the [Engine] abstraction and out of the box implementations.ShlShrNaiveConfigNaive/// Comparatively simple implementation that can be used as something to compare against in testsENCODE_INPUT_CHUNK_SIZEDECODE_INPUT_CHUNK_SIZEdecode_byte_into_u32NaiveEstimaterem/// remainder from dividing input by `Naive::DECODE_CHUNK_SIZE`complete_chunk_len/// Length of input that is in complete `Naive::DECODE_CHUNK_SIZE`-length chunksrstestrstest_reusetemplaterandom_alphabetEngineWrapperall_engines// the case::foo syntax includes the "foo" in the generated test method namesall_engines_except_decoder_reader/// Some decode tests don't make sense for use with `DecoderReader` as they are difficult to/// reason about or otherwise inapplicable given how DecoderReader slice up its input along/// chunk boundaries.rfc_test_vectors_std_alphabetroundtrip_randomencode_doesnt_write_extra_bytesencode_engine_slice_fits_into_precisely_sized_slicedecode_doesnt_write_extra_bytesdecode_detect_invalid_last_symboldecode_detect_invalid_last_symbol_when_length_is_also_invaliddecode_detect_invalid_last_symbol_every_possible_two_symbolsdecode_detect_invalid_last_symbol_every_possible_three_symbolsdecode_invalid_trailing_bits_ignored_when_configureddecode_invalid_byte_errordecode_padding_before_final_non_padding_char_error_invalid_byte/// Any amount of padding anywhere before the final non padding character = invalid byte at first/// pad byte./// From this, we know padding must extend to the end of the input.// DecoderReader pseudo-engine detects InvalidLastSymbol instead of InvalidLength because it// can end a decode on the quad that happens to contain the start of the paddingdecode_padding_starts_before_final_chunk_error_invalid_byte/// Any amount of padding before final chunk that crosses over into final chunk with 2-4 bytes =/// invalid byte at first pad byte./// From this and [decode_padding_starts_before_final_chunk_error_invalid_length] we know the/// padding must start in the final chunk.decode_padding_starts_before_final_chunk_error_invalid_length/// Any amount of padding before final chunk that crosses over into final chunk with 1 byte =/// invalid length./// From this we know the padding must start in the final chunk.// DecoderReader pseudo-engine detects InvalidByte instead of InvalidLength because it starts by// decoding only the available complete quadsdecode_too_little_data_before_padding_error_invalid_byte/// 0-1 bytes of data before any amount of padding in final chunk = invalid byte, since padding/// is not valid data (consistent with error for pad bytes in earlier chunks)./// From this we know there must be 2-3 bytes of data before paddingdecode_malleability_test_case_3_byte_suffix_valid// https://eprint.iacr.org/2022/361.pdf table 2, test 1decode_malleability_test_case_3_byte_suffix_invalid_trailing_symbol// https://eprint.iacr.org/2022/361.pdf table 2, test 2decode_malleability_test_case_3_byte_suffix_no_padding// https://eprint.iacr.org/2022/361.pdf table 2, test 3decode_malleability_test_case_2_byte_suffix_valid_two_padding_symbols// https://eprint.iacr.org/2022/361.pdf table 2, test 4decode_malleability_test_case_2_byte_suffix_short_padding// https://eprint.iacr.org/2022/361.pdf table 2, test 5decode_malleability_test_case_2_byte_suffix_no_padding// https://eprint.iacr.org/2022/361.pdf table 2, test 6decode_malleability_test_case_2_byte_suffix_too_much_padding// https://eprint.iacr.org/2022/361.pdf table 2, test 7// DecoderReader pseudo-engine gets InvalidByte at 8 (extra padding) since it decodes the first// two complete quads correctly.decode_pad_mode_requires_canonical_accepts_canonical/// Requires canonical padding -> accepts 2 + 2, 3 + 1, 4 + 0 final quad configurationsdecode_pad_mode_requires_canonical_rejects_non_canonical/// Requires canonical padding -> rejects 2 + 0-1, 3 + 0 final chunk configurationsdecode_pad_mode_requires_no_padding_accepts_no_padding/// Requires no padding -> accepts 2 + 0, 3 + 0, 4 + 0 final chunk configurationdecode_pad_mode_requires_no_padding_rejects_any_padding/// Requires no padding -> rejects 2 + 1-2, 3 + 1 final chunk configurationdecode_pad_mode_indifferent_padding_accepts_anything/// Indifferent padding accepts 2 + 0-2, 3 + 0-1, 4 + 0 final chunk configurationdecode_pad_byte_in_penultimate_quad_error//this is a MAY in the rfc: https://tools.ietf.org/html/rfc4648#section-3.3// DecoderReader pseudo-engine finds the first padding, but doesn't report it as an error,// because in the next decode it finds more padding, which is reported as InvalidByte, just// with an offset at its position in the second decode, rather than being linked to the start// of the padding that was first seen in the previous decode.decode_bytes_after_padding_in_final_quad_errordecode_absurd_pad_errordecode_too_much_padding_returns_errordecode_padding_followed_by_non_padding_returns_errordecode_one_char_in_final_quad_with_padding_errordecode_too_few_symbols_in_final_quad_errordecode_invalid_trailing_bytes// DecoderReader pseudo-engine can't handle DecodePaddingMode::RequireNone since it will decode// a complete quad with padding in it before encountering the stray byte that makes it an invalid// lengthdecode_invalid_trailing_bytes_all_modesdecode_invalid_trailing_padding_as_invalid_lengthdecode_invalid_trailing_padding_as_invalid_length_all_modesdecode_wrong_length_errorinner_decode_reports_padding_positiondecode_length_estimate_deltado_invalid_trailing_bytedo_invalid_trailing_padding_as_invalid_lengthgenerate_random_encoded_data/// Returns a tuple of the original data length, the encoded data length (just data), and the length including padding./// Vecs provided should be empty.fill_rand// fill to a random lengthfill_rand_len'iprefixed_datastandard/// Return an engine configured for RFC standard base64standard_unpadded/// Return an engine configured for RFC standard base64, except with no padding appended on/// encode, and required no padding on decode.standard_with_pad_mode/// Return an engine configured for RFC standard alphabet with the provided encode and decode/// pad settingsstandard_allow_trailing_bits/// Return an engine configured for RFC standard base64 that allows invalid trailing bitsrandom/// Return an engine configured with a randomized alphabet and config/// Return an engine configured with the specified alphabet and randomized config/// A wrapper to make using engines in rstest fixtures easier./// The functions don't need to be instance methods, but rstest does seem/// to want an instance, so instances are passed to test functions and then ignored.GeneralPurposeWrapperNaiveWrapperDecoderReaderEngine/// A pseudo-Engine that routes all decoding through [DecoderReader]DecoderReaderEngineWrapperseeded_rngall_pad_modespad_modes_allowing_paddingassert_all_suffixes_ok// rstest_reuse template functions have unused variables// has to be included at top level because of the way rstest_reuse defines its macros//! Correct, fast, and configurable [base64][] decoding and encoding. Base64//! transports binary data efficiently in contexts where only plain text is//! allowed.//! [base64]: https://developer.mozilla.org/en-US/docs/Glossary/Base64//! Use an [`Engine`] to decode or encode base64, configured with the base64//! alphabet and padding behavior best suited to your application.//! ## Engine setup//! There is more than one way to encode a stream of bytes as “base64”.//! Different applications use different encoding//! [alphabets][alphabet::Alphabet] and//! [padding behaviors][engine::general_purpose::GeneralPurposeConfig].//! ### Encoding alphabet//! Almost all base64 [alphabets][alphabet::Alphabet] use `A-Z`, `a-z`, and//! `0-9`, which gives nearly 64 characters (26 + 26 + 10 = 62), but they differ//! in their choice of their final 2.//! Most applications use the [standard][alphabet::STANDARD] alphabet specified//! in [RFC 4648][rfc-alphabet].  If that’s all you need, you can get started//! quickly by using the pre-configured//! [`STANDARD`][engine::general_purpose::STANDARD] engine, which is also available//! in the [`prelude`] module as shown here, if you prefer a minimal `use`//! footprint.//! use base64::prelude::*;//! # fn main() -> Result<(), base64::DecodeError> {//! assert_eq!(BASE64_STANDARD.decode(b"+uwgVQA=")?, b"\xFA\xEC\x20\x55\0");//! assert_eq!(BASE64_STANDARD.encode(b"\xFF\xEC\x20\x55\0"), "/+wgVQA=");//! # Ok(())//! [rfc-alphabet]: https://datatracker.ietf.org/doc/html/rfc4648#section-4//! Other common alphabets are available in the [`alphabet`] module.//! #### URL-safe alphabet//! The standard alphabet uses `+` and `/` as its two non-alphanumeric tokens,//! which cannot be safely used in URL’s without encoding them as `%2B` and//! `%2F`.//! To avoid that, some applications use a [“URL-safe” alphabet][alphabet::URL_SAFE],//! which uses `-` and `_` instead. To use that alternative alphabet, use the//! [`URL_SAFE`][engine::general_purpose::URL_SAFE] engine. This example doesn't//! use [`prelude`] to show what a more explicit `use` would look like.//! use base64::{engine::general_purpose::URL_SAFE, Engine as _};//! assert_eq!(URL_SAFE.decode(b"-uwgVQA=")?, b"\xFA\xEC\x20\x55\0");//! assert_eq!(URL_SAFE.encode(b"\xFF\xEC\x20\x55\0"), "_-wgVQA=");//! ### Padding characters//! Each base64 character represents 6 bits (2⁶ = 64) of the original binary//! data, and every 3 bytes of input binary data will encode to 4 base64//! characters (8 bits × 3 = 6 bits × 4 = 24 bits).//! When the input is not an even multiple of 3 bytes in length, [canonical][]//! base64 encoders insert padding characters at the end, so that the output//! length is always a multiple of 4://! [canonical]: https://datatracker.ietf.org/doc/html/rfc4648#section-3.5//! use base64::{engine::general_purpose::STANDARD, Engine as _};//! assert_eq!(STANDARD.encode(b""),    "");//! assert_eq!(STANDARD.encode(b"f"),   "Zg==");//! assert_eq!(STANDARD.encode(b"fo"),  "Zm8=");//! assert_eq!(STANDARD.encode(b"foo"), "Zm9v");//! Canonical encoding ensures that base64 encodings will be exactly the same,//! byte-for-byte, regardless of input length. But the `=` padding characters//! aren’t necessary for decoding, and they may be omitted by using a//! [`NO_PAD`][engine::general_purpose::NO_PAD] configuration://! use base64::{engine::general_purpose::STANDARD_NO_PAD, Engine as _};//! assert_eq!(STANDARD_NO_PAD.encode(b""),    "");//! assert_eq!(STANDARD_NO_PAD.encode(b"f"),   "Zg");//! assert_eq!(STANDARD_NO_PAD.encode(b"fo"),  "Zm8");//! assert_eq!(STANDARD_NO_PAD.encode(b"foo"), "Zm9v");//! The pre-configured `NO_PAD` engines will reject inputs containing padding//! `=` characters. To encode without padding and still accept padding while//! decoding, create an [engine][engine::general_purpose::GeneralPurpose] with//! that [padding mode][engine::DecodePaddingMode].//! # use base64::{engine::general_purpose::STANDARD_NO_PAD, Engine as _};//! assert_eq!(STANDARD_NO_PAD.decode(b"Zm8="), Err(base64::DecodeError::InvalidPadding));//! ### Further customization//! Decoding and encoding behavior can be customized by creating an//! [engine][engine::GeneralPurpose] with an [alphabet][alphabet::Alphabet] and//! [padding configuration][engine::GeneralPurposeConfig]://! use base64::{engine, alphabet, Engine as _};//! // bizarro-world base64: +/ as the first symbols instead of the last//! let alphabet =//!     alphabet::Alphabet::new("+/ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789")//!     .unwrap();//! // a very weird config that encodes with padding but requires no padding when decoding...?//! let crazy_config = engine::GeneralPurposeConfig::new()//!     .with_decode_allow_trailing_bits(true)//!     .with_encode_padding(true)//!     .with_decode_padding_mode(engine::DecodePaddingMode::RequireNone);//! let crazy_engine = engine::GeneralPurpose::new(&alphabet, crazy_config);//! let encoded = crazy_engine.encode(b"abc 123");//! ## Memory allocation//! The [decode][Engine::decode()] and [encode][Engine::encode()] engine methods//! allocate memory for their results – `decode` returns a `Vec<u8>` and//! `encode` returns a `String`. To instead decode or encode into a buffer that//! you allocated, use one of the alternative methods://! #### Decoding//! | Method                     | Output                        | Allocates memory              |//! | -------------------------- | ----------------------------- | ----------------------------- |//! | [`Engine::decode`]         | returns a new `Vec<u8>`       | always                        |//! | [`Engine::decode_vec`]     | appends to provided `Vec<u8>` | if `Vec` lacks capacity       |//! | [`Engine::decode_slice`]   | writes to provided `&[u8]`    | never//! #### Encoding//! | Method                     | Output                       | Allocates memory               |//! | -------------------------- | ---------------------------- | ------------------------------ |//! | [`Engine::encode`]         | returns a new `String`       | always                         |//! | [`Engine::encode_string`]  | appends to provided `String` | if `String` lacks capacity     |//! | [`Engine::encode_slice`]   | writes to provided `&[u8]`   | never                          |//! ## Input and output//! The `base64` crate can [decode][Engine::decode()] and//! [encode][Engine::encode()] values in memory, or//! [`DecoderReader`][read::DecoderReader] and//! [`EncoderWriter`][write::EncoderWriter] provide streaming decoding and//! encoding for any [readable][std::io::Read] or [writable][std::io::Write]//! byte stream.//! # use std::io;//! use base64::{engine::general_purpose::STANDARD, read::DecoderReader};//! # fn main() -> Result<(), Box<dyn std::error::Error>> {//! let mut input = io::stdin();//! let mut decoder = DecoderReader::new(&mut input, &STANDARD);//! io::copy(&mut decoder, &mut io::stdout())?;//! use base64::{engine::general_purpose::STANDARD, write::EncoderWriter};//! let mut output = io::stdout();//! let mut encoder = EncoderWriter::new(&mut output, &STANDARD);//! io::copy(&mut io::stdin(), &mut encoder)?;//! #### Display//! If you only need a base64 representation for implementing the//! [`Display`][std::fmt::Display] trait, use//! [`Base64Display`][display::Base64Display]://! let value = Base64Display::new(b"\0\x01\x02\x03", &STANDARD);//! assert_eq!("base64: AAECAw==", format!("base64: {}", value));// Allow globally until https://github.com/rust-lang/rust-clippy/issues/8768 is resolved.// The desired state is to allow it only for the rstest_reuse import.BASE64_STANDARDBASE64_STANDARD_NO_PADBASE64_URL_SAFEBASE64_URL_SAFE_NO_PAD//! Preconfigured engines for common use cases.//! These are re-exports of `const` engines in [crate::engine::general_purpose], renamed with a `BASE64_`//! prefix for those who prefer to `use` the entire path to a name.//! use base64::prelude::{Engine as _, BASE64_STANDARD_NO_PAD};//! assert_eq!("c29tZSBieXRlcw", &BASE64_STANDARD_NO_PAD.encode(b"some bytes"));// offset of previously seen padding, if any/// use base64::engine::general_purpose;///     &mut wrapped_reader,///     &general_purpose::STANDARD);/// Unwraps this `DecoderReader`, returning the base reader which it reads base64 encoded/// input from./// Because `DecoderReader` performs internal buffering, the state of the inner reader is/// unspecified. This function is mainly provided because the inner reader type may provide/// additional functionality beyond the `Read` implementation which may still be useful.internal_padding_error_with_short_read_concatenated_texts_invalid_byte_errorinternal_padding_anywhere_errormax_read_lenShortReadALPHABETS/// Where encoded data is written to. It's an Option as it's None immediately before Drop is/// called so that finish() can return the underlying writer. None implies that finish() has/// been called successfully./// let mut enc = base64::write::EncoderWriter::new(Vec::new(), &general_purpose::STANDARD);/// enc.write_all(b"asdf").unwrap();/// // could leave this out to be called by Drop, if you don't care/// // about handling errors or getting the delegate writer back/// let delegate = enc.finish().unwrap();/// assert_eq!(b"YXNkZg==", &delegate[..]);/// Calling `write()` (or related methods) or `finish()` after `finish()` has completed without/// error is invalid and will panic./// # Limitations/// Owing to the specification of the `write` and `flush` methods on the `Write` trait and their/// implications for a buffering implementation, these methods may not behave as expected. In/// particular, calling `write_all` on this interface may fail with `io::ErrorKind::WriteZero`./// See the documentation of the `Write` trait implementation for further details./// Create a new encoder that will write to the provided delegate writer./// Once this succeeds, no further writes or calls to this method are allowed./// This may write to the delegate writer multiple times if the delegate writer does not accept/// all input provided to its `write` each invocation./// If you don't care about error handling, it is not necessary to call this function, as the/// equivalent finalization is done by the Drop impl./// Returns the writer that this was constructed around./// The first error that is not of `ErrorKind::Interrupted` will be returned.write_final_leftovers/// Write any remaining buffered data to the delegate writer./// Unwraps this `EncoderWriter`, returning the base writer it writes base64 encoded output/// to./// Normally this method should not be needed, since `finish()` returns the inner writer if/// it completes successfully. That will also ensure all data has been flushed, which the/// `into_inner()` function does *not* do./// Calling this method after `finish()` has completed successfully will panic, since the/// writer has already been returned./// This method may be useful if the writer implements additional APIs beyond the `Write`/// trait. Note that the inner writer might be in an error state or have an incomplete/// base64 string written to it./// <https://github.com/rust-lang/rust/issues/56889> for more on that.Utf8SingleCodeUnitWriterStrConsumerEncoderStringWriter/// A `Write` implementation that base64-encodes data using the provided config and accumulates the/// resulting base64 utf8 `&str` in a [StrConsumer] implementation (typically `String`), which is/// then exposed via `into_inner()`./// Buffer base64 in a new String:/// let mut enc = base64::write::EncoderStringWriter::new(&general_purpose::STANDARD);/// // get the resulting String/// let b64_string = enc.into_inner();/// assert_eq!("YXNkZg==", &b64_string);/// Or, append to an existing `String`, which implements `StrConsumer`:/// let mut buf = String::from("base64: ");/// let mut enc = base64::write::EncoderStringWriter::from_consumer(///     &mut buf,/// // release the &mut reference on buf/// let _ = enc.into_inner();/// assert_eq!("base64: YXNkZg==", &buf);/// Because it has to validate that the base64 is UTF-8, it is about 80% as fast as writing plain/// bytes to a `io::Write`.from_consumer/// Create a EncoderStringWriter that will append to the provided `StrConsumer`./// Encode all remaining buffered data, including any trailing incomplete input triples and/// associated padding./// Returns the base64-encoded form of the accumulated written data./// Create a EncoderStringWriter that will encode into a new `String` with the provided config.consume/// Consume the base64 encoded data in `buf`/// An abstraction around consuming `str`s produced by base64 encoding./// As for io::Write, `StrConsumer` is implemented automatically for `&mut S`./// Pushes the str onto the end of the Stringstr_consumer/// A `Write` that only can handle bytes that are valid single-byte UTF-8 code units./// This is safe because we only use it when writing base64, which is always valid UTF-8.encoder_string_writerincremental_writesURL_SAFE_ENGINENO_PAD_ENGINE// Copyright (c) 2015 Andrew Gallantcopy_nonoverlappingLittleEndianBigEndianNativeEndianread_num_byteswrite_num_bytesserde_if_integer128ByteOrderread_i16read_i32read_i64read_f32read_f64write_i16write_i32write_i64write_f32write_f64read_i128write_i128read_u8read_i8ReadBytesExtwrite_i8WriteBytesExtEndianBincodeByteOrder/// Little-endian byte ordering./// Big-endian byte ordering./// The native byte ordering of the current system.size_ofOptionsBincodeReadu16_size/// Gets the size (in bytes) that a value would be serialized to.u32_sizeu64_sizei16_sizei32_sizei64_sizelen_sizeserialize_len/// Serializes a sequence length.serialize_u16serialize_u32serialize_u64serialize_i16serialize_i32serialize_i64deserialize_len/// Deserializes a sequence length.deserialize_u16deserialize_u32deserialize_u64deserialize_i16deserialize_i32deserialize_i64u128_sizei128_sizeserialize_u128deserialize_u128serialize_i128deserialize_i128IntEncodingFixintEncoding/// Fixed-size integer encoding.////// * Fixed size integers are encoded directly/// * Enum discriminants are encoded as u32/// * Lengths and usize are encoded as u64VarintEncoding/// Variable-size integer encoding (excepting [ui]8)./// Encoding an unsigned integer v (of any type excepting u8) works as follows:/// 1. If `u < 251`, encode it as a single byte with that value./// 2. If `251 <= u < 2**16`, encode it as a literal byte 251, followed by a u16 with value `u`./// 3. If `2**16 <= u < 2**32`, encode it as a literal byte 252, followed by a u32 with value `u`./// 4. If `2**32 <= u < 2**64`, encode it as a literal byte 253, followed by a u64 with value `u`./// 5. If `2**64 <= u < 2**128`, encode it as a literal byte 254, followed by a///   u128 with value `u`./// Then, for signed integers, we first convert to unsigned using the zigzag algorithm,/// and then encode them as we do for unsigned integers generally. The reason we use this/// algorithm is that it encodes those values which are close to zero in less bytes; the/// obvious algorithm, where we encode the cast values, gives a very large encoding for all/// negative values./// The zigzag algorithm is defined as follows:/// ```ignore/// fn zigzag(v: Signed) -> Unsigned {///     match v {///         0 => 0,///         v if v < 0 => |v| * 2 - 1///         v if v > 0 => v * 2///     }/// }/// ```/// And works such that:/// assert_eq!(zigzag(0), 0);/// assert_eq!(zigzag(-1), 1);/// assert_eq!(zigzag(1), 2);/// assert_eq!(zigzag(-2), 3);/// assert_eq!(zigzag(2), 4);/// assert_eq!(zigzag(i64::min_value()), u64::max_value());/// Note that u256 and the like are unsupported by this format; if and when they are added to the/// language, they may be supported via the extension point given by the 255 byte.SINGLE_BYTE_MAXU16_BYTEU32_BYTEU64_BYTEU128_BYTEDESERIALIZE_EXTENSION_POINT_ERRvarint_sizezigzag_encodezigzag_decodeserialize_varintdeserialize_varintzigzag128_encodezigzag128_decodevarint128_sizeserialize_varint128deserialize_varint128cast_u64_to_usizecast_u64_to_u32cast_u64_to_u16cast_i64_to_i32cast_i64_to_i16test_zigzag_encodetest_zigzag_decodetest_zigzag_edge_casesEndianOptionLimitOptionDefaultOptionslimitendian/// A configuration builder whose options Bincode will use/// while serializing and deserializing./// ### Options/// Endianness: The endianness with which multi-byte integers will be read/written.  *default: little endian*/// Limit: The maximum number of bytes that will be read/written in a bincode serialize/deserialize. *default: unlimited*/// ### Byte Limit Details/// The purpose of byte-limiting is to prevent Denial-Of-Service attacks whereby malicious attackers get bincode/// deserialization to crash your process by allocating too much memory or keeping a connection open for too long./// When a byte limit is set, bincode will return `Err` on any deserialization that goes over the limit, or any/// serialization that goes over the limit.UnlimitedLimitedBigLittleNativeconfig_mapno_limit/// Sets the byte limit to be unlimited./// This is the default./// Sets the byte limit to `limit`.little_endian/// Sets the endianness to little-endianbig_endian/// Sets the endianness to big-endiannative_endian/// Sets the endianness to the the machine-native endianness/// Serializes a serializable object into a `Vec` of bytes using this configuration/// Returns the size that an object would be if serialized using Bincode with this configurationserialize_into/// Serializes an object directly into a `Writer` using this configuration/// If the serialization would take more bytes than allowed by the size limit, an error/// is returned and *no bytes* will be written into the `Writer`/// Deserializes a slice of bytes into an instance of `T` using this configuration/// TODO: documentDeserializeSeeddeserialize_seed/// Deserializes a slice of bytes with state `seed` using this configuration.DeserializeOwneddeserialize_from/// Deserializes an object directly from a `Read`er using this configuration/// If this returns an `Error`, `reader` may be in an invalid state.deserialize_from_seed/// Deserializes an object directly from a `Read`er with state `seed` using this configurationdeserialize_from_custom/// Deserializes an object from a custom `BincodeRead`er using the default configuration./// It is highly recommended to use `deserialize_from` unless you need to implement/// `BincodeRead` for performance reasons.deserialize_from_custom_seed/// Deserializes an object from a custom `BincodeRead`er with state `seed` using the default/// configuration. It is highly recommended to use `deserialize_from` unless you need to/// implement `BincodeRead` for performance reasons./// Tells the SizeLimit that a certain number of bytes has been/// read or written.  Returns Err if the limit has been exceeded./// Returns the hard limit (if one exists)SizeLimit/// A trait for stopping serialization and deserialization when a certain limit has been reached.Bounded/// A SizeLimit that restricts serialized or deserialized messages from/// exceeding a certain byte length.Infinite/// A SizeLimit without a limit!/// Use this if you don't care about the size of encoded or decoded messages.trailingTrailingBytesAllowTrailingRejectTrailing/// The default options for bincode serialization/deserialization./// ### Defaults/// By default bincode will use little-endian encoding for multi-byte integers, and will not/// limit the number of serialized/deserialized bytes./// ### Configuring `DefaultOptions`/// `DefaultOptions` implements the [Options] trait, which means it exposes functions to change the behavior of bincode./// For example, if you wanted to limit the bincode deserializer to 1 kilobyte of user input:/// ```rust/// use bincode::Options;/// let my_options = bincode::DefaultOptions::new().with_limit(1024);/// ### DefaultOptions struct vs. functions/// The default configuration used by this struct is not the same as that used by the bincode/// helper functions in the root of this crate. See the/// [config](index.html#options-struct-vs-bincode-functions) module for more details/// Get a default configuration object./// ### Default Configuration:/// | Byte limit | Endianness | Int Encoding | Trailing Behavior |/// |------------|------------|--------------|-------------------|/// | Unlimited  | Little     | Varint       | Reject            |LimitTrailingInternalOptionswith_no_limitWithOtherLimitwith_limitwith_little_endianWithOtherEndianwith_big_endianwith_native_endianwith_varint_encodingWithOtherIntEncoding/// Sets the length encoding to varintwith_fixint_encoding/// Sets the length encoding to be fixedreject_trailing_bytesWithOtherTrailing/// Sets the deserializer to reject trailing bytesallow_trailing_bytes/// Sets the deserializer to allow trailing bytes/// A configuration builder trait whose options Bincode will use/// Int Encoding: The encoding used for numbers, enum discriminants, and lengths. *default: varint*/// Trailing Behavior: The behavior when there are trailing bytes left over in a slice after deserialization. *default: reject*_optionsnew_limit/// A configuration struct with a user-specified byte limitoptions_endian/// A configuration struct with a user-specified endian order_length/// A configuration struct with a user-specified length encoding_trailing/// A configuration struct with a user-specified trailing bytes behavior.//! `bincode` uses a Builder-pattern to configure the Serializers and Deserializers in this//! crate. This means that if you need to customize the behavior of `bincode`, you should create an//! instance of the `DefaultOptions` struct://!//! ```rust//! use bincode::Options;//! let my_options = bincode::DefaultOptions::new();//! ```//! # Options Struct vs bincode functions//! Due to historical reasons, the default options used by the `serialize()` and `deserialize()`//! family of functions are different than the default options created by the `DefaultOptions` struct://! |          | Byte limit | Endianness | Int Encoding | Trailing Behavior |//! |----------|------------|------------|--------------|-------------------|//! | struct   | Unlimited  | Little     | Varint       | Reject            |//! | function | Unlimited  | Little     | Fixint       | Allow             |//! This means that if you want to use the `Serialize` / `Deserialize` structs with the same//! settings as the functions, you should adjust the `DefaultOptions` struct like so://! let my_options = bincode::DefaultOptions::new()//!     .with_fixint_encoding()//!     .allow_trailing_bytes();SliceReadercheck_end/// Checks a given slice reader to determine if deserialization used all bytes in the slice./// A trait for erroring deserialization if not all bytes were read./// A TrailingBytes config that will allow trailing bytes in slices after deserialization./// A TrailingBytes config that will cause bincode to produce an error if bytes are left over in the slice when deserialization is complete.IoReaderDeErrorIntoDeserializer/// Specialized ways to read data into bincode.reader/// A Deserializer that reads bytes from a buffer./// This struct should rarely be used./// In most cases, prefer the `deserialize_from` function./// The ByteOrder that is chosen will impact the endianness that/// is used to read integers out of the reader./// let d = Deserializer::new(&mut some_reader, SizeLimit::new());/// serde::Deserialize::deserialize(&mut deserializer);/// let bytes_read = d.bytes_read();impl_deserialize_literalwith_readerIR/// Creates a new Deserializer with a given `Read`er and options.from_slice/// Creates a new Deserializer that will read from the given slice.with_bincode_read/// Creates a new Deserializer with the given `BincodeRead`erdeserialize_bytedeserialize_literal_u16deserialize_literal_u32deserialize_literal_u64deserialize_literal_u128read_bytesread_literal_typeread_vecread_stringimpl_deserialize_intdeserialize_anyVisitordeserialize_booldeserialize_f32deserialize_f64deserialize_u8deserialize_i8deserialize_unitdeserialize_chardeserialize_strdeserialize_stringdeserialize_bytesdeserialize_byte_bufdeserialize_enumdeserialize_tupledeserialize_optiondeserialize_seqdeserialize_mapdeserialize_structdeserialize_identifierdeserialize_newtype_structdeserialize_unit_structdeserialize_tuple_structdeserialize_ignored_anyis_human_readableunit_variantnewtype_variant_seedtuple_variantstruct_variantVariantAccessUTF8_CHAR_WIDTHutf8_char_width// This function is a copy of core::str::utf8_char_widthforward_read_str'storage/// Check that the next `length` bytes are a valid string and pass/// it on to the serde reader.get_byte_buffer/// Transfer ownership of the next `length` bytes to the caller.forward_read_bytes/// Pass a slice of the next `length` bytes on to the serde reader./// An optional Read trait for advanced Bincode usage./// It is highly recommended to use bincode with `io::Read` or `&[u8]` before/// implementing a custom `BincodeRead`./// The forward_read_* methods are necessary because some byte sources want/// to pass a long-lived borrow to the visitor and others want to pass a/// transient slice./// A BincodeRead implementation for byte slicestemp_buffer/// A BincodeRead implementation for `io::Read`ers/// Constructs a slice readerget_byte_sliceis_finished/// Constructs an IoReadReaderunexpected_eoffill_buffertest_fill_buffer/// The result of a serialization or deserialization operation./// An error that can be produced during (de)serializing./// If the error stems from the reader/writer that is being used/// during (de)serialization, that error will be stored and returned here.InvalidUtf8Encoding/// Returned if the deserializer attempts to deserialize a string that is not valid utf8InvalidBoolEncoding/// Returned if the deserializer attempts to deserialize a bool that was/// not encoded as either a 1 or a 0InvalidCharEncoding/// Returned if the deserializer attempts to deserialize a char that is not in the correct format.InvalidTagEncoding/// Returned if the deserializer attempts to deserialize the tag of an enum that is/// not in the expected rangesDeserializeAnyNotSupported/// Serde has a deserialize_any method that lets the format hint to the/// object which route to take in deserializing./// If (de)serializing a message takes more than the provided size limit, this/// error is returned.SequenceMustHaveLength/// Bincode can not encode sequences of unknown length (like iterators)./// A custom error message from Serde./// The kind of error that can be produced during a serialization or deserialization.custom"bincode"crate_name"rlib"crate_type"dylib"/// Deserialize bincode data to a Rust data structure./// | Byte limit | Endianness |/// |------------|------------|/// | Unlimited  | Little     |/// **Warning:** the default configuration returned by this function/// is not the same as that used by the other functions in this/// module. See the/// [config](config/index.html#options-struct-vs-bincode-functions)/// module for more details/// Serializes an object directly into a `Writer` using the default configuration./// is returned and *no bytes* will be written into the `Writer`./// **Warning:** the default configuration used by this function is not/// the same as that used by the `DefaultOptions` struct. See the/// Serializes a serializable object into a `Vec` of bytes using the default configuration./// Deserializes an object directly from a `Read`er using the default configuration./// Only use this if you know what you're doing./// This is part of the public API./// Deserializes a slice of bytes into an instance of `T` using the default configuration./// Returns the size that an object would be if serialized using Bincode with the default configuration.//! Bincode is a crate for encoding and decoding using a tiny binary//! serialization strategy.  Using it, you can easily go from having//! an object in memory, quickly serialize it to bytes, and then//! deserialize it back just as fast!//! ### Using Basic Functions//! ```edition2018//! fn main() {//!     // The object that we will serialize.//!     let target: Option<String>  = Some("hello world".to_string());//!     let encoded: Vec<u8> = bincode::serialize(&target).unwrap();//!     let decoded: Option<String> = bincode::deserialize(&encoded[..]).unwrap();//!     assert_eq!(target, decoded);//! }//! ### 128bit numbers//! Support for `i128` and `u128` is automatically enabled on Rust toolchains//! greater than or equal to `1.26.0` and disabled for targets which do not support itwriter/// An Serializer that encodes values directly into a Writer./// The specified byte-order will impact the endianness that is/// used during the encoding./// This struct should not be used often./// For most cases, prefer the `encode_into` function.impl_serialize_literal/// Creates a new Serializer with the given `Write`r.serialize_byteserialize_literal_u16serialize_literal_u32serialize_literal_u64serialize_literal_u128impl_serialize_intSerializeSeqCompoundSerializeTupleSerializeTupleStructSerializeTupleVariantSerializeMapSerializeStructSerializeStructVariantserialize_unitserialize_unit_structserialize_boolserialize_u8serialize_i8serialize_f32serialize_f64serialize_strserialize_charserialize_bytesserialize_noneserialize_someserialize_seqserialize_tupleserialize_tuple_structserialize_tuple_variantserialize_mapserialize_structserialize_struct_variantserialize_newtype_structserialize_newtype_variantserialize_unit_varianttotalSizeCheckeradd_discriminantadd_lenimpl_size_intSizeCompoundserialize_elementserialize_fieldserialize_keyserialize_valueEncodeUtf8__declare_public_bitflags__declare_internal_bitflags__impl_internal_bitflags__impl_public_bitflags_forward__impl_public_bitflags_ops__impl_public_bitflags_iter__impl_public_bitflags_consts//! This module shows an example of code generated by the macro. **IT MUST NOT BE USED OUTSIDE THIS//! CRATE**.//! Usually, when you call the `bitflags!` macro, only the `Flags` type would be visible. In this//! example, the `Field0`, `Iter`, and `IterRaw` types are also exposed so that you can explore//! their APIs. The `Field0` type can be accessed as `self.0` on an instance of `Flags`.arbitraryUnstructuredBitsArbitrary/**
Generate some arbitrary flags value with only known bits set.
*/test_arbitrary//! Specialized fuzzing for flags types using `arbitrary`.test_bytemuckParseHexWriteHex/**
Serialize a set of flags as a human-readable string or their underlying bits.

Any unknown bits will be retained.
*//**
Deserialize a set of flags from a human-readable string or their underlying bits.

Any unknown bits will be retained.
*/serde_testassert_tokensConfigureSerdeFlagsPublicFlagsInternal__bitflags_flagFLAGSFlagfrom_bits_retaintest_serde_bitflags_default//! Specialized serialization for flags types using `serde`.__impl_external_bitflags/// Implements traits from external libraries for the internal bitflags type.__impl_external_bitflags_serde/// Implement `Serialize` and `Deserialize` for the internal bitflags type.__impl_external_bitflags_arbitrary__impl_external_bitflags_bytemuck//! Conditional trait implementations for external libraries./*
How do I support a new external library?

Let's say we want to add support for `my_library`.

First, we create a module under `external`, like `serde` with any specialized code.
Ideally, any utilities in here should just work off the `Flags` trait and maybe a
few other assumed bounds.

Next, re-export the library from the `__private` module here.

Next, define a macro like so:

```rust
#[macro_export]
#[doc(hidden)]
#[cfg(feature = "serde")]
macro_rules! __impl_external_bitflags_my_library {
    (
        $InternalBitFlags:ident: $T:ty, $PublicBitFlags:ident {
            $(
                $(#[$inner:ident $($args:tt)*])*
                const $Flag:tt;
            )*
        }
    ) => {
        // Implementation goes here
    };
}

#[macro_export]
#[doc(hidden)]
#[cfg(not(feature = "my_library"))]
macro_rules! __impl_external_bitflags_my_library {
    (
        $InternalBitFlags:ident: $T:ty, $PublicBitFlags:ident {
            $(
                $(#[$inner:ident $($args:tt)*])*
                const $Flag:tt;
            )*
        }
    ) => {};
}
```

Note that the macro is actually defined twice; once for when the `my_library` feature
is available, and once for when it's not. This is because the `__impl_external_bitflags_my_library`
macro is called in an end-user's library, not in `bitflags`. In an end-user's library we don't
know whether or not a particular feature of `bitflags` is enabled, so we unconditionally call
the macro, where the body of that macro depends on the feature flag.

Now, we add our macro call to the `__impl_external_bitflags` macro body:

```rust
__impl_external_bitflags_my_library! {
    $InternalBitFlags: $T, $PublicBitFlags {
        $(
            $(#[$inner $($args)*])*
            const $Flag;
        )*
    }
}
```
*//// Declare the `bitflags`-facing bitflags struct./// This type is part of the `bitflags` crate's public API, but not part of the user's./// Implement functions on the private (bitflags-facing) bitflags type./// Methods and trait implementations can be freely added here without breaking end-users./// If we want to expose new functionality to `#[derive]`, this is the place to do it.//! Generate the internal `bitflags`-facing flags type.//! The code generated here is owned by `bitflags`, but still part of its public API.//! Changes to the types generated here need to be considered like any other public API change.IterNamesdone/**
An iterator over flags values.

This iterator will yield flags values for contained, defined flags first, with any remaining bits yielded
as a final flags value.
*/__private_const_new// Used by the `bitflags` macroremaining/**
An iterator over flags values.

This iterator only yields flags values for contained, defined, named flags. Any remaining bits
won't be yielded, but can be found with the [`IterNames::remaining`] method.
*/// Used by the bitflags macro/// Get a flags value of any remaining bits that haven't been yielded yet./// Once the iterator has finished, this method can be used to/// check whether or not there are any bits that didn't correspond/// to a contained, defined, named flag remaining./*!
Yield the bits of a source flags value in a set of contained flags values.
*/traits// Easier than conditionally checking any optional external dependenciesBitFlags/**
Generate a flags type.

# `struct` mode

A declaration that begins with `$vis struct` will generate a `struct` for a flags type, along with
methods and trait implementations for it. The body of the declaration defines flags as constants,
where each constant is a flags value of the generated flags type.

## Examples

Generate a flags type using `u8` as the bits type:

```
# use bitflags::bitflags;
bitflags! {
    struct Flags: u8 {
        const A = 1;
        const B = 1 << 1;
        const C = 0b0000_0100;
    }
}
```

Flags types are private by default and accept standard visibility modifiers. Flags themselves
are always public:

```
# use bitflags::bitflags;
bitflags! {
    pub struct Flags: u8 {
        // Constants are always `pub`
        const A = 1;
    }
}
```

Flags may refer to other flags using their [`Flags::bits`] value:

```
# use bitflags::bitflags;
bitflags! {
    struct Flags: u8 {
        const A = 1;
        const B = 1 << 1;
        const AB = Flags::A.bits() | Flags::B.bits();
    }
}
```

A single `bitflags` invocation may include zero or more flags type declarations:

```
# use bitflags::bitflags;
bitflags! {}

bitflags! {
    struct Flags1: u8 {
        const A = 1;
    }

    struct Flags2: u8 {
        const A = 1;
    }
}
```

# `impl` mode

A declaration that begins with `impl` will only generate methods and trait implementations for the
`struct` defined outside of the `bitflags` macro.

The struct itself must be a newtype using the bits type as its field.

The syntax for `impl` mode is identical to `struct` mode besides the starting token.

## Examples

Implement flags methods and traits for a custom flags type using `u8` as its underlying bits type:

```
# use bitflags::bitflags;
struct Flags(u8);

bitflags! {
    impl Flags: u8 {
        const A = 1;
        const B = 1 << 1;
        const C = 0b0000_0100;
    }
}
```

# Named and unnamed flags

Constants in the body of a declaration are flags. The identifier of the constant is the name of
the flag. If the identifier is `_`, then the flag is unnamed. Unnamed flags don't appear in the
generated API, but affect how bits are truncated.

## Examples

Adding an unnamed flag that makes all bits known:

```
# use bitflags::bitflags;
bitflags! {
    struct Flags: u8 {
        const A = 1;
        const B = 1 << 1;

        const _ = !0;
    }
}
```

Flags types may define multiple unnamed flags:

```
# use bitflags::bitflags;
bitflags! {
    struct Flags: u8 {
        const _ = 1;
        const _ = 1 << 1;
    }
}
```
*/__impl_bitflags/// Implement functions on bitflags types./// We need to be careful about adding new methods and trait implementations here because they/// could conflict with items added by the end-user.bitflags_match/// A macro that matches flags values, similar to Rust's `match` statement./// In a regular `match` statement, the syntax `Flag::A | Flag::B` is interpreted as an or-pattern,/// instead of the bitwise-or of `Flag::A` and `Flag::B`. This can be surprising when combined with flags types/// because `Flag::A | Flag::B` won't match the pattern `Flag::A | Flag::B`. This macro is an alternative to/// `match` for flags values that doesn't have this issue./// # Syntax/// bitflags_match!(expression, {///     pattern1 => result1,///     pattern2 => result2,///     ..///     _ => default_result,/// })/// The final `_ => default_result` arm is required, otherwise the macro will fail to compile./// use bitflags::{bitflags, bitflags_match};/// bitflags! {///     #[derive(PartialEq)]///     struct Flags: u8 {///         const A = 1 << 0;///         const B = 1 << 1;///         const C = 1 << 2;/// let flags = Flags::A | Flags::B;/// bitflags_match!(flags, {///     Flags::A | Flags::B => println!("A and/or B are set"),///     _ => println!("neither A nor B are set"),/// # How it works/// The macro expands to a series of `if` statements, checking equality between the input expression/// and each pattern. This allows for correct matching of bitflag combinations, which is not possible/// with a regular match expression due to the way bitflags are implemented./// Patterns are evaluated in order.__bitflags_match// Eat an optional `,` following a block match arm// Expand a block match arm `A => { .. }`// Expand an expression match arm `A => x,`// Expand the default case/// Expand the `bitflags_match` macro__bitflags_expr_safe_attrs// Entrypoint: Move all flags and all attributes into `unprocessed` lists// where they'll be munched one-at-a-time// Process the next attribute on the current flag// `cfg`: The next flag should be propagated to expressions// NOTE: You can copy this rules block and replace `cfg` with// your attribute name that should be considered expression-safe// `$other`: The next flag should not be propagated to expressions// Once all attributes on all flags are processed, generate the actual code/// A macro that processed the input to `bitflags!` and shuffles attributes around/// based on whether or not they're "expression-safe"./// This macro is a token-tree muncher that works on 2 levels:/// For each attribute, we explicitly match on its identifier, like `cfg` to determine/// whether or not it should be considered expression-safe./// If you find yourself with an attribute that should be considered expression-safe/// and isn't, it can be added here./// Implement a flag, which may be a wildcard `_`.public// Copyright 2014 The Rust Project Developers. See the COPYRIGHT/*!
Generate types for C-style flags with ergonomic APIs.

# Getting started

Add `bitflags` to your `Cargo.toml`:

```toml
[dependencies.bitflags]
version = "2.9.1"
```

## Crate features

The `bitflags` library defines a few Cargo features that you can opt-in to:

- `std`: Implement the `Error` trait on error types used by `bitflags`.
- `serde`: Support deriving `serde` traits on generated flags types.
- `arbitrary`: Support deriving `arbitrary` traits on generated flags types.
- `bytemuck`: Support deriving `bytemuck` traits on generated flags types.

## Generating flags types

Use the [`bitflags`] macro to generate flags types:

```rust
use bitflags::bitflags;

bitflags! {
    pub struct Flags: u32 {
        const A = 0b00000001;
        const B = 0b00000010;
        const C = 0b00000100;
    }
}
```

See the docs for the `bitflags` macro for the full syntax.

Also see the [`example_generated`](./example_generated/index.html) module for an example of what the `bitflags` macro generates for a flags type.

### Externally defined flags

If you're generating flags types for an external source, such as a C API, you can define
an extra unnamed flag as a mask of all bits the external source may ever set. Usually this would be all bits (`!0`):

```rust
# use bitflags::bitflags;
bitflags! {
    pub struct Flags: u32 {
        const A = 0b00000001;
        const B = 0b00000010;
        const C = 0b00000100;

        // The source may set any bits
        const _ = !0;
    }
}
```

Why should you do this? Generated methods like `all` and truncating operators like `!` only consider
bits in defined flags. Adding an unnamed flag makes those methods consider additional bits,
without generating additional constants for them. It helps compatibility when the external source
may start setting additional bits at any time. The [known and unknown bits](#known-and-unknown-bits)
section has more details on this behavior.

### Custom derives

You can derive some traits on generated flags types if you enable Cargo features. The following
libraries are currently supported:

- `serde`: Support `#[derive(Serialize, Deserialize)]`, using text for human-readable formats,
  and a raw number for binary formats.
- `arbitrary`: Support `#[derive(Arbitrary)]`, only generating flags values with known bits.
- `bytemuck`: Support `#[derive(Pod, Zeroable)]`, for casting between flags values and their
  underlying bits values.

You can also define your own flags type outside of the [`bitflags`] macro and then use it to generate methods.
This can be useful if you need a custom `#[derive]` attribute for a library that `bitflags` doesn't
natively support:

```rust
# use std::fmt::Debug as SomeTrait;
# use bitflags::bitflags;
#[derive(SomeTrait)]
pub struct Flags(u32);

bitflags! {
    impl Flags: u32 {
        const A = 0b00000001;
        const B = 0b00000010;
        const C = 0b00000100;
    }
}
```

### Adding custom methods

The [`bitflags`] macro supports attributes on generated flags types within the macro itself, while
`impl` blocks can be added outside of it:

```rust
# use bitflags::bitflags;
bitflags! {
    // Attributes can be applied to flags types
    #[repr(transparent)]
    #[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
    pub struct Flags: u32 {
        const A = 0b00000001;
        const B = 0b00000010;
        const C = 0b00000100;
    }
}

// Impl blocks can be added to flags types
impl Flags {
    pub fn as_u64(&self) -> u64 {
        self.bits() as u64
    }
}
```

## Working with flags values

Use generated constants and standard bitwise operators to interact with flags values:

```rust
# use bitflags::bitflags;
# bitflags! {
#     #[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
#     pub struct Flags: u32 {
#         const A = 0b00000001;
#         const B = 0b00000010;
#         const C = 0b00000100;
#     }
# }
// union
let ab = Flags::A | Flags::B;

// intersection
let a = ab & Flags::A;

// difference
let b = ab - Flags::A;

// complement
let c = !ab;
```

See the docs for the [`Flags`] trait for more details on operators and how they behave.

# Formatting and parsing

`bitflags` defines a text format that can be used to convert any flags value to and from strings.

See the [`parser`] module for more details.

# Specification

The terminology and behavior of generated flags types is
[specified in the source repository](https://github.com/bitflags/bitflags/blob/main/spec.md).
Details are repeated in these docs where appropriate, but is exhaustively listed in the spec. Some
things are worth calling out explicitly here.

## Flags types, flags values, flags

The spec and these docs use consistent terminology to refer to things in the bitflags domain:

- **Bits type**: A type that defines a fixed number of bits at specific locations.
- **Flag**: A set of bits in a bits type that may have a unique name.
- **Flags type**: A set of defined flags over a specific bits type.
- **Flags value**: An instance of a flags type using its specific bits value for storage.

```
# use bitflags::bitflags;
bitflags! {
    struct FlagsType: u8 {
//                    -- Bits type
//         --------- Flags type
        const A = 1;
//            ----- Flag
    }
}

let flag = FlagsType::A;
//  ---- Flags value
```

## Known and unknown bits

Any bits in a flag you define are called _known bits_. Any other bits are _unknown bits_.
In the following flags type:

```
# use bitflags::bitflags;
bitflags! {
    struct Flags: u8 {
        const A = 1;
        const B = 1 << 1;
        const C = 1 << 2;
    }
}
```

The known bits are `0b0000_0111` and the unknown bits are `0b1111_1000`.

`bitflags` doesn't guarantee that a flags value will only ever have known bits set, but some operators
will unset any unknown bits they encounter. In a future version of `bitflags`, all operators will
unset unknown bits.

If you're using `bitflags` for flags types defined externally, such as from C, you probably want all
bits to be considered known, in case that external source changes. You can do this using an unnamed
flag, as described in [externally defined flags](#externally-defined-flags).

## Zero-bit flags

Flags with no bits set should be avoided because they interact strangely with [`Flags::contains`]
and [`Flags::intersects`]. A zero-bit flag is always contained, but is never intersected. The
names of zero-bit flags can be parsed, but are never formatted.

## Multi-bit flags

Flags that set multiple bits should be avoided unless each bit is also in a single-bit flag.
Take the following flags type as an example:

```
# use bitflags::bitflags;
bitflags! {
    struct Flags: u8 {
        const A = 1;
        const B = 1 | 1 << 1;
    }
}
```

The result of `Flags::A ^ Flags::B` is `0b0000_0010`, which doesn't correspond to either
`Flags::A` or `Flags::B` even though it's still a known bit.
*//*
How does the bitflags crate work?

This library generates a `struct` in the end-user's crate with a bunch of constants on it that represent flags.
The difference between `bitflags` and a lot of other libraries is that we don't actually control the generated `struct` in the end.
It's part of the end-user's crate, so it belongs to them. That makes it difficult to extend `bitflags` with new functionality
because we could end up breaking valid code that was already written.

Our solution is to split the type we generate into two: the public struct owned by the end-user, and an internal struct owned by `bitflags` (us).
To give you an example, let's say we had a crate that called `bitflags!`:

```rust
bitflags! {
    pub struct MyFlags: u32 {
        const A = 1;
        const B = 2;
    }
}
```

What they'd end up with looks something like this:

```rust
pub struct MyFlags(<MyFlags as PublicFlags>::InternalBitFlags);

const _: () = {
    #[repr(transparent)]
    #[derive(Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
    pub struct MyInternalBitFlags {
        bits: u32,
    }

    impl PublicFlags for MyFlags {
        type Internal = InternalBitFlags;
    }
};
```

If we want to expose something like a new trait impl for generated flags types, we add it to our generated `MyInternalBitFlags`,
and let `#[derive]` on `MyFlags` pick up that implementation, if an end-user chooses to add one.

The public API is generated in the `__impl_public_flags!` macro, and the internal API is generated in
the `__impl_internal_flags!` macro.

The macros are split into 3 modules:

- `public`: where the user-facing flags types are generated.
- `internal`: where the `bitflags`-facing flags types are generated.
- `external`: where external library traits are implemented conditionally.
*/to_writer/**
Write a flags value as text.

Any bits that aren't part of a contained flag will be formatted as a hex number.
*/AsDisplay/**
Parse a flags value from text.

This function will fail on any names that don't correspond to defined flags.
Unknown bits will be retained.
*/to_writer_truncate/**
Write a flags value as text, ignoring any unknown bits.
*/from_str_truncate/**
Parse a flags value from text.

This function will fail on any names that don't correspond to defined flags.
Unknown bits will be ignored.
*/to_writer_strict/**
Write only the contained, defined, named flags in a flags value as text.
*/from_str_strict/**
Parse a flags value from text.

This function will fail on any names that don't correspond to defined flags.
This function will fail to parse hex values.
*/write_hex/// Write the value as hex./**
Encode a value as a hex string.

Implementors of this trait should not write the `0x` prefix.
*/parse_hex/// Parse the value from hex./**
Parse a value from a hex string.
*/ParseErrorKind/// An error encountered while parsing flags from text.EmptyFlagInvalidNamedFlagInvalidHexFlaginvalid_hex_flag/// An invalid hex flag was encountered.invalid_named_flag/// A named flag that doesn't correspond to any on the flags type was encountered.empty_flag/// A hex or named flag wasn't found between separators./*!
Parsing flags from text.

Format and parse a flags value as text using the following grammar:

- _Flags:_ (_Whitespace_ _Flag_ _Whitespace_)`|`*
- _Flag:_ _Name_ | _Hex Number_
- _Name:_ The name of any defined flag
- _Hex Number_: `0x`([0-9a-fA-F])*
- _Whitespace_: (\s)*

As an example, this is how `Flags::A | Flags::B | 0x0c` can be represented as text:

```text
A | B | 0x0c
```

Alternatively, it could be represented without whitespace:

```text
A|B|0x0C
```

Note that identifiers are *case-sensitive*, so the following is *not equivalent*:

```text
a|b|0x0C
```
*//// Declare the user-facing bitflags struct./// This type is guaranteed to be a newtype with a `bitflags`-facing type as its single field./// Implement functions on the public (user-facing) bitflags type.__impl_public_bitflags/// Implement iterators on the public (user-facing) bitflags type./// Implement traits on the public (user-facing) bitflags type./// Implement constants on the public (user-facing) bitflags type.//! Generate the user-facing flags type.//! The code here belongs to the end-user, so new trait implementations and methods can't be//! added without potentially breaking users.casescaseflag_to_stringtest_single_flagstest_or_operationstest_and_operationstest_xor_operationstest_complex_operationstest_empty_and_full_flagsLowerHexOctalBinaryBitAndAssignroundtrip// Very slow in miricollectiter_namesroundtrip_truncateroundtrip_strictvalidinvalidBitXorAssignBitOrAssignallcomplementdifferencefrom_bits_truncatefrom_nameintersectionintersectsis_allsymmetric_differenceunionunknownTestFlagsr" 1"r" 1 << 1"r" 1 << 2"r" 1 | (1 << 1) | (1 << 2)"ABCTestFlagsInvertTestZeror" 0"TestZeroOneTestUnicode一r" 2"二TestEmptyTestOverlappingr" 1 | (1 << 1)"ABr" (1 << 1) | (1 << 2)"BCTestOverlappingFullTestExternalTestExternalFull/**
A defined flags value that may be named or unnamed.
*//**
    Define a flag.

    If `name` is non-empty then the flag is named, otherwise it's unnamed.
    *//**
    Get the name of this flag.

    If the flag is unnamed then the returned string will be empty.
    *//**
    Get the flags value of this flag.
    */is_named/**
    Whether the flag is named.

    If [`Flag::name`] returns a non-empty string then this method will return `true`.
    */is_unnamed/**
    Whether the flag is unnamed.

    If [`Flag::name`] returns a non-empty string then this method will return `false`.
    *//// The set of defined flags./// The underlying bits type./// Get a flags value with all bits unset./// Get a flags value with all known bits set.contains_unknown_bits/// This method will return `true` if any unknown bits are set./// Get the underlying bits value./// The returned value is exactly the bits set in this flags value./// Convert from a bits value./// This method will return `None` if any unknown bits are set./// Convert from a bits value, unsetting any unknown bits./// Convert from a bits value exactly./// Get a flags value with the bits of a flag with the given name set./// This method will return `None` if `name` is empty or doesn't/// correspond to any named flag./// Yield a set of contained flags values./// Each yielded flags value will correspond to a defined named flag. Any unknown bits/// will be yielded together as a final flags value./// Yield a set of contained named flags values./// This method is like [`Flags::iter`], except only yields bits in contained named flags./// Any unknown bits, or bits not corresponding to a contained flag will not be yielded./// Whether all bits in this flags value are unset./// Whether all known bits in this flags value are set./// Whether any set bits in a source flags value are also set in a target flags value./// Whether all set bits in a source flags value are also set in a target flags value./// Remove any unknown bits from the flags./// The bitwise or (`|`) of the bits in two flags values./// The intersection of a source flags value with the complement of a target flags value (`&!`)./// This method is not equivalent to `self & !other` when `other` has unknown bits set./// `remove` won't truncate `other`, but the `!` operator will.toggle/// The bitwise exclusive-or (`^`) of the bits in two flags values./// Call [`Flags::insert`] when `value` is `true` or [`Flags::remove`] when `value` is `false`./// Unsets all bits in the flags./// The bitwise and (`&`) of the bits in two flags values./// `difference` won't truncate `other`, but the `!` operator will./// The bitwise negation (`!`) of the bits in a flags value, truncating the result./**
A set of defined flags using a bits type as storage.

## Implementing `Flags`

This trait is implemented by the [`bitflags`](macro.bitflags.html) macro:

```
use bitflags::bitflags;

bitflags! {
    struct MyFlags: u8 {
        const A = 1;
        const B = 1 << 1;
    }
}
```

It can also be implemented manually:

```
use bitflags::{Flag, Flags};

struct MyFlags(u8);

impl Flags for MyFlags {
    const FLAGS: &'static [Flag<Self>] = &[
        Flag::new("A", MyFlags(1)),
        Flag::new("B", MyFlags(1 << 1)),
    ];

    type Bits = u8;

    fn from_bits_retain(bits: Self::Bits) -> Self {
        MyFlags(bits)
    }

    fn bits(&self) -> Self::Bits {
        self.0
    }
}
```

## Using `Flags`

The `Flags` trait can be used generically to work with any flags types. In this example,
we can count the number of defined named flags:

```
# use bitflags::{bitflags, Flags};
fn defined_flags<F: Flags>() -> usize {
    F::FLAGS.iter().filter(|f| f.is_named()).count()
}

bitflags! {
    struct MyFlags: u8 {
        const A = 1;
        const B = 1 << 1;
        const C = 1 << 2;

        const _ = !0;
    }
}

assert_eq!(3, defined_flags::<MyFlags>());
```
*/EMPTY/// A value with all bits unset.ALL/// A value with all bits set./**
A bits type that can be used as storage for a flags type.
*/Primitive// Not re-exported: prevent custom `Bits` impls being used in the `bitflags!` macro,// or they may fail to compile based on crate featuresimpl_bits/// The type of the underlying storage./// The type of the internal field on the generated flags type./// A trait for referencing the `bitflags`-owned internal type/// without exposing it publicly./// An iterator over enabled flags in an instance of the type./// An iterator over the raw names and bits for enabled flags in an instance of the type.ImplementedByBitFlagsMacro/// A marker trait that signals that an implementation of `BitFlags` came from the `bitflags!` macro./// There's nothing stopping an end-user from implementing this trait, but we don't guarantee their/// manual implementations won't break between non-breaking releases.BitOpsSizeStoreBitmap/// A compact array of bits./// The type used to store the bitmap will be the minimum unsigned integer type/// required to fit the number of bits, from `u8` to `u128`. If the size is 1,/// `bool` is used. If the size exceeds 128, an array of `u128` will be used,/// sized as appropriately. The maximum supported size is currently 1024,/// represented by an array `[u128; 8]`./// Construct a bitmap with every bit set to `false`.mask/// Construct a bitmap where every bit with index less than `bits` is/// `true`, and every other bit is `false`.from_value/// Construct a bitmap from a value of the same type as its backing store.into_value/// Convert this bitmap into a value of the type of its backing store./// Count the number of `true` bits in the bitmap./// Test if the bitmap contains only `false` bits./// Get the value of the bit at a given index./// Set the value of the bit at a given index./// Returns the previous value of the bit.first_index/// Find the index of the first `true` bit in the bitmap.invert/// Invert all the bits in the bitmap.bitand_assignbitor_assignbitxor_assignU384U512U640U768U896U1024/// An iterator over the indices in a bitmap which are `true`./// This yields a sequence of `usize` indices, not their contents (which are/// always `true` anyway, by definition)./// # use bitmaps::Bitmap;/// # use typenum::U10;/// let mut bitmap: Bitmap<U10> = Bitmap::new();/// bitmap.set(3, true);/// bitmap.set(5, true);/// bitmap.set(8, true);/// let true_indices: Vec<usize> = bitmap.into_iter().collect();/// assert_eq!(vec![3, 5, 8], true_indices);proptestbtree_set// This Source Code Form is subject to the terms of the Mozilla Public// License, v. 2.0. If a copy of the MPL was not distributed with this// file, You can obtain one at http://mozilla.org/MPL/2.0/.bitmap//! This crate provides the [`Bitmap`][Bitmap] type as a convenient and//! efficient way of declaring and working with fixed size bitmaps in Rust.//! # #[macro_use] extern crate bitmaps;//! # use bitmaps::Bitmap;//! # use typenum::U10;//! let mut bitmap: Bitmap<U10> = Bitmap::new();//! assert_eq!(bitmap.set(5, true), false);//! assert_eq!(bitmap.set(5, true), true);//! assert_eq!(bitmap.get(5), true);//! assert_eq!(bitmap.get(6), false);//! assert_eq!(bitmap.len(), 1);//! assert_eq!(bitmap.set(3, true), false);//! assert_eq!(bitmap.len(), 2);//! assert_eq!(bitmap.first_index(), Some(3));//! # X86 Arch Support//! On `x86` and `x86_64` architectures, [`Bitmap`][Bitmap]s of size 256, 512,//! 768 and 1024 gain the [`load_m256i()`][load_m256i] method, which reads the//! bitmap into an [`__m256i`][m256i] or an array of [`__m256i`][m256i] using//! [`_mm256_loadu_si256()`][loadu_si256].  [`Bitmap`][Bitmap]s of size 128 as//! well as the previous gain the [`load_m128i()`][load_m128i] method, which//! does the same for [`__m128i`][m128i].//! In addition, [`Bitmap<U128>`][Bitmap] and [`Bitmap<U256>`][Bitmap] will have//! `From` and `Into` implementations for [`__m128i`][m128i] and//! [`__m256i`][m256i] respectively.//! Note that alignment is unaffected - your bitmaps will be aligned//! appropriately for `u128`, not [`__m128i`][m128i] or [`__m256i`][m256i],//! unless you arrange for it to be otherwise. This may affect the performance//! of SIMD instructions.//! [Bitmap]: struct.Bitmap.html//! [load_m128i]: struct.Bitmap.html#method.load_m128i//! [load_m256i]: struct.Bitmap.html#method.load_m256i//! [m128i]: https://doc.rust-lang.org/core/arch/x86_64/struct.__m128i.html//! [m256i]: https://doc.rust-lang.org/core/arch/x86_64/struct.__m256i.html//! [loadu_si256]: https://doc.rust-lang.org/core/arch/x86_64/fn._mm256_loadu_si256.htmlbit_andbit_orbit_xormake_maskto_hex/// A trait that defines generalised operations on a `Bits::Store` type.bitops_forbitops_for_big/// A primitive integer type suitable for storing this many bits./// A type level number signifying the number of bits in a bitmap./// This trait is implemented for type level numbers from `U1` to `U1024`./// # #[macro_use] extern crate bitmaps;/// # use bitmaps::Bits;///     std::mem::size_of::<<U10 as Bits>::Store>(),///     std::mem::size_of::<u16>()U1bits_forbits_for_bigU2U3U6U7U9U10U11U13U14U15U17U18U19U20U21U22U23U25U26U27U28U29U30U31U33U34U35U36U37U38U39U40U41U42U43U44U45U46U47U48U49U50U51U52U53U54U55U56U57U58U59U60U61U62U63U65U66U67U68U69U70U71U72U73U74U75U76U77U78U79U80U81U82U83U84U85U86U87U88U89U90U91U92U93U94U95U96U97U98U99U100U101U102U103U104U105U106U107U108U109U110U111U112U113U114U115U116U117U118U119U120U121U122U123U124U125U126U127U129U130U131U132U133U134U135U136U137U138U139U140U141U142U143U144U145U146U147U148U149U150U151U152U153U154U155U156U157U158U159U160U161U162U163U164U165U166U167U168U169U170U171U172U173U174U175U176U177U178U179U180U181U182U183U184U185U186U187U188U189U190U191U192U193U194U195U196U197U198U199U200U201U202U203U204U205U206U207U208U209U210U211U212U213U214U215U216U217U218U219U220U221U222U223U224U225U226U227U228U229U230U231U232U233U234U235U236U237U238U239U240U241U242U243U244U245U246U247U248U249U250U251U252U253U254U255U257U258U259U260U261U262U263U264U265U266U267U268U269U270U271U272U273U274U275U276U277U278U279U280U281U282U283U284U285U286U287U288U289U290U291U292U293U294U295U296U297U298U299U300U301U302U303U304U305U306U307U308U309U310U311U312U313U314U315U316U317U318U319U320U321U322U323U324U325U326U327U328U329U330U331U332U333U334U335U336U337U338U339U340U341U342U343U344U345U346U347U348U349U350U351U352U353U354U355U356U357U358U359U360U361U362U363U364U365U366U367U368U369U370U371U372U373U374U375U376U377U378U379U380U381U382U383U385U386U387U388U389U390U391U392U393U394U395U396U397U398U399U400U401U402U403U404U405U406U407U408U409U410U411U412U413U414U415U416U417U418U419U420U421U422U423U424U425U426U427U428U429U430U431U432U433U434U435U436U437U438U439U440U441U442U443U444U445U446U447U448U449U450U451U452U453U454U455U456U457U458U459U460U461U462U463U464U465U466U467U468U469U470U471U472U473U474U475U476U477U478U479U480U481U482U483U484U485U486U487U488U489U490U491U492U493U494U495U496U497U498U499U500U501U502U503U504U505U506U507U508U509U510U511U513U514U515U516U517U518U519U520U521U522U523U524U525U526U527U528U529U530U531U532U533U534U535U536U537U538U539U540U541U542U543U544U545U546U547U548U549U550U551U552U553U554U555U556U557U558U559U560U561U562U563U564U565U566U567U568U569U570U571U572U573U574U575U576U577U578U579U580U581U582U583U584U585U586U587U588U589U590U591U592U593U594U595U596U597U598U599U600U601U602U603U604U605U606U607U608U609U610U611U612U613U614U615U616U617U618U619U620U621U622U623U624U625U626U627U628U629U630U631U632U633U634U635U636U637U638U639U641U642U643U644U645U646U647U648U649U650U651U652U653U654U655U656U657U658U659U660U661U662U663U664U665U666U667U668U669U670U671U672U673U674U675U676U677U678U679U680U681U682U683U684U685U686U687U688U689U690U691U692U693U694U695U696U697U698U699U700U701U702U703U704U705U706U707U708U709U710U711U712U713U714U715U716U717U718U719U720U721U722U723U724U725U726U727U728U729U730U731U732U733U734U735U736U737U738U739U740U741U742U743U744U745U746U747U748U749U750U751U752U753U754U755U756U757U758U759U760U761U762U763U764U765U766U767U769U770U771U772U773U774U775U776U777U778U779U780U781U782U783U784U785U786U787U788U789U790U791U792U793U794U795U796U797U798U799U800U801U802U803U804U805U806U807U808U809U810U811U812U813U814U815U816U817U818U819U820U821U822U823U824U825U826U827U828U829U830U831U832U833U834U835U836U837U838U839U840U841U842U843U844U845U846U847U848U849U850U851U852U853U854U855U856U857U858U859U860U861U862U863U864U865U866U867U868U869U870U871U872U873U874U875U876U877U878U879U880U881U882U883U884U885U886U887U888U889U890U891U892U893U894U895U897U898U899U900U901U902U903U904U905U906U907U908U909U910U911U912U913U914U915U916U917U918U919U920U921U922U923U924U925U926U927U928U929U930U931U932U933U934U935U936U937U938U939U940U941U942U943U944U945U946U947U948U949U950U951U952U953U954U955U956U957U958U959U960U961U962U963U964U965U966U967U968U969U970U971U972U973U974U975U976U977U978U979U980U981U982U983U984U985U986U987U988U989U990U991U992U993U994U995U996U997U998U999U1000U1001U1002U1003U1004U1005U1006U1007U1008U1009U1010U1011U1012U1013U1014U1015U1016U1017U1018U1019U1020U1021U1022U1023is_pureshould_prefer_intrinsicsis_neonis_no_neonis_wasm32_simdis_citarget_componentsis_x86_64is_windows_targetuse_msvc_asmis_x86_32is_armis_aarch64is_armv7is_wasm32endiannessis_little_endianis_big_endianis_windows_msvc// Windows targets may be using the MSVC toolchain or the MinGW toolchain. The// right compiler flags to use depend on the toolchain. (And we don't want to// use flag_if_supported, because we don't want features to be silently// disabled by old compilers.)is_windows_gnu// MinGW toolchain uses 2 different targets depending on the main compiler.// Target for a general MinGW toolchain ends with `-gnu` (GCC is used as C// compiler). Target for a LLVM-MinGW toolchain (Clang is used as C compiler)// ends with `-gnullvm`.new_buildBuildCCompilerSupportNoCompilerNoAVX512YesAVX512c_compiler_supportbuild_sse2_sse41_avx2_rust_intrinsicsbuild_sse2_sse41_avx2_assemblybuild_avx512_c_intrinsicsbuild_avx512_assemblybuild_neon_c_intrinsicsbuild_wasm32_simdCVWordsIncrementCounterBLOCK_LENOUT_LENhash_many// Unsafe because this may only be called on platforms supporting AVX2."C"blake3_hash_many_avx2test_hash_many// Note that there is no AVX2 implementation of compress_in_place or// compress_xof.compress_in_place// Unsafe because this may only be called on platforms supporting AVX-512.compress_xofxof_manyblake3_compress_in_place_avx512blake3_compress_xof_avx512blake3_hash_many_avx512blake3_xof_many_avx512test_compresstest_xof_many// Unsafe because this may only be called on platforms supporting NEON.no_mangleblake3_compress_in_place_portable// blake3_neon.c normally depends on blake3_portable.c, because the NEON// implementation only provides 4x compression, and it relies on the portable// implementation for 1x compression. However, we expose the portable Rust// implementation here instead, to avoid linking in unnecessary code.blake3_hash_many_neon// Unsafe because this may only be called on platforms supporting SSE2.blake3_compress_in_place_sse2blake3_compress_xof_sse2blake3_hash_many_sse2// Unsafe because this may only be called on platforms supporting SSE4.1.blake3_compress_in_place_sse41blake3_compress_xof_sse41blake3_hash_many_sse41CHUNK_LENChunkState// Currently this type only supports the regular hash mode. If an// incremental user needs keyed_hash or derive_key, we can add that.parent_cv// As above, this currently assumes the regular hash mode. If an incremental// user needs keyed_hash or derive_key, we can add that.//! Deprecated in favor of [`hazmat`](crate::hazmat)platformPlatformIVKEY_LENnew_from_context_keyContextKey/// Similar to [`Hasher::new_derive_key`] but using a pre-hashed [`ContextKey`] from/// [`hash_derive_key_context`]./// The [`hash_derive_key_context`] function is _only_ valid source of the [`ContextKey`]/// use blake3::Hasher;/// use blake3::hazmat::HasherExt;/// let context_key = blake3::hazmat::hash_derive_key_context("foo");/// let mut hasher = Hasher::new_from_context_key(&context_key);/// hasher.update(b"bar");/// let derived_key = *hasher.finalize().as_bytes();/// assert_eq!(derived_key, blake3::derive_key("foo", b"bar"));set_input_offset/// Configure the `Hasher` to process a chunk or subtree starting at `offset` bytes into the/// whole input./// You must call this function before processing any input with [`update`](Hasher::update) or/// similar. This step isn't required for the first chunk, or for a subtree that includes the/// first chunk (i.e. when the `offset` is zero), but it's required for all other chunks and/// subtrees./// The starting input offset of a subtree implies a maximum possible length for that subtree./// See [`max_subtree_len`] and section 2.1 of [the BLAKE3/// paper](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf). Note that only/// subtrees along the right edge of the whole tree can have a length less than their maximum/// possible length./// See the [module level examples](index.html#examples)./// This function panics if the `Hasher` has already accepted any input with/// [`update`](Hasher::update) or similar./// This should always be paired with [`finalize_non_root`](HasherExt::finalize_non_root). It's/// never correct to use a non-zero input offset with [`finalize`](Hasher::finalize) or/// [`finalize_xof`](Hasher::finalize_xof). The `offset` must also be a multiple of/// `CHUNK_LEN`. Violating either of these rules will currently fail an assertion and panic,/// but this is not guaranteed.finalize_non_rootChainingValue/// Finalize the non-root hash ("chaining value") of the current chunk or subtree./// Afterwards you can merge subtree chaining values into parent nodes using/// [`merge_subtrees_non_root`] and ultimately into the root node with either/// [`merge_subtrees_root`] (similar to [`Hasher::finalize`]) or [`merge_subtrees_root_xof`]/// (similar to [`Hasher::finalize_xof`])./// See the [module level examples](index.html#examples), particularly the discussion of valid/// tree structures.HasherExt/// Extension methods for [`Hasher`]. This is the main entrypoint to the `hazmat` module.max_subtree_len/// The maximum length of a subtree in bytes, given its starting offset in bytes/// If you try to hash more than this many bytes as one subtree, you'll end up merging parent nodes/// that shouldn't be merged, and your output will be garbage. [`Hasher::update`] will currently/// panic in this case, but this is not guaranteed./// For input offset zero (the default), there is no maximum length, and this function returns/// `None`. For all other offsets it returns `Some`. Note that valid offsets must be a multiple of/// [`CHUNK_LEN`] (1024); it's not possible to start hashing a chunk in the middle./// In the example tree below, chunks are numbered by their _0-based index_. The subtree that/// _starts_ with chunk 3, i.e. `input_offset = 3 * CHUNK_LEN`, includes only that one chunk, so/// its max length is `Some(CHUNK_LEN)`. The subtree that starts with chunk 6 includes chunk 7 but/// not chunk 8, so its max length is `Some(2 * CHUNK_LEN)`. The subtree that starts with chunk 12/// includes chunks 13, 14, and 15, but if the tree were bigger it would not include chunk 16, so/// its max length is `Some(4 * CHUNK_LEN)`. One way to think about the rule here is that, if you/// go beyond the max subtree length from a given starting offset, you start dealing with subtrees/// that include chunks _to the left_ of where you started./// ```text///                           root///                 /                       \///              .                             .///        /           \                 /           \///       .             .               .             .///    /    \         /    \         /    \         /    \///   .      .       .      .       .      .       .      .///  / \    / \     / \    / \     / \    / \     / \    / \/// 0  1   2  3    4  5   6  7    8  9   10 11   12 13  14 15/// The general rule turns out to be that for a subtree starting at a 0-based chunk index N greater/// than zero, the maximum number of chunks in that subtree is the largest power-of-two that/// divides N, which is given by `1 << N.trailing_zeros()`./// This function can be useful for writing tests or debug assertions, but it's actually rare to/// use this for real control flow. Callers who split their input recursively using/// [`left_subtree_len`] will automatically satisfy the `max_subtree_len` bound and don't/// necessarily need to check. It's also common to choose some fixed power-of-two subtree size, say/// 64 chunks, and divide your input up into slices of that fixed length (with the final slice/// possibly short). This approach also automatically satisfies the `max_subtree_len` bound and/// doesn't need to check. Proving that this is true can be an interesting exercise. Note that/// chunks 0, 4, 8, and 12 all begin subtrees of at least 4 chunks in the example tree above./// This function currently panics if `input_offset` is not a multiple of `CHUNK_LEN`. This is not/// guaranteed.test_max_subtree_lenleft_subtree_len/// Given the length in bytes of either a complete input or a subtree input, return the number of/// bytes that belong to its left child subtree. The rest belong to its right child subtree./// Concretely, this function returns the largest power-of-two number of bytes that's strictly less/// than `input_len`. This leads to a tree where all left subtrees are "complete" and at least as/// large as their sibling right subtrees, as specified in section 2.1 of [the BLAKE3/// paper](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf). For example, if an/// input is exactly two chunks, its left and right subtrees both get one chunk. But if an input is/// two chunks plus one more byte, then its left subtree gets two chunks, and its right subtree/// only gets one byte./// This function isn't meaningful for one chunk of input, because chunks don't have children. It/// currently panics in debug mode if `input_len <= CHUNK_LEN`./// Hash a input of random length as two subtrees:/// # #[cfg(feature = "std")] {/// use blake3::hazmat::{left_subtree_len, merge_subtrees_root, HasherExt, Mode};/// use blake3::{Hasher, CHUNK_LEN};/// // Generate a random-length input. Note that to be split into two subtrees, the input length/// // must be greater than CHUNK_LEN./// let input_len = rand::random_range(CHUNK_LEN + 1..1_000_000);/// let mut input = vec![0; input_len];/// rand::fill(&mut input[..]);/// // Compute the left and right subtree hashes and then the root hash. left_subtree_len() tells/// // us exactly where to split the input. Any other split would either panic (if we're lucky) or/// // lead to an incorrect root hash./// let left_len = left_subtree_len(input_len as u64) as usize;/// let left_subtree_cv = Hasher::new()///     .update(&input[..left_len])///     .finalize_non_root();/// let right_subtree_cv = Hasher::new()///     .set_input_offset(left_len as u64)///     .update(&input[left_len..])/// let root_hash = merge_subtrees_root(&left_subtree_cv, &right_subtree_cv, Mode::Hash);/// // Double check the answer./// assert_eq!(root_hash, blake3::hash(&input));test_left_subtree_lenMode/// Corresponding to [`hash`](crate::hash)KeyedHash/// Corresponding to [`keyed_hash`](crate::hash)DeriveKeyMaterial/// Corresponding to [`derive_key`](crate::hash)/// The [`ContextKey`] comes from [`hash_derive_key_context`]./// The `mode` argument to [`merge_subtrees_root`] and friendskey_wordsflags_byte/// "Chaining value" is the academic term for a non-root or non-final hash./// Besides just sounding fancy, it turns out there are [security/// reasons](https://jacko.io/tree_hashing.html) to be careful about the difference between/// (root/final) hashes and (non-root/non-final) chaining values.merge_subtrees_innermerge_subtrees_non_root/// Compute a non-root parent node chaining value from two child chaining values./// See the [module level examples](index.html#examples), particularly the discussion of valid tree/// structures. The left and right child chaining values can come from either/// [`Hasher::finalize_non_root`](HasherExt::finalize_non_root) or other calls to/// `merge_subtrees_non_root`. "Chaining value" is the academic term for a non-root or non-final/// hash.merge_subtrees_root/// Compute a root hash from two child chaining values./// [`Hasher::finalize_non_root`](HasherExt::finalize_non_root) or [`merge_subtrees_non_root`]./// Note that inputs of [`CHUNK_LEN`] or less don't produce any parent nodes and can't be hashed/// using this function. In that case you must get the root hash from [`Hasher::finalize`] (or just/// [`blake3::hash`](crate::hash)).merge_subtrees_root_xofOutputReader/// Build a root [`OutputReader`](crate::OutputReader) from two child chaining values./// See also the [module level examples](index.html#examples), particularly the discussion of valid/// tree structures. The left and right child chaining values can come from either/// using this function. In that case you must get the `OutputReader` from/// [`Hasher::finalize_xof`]./// use blake3::hazmat::{merge_subtrees_root_xof, HasherExt, Mode};/// // Hash a 2-chunk subtree in steps. Note that only/// // the final chunk can be shorter than CHUNK_LEN./// let chunk0 = &[42; CHUNK_LEN];/// let chunk1 = b"hello world";/// let chunk0_cv = Hasher::new()///     .update(chunk0)/// let chunk1_cv = Hasher::new()///     .set_input_offset(CHUNK_LEN as u64)///     .update(chunk1)/// // Obtain a blake3::OutputReader at the root and extract 1000 bytes./// let mut output_reader = merge_subtrees_root_xof(&chunk0_cv, &chunk1_cv, Mode::Hash);/// let mut output_bytes = [0; 1_000];/// output_reader.fill(&mut output_bytes);/// let mut hasher = Hasher::new();/// hasher.update(chunk0);/// hasher.update(chunk1);/// let mut expected = [0; 1_000];/// hasher.finalize_xof().fill(&mut expected);/// assert_eq!(output_bytes, expected);/// An alias to distinguish [`hash_derive_key_context`] outputs from other keys.hash_derive_key_context/// Hash a [`derive_key`](crate::derive_key) context string and return a [`ContextKey`]./// The _only_ valid uses for the returned [`ContextKey`] are [`Hasher::new_from_context_key`] and/// [`Mode::DeriveKeyMaterial`] (together with the merge subtree functions).test_empty_subtree_should_panictest_unaligned_offset_should_panictest_hasher_already_accepted_input_should_panictest_too_much_input_should_panictest_set_input_offset_cant_finalizetest_set_input_offset_cant_finalize_xoftest_grouped_hashtest_keyed_hash_xoftest_derive_key//! Low-level tree manipulations and other sharp tools//! The target audience for this module is projects like [Bao](https://github.com/oconnor663/bao),//! which work directly with the interior hashes ("chaining values") of BLAKE3 chunks and subtrees.//! For example, you could use these functions to implement a BitTorrent-like protocol using the//! BLAKE3 tree structure, or to hash an input that's distributed across different machines. These//! use cases are advanced, and most applications don't need this module. Also://! <div class="warning">//! **Warning:** This module is *hazardous material*. If you've heard folks say *don't roll your//! own crypto,* this is the sort of thing they're talking about. These functions have complicated//! requirements, and any mistakes will give you garbage output and/or break the security//! properties that BLAKE3 is supposed to have. Read section 2.1 of [the BLAKE3//! paper](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf) to understand the//! tree structure you need to maintain. Test your code against [`blake3::hash`](../fn.hash.html)//! and make sure you can get the same outputs for [lots of different//! inputs](https://github.com/BLAKE3-team/BLAKE3/blob/master/test_vectors/test_vectors.json).//! </div>//! On the other hand://! **Encouragement:** Playing with these functions is a great way to learn how BLAKE3 works on the//! inside. Have fun!//! The main entrypoint for this module is the [`HasherExt`] trait, particularly the//! [`set_input_offset`](HasherExt::set_input_offset) and//! [`finalize_non_root`](HasherExt::finalize_non_root) methods. These let you compute the chaining//! values of individual chunks or subtrees. You then combine these chaining values into larger//! subtrees using [`merge_subtrees_non_root`] and finally (once at the very top)//! [`merge_subtrees_root`] or [`merge_subtrees_root_xof`].//! Here's an example of computing all the interior hashes in a 3-chunk tree://!            root//!          /      \//!      parent      \//!    /       \      \//! chunk0  chunk1  chunk2//! use blake3::{Hasher, CHUNK_LEN};//! use blake3::hazmat::{merge_subtrees_non_root, merge_subtrees_root, Mode};//! use blake3::hazmat::HasherExt; // an extension trait for Hasher//! let chunk0 = [b'a'; CHUNK_LEN];//! let chunk1 = [b'b'; CHUNK_LEN];//! let chunk2 = [b'c'; 42]; // The final chunk can be short.//! // Compute the non-root hashes ("chaining values") of all three chunks. Chunks or subtrees//! // that don't begin at the start of the input use `set_input_offset` to say where they begin.//! let chunk0_cv = Hasher::new()//!     // .set_input_offset(0) is the default.//!     .update(&chunk0)//!     .finalize_non_root();//! let chunk1_cv = Hasher::new()//!     .set_input_offset(CHUNK_LEN as u64)//!     .update(&chunk1)//! let chunk2_cv = Hasher::new()//!     .set_input_offset(2 * CHUNK_LEN as u64)//!     .update(&chunk2)//! // Join the first two chunks with a non-root parent node and compute its chaining value.//! let parent_cv = merge_subtrees_non_root(&chunk0_cv, &chunk1_cv, Mode::Hash);//! // Join that parent node and the third chunk with a root parent node and compute the hash.//! let root_hash = merge_subtrees_root(&parent_cv, &chunk2_cv, Mode::Hash);//! // Double check that we got the right answer.//! let mut combined_input = Vec::new();//! combined_input.extend_from_slice(&chunk0);//! combined_input.extend_from_slice(&chunk1);//! combined_input.extend_from_slice(&chunk2);//! assert_eq!(root_hash, blake3::hash(&combined_input));//! Hashing many chunks together is important for performance, because it allows the implementation//! to use SIMD parallelism internally. ([AVX-512](https://en.wikipedia.org/wiki/AVX-512) for//! example needs 16 chunks to really get going.) We can reproduce `parent_cv` by hashing `chunk0`//! and `chunk1` at the same time://! # use blake3::{Hasher, CHUNK_LEN};//! # use blake3::hazmat::{Mode, HasherExt, merge_subtrees_non_root, merge_subtrees_root};//! # let chunk0 = [b'a'; CHUNK_LEN];//! # let chunk1 = [b'b'; CHUNK_LEN];//! # let chunk0_cv = Hasher::new().update(&chunk0).finalize_non_root();//! # let chunk1_cv = Hasher::new().set_input_offset(CHUNK_LEN as u64).update(&chunk1).finalize_non_root();//! # let parent_cv = merge_subtrees_non_root(&chunk0_cv, &chunk1_cv, Mode::Hash);//! # let mut combined_input = Vec::new();//! # combined_input.extend_from_slice(&chunk0);//! # combined_input.extend_from_slice(&chunk1);//! let left_subtree_cv = Hasher::new()//!     .update(&combined_input[..2 * CHUNK_LEN])//! assert_eq!(left_subtree_cv, parent_cv);//! // Using multiple updates gives the same answer, though it's not as efficient.//! let mut subtree_hasher = Hasher::new();//! // Again, .set_input_offset(0) is the default.//! subtree_hasher.update(&chunk0);//! subtree_hasher.update(&chunk1);//! assert_eq!(left_subtree_cv, subtree_hasher.finalize_non_root());//! However, hashing multiple chunks together **must** respect the overall tree structure. Hashing//! `chunk0` and `chunk1` together is valid, but hashing `chunk1` and `chunk2` together is//! incorrect and gives a garbage result that will never match a standard BLAKE3 hash. The//! implementation includes a few best-effort asserts to catch some of these mistakes, but these//! checks aren't guaranteed. For example, this second call to `update` currently panics://! ```should_panic//! # use blake3::hazmat::HasherExt;//! # let chunk2 = [b'c'; 42];//! let oops = Hasher::new()//!     // PANIC: "the subtree starting at 1024 contains at most 1024 bytes"//! For more on valid tree structures, see the docs for and [`left_subtree_len`] and//! [`max_subtree_len`], and see section 2.1 of [the BLAKE3//! paper](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf). Note that the//! merging functions ([`merge_subtrees_root`] and friends) don't know the shape of the left and//! right subtrees you're giving them, and they can't help you catch mistakes. The best way to//! catch mistakes with these is to compare your root output to the [`blake3::hash`](crate::hash)//! of the same input.copy_wide//! Helper functions for efficient IO.RARBjoinJoin/// The trait that abstracts over single-threaded and multi-threaded recursion./// See the [`join` module docs](index.html) for more details.SerialJoin/// The trivial, serial implementation of `Join`. The left and right sides are/// executed one after the other, on the calling thread. The standalone hashing/// functions and the `Hasher::update` method use this implementation/// internally.test_serial_join//! The multi-threading abstractions used by `Hasher::update_with_join`.//! Different implementations of the `Join` trait determine whether//! `Hasher::update_with_join` performs multi-threading on sufficiently large//! inputs. The `SerialJoin` implementation is single-threaded, and the//! `RayonJoin` implementation (gated by the `rayon` feature) is multi-threaded.//! Interfaces other than `Hasher::update_with_join`, like [`hash`](crate::hash)//! and [`Hasher::update`](crate::Hasher::update), always use `SerialJoin`//! internally.//! The `Join` trait is an almost exact copy of the [`rayon::join`] API, and//! `RayonJoin` is the only non-trivial implementation. Previously this trait//! was public, but currently it's been re-privatized, as it's both 1) of no//! value to most callers and 2) a pretty big implementation detail to commit//! to.//! [`rayon::join`]: https://docs.rs/rayon/1.3.0/rayon/fn.join.htmlguts/// Undocumented and unstable, for benchmarks only."ffi_neon.rs"neonportableMAX_SIMD_DEGREEMAX_SIMD_DEGREE_OR_2/// The number of bytes in a [`Hash`](struct.Hash.html), 32./// The number of bytes in a key, 32./// The number of bytes in a block, 64./// You don't usually need to think about this number. One case where it matters is calling/// [`OutputReader::fill`] in a loop, where using a `buf` argument that's a multiple of `BLOCK_LEN`/// avoids repeating work./// The number of bytes in a chunk, 1024./// You don't usually need to think about this number, but it often comes up in benchmarks, because/// the maximum degree of parallelism used by the implementation equals the number of chunks.MAX_DEPTH// While iterating the compression function within a chunk, the CV is// represented as words, to avoid doing two extra endianness conversions for// each compression in the portable implementation. But the hash_many interface// needs to hash both input bytes and parent nodes, so its better for its// output CVs to be represented as bytes.CVBytesMSG_SCHEDULECHUNK_START// These are the internal flags that we use to domain separate root/non-root,// chunk/parent, and chunk beginning/middle/end. These get set at the high end// of the block flags word in the compression function, so their values start// high and go down.CHUNK_ENDPARENTROOTKEYED_HASHDERIVE_KEY_CONTEXTDERIVE_KEY_MATERIALcounter_lowcounter_high/// An output of the default size, 32 bytes, which provides constant-time/// equality checking./// `Hash` implements [`From`] and [`Into`] for `[u8; 32]`, and it provides/// [`from_bytes`] and [`as_bytes`] for explicit conversions between itself and/// `[u8; 32]`. However, byte arrays and slices don't provide constant-time/// equality checking, which is often a security requirement in software that/// handles private data. `Hash` doesn't implement [`Deref`] or [`AsRef`], to/// avoid situations where a type conversion happens implicitly and the/// constant-time property is accidentally lost./// `Hash` provides the [`to_hex`] and [`from_hex`] methods for converting to/// and from hexadecimal. It also implements [`Display`] and [`FromStr`]./// [`From`]: https://doc.rust-lang.org/std/convert/trait.From.html/// [`Into`]: https://doc.rust-lang.org/std/convert/trait.Into.html/// [`as_bytes`]: #method.as_bytes/// [`from_bytes`]: #method.from_bytes/// [`Deref`]: https://doc.rust-lang.org/stable/std/ops/trait.Deref.html/// [`AsRef`]: https://doc.rust-lang.org/std/convert/trait.AsRef.html/// [`to_hex`]: #method.to_hex/// [`from_hex`]: #method.from_hex/// [`Display`]: https://doc.rust-lang.org/std/fmt/trait.Display.html/// [`FromStr`]: https://doc.rust-lang.org/std/str/trait.FromStr.htmlas_bytes/// The raw bytes of the `Hash`. Note that byte arrays don't provide/// constant-time equality checking, so if  you need to compare hashes,/// prefer the `Hash` type.from_bytes/// Create a `Hash` from its raw bytes representation.TryFromSliceError/// Create a `Hash` from its raw bytes representation as a slice./// Returns an error if the slice is not exactly 32 bytes long.*/// Encode a `Hash` in lowercase hexadecimal./// The returned [`ArrayString`] is a fixed size and doesn't allocate memory/// on the heap. Note that [`ArrayString`] doesn't provide constant-time/// equality checking, so if you need to compare hashes, prefer the `Hash`/// type./// [`ArrayString`]: https://docs.rs/arrayvec/0.5.1/arrayvec/struct.ArrayString.htmlfrom_hexHexError/// Decode a `Hash` from hexadecimal. Both uppercase and lowercase ASCII/// bytes are supported./// Any byte outside the ranges `'0'...'9'`, `'a'...'f'`, and `'A'...'F'`/// results in an error. An input length other than 64 also results in an/// Note that `Hash` also implements `FromStr`, so `Hash::from_hex("...")`/// is equivalent to `"...".parse()`./// This implementation is constant-time./// This implementation is constant-time if the target is 32 bytes long.HexErrorInner/// The error type for [`Hash::from_hex`]./// The `.to_string()` representation of this error currently distinguishes between bad length/// errors and bad character errors. This is to help with logging and debugging, but it isn't a/// stable API detail, and it may change at any time.InvalidLeninput_chaining_valueblockblock_len// Each chunk or parent node can produce either a 32-byte chaining value or, by// setting the ROOT flag, any number of final output bytes. The Output struct// captures the state just prior to choosing between those two possibilities.chaining_valueroot_hashroot_output_blockcvchunk_counterbuf_lenblocks_compressedfill_bufstart_flag// Try to avoid buffering as much as possible, by compressing directly from// the input slice when full blocks are available.// Don't derive(Debug), because the state may be secret.yeslargest_power_of_two_leq// The largest power of two less than or equal to `n`, used in Hasher::update(). This is similar to// left_subtree_len(n), but note that left_subtree_len(n) is strictly less than `n`.compress_chunks_parallel// Use SIMD parallelism to hash up to MAX_SIMD_DEGREE chunks at the same time// on a single thread. Write out the chunk chaining values and return the// number of chunks hashed. These chunks are never the root and never empty;// those cases use a different codepath.compress_parents_parallel// Use SIMD parallelism to hash up to MAX_SIMD_DEGREE parents at the same time// on a single thread. Write out the parent chaining values and return the// number of parents hashed. (If there's an odd input chaining value left over,// return it as an additional output.) These parents are never the root and// never empty; those cases use a different codepath.compress_subtree_wide// The wide helper function returns (writes out) an array of chaining values// and returns the length of that array. The number of chaining values returned// is the dynamically detected SIMD degree, at most MAX_SIMD_DEGREE. Or fewer,// if the input is shorter than that many chunks. The reason for maintaining a// wide array of chaining values going back up the tree, is to allow the// implementation to hash as many parents in parallel as possible.// As a special case when the SIMD degree is 1, this function will still return// at least 2 outputs. This guarantees that this function doesn't perform the// root compression. (If it did, it would use the wrong flags, and also we// wouldn't be able to implement extendable output.) Note that this function is// not used when the whole input is only 1 chunk long; that's a different// codepath.// Why not just have the caller split the input on the first update(), instead// of implementing this special rule? Because we don't want to limit SIMD or// multithreading parallelism for that update().compress_subtree_to_parent_node// Hash a subtree with compress_subtree_wide(), and then condense the resulting// list of chaining values down to a single parent node. Don't compress that// last parent node, however. Instead, return its message bytes (the// concatenated chaining values of its children). This is necessary when the// first call to update() supplies a complete subtree, because the topmost// parent node of that subtree could end up being the root. It's also necessary// for extended output in the general case.// As with compress_subtree_wide(), this function is not used on inputs of 1// chunk or less. That's a different codepath.hash_all_at_once// Hash a complete input all at once. Unlike compress_subtree_wide() and// compress_subtree_to_parent_node(), this function handles the 1 chunk case./// The default hash function./// For an incremental version that accepts multiple writes, see [`Hasher::new`],/// [`Hasher::update`], and [`Hasher::finalize`]. These two lines are equivalent:/// let hash = blake3::hash(b"foo");/// # let hash1 = hash;/// let hash = blake3::Hasher::new().update(b"foo").finalize();/// # let hash2 = hash;/// # assert_eq!(hash1, hash2);/// For output sizes other than 32 bytes, see [`Hasher::finalize_xof`] and/// [`OutputReader`]./// This function is always single-threaded. For multithreading support, see/// [`Hasher::update_rayon`](struct.Hasher.html#method.update_rayon).keyed_hash/// The keyed hash function./// This is suitable for use as a message authentication code, for example to/// replace an HMAC instance. In that use case, the constant-time equality/// checking provided by [`Hash`](struct.Hash.html) is almost always a security/// requirement, and callers need to be careful not to compare MACs as raw/// For an incremental version that accepts multiple writes, see [`Hasher::new_keyed`],/// # const KEY: &[u8; 32] = &[0; 32];/// let mac = blake3::keyed_hash(KEY, b"foo");/// # let mac1 = mac;/// let mac = blake3::Hasher::new_keyed(KEY).update(b"foo").finalize();/// # let mac2 = mac;/// # assert_eq!(mac1, mac2);/// For output sizes other than 32 bytes, see [`Hasher::finalize_xof`], and [`OutputReader`].derive_key/// The key derivation function./// Given cryptographic key material of any length and a context string of any/// length, this function outputs a 32-byte derived subkey. **The context string/// should be hardcoded, globally unique, and application-specific.** A good/// default format for such strings is `"[application] [commit timestamp]/// [purpose]"`, e.g., `"example.com 2019-12-25 16:18:03 session tokens v1"`./// Key derivation is important when you want to use the same key in multiple/// algorithms or use cases. Using the same key with different cryptographic/// algorithms is generally forbidden, and deriving a separate subkey for each/// use case protects you from bad interactions. Derived keys also mitigate the/// damage from one part of your application accidentally leaking its key./// As a rare exception to that general rule, however, it is possible to use/// `derive_key` itself with key material that you are already using with/// another algorithm. You might need to do this if you're adding features to/// an existing application, which does not yet use key derivation internally./// However, you still must not share key material with algorithms that forbid/// key reuse entirely, like a one-time pad. For more on this, see sections 6.2/// and 7.8 of the [BLAKE3 paper](https://github.com/BLAKE3-team/BLAKE3-specs/blob/master/blake3.pdf)./// Note that BLAKE3 is not a password hash, and **`derive_key` should never be/// used with passwords.** Instead, use a dedicated password hash like/// [Argon2]. Password hashes are entirely different from generic hash/// functions, with opposite design requirements./// For an incremental version that accepts multiple writes, see [`Hasher::new_derive_key`],/// [`Hasher::update`], and [`Hasher::finalize`]. These two statements are equivalent:/// # const CONTEXT: &str = "example.com 2019-12-25 16:18:03 session tokens v1";/// let key = blake3::derive_key(CONTEXT, b"key material, not a password");/// # let key1 = key;/// let key: [u8; 32] = blake3::Hasher::new_derive_key(CONTEXT)///     .update(b"key material, not a password")///     .finalize()///     .into();/// # let key2 = key;/// # assert_eq!(key1, key2);/// [Argon2]: https://en.wikipedia.org/wiki/Argon2parent_node_outputchunk_stateinitial_chunk_countercv_stack+// The stack size is MAX_DEPTH + 1 because we do lazy merging. For example,// with 7 chunks, we have 3 entries in the stack. Adding an 8th chunk// requires a 4th entry, rather than merging everything down to 1, because// we don't know whether more input is coming. This is different from how// the reference implementation does things./// An incremental hash state that can accept any number of writes./// The `rayon` and `mmap` Cargo features enable additional methods on this/// type related to multithreading and memory-mapped IO./// When the `traits-preview` Cargo feature is enabled, this type implements/// several commonly used traits from the/// [`digest`](https://crates.io/crates/digest) crate. However, those/// traits aren't stable, and they're expected to change in incompatible ways/// before that crate reaches 1.0. For that reason, this crate makes no SemVer/// guarantees for this feature, and callers who use it should expect breaking/// changes between patch versions./// # fn main() -> Result<(), Box<dyn std::error::Error>> {/// // Hash an input incrementally./// let mut hasher = blake3::Hasher::new();/// hasher.update(b"foo");/// hasher.update(b"baz");/// assert_eq!(hasher.finalize(), blake3::hash(b"foobarbaz"));/// // Extended output. OutputReader also implements Read and Seek./// let mut output = [0; 1000];/// let mut output_reader = hasher.finalize_xof();/// output_reader.fill(&mut output);/// assert_eq!(&output[..32], blake3::hash(b"foobarbaz").as_bytes());/// # Ok(())new_internal/// Construct a new `Hasher` for the regular hash function.new_keyed/// Construct a new `Hasher` for the keyed hash function. See/// [`keyed_hash`]./// [`keyed_hash`]: fn.keyed_hash.htmlnew_derive_key/// Construct a new `Hasher` for the key derivation function. See/// [`derive_key`]. The context string should be hardcoded, globally/// unique, and application-specific./// [`derive_key`]: fn.derive_key.html/// Reset the `Hasher` to its initial state./// This is functionally the same as overwriting the `Hasher` with a new/// one, using the same key or context string if any.merge_cv_stack// As described in push_cv() below, we do "lazy merging", delaying merges// until right before the next CV is about to be added. This is different// from the reference implementation. Another difference is that we aren't// always merging 1 chunk at a time. Instead, each CV might represent any// power-of-two number of chunks, as long as the smaller-above-larger stack// order is maintained. Instead of the "count the trailing 0-bits"// algorithm described in the spec (which assumes you're adding one chunk// at a time), we use a "count the total number of 1-bits" variant (which// doesn't assume that). The principle is the same: each CV that should// remain in the stack is represented by a 1-bit in the total number of// chunks (or bytes) so far.push_cv// In reference_impl.rs, we merge the new CV with existing CVs from the// stack before pushing it. We can do that because we know more input is// coming, so we know none of the merges are root.// This setting is different. We want to feed as much input as possible to// compress_subtree_wide(), without setting aside anything for the// chunk_state. If the user gives us 64 KiB, we want to parallelize over// all 64 KiB at once as a single subtree, if at all possible.// This leads to two problems:// 1) This 64 KiB input might be the only call that ever gets made to//    update. In this case, the root node of the 64 KiB subtree would be//    the root node of the whole tree, and it would need to be ROOT//    finalized. We can't compress it until we know.// 2) This 64 KiB input might complete a larger tree, whose root node is//    similarly going to be the root of the whole tree. For example,//    maybe we have 196 KiB (that is, 128 + 64) hashed so far. We can't//    compress the node at the root of the 256 KiB subtree until we know//    how to finalize it.// The second problem is solved with "lazy merging". That is, when we're// about to add a CV to the stack, we don't merge it with anything first,// as the reference impl does. Instead we do merges using the *previous* CV// that was added, which is sitting on top of the stack, and we put the new// CV (unmerged) on top of the stack afterwards. This guarantees that we// never merge the root node until finalize().// Solving the first problem requires an additional tool,// compress_subtree_to_parent_node(). That function always returns the top// *two* chaining values of the subtree it's compressing. We then do lazy// merging with each of them separately, so that the second CV will always// remain unmerged. (That also helps us support extendable output when// we're hashing an input all-at-once.)/// Add input bytes to the hash state. You can call this any number of times./// This method is always single-threaded. For multithreading support, see/// [`update_rayon`](#method.update_rayon) (enabled with the `rayon` Cargo feature)./// Note that the degree of SIMD parallelism that `update` can use is limited by the size of/// this input buffer. See [`update_reader`](#method.update_reader).update_with_joinfinal_output/// Finalize the hash state and return the [`Hash`](struct.Hash.html) of/// the input./// This method is idempotent. Calling it twice will give the same result./// You can also add more input and finalize again.finalize_xof/// Finalize the hash state and return an [`OutputReader`], which can/// supply any number of output bytes./// [`OutputReader`]: struct.OutputReader.html/// Return the total number of bytes hashed so far./// [`hazmat::HasherExt::set_input_offset`] does not affect this value. This only counts bytes/// passed to [`update`](Hasher::update).update_reader/// As [`update`](Hasher::update), but reading from a/// [`std::io::Read`](https://doc.rust-lang.org/std/io/trait.Read.html) implementation./// [`Hasher`] implements/// [`std::io::Write`](https://doc.rust-lang.org/std/io/trait.Write.html), so it's possible to/// use [`std::io::copy`](https://doc.rust-lang.org/std/io/fn.copy.html) to update a [`Hasher`]/// from any reader. Unfortunately, this standard approach can limit performance, because/// `copy` currently uses an internal 8 KiB buffer that isn't big enough to take advantage of/// all SIMD instruction sets. (In particular, [AVX-512](https://en.wikipedia.org/wiki/AVX-512)/// needs a 16 KiB buffer.) `update_reader` avoids this performance problem and is slightly/// more convenient./// The internal buffer size this method uses may change at any time, and it may be different/// for different targets. The only guarantee is that it will be large enough for all of this/// crate's SIMD implementations on the current platform./// The most common implementer of/// [`std::io::Read`](https://doc.rust-lang.org/std/io/trait.Read.html) might be/// [`std::fs::File`](https://doc.rust-lang.org/std/fs/struct.File.html), but note that memory/// mapping can be faster than this method for hashing large files. See/// [`update_mmap`](Hasher::update_mmap) and [`update_mmap_rayon`](Hasher::update_mmap_rayon),/// which require the `mmap` and (for the latter) `rayon` Cargo features./// This method requires the `std` Cargo feature, which is enabled by default./// # use std::fs::File;/// # use std::io;/// # fn main() -> io::Result<()> {/// // Hash standard input./// hasher.update_reader(std::io::stdin().lock())?;/// println!("{}", hasher.finalize());/// This is equivalent to [`update`](#method.update).position_within_block/// An incremental reader for extended output, returned by/// [`Hasher::finalize_xof`](struct.Hasher.html#method.finalize_xof)./// Shorter BLAKE3 outputs are prefixes of longer ones, and explicitly requesting a short output is/// equivalent to truncating the default-length output. Note that this is a difference between/// BLAKE2 and BLAKE3./// # Security notes/// Outputs shorter than the default length of 32 bytes (256 bits) provide less security. An N-bit/// BLAKE3 output is intended to provide N bits of first and second preimage resistance and N/2/// bits of collision resistance, for any N up to 256. Longer outputs don't provide any additional/// security./// Avoid relying on the secrecy of the output offset, that is, the number of output bytes read or/// the arguments to [`seek`](struct.OutputReader.html#method.seek) or/// [`set_position`](struct.OutputReader.html#method.set_position). [_Block-Cipher-Based Tree/// Hashing_ by Aldo Gunsing](https://eprint.iacr.org/2022/283) shows that an attacker who knows/// both the message and the key (if any) can easily determine the offset of an extended output./// For comparison, AES-CTR has a similar property: if you know the key, you can decrypt a block/// from an unknown position in the output stream to recover its block index. Callers with strong/// secret keys aren't affected in practice, but secret offsets are a [design/// smell](https://en.wikipedia.org/wiki/Design_smell) in any case.fill_one_block// This helper function handles both the case where the output buffer is// shorter than one block, and the case where our position_within_block is// non-zero./// Fill a buffer with output bytes and advance the position of the/// `OutputReader`. This is equivalent to [`Read::read`], except that it/// doesn't return a `Result`. Both methods always fill the entire buffer./// Note that `OutputReader` doesn't buffer output bytes internally, so/// calling `fill` repeatedly with a short-length or odd-length slice will/// end up performing the same compression multiple times. If you're/// reading output in a loop, prefer a slice length that's a multiple of/// [`BLOCK_LEN`] (64 bytes)./// The maximum output size of BLAKE3 is 2<sup>64</sup>-1 bytes. If you try/// to extract more than that, for example by seeking near the end and/// reading further, the behavior is unspecified./// [`Read::read`]: #method.read/// Return the current read position in the output stream. This is/// equivalent to [`Seek::stream_position`], except that it doesn't return/// a `Result`. The position of a new `OutputReader` starts at 0, and each/// call to [`fill`] or [`Read::read`] moves the position forward by the/// number of bytes read./// [`Seek::stream_position`]: #method.stream_position/// [`fill`]: #method.fill/// Seek to a new read position in the output stream. This is equivalent to/// calling [`Seek::seek`] with [`SeekFrom::Start`], except that it doesn't/// return a `Result`./// [`Seek::seek`]: #method.seek/// [`SeekFrom::Start`]: https://doc.rust-lang.org/std/io/enum.SeekFrom.htmlseekSeekFromSeek//! The official Rust implementation of the [BLAKE3] cryptographic hash//! function.//! // Hash an input all at once.//! let hash1 = blake3::hash(b"foobarbaz");//! // Hash an input incrementally.//! let mut hasher = blake3::Hasher::new();//! hasher.update(b"foo");//! hasher.update(b"bar");//! hasher.update(b"baz");//! let hash2 = hasher.finalize();//! assert_eq!(hash1, hash2);//! // Extended output. OutputReader also implements Read and Seek.//! # #[cfg(feature = "std")] {//! let mut output = [0; 1000];//! let mut output_reader = hasher.finalize_xof();//! output_reader.fill(&mut output);//! assert_eq!(hash1, output[..32]);//! // Print a hash as hex.//! println!("{}", hash1);//! # Cargo Features//! The `std` feature (the only feature enabled by default) is required for//! implementations of the [`Write`] and [`Seek`] traits, the//! [`update_reader`](Hasher::update_reader) helper method, and runtime CPU//! feature detection on x86. If this feature is disabled, the only way to use//! the x86 SIMD implementations is to enable the corresponding instruction sets//! globally, with e.g. `RUSTFLAGS="-C target-cpu=native"`. The resulting binary//! will not be portable to other machines.//! The `rayon` feature (disabled by default, but enabled for [docs.rs]) adds//! the [`update_rayon`](Hasher::update_rayon) and (in combination with `mmap`//! below) [`update_mmap_rayon`](Hasher::update_mmap_rayon) methods, for//! multithreaded hashing. However, even if this feature is enabled, all other//! APIs remain single-threaded.//! The `mmap` feature (disabled by default, but enabled for [docs.rs]) adds the//! [`update_mmap`](Hasher::update_mmap) and (in combination with `rayon` above)//! [`update_mmap_rayon`](Hasher::update_mmap_rayon) helper methods for//! memory-mapped IO.//! The `zeroize` feature (disabled by default, but enabled for [docs.rs])//! implements//! [`Zeroize`](https://docs.rs/zeroize/latest/zeroize/trait.Zeroize.html) for//! this crate's types.//! The `serde` feature (disabled by default, but enabled for [docs.rs]) implements//! [`serde::Serialize`](https://docs.rs/serde/latest/serde/trait.Serialize.html) and//! [`serde::Deserialize`](https://docs.rs/serde/latest/serde/trait.Deserialize.html)//! for [`Hash`](struct@Hash).//! The NEON implementation is enabled by default for AArch64 but requires the//! `neon` feature for other ARM targets. Not all ARMv7 CPUs support NEON, and//! enabling this feature will produce a binary that's not portable to CPUs//! without NEON support.//! The `wasm32_simd` feature enables the WASM SIMD implementation for all `wasm32-`//! targets. Similar to the `neon` feature, if `wasm32_simd` is enabled, WASM SIMD//! support is assumed. This may become the default in the future.//! The `traits-preview` feature enables implementations of traits from the//! RustCrypto [`digest`] crate, and re-exports that crate as `traits::digest`.//! However, the traits aren't stable, and they're expected to change in//! incompatible ways before that crate reaches 1.0. For that reason, this crate//! makes no SemVer guarantees for this feature, and callers who use it should//! expect breaking changes between patch versions. (The "-preview" feature name//! follows the conventions of the RustCrypto [`signature`] crate.)//! [`Hasher::update_rayon`]: struct.Hasher.html#method.update_rayon//! [BLAKE3]: https://blake3.io//! [Rayon]: https://github.com/rayon-rs/rayon//! [docs.rs]: https://docs.rs///! [`Write`]: https://doc.rust-lang.org/std/io/trait.Write.html//! [`Seek`]: https://doc.rust-lang.org/std/io/trait.Seek.html//! [`digest`]: https://crates.io/crates/digest//! [`signature`]: https://crates.io/crates/signature// 2^54 * CHUNK_LEN = 2^64// little-endian// IMPLEMENTATION NOTE// ===================// The recursive function compress_subtree_wide(), implemented below, is the// basis of high-performance BLAKE3. We use it both for all-at-once hashing,// and for the incremental input with Hasher (though we have to be careful with// subtree boundaries in the incremental case). compress_subtree_wide() applies// several optimizations at the same time:// - Multithreading with Rayon.// - Parallel chunk hashing with SIMD.// - Parallel parent hashing with SIMD. Note that while SIMD chunk hashing//   maxes out at MAX_SIMD_DEGREE*CHUNK_LEN, parallel parent hashing continues//   to benefit from larger inputs, because more levels of the tree benefit can//   use full-width SIMD vectors for parent hashing. Without parallel parent//   hashing, we lose about 10% of overall throughput on AVX2 and AVX-512.// There are some places where we want a static size that's equal to the// MAX_SIMD_DEGREE, but also at least 2. Constant contexts aren't currently// allowed to use cmp::max, so we have to hardcode this additional constant// value. Get rid of this once cmp::max is a const fn.PortableNEONdetectsimd_degree// hash_many() applies two optimizations. The critically important// optimization is the high-performance parallel SIMD hashing mode,// described in detail in the spec. This more than doubles throughput per// thread. Another optimization is keeping the state vectors transposed// from block to block within a chunk. When state vectors are transposed// after every block, there's a small but measurable performance loss.// Compressing chunks with a dedicated loop avoids this.// Explicit platform constructors, for benchmarks.words_from_le_bytes_32words_from_le_bytes_64le_bytes_from_words_32le_bytes_from_words_64groundcompress_prehash1// This is basically testing the portable implementation against itself,// but it also checks that compress_in_place and compress_xof are// consistent. And there are tests against the reference implementation and// against hardcoded test vectors elsewhere.// Ditto.DEGREEloadu__m256istoreuset1set8rot16rot12rot8rot7interleave128transpose_vecs// There are several ways to do a transposition. We could do it naively, with 8 separate// _mm256_set_epi32 instructions, referencing each of the 32 words explicitly. Or we could copy// the vecs into contiguous storage and then use gather instructions. This third approach is to use// a series of unpack instructions to interleave the vectors. In my benchmarks, interleaving is the// fastest approach. To test this, run `cargo +nightly bench --bench libtest load_8` in the// https://github.com/oconnor663/bao_experiments repo.transpose_msg_vecsload_countershash8test_transpose// These rotations are the "simple/shifts version". For the// "complicated/shuffles version", see// https://github.com/sneves/blake2-avx2/blob/b3723921f668df09ece52dcd225a36d4a4eea1d9/blake2s-common.h#L63-L66.// For a discussion of the tradeoffs, see// https://github.com/sneves/blake2-avx2/pull/5. Due to an LLVM bug// (https://bugs.llvm.org/show_bug.cgi?id=44379), this version performs better// on recent x86 chips.set4_MM_SHUFFLE// Adapted from https://github.com/rust-lang-nursery/stdsimd/pull/479.shuffle2diagonalize// Note the optimization here of leaving row1 as the unrotated row, rather than// row0. All the message loads below are adjusted to compensate for this. See// discussion at https://github.com/sneves/blake2-avx2/pull/4undiagonalizeblend_epi16hash4TEST_CASES// Interesting input lengths to run tests on.TEST_CASES_MAXTEST_KEY// There's a test to make sure these two are equal below.TEST_KEY_WORDSpaint_test_input// Paint the input with a repeating byte pattern. We use a cycle length of 251,// because that's the largest prime number less than 256. This makes it// unlikely to swapping any two adjacent input blocks or chunks will give the// same answer.CompressInPlaceFnCompressXofFntest_compress_fn// A shared helper function for platform-specific tests.HashManyFntest_hash_many_fnXofManyFunctiontest_xof_many_fntest_key_bytes_equal_key_wordstest_reference_impl_sizetest_counter_wordstest_largest_power_of_two_leqtest_compare_reference_impltest_compare_reference_impl_long_xoftest_xof_partial_blocksreference_hashtest_compare_update_multipletest_fuzz_hashertest_fuzz_xoftest_xof_seektest_msg_schedule_permutationtest_resettest_hex_encoding_decodingtest_issue_206_windows_sse2// This test is a mimized failure case for the Windows SSE2 bug described in// https://github.com/BLAKE3-team/BLAKE3/issues/206.// Before that issue was fixed, this test would fail on Windows in the following configuration://     cargo test --features=no_avx512,no_avx2,no_sse41 --release// Bugs like this one (stomping on a caller's register) are very sensitive to the details of// surrounding code, so it's not especially likely that this test will catch another bug (or even// the same bug) in the future. Still, there's no harm in keeping it.test_hash_conversionstest_hash_const_conversionstest_update_readertest_update_reader_interruptedtest_miri_smoketest// `cargo +nightly miri test` currently works, but it takes forever, because some of our test// inputs are quite large. Most of our unsafe code is platform specific and incompatible with Miri// anyway, but we'd like it to be possible for callers to run their own tests under Miri, assuming// they don't use incompatible features like Rayon or mmap. This test should get reasonable// coverage of our public API without using any large inputs, so we can run it in CI and catch// obvious breaks. (For example, constant_time_eq is not compatible with Miri.)test_chunktest_parentsguts_tests// I had to move these tests out of the deprecated guts module, because leaving them there causes// an un-silenceable warning: https://github.com/rust-lang/rust/issues/47238HashMarkerResetfinalize_intoFixedOutputfinalize_into_resetFixedOutputResetReaderfinalize_xof_resetExtendableOutputResetXofReaderKeySizeUserBlockSizeUserMacMarkerKeyInittest_digest_traitstest_mac_traitexpected_hmac_blake3test_hmac_compatibility//! Implementations of commonly used traits like `Digest` and `Mac` from the//! [`digest`](https://crates.io/crates/digest) crate.wasm32v128// It could be a function, but artimetics in const generics is too limited yet.unpacklo_epi64unpackhi_epi64unpacklo_epi32unpackhi_epi32I3I2I1I0shuffle_epi32/*
 * This code is based on rust_sse2.rs of the same distribution, and is subject to further improvements.
 * Some comments are left intact even if their applicability is questioned.
 *
 * Performance measurements with a primitive benchmark with ~16Kb of data:
 *
 * | M1 native     | 11,610 ns |
 * | M1 Wasm SIMD  | 13,355 ns |
 * | M1 Wasm       | 22,037 ns |
 * | x64 native    |  6,713 ns |
 * | x64 Wasm SIMD | 11,985 ns |
 * | x64 Wasm      | 25,978 ns |
 *
 * wasmtime v12.0.1 was used on both platforms.
 */IsLessLeNonZerosealed/// Block on which `BlockBuffer` operates.BufferKind/// Trait for buffer kinds.Eager/// Eager block buffer kind, which guarantees that buffer position/// always lies in the range of `0..BlockSize`.Lazy/// Lazy block buffer kind, which guarantees that buffer position/// always lies in the range of `0..=BlockSize`.EagerBufferBlockBuffer/// Eager block buffer.LazyBuffer/// Lazy block buffer./// Block buffer error._pdKind/// Buffer for block processing of data./// Create new buffer from slice./// If slice length is not valid for used buffer kind.try_new/// Returns an error if slice length is not valid for used buffer kind.digest_blocks/// Digest data in `input` in blocks of size `BlockSize` using/// the `compress` function, which accepts slice of blocks./// Reset buffer by setting cursor position to zero.pad_with_zeros/// Pad remaining data with zeros and return resulting block.get_pos/// Return current cursor position.get_data/// Return slice of data stored inside the buffer./// Set buffer content and cursor position./// If `pos` is bigger or equal to block size./// Return size of the internal buffer in bytes./// Return number of remaining bytes in the internal buffer.set_pos_uncheckedset_data/// Set `data` to generated blocks.digest_pad/// Compress remaining data after padding it with `delim`, zeros and/// the `suffix` bytes. If there is not enough unused space, `compress`/// will be called twice./// If suffix length is bigger than block size.len64_padding_be/// Pad message with 0x80, zeros and 64-bit message length using/// big-endian byte order.len64_padding_le/// little-endian byte order.len128_padding_be/// Pad message with 0x80, zeros and 128-bit message length usingto_blocks_mut/// Split message into mutable slice of parallel blocks, blocks, and leftover bytes.//! Fixed size buffer for block processing of data.invariant/// Invariant guaranteed by a buffer kind, i.e. with correct/// buffer code this function always returns true.split_blocks/// Split input data into slice of blocks and tail./// Sealed trait for buffer kinds.PaddingPadError/// Buffer for block processing of datainput_block/// Process data in `input` in blocks of size `BlockSize` using function `f`.input_blocks/// Process data in `input` in blocks of size `BlockSize` using function `f`, which accepts/// slice of blocks.input_lazy/// Variant that doesn't flush the buffer until there's additional/// data to be processed. Suitable for tweakable block ciphers/// like Threefish that need to know whether a block is the *last*/// data block before processing it./// Pad buffer with `prefix` and make sure that internall buffer/// has at least `up_to` free bytes. All remaining bytes get/// zeroed-out./// Pad message with 0x80, zeros and 64-bit message length/// using big-endian byte order/// using little-endian byte order/// Pad message with 0x80, zeros and 128-bit message lengthpad_with/// Pad message with a given padding `P`/// Returns `PadError` if internall buffer is full, which can only happen if/// `input_lazy` was used./// Return size of the internall buffer in bytes/// Return current cursor position/// Return number of remaining bytes in the internall buffer/// Reset buffer by setting cursor position to zeroset_zero/// Sets all bytes in `dst` to zero/// Error for indicating failed padding operationUnpadError/// Error for indicating failed unpadding operationpad_block/// Pads `block` filled with data up to `pos`./// `pos` should be inside of the block and block must not be full, i.e./// `pos < block.len()` must be true. Otherwise method will return/// `PadError`. Some potentially irreversible padding schemes can allow/// padding of the full block, in this case aforementioned condition is/// relaxed to `pos <= block.len()`./// Pads message with length `pos` in the provided buffer./// `&buf[..pos]` is perceived as the message, the buffer must contain/// enough leftover space for padding: `block_size - (pos % block_size)`/// extra bytes must be available. Otherwise method will return/// `PadError`.unpad/// Unpad given `data` by truncating it according to the used padding./// In case of the malformed padding will return `UnpadError`/// Trait for padding messages divided into blocksZeroPadding/// Pad block with zeros./// use block_padding::{ZeroPadding, Padding};/// let msg = b"test";/// let n = msg.len();/// let mut buffer = [0xff; 16];/// buffer[..n].copy_from_slice(msg);/// let padded_msg = ZeroPadding::pad(&mut buffer, n, 8).unwrap();/// assert_eq!(padded_msg, b"test\x00\x00\x00\x00");/// assert_eq!(ZeroPadding::unpad(&padded_msg).unwrap(), msg);/// # use block_padding::{ZeroPadding, Padding};/// # let msg = b"test";/// # let n = msg.len();/// # let mut buffer = [0xff; 16];/// # buffer[..n].copy_from_slice(msg);/// let padded_msg = ZeroPadding::pad(&mut buffer, n, 2).unwrap();/// assert_eq!(padded_msg, b"test");/// Note that zero padding may not be reversible if the original message ends/// with one or more zero bytes.Pkcs7/// Pad block with bytes with value equal to the number of bytes added./// PKCS#7 described in the [RFC 5652](https://tools.ietf.org/html/rfc5652#section-6.3)./// use block_padding::{Pkcs7, Padding};/// let mut buffer = [0xff; 8];/// let padded_msg = Pkcs7::pad(&mut buffer, n, 8).unwrap();/// assert_eq!(padded_msg, b"test\x04\x04\x04\x04");/// assert_eq!(Pkcs7::unpad(&padded_msg).unwrap(), msg);/// # use block_padding::{Pkcs7, Padding};/// # let mut buffer = [0xff; 8];/// let padded_msg = Pkcs7::pad(&mut buffer, n, 2).unwrap();/// assert_eq!(padded_msg, b"test\x02\x02");/// let mut buffer = [0xff; 5];/// assert!(Pkcs7::pad(&mut buffer, 4, 2).is_err());/// # let buffer = [0xff; 16];/// assert!(Pkcs7::unpad(&buffer).is_err());/// In addition to conditions stated in the `Padding` trait documentation,/// `pad_block` will return `PadError` if `block.len() > 255`, and in case of/// `pad` if `block_size > 255`.AnsiX923/// Pad block with zeros except the last byte which will be set to the number/// use block_padding::{AnsiX923, Padding};/// let padded_msg = AnsiX923::pad(&mut buffer, n, 8).unwrap();/// assert_eq!(padded_msg, b"test\x00\x00\x00\x04");/// assert_eq!(AnsiX923::unpad(&padded_msg).unwrap(), msg);/// # use block_padding::{AnsiX923, Padding};/// let padded_msg = AnsiX923::pad(&mut buffer, n, 2).unwrap();/// assert_eq!(padded_msg, b"test\x00\x02");/// assert!(AnsiX923::unpad(&buffer).is_err());Iso7816/// Pad block with byte sequence `\x80 00...00 00`./// use block_padding::{Iso7816, Padding};/// let padded_msg = Iso7816::pad(&mut buffer, n, 8).unwrap();/// assert_eq!(padded_msg, b"test\x80\x00\x00\x00");/// assert_eq!(Iso7816::unpad(&padded_msg).unwrap(), msg);/// # use block_padding::{Iso7816, Padding};/// let padded_msg = Iso7816::pad(&mut buffer, n, 2).unwrap();/// assert_eq!(padded_msg, b"test\x80\x00");NoPadding/// Don't pad the data. Useful for key wrapping. Padding will fail if the data cannot be/// fitted into blocks without padding./// use block_padding::{NoPadding, Padding};/// let padded_msg = NoPadding::pad(&mut buffer, n, 4).unwrap();/// assert_eq!(NoPadding::unpad(&padded_msg).unwrap(), msg);/// # use block_padding::{NoPadding, Padding};/// let padded_msg = NoPadding::pad(&mut buffer, n, 2).unwrap();/// Sets all bytes in `dst` equal to `value`//! Padding and unpadding of messages divided into blocks.//! This crate provides `Padding` trait which provides padding and unpadding//! operations. Additionally several common padding schemes are available out//! of the box.cautioustest_cautious_u8BufMutBytesMutBinaryHeapLinkedListhintERROR_NOT_ALL_BYTES_READERROR_UNEXPECTED_LENGTH_OF_INPUTERROR_OVERFLOW_ON_MACHINE_WITH_32_BIT_ISIZEERROR_OVERFLOW_ON_MACHINE_WITH_32_BIT_USIZEERROR_INVALID_ZERO_VALUE/// Deserializes this instance from a given slice of bytes./// Updates the buffer to point at the remaining bytes.try_from_slice/// Deserialize this instance from a slice of bytes.try_from_readervec_from_readerarray_from_reader/// A data-structure that can be de-serialized from binary format by NBOR./// Deserialises given variant of an enum from the reader./// This may be used to perform validation or filtering based on what/// variant is being deserialised./// use borsh::BorshDeserialize;/// use borsh::de::EnumExt as _;/// #[derive(Debug, PartialEq, Eq, BorshDeserialize)]/// enum MyEnum {///     Zero,///     One(u8),///     Many(Vec<u8>)/// #[derive(Debug, PartialEq, Eq)]/// struct OneOrZero(MyEnum);/// impl borsh::de::BorshDeserialize for OneOrZero {///     fn deserialize_reader<R: borsh::maybestd::io::Read>(///         reader: &mut R,///     ) -> borsh::maybestd::io::Result<Self> {///         use borsh::de::EnumExt;///         let tag = u8::deserialize_reader(reader)?;///         if tag == 2 {///             Err(borsh::maybestd::io::Error::new(///                 borsh::maybestd::io::ErrorKind::InvalidInput,///                 "MyEnum::Many not allowed here",///             ))///         } else {///             MyEnum::deserialize_variant(reader, tag).map(Self)/// let data = b"\0";/// assert_eq!(MyEnum::Zero, MyEnum::try_from_slice(&data[..]).unwrap());/// assert_eq!(MyEnum::Zero, OneOrZero::try_from_slice(&data[..]).unwrap().0);/// let data = b"\x02\0\0\0\0";/// assert_eq!(MyEnum::Many(Vec::new()), MyEnum::try_from_slice(&data[..]).unwrap());/// assert!(OneOrZero::try_from_slice(&data[..]).is_err());/// Additional methods offered on enums which uses `[derive(BorshDeserialize)]`.unexpected_eof_to_unexpected_length_of_inputimpl_for_integerimpl_for_nonzero_integerNonZeroI8NonZeroI16NonZeroI32NonZeroI64NonZeroI128NonZeroU8NonZeroU16NonZeroU32NonZeroU128NonZeroUsizeimpl_for_float// Note NaNs have a portability issue. Specifically, signalling NaNs on MIPS are quiet NaNs on x86,// and vice-versa. We disallow NaNs to avoid this issue.netSocketAddrSocketAddrV4SocketAddrV6Ipv4AddrIpv6Addrarray_deserialization_doesnt_leakT0T1T2T3T4T5T6T7T8T9T10T11T12T13T14T15T16T17T18T19schemaBorshSchema//! Generate `BorshSchemaCointainer` for `BorshSchemaContainer` and save it into a file.// TODO: re-enable this lint when we bump msrv to 1.58schema_helperstry_from_slice_with_schematry_to_vec_with_schemahelpersto_vec/// A facade around all the types we need from the `std`, `core`, and `alloc`/// crates. This avoids elaborate import wrangling having to happen in every/// module./// A specialized [`Result`] type for I/O operations./// This type is broadly used across [`std::io`] for any operation which may/// produce an error./// This typedef is generally used to avoid writing out [`io::Error`] directly and/// is otherwise a direct mapping to [`Result`]./// While usual Rust style is to import types directly, aliases of [`Result`]/// often are not, to make it easier to distinguish between them. [`Result`] is/// generally assumed to be [`std::result::Result`][`Result`], and so users of this alias/// will generally use `io::Result` instead of shadowing the [prelude]'s import/// of [`std::result::Result`][`Result`]./// [`std::io`]: crate::io/// [`Result`]: crate::result::Result/// [prelude]: crate::prelude/// A convenience function that bubbles an `io::Result` to its caller:/// fn get_string() -> io::Result<String> {///     let mut buffer = String::new();///     io::stdin().read_line(&mut buffer)?;///     Ok(buffer)// #[allow(deprecated)]/// use std::io::{Error, ErrorKind};/// Returns a reference to the inner error wrapped by this error (if any)./// fn print_error(err: &Error) {///     if let Some(inner_err) = err.get_ref() {///         println!("Inner error: {:?}", inner_err);///     } else {///         println!("No inner error");///     // Will print "No inner error".///     print_error(&Error::last_os_error());///     // Will print "Inner error: ...".///     print_error(&Error::new(ErrorKind::Other, "oh no!"));/// fn print_error(err: Error) {///     if let Some(inner_err) = err.into_inner() {///         println!("Inner error: {}", inner_err);///     print_error(Error::last_os_error());///     print_error(Error::new(ErrorKind::Other, "oh no!"));///     println!("{:?}", err.kind());///     // Will print "Other".///     // Will print "AddrInUse".///     print_error(Error::new(ErrorKind::AddrInUse, "oh no!"));/// `n <= buf.len()`. A return value of `0` typically means that the/// use std::io::prelude::*;/// fn main() -> std::io::Result<()> {///     let mut buffer = File::create("foo.txt")?;///     // Writes some prefix of the byte string, not necessarily all of it.///     buffer.write(b"some bytes")?;/// [`Ok(n)`]: Ok/// use std::io::BufWriter;///     let mut buffer = BufWriter::new(File::create("foo.txt")?);///     buffer.write_all(b"some bytes")?;///     buffer.flush()?;/// If the buffer contains no data, this will never call [`write`]./// [`write`]: Write::writewrite_fmt/// Writes a formatted string into this writer, returning any error/// encountered./// This method is primarily used to interface with the/// [`format_args!()`] macro, but it is rare that this should/// explicitly be called. The [`write!()`] macro should be favored to/// invoke this method instead./// This function internally uses the [`write_all`] method on/// this trait and hence will continuously write data so long as no errors/// are received. This also means that partial writes are not indicated in/// this signature./// [`write_all`]: Write::write_all/// This function will return any I/O error reported while formatting.///     // this call///     write!(buffer, "{:.*}", 2, 1.234567)?;///     // turns into this:///     buffer.write_fmt(format_args!("{:.*}", 2, 1.234567))?;///     let reference = buffer.by_ref();///     // we can use reference just like our original buffer///     reference.write_all(b"some bytes")?;/// A trait for objects which are byte-oriented sinks./// Implementors of the `Write` trait are sometimes called 'writers'./// Writers are defined by two required methods, [`write`] and [`flush`]:/// * The [`write`] method will attempt to write some data into the object,///   returning how many bytes were successfully written./// * The [`flush`] method is useful for adaptors and explicit buffers///   themselves for ensuring that all buffered data has been pushed out to the///   'true sink'./// Writers are intended to be composable with one another. Many implementors/// throughout [`std::io`] take and provide types which implement the `Write`/// [`flush`]: Write::flush/// [`std::io`]: self///     let data = b"some bytes";///     let mut pos = 0;///     while pos < data.len() {///         let bytes_written = buffer.write(&data[pos..])?;///         pos += bytes_written;/// The trait also provides convenience methods like [`write_all`], which calls/// `write` in a loop until its entire input has been written./// Write is implemented for `&mut [u8]` by copying into the slice, overwriting/// its data./// Note that writing updates the slice to point to the yet unwritten part./// The slice will be empty when it has been completely overwritten./// Write is implemented for `Vec<u8>` by appending to the vector./// The vector will grow as needed./// waiting for data, but if an object needs to block for a read and cannot,/// If the return value of this method is [`Ok(n)`], then implementations must/// guarantee that `0 <= n <= buf.len()`. A nonzero `n` value indicates/// source. If `n` is `0`, then it can indicate one of two scenarios:/// 1. This reader has reached its "end of file" and will likely no longer///    be able to produce bytes. Note that this does not mean that the///    reader will *always* no longer be able to produce bytes. As an example,///    on Linux, this method will call the `recv` syscall for a [`TcpStream`],///    where returning zero indicates the connection was shut down correctly. While///    for [`File`], it is possible to reach the end of file and get zero as result,///    but if more data is appended to the file, future calls to `read` will return///    more data./// 2. The buffer specified was 0 bytes in length./// It is not an error if the returned value `n` is smaller than the buffer size,/// even when the reader is not at the end of the stream yet./// This may happen for example because fewer bytes are actually available right now/// (e. g. being close to end-of-file) or because read() was interrupted by a signal./// As this trait is safe to implement, callers cannot rely on `n <= buf.len()` for safety./// Extra care needs to be taken when `unsafe` functions are used to access the read bytes./// Callers have to ensure that no unchecked out-of-bounds accesses are possible even if/// `n > buf.len()`./// contents of `buf` being true. It is recommended that *implementations*/// Correspondingly, however, *callers* of this method must not assume any guarantees/// about how the implementation uses `buf`. The trait is safe to implement,/// so it is possible that the code that's supposed to write to the buffer might also read/// from it. It is your responsibility to make sure that `buf` is initialized/// before calling `read`. Calling `read` with an uninitialized `buf` (of the kind one/// obtains via [`MaybeUninit<T>`]) is not safe, and can lead to undefined behavior./// [`MaybeUninit<T>`]: crate::mem::MaybeUninit/// [`File`]s implement `Read`:/// [`File`]: crate::fs::File/// [`TcpStream`]: crate::net::TcpStream/// fn main() -> io::Result<()> {///     let mut f = File::open("foo.txt")?;///     let n = f.read(&mut buffer[..])?;///     println!("The bytes: {:?}", &buffer[..n]);/// only write data to `buf` instead of reading its contents. The/// documentation on [`read`] has a more detailed explanation on this/// subject./// If this function encounters an "end of file" before completely filling/// the buffer, it returns an error of the kind [`ErrorKind::UnexpectedEof`]./// The contents of `buf` are unspecified in this case./// [`read`]: Read::read///     // read exactly 10 bytes///     f.read_exact(&mut buffer)?;/// The returned adapter also implements `Read` and will simply borrow this///     let mut buffer = Vec::new();///     let mut other_buffer = Vec::new();///     {///         let reference = f.by_ref();///         // read at most 5 bytes///         reference.take(5).read_to_end(&mut buffer)?;///     } // drop our &mut reference so we can use f again///     // original file still usable, read the rest///     f.read_to_end(&mut other_buffer)?;/// throughout [`std::io`] take and provide types which implement the `Read`///     f.read(&mut buffer)?;///     // read the whole file///     f.read_to_end(&mut buffer)?;///     // read into a String, so that you don't need to do the conversion.///     f.read_to_string(&mut buffer)?;///     // and more! See the other methods for more details./// Read from [`&str`] because [`&[u8]`][prim@slice] implements `Read`:///     // etc... it works exactly as a File does!/// [`read()`]: Read::read/// [`&str`]: prim@strdefault_read_exact//! Taken from https://github.com/bbqsrc/bare-io (with adjustments)// Unclear why rust check complains on fields of `Definition` variants.Entry// For `#[derive(BorshSerialize, BorshDeserialize)]`.BorshSchemaMacro/// The type that we use to represent the declaration of the Borsh type.VariantName/// The type that we use for the name of the variant.FieldName/// The name of the field in the struct (can be used to convert JSON to Borsh using the schema).Definitionlength/// A fixed-size array with the length known at the compile time and the same-type elements.Sequence/// A sequence of elements of length known at the run time and the same-type elements./// A fixed-size tuple with the length known at the compile time and the elements of different/// types./// A tagged union, a.k.a enum. Tagged-unions have variants with associated structures./// A structure, structurally similar to a tuple.declarationadd_definitions_recursively/// The type that we use to represent the definition of the Borsh type.NamedFields/// The struct with named fields.UnnamedFields/// The struct with unnamed fields, structurally identical to a tuple.Empty/// The struct with no fields./// The collection representing the fields of a struct./// Declaration of the type.definitions/// All definitions needed to deserialize the given type.BorshSchemaContainer/// All schema information needed to deserialize a single type./// Recursively, using DFS, add type definitions required for this type. For primitive types/// this is an empty map. Type definition explains how to serialize/deserialize a type.add_definition/// Helper method to add a single type definition to the map./// Get the name of the type without brackets.schema_container/// The declaration and the definition of the type that can be used to (de)serialize Borsh without/// the Rust type that produced it.impl_for_renamed_primitivesimpl_for_primitivesT20simple_optionnested_optionsimple_vecnested_vecsimple_tuplenested_tuplesimple_mapsimple_setsimple_arraynested_arrayboxed_schema//! Since Borsh is not a self-descriptive format we have a way to describe types serialized with Borsh so that//! we can deserialize serialized blobs without having Rust types available. Additionally, this can be used to//! serialize content provided in a different format, e.g. JSON object `{"user": "alice", "message": "Message"}`//! can be serialized by JS code into Borsh format such that it can be deserialized into `struct UserMessage {user: String, message: String}`//! on Rust side.//! The important components are: `BorshSchema` trait, `Definition` and `Declaration` types, and `BorshSchemaContainer` struct.//! * `BorshSchema` trait allows any type that implements it to be self-descriptive, i.e. generate it's own schema;//! * `Declaration` is used to describe the type identifier, e.g. `HashMap<u64, String>`;//! * `Definition` is used to describe the structure of the type;//! * `BorshSchemaContainer` is used to store all declarations and defintions that are needed to work with a single type./// Deserialize this instance from a slice of bytes, but assume that at the beginning we have/// bytes describing the schema of the type. We deserialize this schema and verify that it is/// correct./// Serialize object into a vector of bytes and prefix with the schema serialized as vector of/// bytes in Borsh format./// Serialize an object into a vector of bytes./// Serializes an object directly into a `Writer`.DEFAULT_SERIALIZER_CAPACITYtry_to_vec/// Serialize this instance into a vector of bytes.u8_slice/// A data-structure that can be serialized into binary format by NBOR./// use borsh::BorshSerialize;/// #[derive(BorshSerialize)]/// struct MyBorshSerializableStruct {///     value: String,/// let x = MyBorshSerializableStruct { value: "hello".to_owned() };/// let mut buffer: Vec<u8> = Vec::new();/// x.serialize(&mut buffer).unwrap();/// let single_serialized_buffer_len = buffer.len();/// assert_eq!(buffer.len(), single_serialized_buffer_len * 2);/// let mut buffer: Vec<u8> = vec![0; 1024 + single_serialized_buffer_len];/// let mut buffer_slice_enough_for_the_data = &mut buffer[1024..1024 + single_serialized_buffer_len];/// x.serialize(&mut buffer_slice_enough_for_the_data).unwrap();serialize_slice/// Helper method that is used to serialize a slice of data (without the length marker).forgetvec_from_bytescopy_from_bytescheck_zst/// /// derive is only available if borsh is built with `features = ["derive"]`///     fn deserialize_reader<R: borsh::io::Read>(///     ) -> borsh::io::Result<Self> {///             Err(borsh::io::Error::new(///                 borsh::io::ErrorKind::InvalidData,/// use borsh::from_slice;/// assert_eq!(MyEnum::Zero, from_slice::<MyEnum>(&data[..]).unwrap());/// assert_eq!(MyEnum::Zero, from_slice::<OneOrZero>(&data[..]).unwrap().0);/// assert_eq!(MyEnum::Many(Vec::new()), from_slice::<MyEnum>(&data[..]).unwrap());/// assert!(from_slice::<OneOrZero>(&data[..]).is_err());/// Additional methods offered on enums which is used by `[derive(BorshDeserialize)]`.hashes/// Module is available if borsh is built with `features = ["std"]` or `features = ["hashbrown"]`./// Module defines [BorshDeserialize] implementation for/// [HashMap](std::collections::HashMap)/[HashSet](std::collections::HashSet).IpAddrRangeFullimpl_rangeRangeFromRangeToRangeToInclusiveCell/// Deserializes an object from a slice of bytes./// use borsh::{BorshDeserialize, BorshSerialize, from_slice, to_vec};/// #[derive(BorshSerialize, BorshDeserialize, PartialEq, Debug)]/// struct MyStruct {///    a: u64,///    b: Vec<u8>,/// let original = MyStruct { a: 10, b: vec![1, 2, 3] };/// let encoded = to_vec(&original).unwrap();/// let decoded = from_slice::<MyStruct>(&encoded).unwrap();/// assert_eq!(original, decoded);/// If the data is invalid, this function will panic./// If the data is invalid, this function will return an error./// This function will return an error if the data is not fully read.from_reader/// Deserializes an object from a reader./// use borsh::{BorshDeserialize, BorshSerialize, from_reader, to_vec};///     b: Vec<u8>,/// let decoded = from_reader::<_, MyStruct>(&mut encoded.as_slice()).unwrap();ERROR_ZST_FORBIDDENschema_container_of// See `hash_collections` alias definition in build.rs/// Module is available if borsh is built with `features = ["unstable__schema"]`.max_serialized_sizeobject_lengthio_impl/// Subset of `std::io` which is used as part of borsh public API./// When crate is built with `std` feature disabled (it’s enabled by default),/// the exported types are custom borsh types which try to mimic behaviour of/// corresponding standard types usually offering subset of features./// A facade around all the types we need from the `std`, and `alloc`OutOfMemory/// An operation could not be completed, because it failed/// to allocate enough memory./// NonZeroUsize of value one.// TODO: Replace usage by NonZeroUsize::MIN once MSRV is 1.70+./// Returns the largest possible size of a serialised object based solely on its type./// Even when if returned upper bound is correct, the theoretical value may be/// *much* larger than any practical length.  For example, maximum encoded/// length of `String` is 4 GiB while in practice one may encounter strings of/// at most dozen of characters./// use borsh::schema::BorshSchemaContainer;/// let schema = BorshSchemaContainer::for_type::<()>();/// assert_eq!(Ok(0), schema.max_serialized_size());/// let schema = BorshSchemaContainer::for_type::<usize>();/// assert_eq!(Ok(8), schema.max_serialized_size());/// // 4 bytes of length and u32::MAX for the longest possible string./// let schema = BorshSchemaContainer::for_type::<String>();/// assert_eq!(Ok(4 + 4294967295), schema.max_serialized_size());/// let schema = BorshSchemaContainer::for_type::<Vec<String>>();/// assert_eq!(Err(borsh::schema::SchemaMaxSerializedSizeError::Overflow),///            schema.max_serialized_size());Overflow/// The theoretical maximum size of the encoded value overflows `usize`./// This may happen for nested dynamically-sized types such as/// `Vec<Vec<u8>>` whose maximum size is `4 + u32::MAX * (4 + u32::MAX)`.Recursive/// The type is recursive and thus theoretical maximum size is infinite./// Simple type in which this triggers is `struct Rec(Option<Box<Rec>>)`.MissingDefinition/// Some of the declared types were lacking definition making it impossible/// to calculate the size./// Possible error when calculating theoretical maximum size of encoded type `T`.max_serialized_size_impl/// Implementation of [`BorshSchema::max_serialized_size`].is_zero_sizeZeroSizeError/// Checks whether given declaration schema serialises to an empty string./// This is used by [`BorshSchemaContainer::max_serialized_size`] to handle weird types/// such as `[[[(); u32::MAX]; u32::MAX]; u32::MAX]` which serialises to an/// empty string even though its number of elements overflows `usize`./// Error value means that the method has been called recursively./// A recursive type either has no exit, so it cannot be instantiated/// or it uses `Definiotion::Enum` or `Definition::Sequence` to exit from recursion/// which make it non-zero sizeis_zero_size_impl// this is not integration test module, so can use __private for ease of imports;// it cannot be made integration, as it tests `is_zero_size` function, chosen to be non-pubtest_is_zero_size_recursive_check_bypassedtest_is_zero_size_recursive_check_errvalidate/// Validates container for violation of any well-known rules with/// respect to `borsh` serialization./// assert_eq!(Ok(()), schema.validate());ZSTSequence/// sequences of zero-sized types of dynamic length are forbidden by definition/// see <https://github.com/near/borsh-rs/pull/202> and related onesTagTooWide/// Declared tag width is too large.  Tags may be at most eight bytes.TagTooNarrow/// Declared tag width is too small.  Tags must be large enough to represent/// possible length of sequence.TagNotPowerOfTwo/// only 0, 1, 2, 4 and 8 bytes long sequences' `length_width` are allowed/// Some of the declared types were lacking definition, which is considered/// a container's validation errorEmptyLengthRange/// A Sequence defined with an empty length range./// Possible error when validating a [`BorshSchemaContainer`], generated for some type `T`,/// for violation of any well-known rules with respect to `borsh` serialization.check_length_widthU64_LENvalidate_impltest_check_tag_widthmax_sizeSchemaMaxSerializedSizeErrorSchemaContainerValidateErrorbtree_mapIOResultcontainer_extDiscriminantValue/// The type that we use for value of discriminant./// A fixed-size type, which is considered undivisiblelength_width/// How many bytes does the length tag occupy./// Zero if this is fixed-length array or the length must be determined/// by means not specified in the schema.  The schema is invalid if the/// value is greater than eight.length_range/// Bounds on the possible lengths of the sequence./// Note: The schema is invalid if the range is empty or `length_width`/// is non-zero and either bound of the range cannot be represented as/// `length_width`-byte-wide unsigned integer./// Type of each element of the sequence./// A sequence of homogeneous elements./// If `length_width` is non-zero, the sequence is tagged, i.e. prefixed by/// the number of elements in the sequence.  In that case, the length is/// encoded as a `length_width`-byte wide little-endian unsigned integer./// If `length_width` is zero, the sequence is untagged.  In that case, if/// `length_range` contains a single number, the sequence is fixed-sized/// with the range determining number of elements.  Otherwise, knowledge of/// the type is necessary to be able to decode the number of elements./// Prototypical examples of the use of this definitions are:/// * `[T; N]` → `length_width: 0, length_range: N..=N, elements: "T"` and/// * `Vec<T>` → `length_width: 4, length_range: 0..=u32::MAX,///   elements: "T"`./// With `length_width` and `length_range` other custom encoding formats can/// also be expressed.  For example:/// * `BoundedVec<LO, HI, T>` → `length_width: 4, length_range: LO..=HI`;/// * `PascalString` → `length_width: 1, length_range: 0..=255`;/// * `Ipv4Packet` → `length_width: 0, length_range: 20..=65536` or/// * `VarInt<u32>` → `length_width: 0, length_range: 1..=5`.tag_width/// Width in bytes of the discriminant tag./// Zero indicates this is an untagged union.  In standard borsh/// encoding this is one.  Custom encoding formats may use larger width/// if they need to encode more than 256 variants.  The schema is/// invalid if the value is greater than eight./// Possible variants of the enumeration./// `VariantName` is metadata, not present in a type's serialized representation./// A possibly tagged union, a.k.a enum./// Tagged unions are prefixed by a tag identifying encoded variant followed/// by encoding of that variant.  The tag is `tag_width`-byte wide/// little-endian number./// Untagged unions don’t have a separate tag which means that knowledge of/// the type is necessary to fully analyse the binary.  Variants may still/// be used to list possible values or determine the longest possible/// encoding.__W__R/// Description of data encoding on the wire.ARRAY_LENGTH_WIDTH/// Array length isn't present in payload, it's determined by type of data/// serialized.DEFAULT_LENGTH_WIDTH/// Convenience constant representing the length width of a standard borsh/// sequence./// Can be used for `Definition::Sequence::length_width`.DEFAULT_LENGTH_RANGE/// Convenience constant representing the length range of a standard borsh/// It equals `0..=u32::MAX`.  Can be used with/// `Definition::Sequence::length_range`./// The struct with named fields, structurally identical to a tuple./// `FieldName` is metadata, not present in a type's serialized representation./// The struct with no fields, structurally identical to an empty tuple.for_type/// generate [BorshSchemaContainer] for type `T`get_definitionget_mut_definitioninsert_definitionremove_definition/// Recursively, using DFS, add type definitions required for this type./// Type definition partially explains how to serialize/deserialize a type.// see 12 lines aboveimpl_for_rangeimpl_for_vec_like_collection// S is not serialized, so we ignore it in schema too// forcing S to be BorshSchema forces to define Definition// which must be empty, but if not - it will fail// so better to ignore it/// Module defines [BorshSchema] implementation for// Because it's a zero-sized marker, its type parameter doesn't need to be// included in the schema and so it's not bound to `BorshSchema`octetsV4/// An IPv4 address.V6/// An IPv6 address.ip_addr_std_derive_impl//! * `BorshSchemaContainer` is used to store all declarations and definitions that are needed to work with a single type./// this is an alias of [BorshSchemaContainer::for_type]/// Returns the largest possible size of a serialised object based solely on its type `T`./// this is a shortcut for using [BorshSchemaContainer::max_serialized_size]/// assert_eq!(Ok(8), borsh::max_serialized_size::<usize>());/// assert_eq!(vec![12, 0, 0, 0, 0, 0, 0, 0], borsh::to_vec(&12u64).unwrap());/// # #[cfg(feature = "std")]/// let stderr = std::io::stderr();/// assert_eq!((), borsh::to_writer(&stderr, "hello_0x0a").unwrap());/// Serializes an object without allocation to compute and return its length/// struct A {///     tag: String,///     value: u64,/// let a = A { tag: "hello".to_owned(), value: 42 };/// assert_eq!(8, borsh::object_length(&12u64).unwrap());/// assert_eq!(17, borsh::object_length(&a).unwrap());FLOAT_NAN_ERR/// Module defines [BorshSerialize] implementation forborsh_serializeborsh_schemametaParseNestedMetainternalsattributesparsingparse_lit_into_vecSymbolDESERIALIZESERIALIZEVariantsParseFnBOUNDS_FIELD_PARSE_MAPBoundsboundsget_one_attributeattr_get_by_symbol_keysmeta_get_by_symbol_keysparse_lit_intoBoundTypeBORSHBOUNDDESERIALIZE_WITHSERIALIZE_WITHSKIPschema_keysPARAMSSCHEMAWITH_FUNCSSCHEMA_FIELD_PARSE_MAPExprPathSerializeWithDeserializeWithAttributesSchemaBORSH_FIELD_PARSE_MAPserialize_withdeserialize_withfilter_attrsneeds_bounds_deriveget_boundscollect_boundscheck_schemaneeds_schema_params_deriveschema_declarationschema_definitionsparse_boundstest_helpersdebug_print_tokenizabledebug_print_vec_of_tokenizablelocal_insta_assert_debug_snapshotlocal_insta_assert_snapshottest_reject_multiple_borsh_attrstest_bounds_parsing1test_bounds_parsing2test_bounds_parsing3test_bounds_parsing4test_bounds_parsing_errortest_bounds_parsing_error2test_bounds_parsing_error3test_ser_de_with_parsing1test_borsh_skiptest_borsh_no_skipfieldparse_schema_attrstest_root_bounds_and_params_combinedtest_schema_params_parsing1test_schema_params_parsing_errortest_schema_params_parsing_error2test_schema_params_parsing2test_schema_params_parsing3test_schema_params_parsing4test_schema_with_funcs_parsingtest_schema_with_funcs_parsing_error// both `declaration` and `definitions` have to be specifiedtest_root_errortest_root_bounds_and_wrong_key_combinedtests_schemaDECLARATIONDEFINITIONSDefinitionsWITH_FUNCS_FIELD_PARSE_MAPWithFuncswith_funcsParameterOverrideParamsorder_paramarrow_tokenFatArrowoverride_type/**
Struct describes an entry like `order_param => override_type`,  e.g. `K => <K as TraitName>::Associated`
*/paramsCRATEINITUSE_DISCRIMINANTcheck_attributescontains_use_discriminantcontains_initialize_withget_cratetest_use_discriminanttest_use_discriminant_truetest_use_discriminant_wrong_valuetest_check_attrs_use_discriminant_on_structtest_check_attrs_borsh_skip_on_whole_itemtest_check_attrs_borsh_invalid_on_whole_itemtest_check_attrs_init_functiontest_check_attrs_init_function_with_use_discriminant_reversedtest_check_attrs_init_function_with_use_discriminanttest_check_attrs_init_function_wrong_formattest_init_functiontest_init_function_parsing_errortest_init_function_with_use_discriminanttest_init_function_with_use_discriminant_reversedtest_init_function_with_use_discriminant_with_crate/// first field is attr name/// second field is its expected value format representation for error printing/// borsh - top level prefix in nested meta attribute/// bound - sub-borsh nested meta, field-level only, `BorshSerialize` and `BorshDeserialize` contexts//  use_discriminant - sub-borsh nested meta, item-level only, enums only, `BorshSerialize` and `BorshDeserialize` contexts/// serialize - sub-bound nested meta attribute/// deserialize - sub-bound nested meta attribute/// skip - sub-borsh nested meta, field-level only attribute, `BorshSerialize`, `BorshDeserialize`, `BorshSchema` contexts/// init - sub-borsh nested meta, item-level only attribute  `BorshDeserialize` context/// serialize_with - sub-borsh nested meta, field-level only, `BorshSerialize` context/// deserialize_with - sub-borsh nested meta, field-level only, `BorshDeserialize` context/// crate - sub-borsh nested meta, item-level only, `BorshSerialize`, `BorshDeserialize`, `BorshSchema` contexts/// schema - sub-borsh nested meta, `BorshSchema` context/// params - sub-schema nested meta, field-level only attribute/// with_funcs - sub-schema nested meta, field-level only attribute/// declaration - sub-with_funcs nested meta, field-level only attribute/// definitions - sub-with_funcs nested meta, field-level only attributeParenget_lit_str2get_nested_meta_logicFoundCrateget_from_cargoenum_discriminantDiscriminantsprocess_variantGenericsOutputdefault_cratenamepretty_print_syn_strborsh_skip_struct_variant_fieldborsh_skip_tuple_variant_fieldsimple_enum_with_custom_cratesimple_genericsbound_genericsrecursive_enumgeneric_borsh_skip_struct_fieldgeneric_borsh_skip_tuple_fieldgeneric_deserialize_boundcheck_deserialize_with_attrborsh_discriminant_falseborsh_discriminant_trueborsh_init_funcunionsoverridesdefault_visitorFindTyParamsdeserialize_visitorprocess_fieldfield_output/// function which computes derive output [proc_macro2::TokenStream]/// of code, which deserializes single fieldfield_default_output/// of code, which deserializes single skipped fieldsimple_structsimple_struct_with_custom_cratesimple_generic_tuple_structrecursive_structgeneric_tuple_struct_borsh_skip1generic_tuple_struct_borsh_skip2generic_named_fields_struct_borsh_skiptest_override_automatically_added_default_trait/// Calculates the discriminant that will be assigned by the compiler./// See: https://doc.rust-lang.org/reference/items/enumerations.html#assigning-discriminant-valuesPairMacroReturnTypeTypeParamBounddefault_wherecompute_predicateswithout_defaults// Remove the default from every type parameter because in the generated impls// they look like associated types: "error: associated type bindings are not// allowed here".type_contains_some_paramall_type_params// Set of all generic type parameters on the current struct . Initialized up front.all_type_params_orderedrelevant_type_params// Set of generic type parameters used in fields for which filter// returns true . Filled in as the visitor sees them.associated_type_params_usage// [Param] => [Type, containing Param] mapping/// a Visitor-like struct, which helps determine, if a type parameter is found in fieldungroupprocess_for_boundsfrom_paramsprocess_for_paramsat_least_one_hitvisit_fieldvisit_type_top_levelparam_associated_type_insertvisit_return_typevisit_path_segmentvisit_path_argumentsvisit_pathvisit_type_param_boundvisit_macro// Type parameter should not be considered used by a macro path.//     struct TypeMacro<T> {//         mac: T!(),//         marker: PhantomData<T>,visit_typecratenameVisibilitytransform_variant_fieldsinner_struct/// rust definition of the inner struct used in variant.add_definitions_recursively_call/// call to `add_definitions_recursively`.variant_entry/// entry with a variant's declaration, element in vector of whole enum's definitionVariantOutputvariant_idxdiscriminantsuse_discriminantDiscriminantInfoprocess_discriminantinner_struct_definitionsimple_enumsingle_field_enumcomplex_enumcomplex_enum_genericstrailing_comma_genericstest_filter_foreign_attrscomplex_enum_generics_borsh_skip_tuple_fieldcomplex_enum_generics_borsh_skip_named_fieldgeneric_associated_typegeneric_associated_type_param_overridegeneric_associated_type_param_override_conflictcheck_with_funcs_skip_conflictwith_funcs_attrparams_visitorfilter_used_paramsvisit_struct_fields/// check param usage in fields with respect to `borsh(skip)` attribute usagevisit_struct_fields_unconditional/// check param usage in fieldsfield_declaration_output/// of code, which computes declaration of a single field, which is later added to/// the struct's definition as a whole  field_definitions_output/// of code, which adds definitions of a field to the output `definitions: &mut BTreeMap`process_fieldsunit_structwrapper_structtuple_structtuple_struct_paramstuple_struct_whole_skiptuple_struct_partial_skipgeneric_tuple_struct_borsh_skip3generic_tuple_struct_borsh_skip4generic_associated_type_param_override2schema_param_override3optimize_fields_bodyheaderbodyVariantFieldsnamed_headerunnamed_headerVariantBodyUnit// No body variant, unit enum variant.// Variant with body (fields)variant_idx_bodyFieldIdstruct_variant_fieldborsh_skip_struct_variant_all_fieldsgeneric_serialize_boundcheck_serialize_with_attrmixed_with_unit_variantsserialize_visitorStructUnnamedEnumUnnamednew_struct_unnamednew_enum_unnamedserialize_argserialize_output/// of code, which serializes single fieldenum_variant_headeroverride_generic_associated_type_wrong_derivecheck_serialize_with_skip_conflict///  by convention, local to borsh-derive crate, imports from proc_macro (1) are not allowed in `internals` module or in any of its submodules.check_attrs_get_cratename/// ---/// moved to docs of **Derive Macro** `BorshSerialize` in `borsh` crate/// moved to docs of **Derive Macro** `BorshDeserialize` in `borsh` crate/// moved to docs of **Derive Macro** `BorshSchema` in `borsh` crateNestedMetacontains_skipattribute_helpersenum_deenum_serstruct_destruct_serunion_deunion_serassert_eq// Rustfmt removes comas.AttrStyleFieldsUnnamedquote_where_clauseprocess_enumenum_schemastruct_schemaprocess_struct58/// Prepared Alphabet for/// [`EncodeBuilder::with_alphabet`](crate::encode::EncodeBuilder::with_alphabet) and/// [`DecodeBuilder::with_alphabet`](crate::decode::DecodeBuilder::with_alphabet).character/// The duplicate character encountered.first/// The first index the character was seen at.second/// The second index the character was seen at.DuplicateCharacter/// The alphabet contained a duplicate character at at least 2 indexes./// The index at which the non-ASCII character was seen.NonAsciiCharacter/// The alphabet contained a multi-byte (or non-utf8) character./// Errors that could occur when preparing a Base58 alphabet.BITCOIN/// Bitcoin's alphabet as defined in their Base58Check encoding./// See <https://en.bitcoin.it/wiki/Base58Check_encoding#Base58_symbol_chart>MONERO/// Monero's alphabet as defined in this forum post./// See <https://forum.getmonero.org/4/academic-and-technical/221/creating-a-standard-for-physical-coins>RIPPLE/// Ripple's alphabet as defined in their wiki./// See <https://wiki.ripple.com/Encodings>FLICKR/// Flickr's alphabet for creating short urls from photo ids./// See <https://www.flickr.com/groups/api/discuss/72157616713786392/>DEFAULT/// The default alphabet used if none is given. Currently is the/// [`BITCOIN`](Self::BITCOIN) alphabet./// Create prepared alphabet, checks that the alphabet is pure ASCII and that there are no/// duplicate characters, which would result in inconsistent encoding/decoding/// let alpha = bs58::Alphabet::new(///     b" !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXY"/// let decoded = bs58::decode("he11owor1d")///     .with_alphabet(bs58::Alphabet::RIPPLE)///     .into_vec()?;/// let encoded = bs58::encode(decoded)///     .with_alphabet(&alpha)///     .into_string();/// assert_eq!("#ERRN)N RD", encoded);/// ## Errors/// ### Duplicate Character/// let alpha = b"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa";///     bs58::alphabet::Error::DuplicateCharacter { character: 'a', first: 0, second: 1 },///     bs58::Alphabet::new(alpha).unwrap_err());/// ### Non-ASCII Character/// let mut alpha = *b"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa";/// alpha[1] = 255;///     bs58::alphabet::Error::NonAsciiCharacter { index: 1 },///     bs58::Alphabet::new(&alpha).unwrap_err());new_unwrap/// Same as [`Self::new`], but gives a panic instead of an [`Err`] on bad input./// Intended to support usage in `const` context until [`Result::unwrap`] is able to be called./// const ALPHA: &'static bs58::Alphabet = &bs58::Alphabet::new_unwrap(///     .with_alphabet(ALPHA)/// If your alphabet is inconsistent then this will fail to compile in a `const` context:/// ```compile_fail/// const _: &'static bs58::Alphabet = &bs58::Alphabet::new_unwrap(///     b"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa"// Force evaluation of the associated constants to make sure they don't errortest_new_unwrap_does_panic//! Support for configurable alphabetsCheckalphaDecodeBuilder/// A builder for setting up the alphabet and output of a base58 decode./// See the documentation for [`bs58::decode`](crate::decode()) for a more/// high level view of how to use this./// A specialized [`Result`](core::result::Result) type for [`bs58::decode`](module@crate::decode)BufferTooSmall/// The output buffer was too small to contain the entire input./// The unexpected character./// The (byte) index in the input string the character was at.InvalidCharacter/// The input contained a character that was not part of the current Base58/// alphabet./// The (byte) index in the input string the start of the character was/// at./// The input contained a multi-byte (or non-utf8) character which is/// unsupported by this Base58 decoder./// Errors that could occur when decoding a Base58 encoded string./// Setup decoder for the given string using the given alphabet./// Preferably use [`bs58::decode`](crate::decode()) instead of this directly.from_input/// Setup decoder for the given string using default prepared alphabet.with_alphabet/// Change the alphabet that will be used for decoding.///     vec![0x60, 0x65, 0xe7, 0x9b, 0xba, 0x2f, 0x78],///     bs58::decode("he11owor1d")///         .with_alphabet(bs58::Alphabet::RIPPLE)///         .into_vec()?);/// # Ok::<(), bs58::decode::Error>(())into_vec/// Decode into a new vector of bytes./// See the documentation for [`bs58::decode`](crate::decode()) for an/// explanation of the errors that may occur.///     vec![0x04, 0x30, 0x5e, 0x2b, 0x24, 0x73, 0xf0, 0x58],///     bs58::decode("he11owor1d").into_vec()?);/// Decode into the given buffer./// Returns the length written into the buffer, the rest of the bytes in/// the buffer will be untouched./// let mut output = [0xFF; 10];/// assert_eq!(8, bs58::decode("he11owor1d").into(&mut output)?);///     [0x04, 0x30, 0x5e, 0x2b, 0x24, 0x73, 0xf0, 0x58, 0xFF, 0xFF],///     output);decode_into//! Functions for decoding Base58 encoded strings.EncodeBuilder/// A builder for setting up the alphabet and output of a base58 encode./// A specialized [`Result`](core::result::Result) type for [`bs58::encode`](module@crate::encode)/// Errors that could occur when encoding a Base58 encoded string.encode_with/// Encodes into this buffer, provides the maximum length for implementations that wish to/// preallocate space, along with a function that will encode ASCII bytes into the buffer and/// return the length written to it.EncodeTarget/// Represents a buffer that can be encoded into. See [`EncodeBuilder::into`] and the provided/// implementations for more details./// Setup encoder for the given string using the given alphabet./// Preferably use [`bs58::encode`](crate::encode()) instead of this/// directly./// Setup encoder for the given string using default prepared alphabet./// Change the alphabet that will be used for encoding./// let input = [0x60, 0x65, 0xe7, 0x9b, 0xba, 0x2f, 0x78];///     "he11owor1d",///     bs58::encode(input)///         .into_string());into_string/// Encode into a new owned string./// let input = [0x04, 0x30, 0x5e, 0x2b, 0x24, 0x73, 0xf0, 0x58];/// assert_eq!("he11owor1d", bs58::encode(input).into_string());/// Encode into a new owned vector./// assert_eq!(b"he11owor1d", &*bs58::encode(input).into_vec());/// Encode into the given buffer./// Returns the length written into the buffer./// If the buffer is resizeable it will be reallocated to fit the encoded data and truncated to/// If the buffer is not resizeable bytes after the final character will be left alone, except/// up to 3 null bytes may be written to an `&mut str` to overwrite remaining characters of a/// partially overwritten multi-byte character./// See the documentation for [`bs58::encode`](crate::encode()) for an/// ## `Vec<u8>`/// let mut output = "goodbye world".to_owned().into_bytes();/// bs58::encode(input).into(&mut output)?;/// assert_eq!(b"he11owor1d", &*output);/// # Ok::<(), bs58::encode::Error>(())/// ## `&mut [u8]`/// let mut output = Vec::from("goodbye world");/// bs58::encode(input).into(&mut output[..])?;/// assert_eq!(b"he11owor1drld", &*output);/// ## `String`/// let mut output = "goodbye world".to_owned();/// assert_eq!("he11owor1d", output);/// ## `&mut str`/// bs58::encode(input).into(output.as_mut_str())?;/// assert_eq!("he11owor1drld", output);/// ### Clearing partially overwritten characters/// let mut output = "goodbye w®ld".to_owned();/// assert_eq!("he11owor1d\0ld", output);encode_into//! Functions for encoding into Base58 encoded strings.Disabled/// Possible check variants./// Setup decoder for the given string using the [default alphabet][Alphabet::DEFAULT]./// ## Basic example/// ## Changing the alphabet/// ## Decoding into an existing buffer/// ### Invalid Character///     bs58::decode::Error::InvalidCharacter { character: 'l', index: 2 },///     bs58::decode("hello world").into_vec().unwrap_err());///     bs58::decode::Error::NonAsciiCharacter { index: 5 },///     bs58::decode("he11o🇳🇿").into_vec().unwrap_err());/// ### Too Small Buffer/// This error can only occur when reading into a provided buffer, when using/// [`into_vec()`][decode::DecodeBuilder::into_vec] a vector large enough is guaranteed to be/// used./// let mut output = [0; 7];///     bs58::decode::Error::BufferTooSmall,///     bs58::decode("he11owor1d").into(&mut output).unwrap_err());/// Setup encoder for the given bytes using the [default alphabet][Alphabet::DEFAULT]./// ## Encoding into an existing string/// This error can only occur when reading into an unresizeable buffer.///     bs58::encode::Error::BufferTooSmall,///     bs58::encode(input).into(&mut output[..]).unwrap_err());//! Another [Base58][] codec implementation.//! Compared to [`base58`][] this is significantly faster at decoding (about//! 2.4x as fast when decoding 32 bytes), almost the same speed for encoding//! (about 3% slower when encoding 32 bytes) and doesn't have the 128 byte//! limitation.//! Compared to [`rust-base58`][] this is massively faster (over ten times as//! fast when decoding 32 bytes, almost 40 times as fast when encoding 32//! bytes) and has no external dependencies.//! Compared to both this supports a configurable alphabet and user provided//! buffers for zero-allocation {en,de}coding.//! [Base58]: https://en.wikipedia.org/wiki/Base58//! [`base58`]: https://github.com/debris/base58//! [`rust-base58`]: https://github.com/nham/rust-base58//! # Features//!  Feature | Activation         | Effect//! ---------|--------------------|--------//!  `std`   | **on**-by-default  | Implement [`Error`](std::error::Error) for error types//!  `alloc` | implied by `std`   | Support encoding/decoding to [`Vec`](alloc::vec::Vec) and [`String`](alloc::string::String) as appropriate//!  `check` | **off**-by-default | Integrated support for [Base58Check][]//! [Base58Check]: https://en.bitcoin.it/wiki/Base58Check_encoding//! ## Basic example//! let decoded = bs58::decode("he11owor1d").into_vec()?;//! let encoded = bs58::encode(decoded).into_string();//! assert_eq!("he11owor1d", encoded);//! # Ok::<(), bs58::decode::Error>(())//! ## Changing the alphabet//! let decoded = bs58::decode("he11owor1d")//!     .with_alphabet(bs58::Alphabet::RIPPLE)//!     .into_vec()?;//! let encoded = bs58::encode(decoded)//!     .with_alphabet(bs58::Alphabet::FLICKR)//!     .into_string();//! assert_eq!("4DSSNaN1SC", encoded);//! ## Decoding into an existing buffer//! let (mut decoded, mut encoded) = ([0xFF; 8], String::with_capacity(10));//! bs58::decode("he11owor1d").into(&mut decoded)?;//! bs58::encode(decoded).into(&mut encoded)?;//! # Ok::<(), Box<dyn std::error::Error>>(())decode_with/// Decodes into this buffer, provides the maximum length for implementations that wish to/// preallocate space, along with a function that will write bytes into the buffer and return/// the length written to it.DecodeTarget/// Represents a buffer that can be decoded into. See [`DecodeBuilder::onto`] and the providedonto/// If the buffer is resizeable it will be extended and the new data will be written to the end/// of it./// If the buffer is not resizeable bytes will be written from the beginning and bytes after/// the final encoded byte will not be touched./// let mut output = b"hello ".to_vec();/// assert_eq!(5, bs58::decode("EUYUqQf").onto(&mut output)?);/// assert_eq!(b"hello world", output.as_slice());/// let mut output = b"hello ".to_owned();/// assert_eq!(b"world ", output.as_ref());into_array_const/// Decode into a new array./// Returns the decoded array as bytes./// See the documentation for [`bs58::decode`](crate::decode())/// for an explanation of the errors that may occur./// const _: () = {///     let Ok(output) = bs58::decode(b"EUYUqQf".as_slice()).into_array_const::<5>() else {///         panic!()///     assert!(matches!(&output, b"world"));into_array_const_unwrap/// [`Self::into_array_const`] but the result will be unwrapped, turning any error into a panic/// message via [`Error::unwrap_const`], as a simple `into_array_const().unwrap()` isn't/// possible yet.///     let output: [u8; 5] = bs58::decode(b"EUYUqQf".as_slice()).into_array_const_unwrap();///     assert!(matches!(///         bs58::decode(b"he11owor1d".as_slice())///             .with_alphabet(bs58::Alphabet::RIPPLE)///             .into_array_const_unwrap(),///         [0x60, 0x65, 0xe7, 0x9b, 0xba, 0x2f, 0x78],///     ));/// For `const` compatibility we are restricted to using a concrete input and output type, as/// `const` trait implementations and `&mut` are unstable. These methods will eventually be/// deprecated once the primary interfaces can be converted into `const fn` directly.decode_into_constunwrap_const/// Panic with an error message based on this error. This cannot include any of the dynamic/// content because formatting in `const` is not yet possible./// Represents a buffer that can be encoded into. See [`EncodeBuilder::onto`] and the provided/// Encode onto the given buffer./// Returns the length written onto the buffer./// of it, otherwise the data will be overwritten from the start./// let mut output = b"goodbye world ".to_vec();/// bs58::encode(input).onto(&mut output)?;/// assert_eq!(b"goodbye world he11owor1d", output.as_slice());/// let mut output = b"goodbye world".to_owned();/// bs58::encode(input).onto(&mut output[..])?;/// assert_eq!(b"he11owor1drld", output.as_ref());/// let mut output = "goodbye world ".to_owned();/// assert_eq!("goodbye world he11owor1d", output);/// bs58::encode(input).onto(output.as_mut_str())?;max_encoded_len/// Return maximum possible encoded length of a buffer with given length./// Assumes that the `len` already includes version and checksum bytes if those/// are/// assert_eq!(8, bs58::decode("he11owor1d").onto(&mut output)?);///     bs58::decode("he11owor1d").onto(&mut output).unwrap_err());///     bs58::encode(input).onto(&mut output[..]).unwrap_err());// This would be forbid, except unsafe is necessary to work with `&mut str`,// nowhere else should use it//!  `cb58`  | **off**-by-default | Integrated support for [CB58][]//! [CB58]: https://support.avax.network/en/articles/4587395-what-is-cb58//! bs58::decode("he11owor1d").onto(&mut decoded)?;//! bs58::encode(decoded).onto(&mut encoded)?;LayoutLayoutErrnew_layout_errhandle_alloc_errorpadding_needed_forrepeatUnstableLayoutMethodsExcess/// Represents the combination of a starting address and/// a total capacity of the returned block.// #[unstable(feature = "allocator_api", issue = "32838")]size_alignAllocErr/// The `AllocErr` error indicates an allocation failure/// that may be due to resource exhaustion or to/// something wrong when combining the given input arguments with this/// allocator.// (we need this for downstream impl of trait Error)CannotReallocInPlace/// The `CannotReallocInPlace` error is used when `grow_in_place` or/// `shrink_in_place` were unable to reuse the given memory block for/// a requested layout./// Returns a pointer meeting the size and alignment guarantees of/// `layout`./// If this method returns an `Ok(addr)`, then the `addr` returned/// will be non-null address pointing to a block of storage/// suitable for holding an instance of `layout`./// The returned block of storage may or may not have its contents/// initialized. (Extension subtraits might restrict this/// behavior, e.g. to ensure initialization to particular sets of/// bit patterns.)/// This function is unsafe because undefined behavior can result/// if the caller does not ensure that `layout` has non-zero size./// (Extension subtraits might provide more specific bounds on/// behavior, e.g. guarantee a sentinel address or a null pointer/// in response to a zero-size allocation request.)/// Returning `Err` indicates that either memory is exhausted or/// `layout` does not meet allocator's size or alignment/// constraints./// Implementations are encouraged to return `Err` on memory/// exhaustion rather than panicking or aborting, but this is not/// a strict requirement. (Specifically: it is *legal* to/// implement this trait atop an underlying native allocation/// library that aborts on memory exhaustion.)/// Clients wishing to abort computation in response to an/// allocation error are encouraged to call the [`handle_alloc_error`] function,/// rather than directly invoking `panic!` or similar./// [`handle_alloc_error`]: ../../alloc/alloc/fn.handle_alloc_error.htmldealloc/// Deallocate the memory referenced by `ptr`./// if the caller does not ensure all of the following:/// * `ptr` must denote a block of memory currently allocated via///   this allocator,/// * `layout` must *fit* that block of memory,/// * In addition to fitting the block of memory `layout`, the///   alignment of the `layout` must match the alignment used///   to allocate that block of memory.usable_size/// Returns bounds on the guaranteed usable size of a successful/// allocation created with the specified `layout`./// In particular, if one has a memory block allocated via a given/// allocator `a` and layout `k` where `a.usable_size(k)` returns/// `(l, u)`, then one can pass that block to `a.dealloc()` with a/// layout in the size range [l, u]./// (All implementors of `usable_size` must ensure that/// `l <= k.size() <= u`)/// Both the lower- and upper-bounds (`l` and `u` respectively)/// are provided, because an allocator based on size classes could/// misbehave if one attempts to deallocate a block without/// providing a correct value for its size (i.e., one within the/// range `[l, u]`)./// Clients who wish to make use of excess capacity are encouraged/// to use the `alloc_excess` and `realloc_excess` instead, as/// this method is constrained to report conservative values that/// serve as valid bounds for *all possible* allocation method/// calls./// However, for clients that do not wish to track the capacity/// returned by `alloc_excess` locally, this method is likely to/// produce useful results./// Returns a pointer suitable for holding data described by/// a new layout with `layout`’s alignment and a size given/// by `new_size`. To/// accomplish this, this may extend or shrink the allocation/// referenced by `ptr` to fit the new layout./// If this returns `Ok`, then ownership of the memory block/// referenced by `ptr` has been transferred to this/// allocator. The memory may or may not have been freed, and/// should be considered unusable (unless of course it was/// transferred back to the caller again via the return value of/// this method)./// If this method returns `Err`, then ownership of the memory/// block has not been transferred to this allocator, and the/// contents of the memory block are unaltered./// * `ptr` must be currently allocated via this allocator,/// * `layout` must *fit* the `ptr` (see above). (The `new_size`///   argument need not fit it.)/// * `new_size` must be greater than zero./// * `new_size`, when rounded up to the nearest multiple of `layout.align()`,///   must not overflow (i.e. the rounded value must be less than `usize::MAX`)./// Returns `Err` only if the new layout/// does not meet the allocator's size/// and alignment constraints of the allocator, or if reallocation/// otherwise fails./// Clients wishing to abort computation in response to a/// reallocation error are encouraged to call the [`handle_alloc_error`] function,alloc_zeroed/// Behaves like `alloc`, but also ensures that the contents/// are set to zero before being returned./// This function is unsafe for the same reasons that `alloc` is./// constraints, just as in `alloc`.alloc_excess/// Behaves like `alloc`, but also returns the whole size of/// the returned block. For some `layout` inputs, like arrays, this/// may include extra storage usable for additional data.realloc_excess/// Behaves like `realloc`, but also returns the whole size of/// This function is unsafe for the same reasons that `realloc` is./// constraints, just as in `realloc`.grow_in_place/// Attempts to extend the allocation referenced by `ptr` to fit `new_size`./// If this returns `Ok`, then the allocator has asserted that the/// memory block referenced by `ptr` now fits `new_size`, and thus can/// be used to carry data of a layout of that size and same alignment as/// `layout`. (The allocator is allowed to/// expend effort to accomplish this, such as extending the memory block to/// include successor blocks, or virtual memory tricks.)/// Regardless of what this method returns, ownership of the/// memory block referenced by `ptr` has not been transferred, and/// the contents of the memory block are unaltered./// * `layout` must *fit* the `ptr` (see above); note the///   `new_size` argument need not fit it,/// * `new_size` must not be less than `layout.size()`,/// Returns `Err(CannotReallocInPlace)` when the allocator is/// unable to assert that the memory block referenced by `ptr`/// could fit `layout`./// Note that one cannot pass `CannotReallocInPlace` to the `handle_alloc_error`/// function; clients are expected either to be able to recover from/// `grow_in_place` failures without aborting, or to fall back on/// another reallocation method before resorting to an abort.shrink_in_place/// Attempts to shrink the allocation referenced by `ptr` to fit `new_size`./// memory block referenced by `ptr` now fits `new_size`, and/// thus can only be used to carry data of that smaller/// layout. (The allocator is allowed to take advantage of this,/// carving off portions of the block for reuse elsewhere.) The/// truncated contents of the block within the smaller layout are/// unaltered, and ownership of block has not been transferred./// If this returns `Err`, then the memory block is considered to/// still represent the original (larger) `layout`. None of the/// block has been carved off for reuse elsewhere, ownership of/// the memory block has not been transferred, and the contents of/// the memory block are unaltered./// * `new_size` must not be greater than `layout.size()`///   (and must be greater than zero),/// `shrink_in_place` failures without aborting, or to fall back/// on another reallocation method before resorting to an abort.alloc_one/// Allocates a block suitable for holding an instance of `T`./// Captures a common usage pattern for allocators./// The returned block is suitable for passing to the/// `alloc`/`realloc` methods of this allocator./// Note to implementors: If this returns `Ok(ptr)`, then `ptr`/// must be considered "currently allocated" and must be/// acceptable input to methods such as `realloc` or `dealloc`,/// *even if* `T` is a zero-sized type. In other words, if your/// `Alloc` implementation overrides this method in a manner/// that can return a zero-sized `ptr`, then all reallocation and/// deallocation methods need to be similarly overridden to accept/// such values as input./// `T` does not meet allocator's size or alignment constraints./// For zero-sized `T`, may return either of `Ok` or `Err`, but/// will *not* yield undefined behavior.dealloc_one/// Deallocates a block suitable for holding an instance of `T`./// The given block must have been produced by this allocator,/// and must be suitable for storing a `T` (in terms of alignment/// as well as minimum and maximum size); otherwise yields/// undefined behavior./// if the caller does not ensure both:/// * `ptr` must denote a block of memory currently allocated via this allocator/// * the layout of `T` must *fit* that block of memory.alloc_array/// Allocates a block suitable for holding `n` instances of `T`./// `[T; n]` does not meet allocator's size or alignment/// For zero-sized `T` or `n == 0`, may return either of `Ok` or/// `Err`, but will *not* yield undefined behavior./// Always returns `Err` on arithmetic overflow.realloc_array/// Reallocates a block previously suitable for holding `n_old`/// instances of `T`, returning a block suitable for holding/// `n_new` instances of `T`./// * the layout of `[T; n_old]` must *fit* that block of memory./// `[T; n_new]` does not meet allocator's size or alignment/// For zero-sized `T` or `n_new == 0`, may return either of `Ok` ordealloc_array/// Deallocates a block suitable for holding `n` instances of `T`./// * the layout of `[T; n]` must *fit* that block of memory./// Returning `Err` indicates that either `[T; n]` or the given/// memory block does not meet allocator's size or alignment// (Note: some existing allocators have unspecified but well-defined// behavior in response to a zero size allocation request ;// e.g. in C, `malloc` of 0 will either return a null pointer or a// unique pointer, but will not have arbitrary undefined// behavior.// However in jemalloc for example,// `mallocx(0)` is documented as undefined behavior.)// == ALLOCATOR-SPECIFIC QUANTITIES AND LIMITS ==// usable_size// == METHODS FOR MEMORY REUSE ==// realloc. alloc_excess, realloc_excess// == COMMON USAGE PATTERNS ==// alloc_one, dealloc_one, alloc_array, realloc_array. dealloc_arrayAlloc/// An implementation of `Alloc` can allocate, reallocate, and/// deallocate arbitrary blocks of data described via `Layout`./// Some of the methods require that a memory block be *currently/// allocated* via an allocator. This means that:/// * the starting address for that memory block was previously///   returned by a previous call to an allocation method (`alloc`,///   `alloc_zeroed`, `alloc_excess`, `alloc_one`, `alloc_array`) or///   reallocation method (`realloc`, `realloc_excess`, or///   `realloc_array`), and/// * the memory block has not been subsequently deallocated, where///   blocks are deallocated either by being passed to a deallocation///   method (`dealloc`, `dealloc_one`, `dealloc_array`) or by being///   passed to a reallocation method (see above) that returns `Ok`./// A note regarding zero-sized types and zero-sized layouts: many/// methods in the `Alloc` trait state that allocation requests/// must be non-zero size, or else undefined behavior can result./// * However, some higher-level allocation methods (`alloc_one`,///   `alloc_array`) are well-defined on zero-sized types and can///   optionally support them: it is left up to the implementor///   whether to return `Err`, or to return `Ok` with some pointer./// * If an `Alloc` implementation chooses to return `Ok` in this///   case (i.e. the pointer denotes a zero-sized inaccessible block)///   then that returned pointer must be considered "currently///   allocated". On such an allocator, *all* methods that take///   currently-allocated pointers as inputs must accept these///   zero-sized pointers, *without* causing undefined behavior./// * In other words, if a zero-sized pointer can flow out of an///   allocator, then that allocator must likewise accept that pointer///   flowing back into its deallocation and reallocation methods./// Some of the methods require that a layout *fit* a memory block./// What it means for a layout to "fit" a memory block means (or/// equivalently, for a memory block to "fit" a layout) is that the/// following two conditions must hold:/// 1. The block's starting address must be aligned to `layout.align()`./// 2. The block's size must fall in the range `[use_min, use_max]`, where:///    * `use_min` is `self.usable_size(layout).0`, and///    * `use_max` is the capacity that was (or would have been)///      returned when (if) the block was allocated via a call to///      `alloc_excess` or `realloc_excess`./// Note that:///  * the size of the layout most recently used to allocate the block///    is guaranteed to be in the range `[use_min, use_max]`, and///  * a lower-bound on `use_max` can be safely approximated by a call to///    `usable_size`.///  * if a layout `k` fits a memory block (denoted by `ptr`)///    currently allocated via an allocator `a`, then it is legal to///    use that layout to deallocate it, i.e. `a.dealloc(ptr, k);`./// # Unsafety/// The `Alloc` trait is an `unsafe` trait for a number of reasons, and/// implementors must ensure that they adhere to these contracts:/// * Pointers returned from allocation functions must point to valid memory and///   retain their validity until at least the instance of `Alloc` is dropped///   itself./// * `Layout` queries and calculations in general must be correct. Callers of///   this trait are allowed to rely on the contracts defined on each method,///   and implementors must ensure such contracts remain true./// Note that this list may get tweaked over time as clarifications are made in/// the future.// Copyright 2015 The Rust Project Developers. See the COPYRIGHT//! Memory allocation APIsfutureFutureFusedIteratorpinPintaskPollcore_alloc/// An owned pointer to a bump-allocated `T` value, that runs `Drop`/// implementations./// See the [module-level documentation][crate::boxed] for more details.new_in/// Allocates memory on the heap and then places `x` into it./// This doesn't actually allocate if `T` is zero-sized./// use bumpalo::{Bump, boxed::Box};/// let b = Bump::new();/// let five = Box::new_in(5, &b);pin_in/// Constructs a new `Pin<Box<T>>`. If `T` does not implement `Unpin`, then/// `x` will be pinned in memory and unable to be moved./// Consumes the `Box`, returning the wrapped value./// let hello = Box::new_in("hello".to_owned(), &b);/// assert_eq!(Box::into_inner(hello), "hello");/// Constructs a box from a raw pointer./// After calling this function, the raw pointer is owned by the/// resulting `Box`. Specifically, the `Box` destructor will call/// the destructor of `T` and free the allocated memory. For this/// to be safe, the memory must have been allocated in accordance/// with the memory layout used by `Box` ./// This function is unsafe because improper use may lead to/// memory problems. For example, a double-free may occur if the/// function is called twice on the same raw pointer./// Recreate a `Box` which was previously converted to a raw pointer/// using [`Box::into_raw`]:/// let x = Box::new_in(5, &b);/// let ptr = Box::into_raw(x);/// let x = unsafe { Box::from_raw(ptr) }; // Note that new `x`'s lifetime is unbound. It must be bound to the `b` immutable borrow before `b` is reset./// Manually create a `Box` from scratch by using the bump allocator:/// use std::alloc::{alloc, Layout};/// unsafe {///     let ptr = b.alloc_layout(Layout::new::<i32>()).as_ptr() as *mut i32;///     *ptr = 5;///     let x = Box::from_raw(ptr); // Note that `x`'s lifetime is unbound. It must be bound to the `b` immutable borrow before `b` is reset.into_raw/// Consumes the `Box`, returning a wrapped raw pointer./// The pointer will be properly aligned and non-null./// After calling this function, the caller is responsible for the/// value previously managed by the `Box`. In particular, the/// caller should properly destroy `T`. The easiest way to/// do this is to convert the raw pointer back into a `Box` with the/// [`Box::from_raw`] function, allowing the `Box` destructor to perform/// the cleanup./// Note: this is an associated function, which means that you have/// to call it as `Box::into_raw(b)` instead of `b.into_raw()`. This/// is so that there is no conflict with a method on the inner type./// Converting the raw pointer back into a `Box` with [`Box::from_raw`]/// for automatic cleanup:/// let x = Box::new_in(String::from("Hello"), &b);/// Manual cleanup by explicitly running the destructor:/// use std::ptr;/// let mut x = Box::new_in(String::from("Hello"), &b);/// let p = Box::into_raw(x);///     ptr::drop_in_place(p);leak/// Consumes and leaks the `Box`, returning a mutable reference,/// `&'a mut T`. Note that the type `T` must outlive the chosen lifetime/// `'a`. If the type has only static references, or none at all, then this/// may be chosen to be `'static`./// This function is mainly useful for data that lives for the remainder of/// the program's life. Dropping the returned reference will cause a memory/// leak. If this is not acceptable, the reference should first be wrapped/// with the [`Box::from_raw`] function producing a `Box`. This `Box` can/// then be dropped which will properly destroy `T` and release the/// allocated memory./// to call it as `Box::leak(b)` instead of `b.leak()`. This/// Simple usage:/// let x = Box::new_in(41, &b);/// let reference: &mut usize = Box::leak(x);/// *reference += 1;/// assert_eq!(*reference, 42);/// # #[cfg(feature = "collections")]/// # {/// use bumpalo::{Bump, boxed::Box, vec};/// let x = vec![in &b; 1, 2, 3].into_boxed_slice();/// let reference = Box::leak(x);/// reference[0] = 4;/// assert_eq!(*reference, [4, 2, 3]);newrite_isize/// Converts a `Box<T>` into a `Pin<Box<T>>`./// This conversion does not allocate on the heap and happens in place./// Attempt to downcast the box to a concrete type./// use std::any::Any;/// fn print_if_string(value: Box<dyn Any>) {///     if let Ok(string) = value.downcast::<String>() {///         println!("String ({}): {}", string.len(), string);/// let my_string = "Hello World".to_string();/// print_if_string(Box::new(my_string));/// print_if_string(Box::new(0i8));/// fn print_if_string(value: Box<dyn Any + Send>) {nthnth_backfrom_iter_in/// Creates a value from an iterator./// This method is an adapted version of [`FromIterator::from_iter`][from_iter]./// It cannot be made as that trait implementation given different signature./// [from_iter]: https://doc.rust-lang.org/std/iter/trait.FromIterator.html#tymethod.from_iter/// let five_fives = std::iter::repeat(5).take(5);/// let slice = Box::from_iter_in(five_fives, &b);/// assert_eq!(vec![in &b; 5, 5, 5, 5, 5], &*slice);Unpinpoll/// This impl replaces unsize coercion.//! A pointer type for bump allocation.//! [`Box<'a, T>`] provides the simplest form of//! bump allocation in `bumpalo`. Boxes provide ownership for this allocation, and//! drop their contents when they go out of scope.//! Move a value from the stack to the heap by creating a [`Box`]://! use bumpalo::{Bump, boxed::Box};//! let b = Bump::new();//! let val: u8 = 5;//! let boxed: Box<u8> = Box::new_in(val, &b);//! Move a value from a [`Box`] back to the stack by [dereferencing]://! let boxed: Box<u8> = Box::new_in(5, &b);//! let val: u8 = *boxed;//! Running [`Drop`] implementations on bump-allocated values://! use std::sync::atomic::{AtomicUsize, Ordering};//! static NUM_DROPPED: AtomicUsize = AtomicUsize::new(0);//! struct CountDrops;//! impl Drop for CountDrops {//!     fn drop(&mut self) {//!         NUM_DROPPED.fetch_add(1, Ordering::SeqCst);//! // Create a new bump arena.//! let bump = Bump::new();//! // Create a `CountDrops` inside the bump arena.//! let mut c = Box::new_in(CountDrops, &bump);//! // No `CountDrops` have been dropped yet.//! assert_eq!(NUM_DROPPED.load(Ordering::SeqCst), 0);//! // Drop our `Box<CountDrops>`.//! drop(c);//! // Its `Drop` implementation was run, and so `NUM_DROPS` has been incremented.//! assert_eq!(NUM_DROPPED.load(Ordering::SeqCst), 1);//! Creating a recursive data structure://! #[derive(Debug)]//! enum List<'a, T> {//!     Cons(T, Box<'a, List<'a, T>>),//!     Nil,//! let list: List<i32> = List::Cons(1, Box::new_in(List::Cons(2, Box::new_in(List::Nil, &b)), &b));//! println!("{:?}", list);//! This will print `Cons(1, Cons(2, Nil))`.//! Recursive structures must be boxed, because if the definition of `Cons`//! looked like this://! ```compile_fail,E0072//! # enum List<T> {//! Cons(T, List<T>),//! It wouldn't work. This is because the size of a `List` depends on how many//! elements are in the list, and so we don't know how much memory to allocate//! for a `Cons`. By introducing a [`Box<'a, T>`], which has a defined size, we know how//! big `Cons` needs to be.//! # Memory layout//! For non-zero-sized values, a [`Box`] will use the provided [`Bump`] allocator for//! its allocation. It is valid to convert both ways between a [`Box`] and a//! pointer allocated with the [`Bump`] allocator, given that the//! [`Layout`] used with the allocator is correct for the type. More precisely,//! a `value: *mut T` that has been allocated with the [`Bump`] allocator//! with `Layout::for_value(&*value)` may be converted into a box using//! [`Box::<T>::from_raw(value)`]. Conversely, the memory backing a `value: *mut//! T` obtained from [`Box::<T>::into_raw`] will be deallocated by the//! [`Bump`] allocator with [`Layout::for_value(&*value)`].//! Note that roundtrip `Box::from_raw(Box::into_raw(b))` looses the lifetime bound to the//! [`Bump`] immutable borrow which guarantees that the allocator will not be reset//! and memory will not be freed.//! [dereferencing]: https://doc.rust-lang.org/std/ops/trait.Deref.html//! [`Box`]: struct.Box.html//! [`Box<'a, T>`]: struct.Box.html//! [`Box::<T>::from_raw(value)`]: struct.Box.html#method.from_raw//! [`Box::<T>::into_raw`]: struct.Box.html#method.into_raw//! [`Bump`]: ../struct.Bump.html//! [`Drop`]: https://doc.rust-lang.org/std/ops/trait.Drop.html//! [`Layout`]: https://doc.rust-lang.org/std/alloc/struct.Layout.html//! [`Layout::for_value(&*value)`]: https://doc.rust-lang.org/std/alloc/struct.Layout.html#method.for_value/// The allocator type/// Similar to [`FromIterator::from_iter`][from_iter], but with a given allocator./// # use bumpalo::collections::{FromIteratorIn, Vec};/// # use bumpalo::Bump;/// let bump = Bump::new();/// let v = Vec::from_iter_in(five_fives, &bump);/// assert_eq!(v, [5, 5, 5, 5, 5]);FromIteratorIn/// A trait for types that support being constructed from an iterator, parameterized by an allocator.'bump/// Takes each element in the `Iterator`: if it is an `Err`, no further/// elements are taken, and the `Err` is returned. Should no `Err` occur, a/// container with the values of each `Result` is returned./// Here is an example which increments every integer in a vector,/// checking for overflow:/// # use bumpalo::collections::{FromIteratorIn, CollectIn, Vec, String};/// let v = vec![1, 2, u32::MAX];/// let res: Result<Vec<u32>, &'static str> = v.iter().take(2).map(|x: &u32|///     x.checked_add(1).ok_or("Overflow!")/// ).collect_in(&bump);/// assert_eq!(res, Ok(bumpalo::vec![in &bump; 2, 3]));/// let res: Result<Vec<u32>, &'static str> = v.iter().map(|x: &u32|/// assert_eq!(res, Err("Overflow!"));collect_in/// Collect all items from an iterator, into a collection parameterized by an allocator./// Similar to [`Iterator::collect`][collect]./// [collect]: https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.collect/// let str = "hello, world!".to_owned();/// let bump_str: String = str.chars().collect_in(&bump);/// assert_eq!(&bump_str, &str);/// let nums: Vec<i32> = (0..=3).collect_in::<Vec<_>>(&bump);/// assert_eq!(&nums, &[0,1,2,3]);CollectIn/// Extension trait for iterators, in order to allow allocator-parameterized collections to be constructed more easily.raw_vecCollectionAllocErrCapacityOverflow/// Error due to the computed capacity exceeding the collection's maximum/// (usually `isize::MAX` bytes)./// Error due to the allocator (see the documentation for the [`AllocErr`] type)./// Augments `AllocErr` with a `CapacityOverflow` variant.// #[unstable(feature = "try_reserve", reason = "new API", issue="48043")]// Copyright 2018 The Rust Project Developers. See the COPYRIGHT//! Collection types that allocate inside a [`Bump`] arena.// pub mod binary_heap;// mod btree;// pub mod linked_list;// pub mod vec_deque;// pub mod btree_map {//     //! A map based on a B-Tree.//     pub use super::btree::map::*;// pub mod btree_set {//     //! A set based on a B-Tree.//     pub use super::btree::set::*;// #[doc(no_inline)]// pub use self::binary_heap::BinaryHeap;// pub use self::btree_map::BTreeMap;// pub use self::btree_set::BTreeSet;// pub use self::linked_list::LinkedList;// pub use self::vec_deque::VecDeque;// /// An intermediate trait for specialization of `Extend`.// trait SpecExtend<I: IntoIterator> {//     /// Extends `self` with the contents of the given iterator.//     fn spec_extend(&mut self, iter: I);capRawVec/// A low-level utility for more ergonomically allocating, reallocating, and deallocating/// a buffer of memory on the heap without having to worry about all the corner cases/// involved. This type is excellent for building your own data structures like Vec and VecDeque./// In particular:/// * Produces Unique::empty() on zero-sized types/// * Produces Unique::empty() on zero-length allocations/// * Catches all overflows in capacity computations (promotes them to "capacity overflow" panics)/// * Guards against 32-bit systems allocating more than isize::MAX bytes/// * Guards against overflowing your length/// * Aborts on OOM/// * Avoids freeing Unique::empty()/// * Contains a ptr::Unique and thus endows the user with all related benefits/// This type does not in anyway inspect the memory that it manages. When dropped it *will*/// free its memory, but it *won't* try to Drop its contents. It is up to the user of RawVec/// to handle the actual things *stored* inside of a RawVec./// Note that a RawVec always forces its capacity to be usize::MAX for zero-sized types./// This enables you to use capacity growing logic catch the overflows in your length/// that might occur with zero-sized types./// However this means that you need to be careful when round-tripping this type/// with a `Box<[T]>`: `cap()` won't yield the len. However `with_capacity`,/// `shrink_to_fit`, and `from_box` will actually set RawVec's private capacity/// field. This allows zero-sized types to not be special-cased by consumers of/// this type./// Like `new` but parameterized over the choice of allocator for/// the returned RawVec.with_capacity_in/// Like `with_capacity` but parameterized over the choice of/// allocator for the returned RawVec.with_capacity_zeroed_in/// Like `with_capacity_zeroed` but parameterized over the choice/// of allocator for the returned RawVec.allocate_infrom_raw_parts_in/// Reconstitutes a RawVec from a pointer, capacity, and allocator./// # Undefined Behavior/// The ptr must be allocated (via the given allocator `a`), and with the given capacity. The/// capacity cannot exceed `isize::MAX` (only a concern on 32-bit systems)./// If the ptr and capacity come from a RawVec created via `a`, then this is guaranteed./// Gets a raw pointer to the start of the allocation. Note that this is/// Unique::empty() if `cap = 0` or T is zero-sized. In the former case, you must/// be careful./// Gets the capacity of the allocation./// This will always be `usize::MAX` if `T` is zero-sized./// Returns a shared reference to the allocator backing this RawVec.current_layout/// Doubles the size of the type's backing allocation. This is common enough/// to want to do that it's easiest to just have a dedicated method. Slightly/// more efficient logic can be provided for this than the general case./// This function is ideal for when pushing elements one-at-a-time because/// you don't need to incur the costs of the more general computations/// reserve needs to do to guard against overflow. You do however need to/// manually check if your `len == cap`./// * Panics if T is zero-sized on the assumption that you managed to exhaust///   all `usize::MAX` slots in your imaginary buffer./// * Panics on 32-bit platforms if the requested capacity exceeds///   `isize::MAX` bytes./// # Aborts/// Aborts on OOM/// # #![feature(alloc, raw_vec_internals)]/// # extern crate alloc;/// # use std::ptr;/// # use alloc::raw_vec::RawVec;/// struct MyVec<T> {///     buf: RawVec<T>,///     len: usize,/// impl<T> MyVec<T> {///     pub fn push(&mut self, elem: T) {///         if self.len == self.buf.cap() { self.buf.double(); }///         // double would have aborted or panicked if the len exceeded///         // `isize::MAX` so this is safe to do unchecked now.///         unsafe {///             ptr::write(self.buf.ptr().add(self.len), elem);///         self.len += 1;/// #   let mut vec = MyVec { buf: RawVec::new(), len: 0 };/// #   vec.push(1);/// Attempts to double the size of the type's backing allocation in place. This is common/// enough to want to do that it's easiest to just have a dedicated method. Slightly/// Returns true if the reallocation attempt has succeeded, or false otherwise.try_reserve_exact/// The same as `reserve_exact`, but returns on errors instead of panicking or aborting.reserve_exact/// Ensures that the buffer contains at least enough space to hold/// `used_cap + needed_extra_cap` elements. If it doesn't already,/// will reallocate the minimum possible amount of memory necessary./// Generally this will be exactly the amount of memory necessary,/// but in principle the allocator is free to give back more than/// we asked for./// If `used_cap` exceeds `self.cap()`, this may fail to actually allocate/// the requested space. This is not really unsafe, but the unsafe/// code *you* write that relies on the behavior of this function may break./// * Panics if the requested capacity exceeds `usize::MAX` bytes.amortized_new_size/// Calculates the buffer's new size given that it'll hold `used_cap +/// needed_extra_cap` elements. This logic is used in amortized reserve methods./// Returns `(new_capacity, new_alloc_size)`.try_reserve/// The same as `reserve`, but returns on errors instead of panicking or aborting.reserve/// `used_cap + needed_extra_cap` elements. If it doesn't already have/// enough capacity, will reallocate enough space plus comfortable slack/// space to get amortized `O(1)` behavior. Will limit this behavior/// if it would needlessly cause itself to panic./// This is ideal for implementing a bulk-push operation like `extend`./// impl<T: Clone> MyVec<T> {///     pub fn push_all(&mut self, elems: &[T]) {///         self.buf.reserve(self.len, elems.len());///         // reserve would have aborted or panicked if the len exceeded///         for x in elems {///             unsafe {///                 ptr::write(self.buf.ptr().add(self.len), x.clone());///             self.len += 1;/// #   let mut vector = MyVec { buf: RawVec::new(), len: 0 };/// #   vector.push_all(&[1, 3, 5, 7, 9]);reserve_in_place/// Attempts to ensure that the buffer contains at least enough space to hold/// enough capacity, will reallocate in place enough space plus comfortable slack/// space to get amortized `O(1)` behavior. Will limit this behaviourshrink_to_fit/// Shrinks the allocation down to the specified amount. If the given amount/// is 0, actually completely deallocates./// Panics if the given amount is *larger* than the current capacity./// Aborts on OOM.into_box/// Converts the entire buffer into `Box<[T]>`./// Note that this will correctly reconstitute any `cap` changes/// that may have been performed. (See description of type for details.)/// All elements of `RawVec<T>` must be initialized. Notice that/// the rules around uninitialized boxed values are not finalized yet,/// but until they are, it is advisable to avoid them.FallibilityFallibleReserveStrategyExactAmortizedfallible_reserve_internalinfallible_reserve_internalreserve_internal_or_panicreserve_internal_or_errorreserve_internal/// Helper method to reserve additional space, reallocating the backing memory./// The caller is responsible for confirming that there is not already enough space available.dealloc_buffer/// Frees the memory owned by the RawVec *without* trying to Drop its contents.alloc_guardcapacity_overflow// One central function responsible for reporting capacity overflows. This'll// ensure that the code generation related to these panics is minimal as there's// only one location which panics rather than a bunch throughout the module.reserve_does_not_overallocate// use boxed::Box;// We need to guarantee the following:// * We don't ever allocate `> isize::MAX` byte-size objects// * We don't overflow `usize::MAX` and actually allocate too little// On 64-bit we just need to check for overflow since trying to allocate// `> isize::MAX` bytes will surely fail. On 32-bit and 16-bit we need to add// an extra guard for this in case we're running on a platform which can use// all 4GB in user-space. e.g. PAE or x32core_strUtf8Lossy/// Lossy UTF-8 string.chunksUtf8LossyChunksIter/// Iterator over lossy UTF-8 string/// Sequence of valid chars./// Can be empty between broken UTF-8 chars.broken/// Single broken char, empty if none./// Empty iff iterator item is last.Utf8LossyChunk// Copyright 2012-2017 The Rust Project Developers. See the COPYRIGHTlossy// https://tools.ietf.org/html/rfc3629/// Given a first byte, determines how many bytes are in this UTF-8 character.// Copyright 2012-2014 The Rust Project Developers. See the COPYRIGHT//! String manipulation//! For more details, see std::strdecode_utf16ExcludedIncludedUnboundedChars/// Like the [`format!`] macro, but for creating [`bumpalo::collections::String`]s./// [`format!`]: https://doc.rust-lang.org/std/macro.format.html/// [`bumpalo::collections::String`]: collections/string/struct.String.html/// use bumpalo::Bump;/// let who = "World";/// let s = bumpalo::format!(in &b, "Hello, {}!", who);/// assert_eq!(s, "Hello, World!")/// A UTF-8 encoded, growable string./// The `String` type is the most common string type that has ownership over the/// contents of the string. It has a close relationship with its borrowed/// counterpart, the primitive [`str`]./// [`str`]: https://doc.rust-lang.org/std/primitive.str.html/// You can create a `String` from a literal string with [`String::from_str_in`]:/// use bumpalo::{Bump, collections::String};/// let hello = String::from_str_in("Hello, world!", &b);/// You can append a [`char`] to a `String` with the [`push`] method, and/// append a [`&str`] with the [`push_str`] method:/// let mut hello = String::from_str_in("Hello, ", &b);/// hello.push('w');/// hello.push_str("orld!");/// [`char`]: https://doc.rust-lang.org/std/primitive.char.html/// [`push`]: #method.push/// [`push_str`]: #method.push_str/// If you have a vector of UTF-8 bytes, you can create a `String` from it with/// the [`from_utf8`] method:/// // some bytes, in a vector/// let sparkle_heart = bumpalo::vec![in &b; 240, 159, 146, 150];/// // We know these bytes are valid, so we'll use `unwrap()`./// let sparkle_heart = String::from_utf8(sparkle_heart).unwrap();/// assert_eq!("💖", sparkle_heart);/// [`from_utf8`]: #method.from_utf8/// # Deref/// `String`s implement <code>[`Deref`]<Target = [`str`]></code>, and so inherit all of [`str`]'s/// methods. In addition, this means that you can pass a `String` to a/// function which takes a [`&str`] by using an ampersand (`&`):/// fn takes_str(s: &str) { }/// let s = String::from_str_in("Hello", &b);/// takes_str(&s);/// This will create a [`&str`] from the `String` and pass it in. This/// conversion is very inexpensive, and so generally, functions will accept/// [`&str`]s as arguments unless they need a `String` for some specific/// reason./// In certain cases Rust doesn't have enough information to make this/// conversion, known as [`Deref`] coercion. In the following example a string/// slice [`&'a str`][`&str`] implements the trait `TraitExample`, and the function/// `example_func` takes anything that implements the trait. In this case Rust/// would need to make two implicit conversions, which Rust doesn't have the/// means to do. For that reason, the following example will not compile./// ```compile_fail,E0277/// trait TraitExample {}/// impl<'a> TraitExample for &'a str {}/// fn example_func<A: TraitExample>(example_arg: A) {}/// let example_string = String::from_str_in("example_string", &b);/// example_func(&example_string);/// There are two options that would work instead. The first would be to/// change the line `example_func(&example_string);` to/// `example_func(example_string.as_str());`, using the method [`as_str()`]/// to explicitly extract the string slice containing the string. The second/// way changes `example_func(&example_string);` to/// `example_func(&*example_string);`. In this case we are dereferencing a/// `String` to a [`str`][`&str`], then referencing the [`str`][`&str`] back to/// [`&str`]. The second way is more idiomatic, however both work to do the/// conversion explicitly rather than relying on the implicit conversion./// A `String` is made up of three components: a pointer to some bytes, a/// length, and a capacity. The pointer points to an internal buffer `String`/// uses to store its data. The length is the number of bytes currently stored/// in the buffer, and the capacity is the size of the buffer in bytes. As such,/// the length will always be less than or equal to the capacity./// This buffer is always stored on the heap./// You can look at these with the [`as_ptr`], [`len`], and [`capacity`]/// methods:/// use std::mem;/// let mut story = String::from_str_in("Once upon a time...", &b);/// let ptr = story.as_mut_ptr();/// let len = story.len();/// let capacity = story.capacity();/// // story has nineteen bytes/// assert_eq!(19, len);/// // Now that we have our parts, we throw the story away./// mem::forget(story);/// // We can re-build a String out of ptr, len, and capacity. This is all/// // unsafe because we are responsible for making sure the components are/// // valid:/// let s = unsafe { String::from_raw_parts_in(ptr, len, capacity, &b) } ;/// assert_eq!(String::from_str_in("Once upon a time...", &b), s);/// [`as_ptr`]: https://doc.rust-lang.org/std/primitive.str.html#method.as_ptr/// [`len`]: #method.len/// [`capacity`]: #method.capacity/// If a `String` has enough capacity, adding elements to it will not/// re-allocate. For example, consider this program:/// let mut s = String::new_in(&b);/// println!("{}", s.capacity());/// for _ in 0..5 {///     s.push_str("hello");///     println!("{}", s.capacity());/// This will output the following:/// 0/// 5/// 10/// 20/// 40/// At first, we have no memory allocated at all, but as we append to the/// string, it increases its capacity appropriately. If we instead use the/// [`with_capacity_in`] method to allocate the correct capacity initially:/// let mut s = String::with_capacity_in(25, &b);/// [`with_capacity_in`]: #method.with_capacity_in/// We end up with a different output:/// 25/// Here, there's no need to allocate more memory inside the loop./// [`&str`]: https://doc.rust-lang.org/std/primitive.str.html/// [`Deref`]: https://doc.rust-lang.org/std/ops/trait.Deref.html/// [`as_str()`]: struct.String.html#method.as_strFromUtf8Error/// A possible error value when converting a `String` from a UTF-8 byte vector./// This type is the error type for the [`from_utf8`] method on [`String`]. It/// is designed in such a way to carefully avoid reallocations: the/// [`into_bytes`] method will give back the byte vector that was used in the/// conversion attempt./// [`from_utf8`]: struct.String.html#method.from_utf8/// [`String`]: struct.String.html/// [`into_bytes`]: struct.FromUtf8Error.html#method.into_bytes/// The [`Utf8Error`] type provided by [`std::str`] represents an error that may/// occur when converting a slice of [`u8`]s to a [`&str`]. In this sense, it's/// an analogue to `FromUtf8Error`, and you can get one from a `FromUtf8Error`/// through the [`utf8_error`] method./// [`Utf8Error`]: https://doc.rust-lang.org/std/str/struct.Utf8Error.html/// [`std::str`]: https://doc.rust-lang.org/std/str/index.html/// [`u8`]: https://doc.rust-lang.org/std/primitive.u8.html/// [`utf8_error`]: #method.utf8_error/// // some invalid bytes, in a vector/// let bytes = bumpalo::vec![in &b; 0, 159];/// let value = String::from_utf8(bytes);/// assert!(value.is_err());/// assert_eq!(bumpalo::vec![in &b; 0, 159], value.unwrap_err().into_bytes());FromUtf16Error/// A possible error value when converting a `String` from a UTF-16 byte slice./// This type is the error type for the [`from_utf16_in`] method on [`String`]./// [`from_utf16_in`]: struct.String.html#method.from_utf16_in/// // 𝄞mu<invalid>ic/// let v = &[0xD834, 0xDD1E, 0x006d, 0x0075, 0xD800, 0x0069, 0x0063];/// assert!(String::from_utf16_in(v, &b).is_err());/// Creates a new empty `String`./// Given that the `String` is empty, this will not allocate any initial/// buffer. While that means that this initial operation is very/// inexpensive, it may cause excessive allocation later when you add/// data. If you have an idea of how much data the `String` will hold,/// consider the [`with_capacity_in`] method to prevent excessive/// re-allocation./// let s = String::new_in(&b);/// Creates a new empty `String` with a particular capacity./// `String`s have an internal buffer to hold their data. The capacity is/// the length of that buffer, and can be queried with the [`capacity`]/// method. This method creates an empty `String`, but one with an initial/// buffer that can hold `capacity` bytes. This is useful when you may be/// appending a bunch of data to the `String`, reducing the number of/// reallocations it needs to do./// If the given capacity is `0`, no allocation will occur, and this method/// is identical to the [`new_in`] method./// [`new_in`]: #method.new/// let mut s = String::with_capacity_in(10, &b);/// // The String contains no chars, even though it has capacity for more/// assert_eq!(s.len(), 0);/// // These are all done without reallocating.../// let cap = s.capacity();/// for _ in 0..10 {///     s.push('a');/// assert_eq!(s.capacity(), cap);/// // ...but this may make the vector reallocate/// s.push('a');/// Converts a vector of bytes to a `String`./// A string (`String`) is made of bytes ([`u8`]), and a vector of bytes/// ([`Vec<u8>`]) is made of bytes, so this function converts between the/// two. Not all byte slices are valid `String`s, however: `String`/// requires that it is valid UTF-8. `from_utf8()` checks to ensure that/// the bytes are valid UTF-8, and then does the conversion./// If you are sure that the byte slice is valid UTF-8, and you don't want/// to incur the overhead of the validity check, there is an unsafe version/// of this function, [`from_utf8_unchecked`], which has the same behavior/// but skips the check./// This method will take care to not copy the vector, for efficiency's/// sake./// If you need a [`&str`] instead of a `String`, consider/// [`str::from_utf8`]./// The inverse of this method is [`into_bytes`]./// Returns [`Err`] if the slice is not UTF-8 with a description as to why the/// provided bytes are not UTF-8. The vector you moved in is also included./// Incorrect bytes:/// let sparkle_heart = bumpalo::vec![in &b; 0, 159, 146, 150];/// assert!(String::from_utf8(sparkle_heart).is_err());/// See the docs for [`FromUtf8Error`] for more details on what you can do/// with this error./// [`from_utf8_unchecked`]: struct.String.html#method.from_utf8_unchecked/// [`Vec<u8>`]: ../vec/struct.Vec.html/// [`str::from_utf8`]: https://doc.rust-lang.org/std/str/fn.from_utf8.html/// [`into_bytes`]: struct.String.html#method.into_bytes/// [`FromUtf8Error`]: struct.FromUtf8Error.html/// [`Err`]: https://doc.rust-lang.org/std/result/enum.Result.html#variant.Errfrom_utf8_lossy_in/// Converts a slice of bytes to a string, including invalid characters./// Strings are made of bytes ([`u8`]), and a slice of bytes/// ([`&[u8]`][slice]) is made of bytes, so this function converts/// between the two. Not all byte slices are valid strings, however: strings/// are required to be valid UTF-8. During this conversion,/// `from_utf8_lossy_in()` will replace any invalid UTF-8 sequences with/// [`U+FFFD REPLACEMENT CHARACTER`][U+FFFD], which looks like this: �/// [slice]: https://doc.rust-lang.org/std/primitive.slice.html/// [U+FFFD]: https://doc.rust-lang.org/std/char/constant.REPLACEMENT_CHARACTER.html/// to incur the overhead of the conversion, there is an unsafe version/// but skips the checks./// use bumpalo::{collections::String, Bump, vec};/// let sparkle_heart = String::from_utf8_lossy_in(&sparkle_heart, &b);/// // some invalid bytes/// let input = b"Hello \xF0\x90\x80World";/// let output = String::from_utf8_lossy_in(input, &b);/// assert_eq!("Hello �World", output);from_utf16_in/// Decode a UTF-16 encoded slice `v` into a `String`, returning [`Err`]/// if `v` contains any invalid data./// // 𝄞music/// let v = &[0xD834, 0xDD1E, 0x006d, 0x0075, 0x0073, 0x0069, 0x0063];/// assert_eq!(String::from_str_in("𝄞music", &b), String::from_utf16_in(v, &b).unwrap());from_str_in/// Construct a new `String<'bump>` from a string slice./// let s = String::from_str_in("hello", &b);/// assert_eq!(s, "hello");/// Construct a new `String<'bump>` from an iterator of `char`s./// let s = String::from_iter_in(['h', 'e', 'l', 'l', 'o'].iter().cloned(), &b);/// Creates a new `String` from a length, capacity, and pointer./// This is highly unsafe, due to the number of invariants that aren't/// checked:/// * The memory at `ptr` needs to have been previously allocated by the///   same allocator the standard library uses./// * `length` needs to be less than or equal to `capacity`./// * `capacity` needs to be the correct value./// Violating these may cause problems like corrupting the allocator's/// internal data structures./// The ownership of `ptr` is effectively transferred to the/// `String` which may then deallocate, reallocate or change the/// contents of memory pointed to by the pointer at will. Ensure/// that nothing else uses the pointer after calling this/// function.///     let mut s = String::from_str_in("hello", &b);///     let ptr = s.as_mut_ptr();///     let len = s.len();///     let capacity = s.capacity();///     mem::forget(s);///     let s = String::from_raw_parts_in(ptr, len, capacity, &b);///     assert_eq!(s, "hello");from_utf8_unchecked/// Converts a vector of bytes to a `String` without checking that the/// string contains valid UTF-8./// See the safe version, [`from_utf8`], for more details./// This function is unsafe because it does not check that the bytes passed/// to it are valid UTF-8. If this constraint is violated, it may cause/// memory unsafety issues with future users of the `String`,/// as it is assumed that `String`s are valid UTF-8./// let sparkle_heart = unsafe {///     String::from_utf8_unchecked(sparkle_heart)/// Returns a shared reference to the allocator backing this `String`./// // uses the same allocator as the provided `String`/// fn copy_string<'bump>(s: &String<'bump>) -> &'bump str {///     s.bump().alloc_str(s.as_str())into_bytes/// Converts a `String` into a byte vector./// This consumes the `String`, so we do not need to copy its contents./// assert_eq!(s.into_bytes(), [104, 101, 108, 108, 111]);into_bump_str/// Convert this `String<'bump>` into a `&'bump str`. This is analogous to/// [`std::string::String::into_boxed_str`][into_boxed_str]./// [into_boxed_str]: https://doc.rust-lang.org/std/string/struct.String.html#method.into_boxed_str/// let s = String::from_str_in("foo", &b);/// assert_eq!(s.into_bump_str(), "foo");/// Extracts a string slice containing the entire `String`./// assert_eq!("foo", s.as_str());/// Converts a `String` into a mutable string slice./// let mut s = String::from_str_in("foobar", &b);/// let s_mut_str = s.as_mut_str();/// s_mut_str.make_ascii_uppercase();/// assert_eq!("FOOBAR", s_mut_str);/// Appends a given string slice onto the end of this `String`./// let mut s = String::from_str_in("foo", &b);/// s.push_str("bar");/// assert_eq!("foobar", s);/// Returns this `String`'s capacity, in bytes./// let s = String::with_capacity_in(10, &b);/// assert!(s.capacity() >= 10);/// Ensures that this `String`'s capacity is at least `additional` bytes/// larger than its length./// The capacity may be increased by more than `additional` bytes if it/// chooses, to prevent frequent reallocations./// If you do not want this "at least" behavior, see the [`reserve_exact`]/// Panics if the new capacity overflows [`usize`]./// [`reserve_exact`]: struct.String.html#method.reserve_exact/// [`usize`]: https://doc.rust-lang.org/std/primitive.usize.html/// s.reserve(10);/// This may not actually increase the capacity:/// s.push('b');/// // s now has a length of 2 and a capacity of 10/// assert_eq!(2, s.len());/// assert_eq!(10, s.capacity());/// // Since we already have an extra 8 capacity, calling this.../// s.reserve(8);/// // ... doesn't actually increase./// Ensures that this `String`'s capacity is `additional` bytes/// Consider using the [`reserve`] method unless you absolutely know/// better than the allocator./// [`reserve`]: #method.reserve/// Panics if the new capacity overflows `usize`./// s.reserve_exact(10);/// s.reserve_exact(8);/// Shrinks the capacity of this `String` to match its length./// s.reserve(100);/// assert!(s.capacity() >= 100);/// s.shrink_to_fit();/// assert_eq!(3, s.capacity());/// Appends the given [`char`] to the end of this `String`./// let mut s = String::from_str_in("abc", &b);/// s.push('1');/// s.push('2');/// s.push('3');/// assert_eq!("abc123", s);/// Returns a byte slice of this `String`'s contents./// The inverse of this method is [`from_utf8`]./// assert_eq!(&[104, 101, 108, 108, 111], s.as_bytes());/// Shortens this `String` to the specified length./// If `new_len` is greater than the string's current length, this has no/// Note that this method has no effect on the allocated capacity/// of the string./// Panics if `new_len` does not lie on a [`char`] boundary./// let mut s = String::from_str_in("hello", &b);/// s.truncate(2);/// assert_eq!("he", s);/// Removes the last character from the string buffer and returns it./// Returns [`None`] if this `String` is empty./// [`None`]: https://doc.rust-lang.org/std/option/enum.Option.html#variant.None/// Removes a [`char`] from this `String` at a byte position and returns it./// buffer./// Panics if `idx` is larger than or equal to the `String`'s length,/// or if it does not lie on a [`char`] boundary./// Retains only the characters specified by the predicate./// In other words, remove all characters `c` such that `f(c)` returns `false`./// characters./// let mut s = String::from_str_in("f_o_ob_ar", &b);/// s.retain(|c| c != '_');/// Inserts a character into this `String` at a byte position./// This is an `O(n)` operation as it requires copying every element in the/// Panics if `idx` is larger than the `String`'s length, or if it does not/// lie on a [`char`] boundary./// let mut s = String::with_capacity_in(3, &b);/// s.insert(0, 'f');/// s.insert(1, 'o');/// s.insert(2, 'o');/// assert_eq!("foo", s);insert_bytesinsert_str/// Inserts a string slice into this `String` at a byte position./// let mut s = String::from_str_in("bar", &b);/// s.insert_str(0, "foo");as_mut_vec/// Returns a mutable reference to the contents of this `String`./// This function is unsafe because the returned `&mut Vec` allows writing/// bytes which are not valid UTF-8. If this constraint is violated, using/// the original `String` after dropping the `&mut Vec` may violate memory/// safety, as it is assumed that `String`s are valid UTF-8.///     let vec = s.as_mut_vec();///     assert_eq!(vec, &[104, 101, 108, 108, 111]);///     vec.reverse();/// assert_eq!(s, "olleh");/// Returns the length of this `String`, in bytes./// let a = String::from_str_in("foo", &b);/// assert_eq!(a.len(), 3);/// Returns `true` if this `String` has a length of zero./// Returns `false` otherwise./// let mut v = String::new_in(&b);/// v.push('a');/// assert!(!v.is_empty());split_off/// Splits the string into two at the given index./// Returns a newly allocated `String`. `self` contains bytes `[0, at)`, and/// the returned `String` contains bytes `[at, len)`. `at` must be on the/// boundary of a UTF-8 code point./// Note that the capacity of `self` does not change./// Panics if `at` is not on a UTF-8 code point boundary, or if it is beyond the last/// code point of the string./// let mut hello = String::from_str_in("Hello, World!", &b);/// let world = hello.split_off(7);/// assert_eq!(hello, "Hello, ");/// assert_eq!(world, "World!");/// Truncates this `String`, removing all contents./// While this means the `String` will have a length of zero, it does not/// touch its capacity./// s.clear();/// assert!(s.is_empty());/// assert_eq!(0, s.len());/// Creates a draining iterator that removes the specified range in the `String`/// and yields the removed `chars`./// Note: The element range is removed even if the iterator is not/// consumed until the end./// Panics if the starting point or end point do not lie on a [`char`]/// boundary, or if they're out of bounds./// let mut s = String::from_str_in("α is alpha, β is beta", &b);/// let beta_offset = s.find('β').unwrap_or(s.len());/// // Remove the range up until the β from the string/// let t = String::from_iter_in(s.drain(..beta_offset), &b);/// assert_eq!(t, "α is alpha, ");/// assert_eq!(s, "β is beta");/// // A full range clears the string/// drop(s.drain(..));/// assert_eq!(s, "");replace_range/// Removes the specified range in the string,/// and replaces it with the given string./// The given string doesn't need to be the same length as the range./// [`Vec::splice`]: ../vec/struct.Vec.html#method.splice/// // Replace the range up until the β from the string/// s.replace_range(..beta_offset, "Α is capital alpha; ");/// assert_eq!(s, "Α is capital alpha; β is beta");/// Returns a slice of bytes that were attempted to convert to a `String`./// assert_eq!(&[0, 159], value.unwrap_err().as_bytes());/// Returns the bytes that were attempted to convert to a `String`./// This method is carefully constructed to avoid allocation. It will/// consume the error, moving out the bytes, so that a copy of the bytes/// does not need to be made.utf8_error/// Fetch a `Utf8Error` to get more details about the conversion failure./// an analogue to `FromUtf8Error`. See its documentation for more details/// on using it./// let error = String::from_utf8(bytes).unwrap_err().utf8_error();/// // the first byte is invalid here/// assert_eq!(1, error.valid_up_to());impl_eq/// Implements the `+` operator for concatenating two strings./// This consumes the `String<'bump>` on the left-hand side and re-uses its buffer (growing it if/// necessary). This is done to avoid allocating a new `String<'bump>` and copying the entire contents on/// every operation, which would lead to `O(n^2)` running time when building an `n`-byte string by/// repeated concatenation./// The string on the right-hand side is only borrowed; its contents are copied into the returned/// `String<'bump>`./// Concatenating two `String<'bump>`s takes the first by value and borrows the second:/// let a = String::from_str_in("hello", &bump);/// let b = String::from_str_in(" world", &bump);/// let c = a + &b;/// // `a` is moved and can no longer be used here./// If you want to keep using the first `String`, you can clone it and append to the clone instead:/// let c = a.clone() + &b;/// // `a` is still valid here./// Concatenating `&str` slices can be done by converting the first to a `String`:/// let a = "hello";/// let b = " world";/// let c = String::from_str_in(a, &bump) + b;/// Implements the `+=` operator for appending to a `String<'bump>`./// This has the same behavior as the [`push_str`][String::push_str] method./// Will be used as &'a mut String in the destructor/// Start of part to remove/// End of part to remove/// A draining iterator for `String`./// This struct is created by the [`String::drain`] method. See its/// documentation for more information.//! A UTF-8 encoded, growable string.//! This module contains the [`String`] type and several error types that may//! result from working with [`String`]s.//! This module is a fork of the [`std::string`] module, that uses a bump allocator.//! [`std::string`]: https://doc.rust-lang.org/std/string/index.html//! You can create a new [`String`] from a string literal with [`String::from_str_in`]://! use bumpalo::{Bump, collections::String};//! let s = String::from_str_in("world", &b);//! [`String`]: struct.String.html//! [`String::from_str_in`]: struct.String.html#method.from_str_in//! If you have a vector of valid UTF-8 bytes, you can make a [`String`] out of//! it. You can do the reverse too.//! let sparkle_heart = bumpalo::vec![in &b; 240, 159, 146, 150];//! // We know these bytes are valid, so we'll use `unwrap()`.//! let sparkle_heart = String::from_utf8(sparkle_heart).unwrap();//! assert_eq!("💖", sparkle_heart);//! let bytes = sparkle_heart.into_bytes();//! assert_eq!(bytes, [240, 159, 146, 150]);// TODO: implement `AsRef<str/[u8]>` and `as_str`arith_offsetpartition_dedup_byoffset_from/// Creates a [`Vec`] containing the arguments./// `vec!` allows `Vec`s to be defined with the same syntax as array expressions./// There are two forms of this macro:/// - Create a [`Vec`] containing a given list of elements:/// let v = bumpalo::vec![in &b; 1, 2, 3];/// assert_eq!(v, [1, 2, 3]);/// - Create a [`Vec`] from a given element and size:/// let v = bumpalo::vec![in &b; 1; 3];/// assert_eq!(v, [1, 1, 1]);/// Note that unlike array expressions, this syntax supports all elements/// which implement [`Clone`] and the number of elements doesn't have to be/// a constant./// This will use `clone` to duplicate an expression, so one should be careful/// using this with types having a non-standard `Clone` implementation. For/// example, `bumpalo::vec![in &bump; Rc::new(1); 5]` will create a vector of five references/// to the same boxed integer value, not five references pointing to independently/// boxed integers./// [`Vec`]: collections/vec/struct.Vec.html/// [`Clone`]: https://doc.rust-lang.org/std/clone/trait.Clone.html/// A contiguous growable array type, written `Vec<'bump, T>` but pronounced 'vector'./// use bumpalo::{Bump, collections::Vec};/// let mut vec = Vec::new_in(&b);/// vec.push(2);/// assert_eq!(vec.len(), 2);/// assert_eq!(vec[0], 1);/// assert_eq!(vec.pop(), Some(2));/// assert_eq!(vec.len(), 1);/// vec[0] = 7;/// assert_eq!(vec[0], 7);/// vec.extend([1, 2, 3].iter().cloned());/// for x in &vec {///     println!("{}", x);/// assert_eq!(vec, [7, 1, 2, 3]);/// The [`vec!`] macro is provided to make initialization more convenient:/// let mut vec = bumpalo::vec![in &b; 1, 2, 3];/// vec.push(4);/// assert_eq!(vec, [1, 2, 3, 4]);/// It can also initialize each element of a `Vec<'bump, T>` with a given value./// This may be more efficient than performing allocation and initialization/// in separate steps, especially when initializing a vector of zeros:/// let vec = bumpalo::vec![in &b; 0; 5];/// assert_eq!(vec, [0, 0, 0, 0, 0]);/// // The following is equivalent, but potentially slower:/// let mut vec1 = Vec::with_capacity_in(5, &b);/// vec1.resize(5, 0);/// Use a `Vec<'bump, T>` as an efficient stack:/// let mut stack = Vec::new_in(&b);/// stack.push(1);/// stack.push(2);/// stack.push(3);/// while let Some(top) = stack.pop() {///     // Prints 3, 2, 1///     println!("{}", top);/// The `Vec` type allows to access values by index, because it implements the/// [`Index`] trait. An example will be more explicit:/// let v = bumpalo::vec![in &b; 0, 2, 4, 6];/// println!("{}", v[1]); // it will display '2'/// However be careful: if you try to access an index which isn't in the `Vec`,/// your software will panic! You cannot do this:/// ```should_panic/// println!("{}", v[6]); // it will panic!/// In conclusion: always check if the index you want to get really exists/// before doing it./// # Slicing/// A `Vec` can be mutable. Slices, on the other hand, are read-only objects./// To get a slice, use `&`. Example:/// fn read_slice(slice: &[usize]) {/// let v = bumpalo::vec![in &b; 0, 1];/// read_slice(&v);/// // ... and that's all!/// // you can also do it like this:/// let x : &[usize] = &v;/// In Rust, it's more common to pass slices as arguments rather than vectors/// when you just want to provide a read access. The same goes for [`String`] and/// [`&str`]./// # Capacity and reallocation/// The capacity of a vector is the amount of space allocated for any future/// elements that will be added onto the vector. This is not to be confused with/// the *length* of a vector, which specifies the number of actual elements/// within the vector. If a vector's length exceeds its capacity, its capacity/// will automatically be increased, but its elements will have to be/// reallocated./// For example, a vector with capacity 10 and length 0 would be an empty vector/// with space for 10 more elements. Pushing 10 or fewer elements onto the/// vector will not change its capacity or cause reallocation to occur. However,/// if the vector's length is increased to 11, it will have to reallocate, which/// can be slow. For this reason, it is recommended to use [`Vec::with_capacity_in`]/// whenever possible to specify how big the vector is expected to get./// # Guarantees/// Due to its incredibly fundamental nature, `Vec` makes a lot of guarantees/// about its design. This ensures that it's as low-overhead as possible in/// the general case, and can be correctly manipulated in primitive ways/// by unsafe code. Note that these guarantees refer to an unqualified `Vec<'bump, T>`./// If additional type parameters are added (e.g. to support custom allocators),/// overriding their defaults may change the behavior./// Most fundamentally, `Vec` is and always will be a (pointer, capacity, length)/// triplet. No more, no less. The order of these fields is completely/// unspecified, and you should use the appropriate methods to modify these./// The pointer will never be null, so this type is null-pointer-optimized./// However, the pointer may not actually point to allocated memory. In particular,/// if you construct a `Vec` with capacity 0 via [`Vec::new_in`], [`bumpalo::vec![in bump]`][`vec!`],/// [`Vec::with_capacity_in(0)`][`Vec::with_capacity_in`], or by calling [`shrink_to_fit`]/// on an empty Vec, it will not allocate memory. Similarly, if you store zero-sized/// types inside a `Vec`, it will not allocate space for them. *Note that in this case/// the `Vec` may not report a [`capacity`] of 0*. `Vec` will allocate if and only/// if <code>[`mem::size_of::<T>`]\() * capacity() > 0</code>. In general, `Vec`'s allocation/// details are very subtle &mdash; if you intend to allocate memory using a `Vec`/// and use it for something else (either to pass to unsafe code, or to build your/// own memory-backed collection), be sure to deallocate this memory by using/// `from_raw_parts` to recover the `Vec` and then dropping it./// If a `Vec` *has* allocated memory, then the memory it points to is/// in the [`Bump`] arena used to construct it, and its/// pointer points to [`len`] initialized, contiguous elements in order (what/// you would see if you coerced it to a slice), followed by <code>[`capacity`] -/// [`len`]</code> logically uninitialized, contiguous elements./// `Vec` will never perform a "small optimization" where elements are actually/// stored on the stack for two reasons:/// * It would make it more difficult for unsafe code to correctly manipulate///   a `Vec`. The contents of a `Vec` wouldn't have a stable address if it were///   only moved, and it would be more difficult to determine if a `Vec` had///   actually allocated memory./// * It would penalize the general case, incurring an additional branch///   on every access./// `Vec` will never automatically shrink itself, even if completely empty. This/// ensures no unnecessary allocations or deallocations occur. Emptying a `Vec`/// and then filling it back up to the same [`len`] should incur no calls to/// the allocator. If you wish to free up unused memory, use/// [`shrink_to_fit`][`shrink_to_fit`]./// [`push`] and [`insert`] will never (re)allocate if the reported capacity is/// sufficient. [`push`] and [`insert`] *will* (re)allocate if/// <code>[`len`] == [`capacity`]</code>. That is, the reported capacity is completely/// accurate, and can be relied on. It can even be used to manually free the memory/// allocated by a `Vec` if desired. Bulk insertion methods *may* reallocate, even/// when not necessary./// `Vec` does not guarantee any particular growth strategy when reallocating/// when full, nor when [`reserve`] is called. The current strategy is basic/// and it may prove desirable to use a non-constant growth factor. Whatever/// strategy is used will of course guarantee `O(1)` amortized [`push`]./// `bumpalo::vec![in bump; x; n]`, `bumpalo::vec![in bump; a, b, c, d]`, and/// [`Vec::with_capacity_in(n)`][`Vec::with_capacity_in`], will all produce a/// `Vec` with exactly the requested capacity. If <code>[`len`] == [`capacity`]</code>, (as/// is the case for the [`vec!`] macro), then a `Vec<'bump, T>` can be converted/// to and from a [`Box<[T]>`][owned slice] without reallocating or moving the/// `Vec` will not specifically overwrite any data that is removed from it,/// but also won't specifically preserve it. Its uninitialized memory is/// scratch space that it may use however it wants. It will generally just do/// whatever is most efficient or otherwise easy to implement. Do not rely on/// removed data to be erased for security purposes. Even if you drop a `Vec`, its/// buffer may simply be reused by another `Vec`. Even if you zero a `Vec`'s memory/// first, that may not actually happen because the optimizer does not consider/// this a side-effect that must be preserved. There is one case which we will/// not break, however: using `unsafe` code to write to the excess capacity,/// and then increasing the length to match, is always valid./// `Vec` does not currently guarantee the order in which elements are dropped./// The order has changed in the past and may change again./// [`vec!`]: ../../macro.vec.html/// [`Index`]: https://doc.rust-lang.org/std/ops/trait.Index.html/// [`String`]: ../string/struct.String.html/// [`Vec::with_capacity_in`]: struct.Vec.html#method.with_capacity_in/// [`Vec::new_in`]: struct.Vec.html#method.new_in/// [`shrink_to_fit`]: struct.Vec.html#method.shrink_to_fit/// [`capacity`]: struct.Vec.html#method.capacity/// [`mem::size_of::<T>`]: https://doc.rust-lang.org/std/mem/fn.size_of.html/// [`len`]: struct.Vec.html#method.len/// [`push`]: struct.Vec.html#method.push/// [`insert`]: struct.Vec.html#method.insert/// [`reserve`]: struct.Vec.html#method.reserve/// [owned slice]: https://doc.rust-lang.org/std/boxed/struct.Box.html/// Constructs a new, empty `Vec<'bump, T>`./// The vector will not allocate until elements are pushed onto it./// # #![allow(unused_mut)]/// let mut vec: Vec<i32> = Vec::new_in(&b);/// Constructs a new, empty `Vec<'bump, T>` with the specified capacity./// The vector will be able to hold exactly `capacity` elements without/// reallocating. If `capacity` is 0, the vector will not allocate./// It is important to note that although the returned vector has the/// *capacity* specified, the vector will have a zero *length*. For an/// explanation of the difference between length and capacity, see/// *[Capacity and reallocation]*./// [Capacity and reallocation]: #capacity-and-reallocation/// let mut vec = Vec::with_capacity_in(10, &b);/// // The vector contains no items, even though it has capacity for more/// assert_eq!(vec.len(), 0);/// for i in 0..10 {///     vec.push(i);/// vec.push(11);/// Construct a new `Vec` from the given iterator's items./// use std::iter;/// let v = Vec::from_iter_in(iter::repeat(7).take(3), &b);/// assert_eq!(v, [7, 7, 7]);/// Creates a `Vec<'bump, T>` directly from the raw components of another vector./// * `ptr` needs to have been previously allocated via [`String`]/`Vec<'bump, T>`///   (at least, it's highly likely to be incorrect if it wasn't)./// * `ptr`'s `T` needs to have the same size and alignment as it was allocated with./// * `capacity` needs to be the capacity that the pointer was allocated with./// internal data structures. For example it is **not** safe/// to build a `Vec<u8>` from a pointer to a C `char` array and a `size_t`./// `Vec<'bump, T>` which may then deallocate, reallocate or change the/// let mut v = bumpalo::vec![in &b; 1, 2, 3];/// // Pull out the various important pieces of information about `v`/// let p = v.as_mut_ptr();/// let len = v.len();/// let cap = v.capacity();///     // Cast `v` into the void: no destructor run, so we are in///     // complete control of the allocation to which `p` points.///     mem::forget(v);///     // Overwrite memory with 4, 5, 6///     for i in 0..len as isize {///         ptr::write(p.offset(i), 4 + i);///     // Put everything back together into a Vec///     let rebuilt = Vec::from_raw_parts_in(p, len, cap, &b);///     assert_eq!(rebuilt, [4, 5, 6]);/// Returns a shared reference to the allocator backing this `Vec`./// // uses the same allocator as the provided `Vec`/// fn add_strings<'bump>(vec: &mut Vec<'bump, &'bump str>) {///     for string in ["foo", "bar", "baz"] {///         vec.push(vec.bump().alloc_str(string));/// Returns the number of elements the vector can hold without/// reallocating./// let vec: Vec<i32> = Vec::with_capacity_in(10, &b);/// assert_eq!(vec.capacity(), 10);/// Reserves capacity for at least `additional` more elements to be inserted/// in the given `Vec<'bump, T>`. The collection may reserve more space to avoid/// frequent reallocations. After calling `reserve`, capacity will be/// greater than or equal to `self.len() + additional`. Does nothing if/// capacity is already sufficient./// let mut vec = bumpalo::vec![in &b; 1];/// vec.reserve(10);/// assert!(vec.capacity() >= 11);/// Reserves the minimum capacity for exactly `additional` more elements to/// be inserted in the given `Vec<'bump, T>`. After calling `reserve_exact`,/// capacity will be greater than or equal to `self.len() + additional`./// Does nothing if the capacity is already sufficient./// Note that the allocator may give the collection more space than it/// requests. Therefore capacity can not be relied upon to be precisely/// minimal. Prefer `reserve` if future insertions are expected./// vec.reserve_exact(10);/// Attempts to reserve capacity for at least `additional` more elements to be inserted/// frequent reallocations. After calling `try_reserve`, capacity will be/// vec.try_reserve(10).unwrap();/// Attempts to reserve the minimum capacity for exactly `additional` more elements to/// be inserted in the given `Vec<'bump, T>`. After calling `try_reserve_exact`,/// minimal. Prefer `try_reserve` if future insertions are expected./// vec.try_reserve_exact(10).unwrap();/// Shrinks the capacity of the vector as much as possible./// It will drop down as close as possible to the length but the allocator/// may still inform the vector that there is space for a few more elements./// vec.shrink_to_fit();/// assert!(vec.capacity() >= 3);into_bump_slice/// Converts the vector into `&'bump [T]`./// let slice = v.into_bump_slice();/// assert_eq!(slice, [1, 2, 3]);into_bump_slice_mut/// Converts the vector into `&'bump mut [T]`./// let mut slice = v.into_bump_slice_mut();/// slice[0] = 3;/// slice[2] = 1;/// assert_eq!(slice, [3, 2, 1]);/// If `len` is greater than the vector's current length, this has no/// The [`drain`] method can emulate `truncate`, but causes the excess/// elements to be returned instead of dropped./// of the vector./// Truncating a five element vector to two elements:/// let mut vec = bumpalo::vec![in &b; 1, 2, 3, 4, 5];/// vec.truncate(2);/// assert_eq!(vec, [1, 2]);/// No truncation occurs when `len` is greater than the vector's current/// length:/// vec.truncate(8);/// Truncating when `len == 0` is equivalent to calling the [`clear`]/// vec.truncate(0);/// assert_eq!(vec, []);/// [`clear`]: #method.clear/// [`drain`]: #method.drain/// Extracts a slice containing the entire vector./// Equivalent to `&s[..]`./// use std::io::{self, Write};/// let buffer = bumpalo::vec![in &b; 1, 2, 3, 5, 8];/// io::sink().write(buffer.as_slice()).unwrap();/// Extracts a mutable slice of the entire vector./// Equivalent to `&mut s[..]`./// use std::io::{self, Read};/// let mut buffer = bumpalo::vec![in &b; 0; 3];/// io::repeat(0b101).read_exact(buffer.as_mut_slice()).unwrap();/// Returns a raw pointer to the vector's buffer, or a dangling raw pointer/// valid for zero sized reads if the vector didn't allocate./// The caller must ensure that the vector outlives the pointer this/// function returns, or else it will end up pointing to garbage./// Modifying the vector may cause its buffer to be reallocated,/// which would also make any pointers to it invalid./// The caller must also ensure that the memory the pointer (non-transitively) points to/// is never written to (except inside an `UnsafeCell`) using this pointer or any pointer/// derived from it. If you need to mutate the contents of the slice, use [`as_mut_ptr`]./// let x = bumpalo::vec![in &bump; 1, 2, 4];/// let x_ptr = x.as_ptr();///     for i in 0..x.len() {///         assert_eq!(*x_ptr.add(i), 1 << i);/// [`as_mut_ptr`]: Vec::as_mut_ptr/// Returns an unsafe mutable pointer to the vector's buffer, or a dangling/// raw pointer valid for zero sized reads if the vector didn't allocate./// // Allocate vector big enough for 4 elements./// let size = 4;/// let mut x: Vec<i32> = Vec::with_capacity_in(size, &bump);/// let x_ptr = x.as_mut_ptr();/// // Initialize elements via raw pointer writes, then set length.///     for i in 0..size {///         x_ptr.add(i).write(i as i32);///     x.set_len(size);/// assert_eq!(&*x, &[0, 1, 2, 3]);/// Sets the length of a vector./// This will explicitly set the size of the vector, without actually/// modifying its buffers, so it is up to the caller to ensure that the/// vector is actually the specified size./// - `new_len` must be less than or equal to [`capacity()`]./// - The elements at `old_len..new_len` must be initialized./// [`capacity()`]: struct.Vec.html#method.capacity/// let mut vec = bumpalo::vec![in &b; 'r', 'u', 's', 't'];///     ptr::drop_in_place(&mut vec[3]);///     vec.set_len(3);/// assert_eq!(vec, ['r', 'u', 's']);/// In this example, there is a memory leak since the memory locations/// owned by the inner vectors were not freed prior to the `set_len` call:/// let mut vec = bumpalo::vec![in &b;///                             bumpalo::vec![in &b; 1, 0, 0],///                             bumpalo::vec![in &b; 0, 1, 0],///                             bumpalo::vec![in &b; 0, 0, 1]];///     vec.set_len(0);/// In this example, the vector gets expanded from zero to four items/// but we directly initialize uninitialized memory:// TODO: rely upon `spare_capacity_mut`/// let len = 4;/// let mut vec: Vec<u8> = Vec::with_capacity_in(len, &b);/// for i in 0..len {///     // SAFETY: we initialize memory via `pointer::write`///     unsafe { vec.as_mut_ptr().add(i).write(b'a') }///     vec.set_len(len);/// assert_eq!(b"aaaa", &*vec);/// Removes an element from the vector and returns it./// The removed element is replaced by the last element of the vector./// This does not preserve ordering, but is O(1)./// Panics if `index` is out of bounds./// let mut v = bumpalo::vec![in &b; "foo", "bar", "baz", "qux"];/// assert_eq!(v.swap_remove(1), "bar");/// assert_eq!(v, ["foo", "qux", "baz"]);/// assert_eq!(v.swap_remove(0), "foo");/// assert_eq!(v, ["baz", "qux"]);/// Inserts an element at position `index` within the vector, shifting all/// elements after it to the right./// Panics if `index > len`./// vec.insert(1, 4);/// assert_eq!(vec, [1, 4, 2, 3]);/// vec.insert(4, 5);/// assert_eq!(vec, [1, 4, 2, 3, 5]);/// Removes and returns the element at position `index` within the vector,/// shifting all elements after it to the left./// assert_eq!(v.remove(1), 2);/// assert_eq!(v, [1, 3]);/// In other words, remove all elements `e` such that `f(&e)` returns `false`./// let mut vec = bumpalo::vec![in &b; 1, 2, 3, 4];/// vec.retain(|x: &i32| *x % 2 == 0);/// assert_eq!(vec, [2, 4]);retain_mut/// In other words, remove all elements `e` such that `f(&mut e)` returns `false`./// vec.retain_mut(|x: &mut i32| *x % 2 == 0);drain_filterDrainFilter/// Creates an iterator that removes the elements in the vector/// for which the predicate returns `true` and yields the removed items./// use bumpalo::collections::{CollectIn, Vec};/// let mut numbers = bumpalo::vec![in &b; 1, 2, 3, 4, 5];/// let evens: Vec<_> = numbers.drain_filter(|x| *x % 2 == 0).collect_in(&b);/// assert_eq!(numbers, &[1, 3, 5]);/// assert_eq!(evens, &[2, 4]);dedup_by_key/// Removes all but the first of consecutive elements in the vector that resolve to the same/// key./// If the vector is sorted, this removes all duplicates./// let mut vec = bumpalo::vec![in &b; 10, 20, 21, 30, 20];/// vec.dedup_by_key(|i| *i / 10);/// assert_eq!(vec, [10, 20, 30, 20]);dedup_by/// Removes all but the first of consecutive elements in the vector satisfying a given equality/// relation./// The `same_bucket` function is passed references to two elements from the vector and/// must determine if the elements compare equal. The elements are passed in opposite order/// from their order in the slice, so if `same_bucket(a, b)` returns `true`, `a` is removed./// let mut vec = bumpalo::vec![in &b; "foo", "bar", "Bar", "baz", "bar"];/// vec.dedup_by(|a, b| a.eq_ignore_ascii_case(b));/// assert_eq!(vec, ["foo", "bar", "baz", "bar"]);// Proven specification with verus, converted to comments./// # Preconditions/// - old(self).len() < old(self).capacity(),/// # Postconditions/// - self.get_unchecked(old(self).len()) == value,/// - self.len()      == old(self).len() + 1,/// - self.capacity() == old(self).capacity(),/// - forall|i: usize| implies(///       i < old(self).len(),///       self.get_unchecked(i) == old(self).get_unchecked(i)///   )/// Appends an element to the back of a vector./// Panics if the number of elements in the vector overflows a `usize`./// let mut vec = bumpalo::vec![in &b; 1, 2];/// vec.push(3);/// Removes the last element from a vector and returns it, or [`None`] if it/// is empty./// assert_eq!(vec.pop(), Some(3));/// Moves all the elements of `other` into `Self`, leaving `other` empty./// let mut vec2 = bumpalo::vec![in &b; 4, 5, 6];/// vec.append(&mut vec2);/// assert_eq!(vec, [1, 2, 3, 4, 5, 6]);/// assert_eq!(vec2, []);append_elements/// Appends elements to `Self` from other buffer./// Creates a draining iterator that removes the specified range in the vector/// and yields the removed items./// Note 1: The element range is removed even if the iterator is only/// partially consumed or not consumed at all./// Note 2: It is unspecified how many elements are removed from the vector/// Panics if the starting point is greater than the end point or if/// let u: Vec<_> = v.drain(1..).collect_in(&b);/// assert_eq!(v, &[1]);/// assert_eq!(u, &[2, 3]);/// // A full range clears the vector/// v.drain(..);/// assert_eq!(v, &[]);/// Clears the vector, removing all values./// v.clear();/// Returns the number of elements in the vector, also referred to/// as its 'length'./// let a = bumpalo::vec![in &b; 1, 2, 3];/// Returns `true` if the vector contains no elements./// let mut v = Vec::new_in(&b);/// v.push(1);/// Splits the collection into two at the given index./// Returns a newly allocated vector. `self` contains elements `[0, at)`,/// and the returned vector contains elements `[at, len)`./// Panics if `at > len`./// let vec2 = vec.split_off(1);/// assert_eq!(vec, [1]);/// assert_eq!(vec2, [2, 3]);into_boxed_slice/// Converts the vector into [`Box<[T]>`][owned slice]./// Note that this will drop any excess capacity./// [owned slice]: ../../boxed/struct.Box.html/// use bumpalo::{Bump, collections::Vec, vec};/// let v = vec![in &b; 1, 2, 3];/// let slice = v.into_boxed_slice();resize/// Resizes the `Vec` in-place so that `len` is equal to `new_len`./// If `new_len` is greater than `len`, the `Vec` is extended by the/// difference, with each additional slot filled with `value`./// If `new_len` is less than `len`, the `Vec` is simply truncated./// This method requires [`Clone`] to be able clone the passed value. If/// you need more flexibility (or want to rely on [`Default`] instead of/// [`Clone`]), use [`resize_with`]./// let mut vec = bumpalo::vec![in &b; "hello"];/// vec.resize(3, "world");/// assert_eq!(vec, ["hello", "world", "world"]);/// vec.resize(2, 0);/// [`Default`]: https://doc.rust-lang.org/std/default/trait.Default.html/// [`resize_with`]: #method.resize_withextend_from_slice_unchecked/// - old(self).len() + slice.len() <= old(self).capacity(),///   ),///       i < slice.len(),///       self.get_unchecked((old(self).len() + i) as usize)///           == clone(slice.get_unchecked(i))/// - self.len()      == old(self).len() + slice.len(),/// Clones and appends all elements in a slice to the `Vec`./// Iterates over the slice `other`, clones each element, and then appends/// it to this `Vec`. The `other` vector is traversed in-order./// Note that this function is same as [`extend`] except that it is/// specialized to work with slices instead. If and when Rust gets/// specialization this function will likely be deprecated (but still/// available)./// vec.extend_from_slice(&[2, 3, 4]);/// [`extend`]: #method.extendextend_from_slice_copy_unchecked/// Helper method to copy all of the items in `other` and append them to the end of `self`./// SAFETY:///   * The caller is responsible for:///       * calling [`reserve`](Self::reserve) beforehand to guarantee that there is enough///         capacity to store `other.len()` more items.///       * guaranteeing that `self` and `other` do not overlap.extend_from_slice_copy/// Copies all elements in the slice `other` and appends them to the `Vec`./// Note that this function is same as [`extend_from_slice`] except that it is optimized for/// slices of types that implement the `Copy` trait. If and when Rust gets specialization/// this function will likely be deprecated (but still available)./// To copy and append the data from multiple source slices at once, see/// [`extend_from_slices_copy`]./// vec.extend_from_slice_copy(&[2, 3, 4]);/// let mut vec = bumpalo::vec![in &b; 'H' as u8];/// vec.extend_from_slice_copy("ello, world!".as_bytes());/// assert_eq!(vec, "Hello, world!".as_bytes());/// [`extend_from_slice`]: #method.extend_from_slice/// [`extend_from_slices`]: #method.extend_from_slicesextend_from_slices_copy/// For each slice in `slices`, copies all elements in the slice and appends them to the `Vec`./// This method is equivalent to calling [`extend_from_slice_copy`] in a loop, but is able/// to precompute the total amount of space to reserve in advance. This reduces the potential/// maximum number of reallocations needed from one-per-slice to just one./// vec.extend_from_slices_copy(&[&[2, 3], &[], &[4]]);/// vec.extend_from_slices_copy(&["ello,".as_bytes(), &[], " world!".as_bytes()]);/// [`extend_from_slice_copy`]: #method.extend_from_slice_copyExtendWith// This code generalises `extend_with_{element,default}`.ExtendElementextend_with/// Extend the vector by `n` values, using the given generator.local_lenSetLenOnDrop// Set the length of the vec when the `SetLenOnDrop` value goes out of scope.// The idea is: The length field in SetLenOnDrop is a local variable// that the optimizer will see does not alias with any stores through the Vec's data// pointer. This is a workaround for alias analysis issue #32155increment_lendecrement_lendedup/// Removes consecutive repeated elements in the vector according to the/// [`PartialEq`] trait implementation./// let mut vec = bumpalo::vec![in &b; 1, 2, 2, 3, 2];/// vec.dedup();/// assert_eq!(vec, [1, 2, 3, 2]);// HACK(japaric): with cfg(test) the inherent `[T]::to_vec` method, which is// required for this method definition, is not available. Instead use the// `slice::to_vec`  function which is only available with cfg(test)// NB see the slice::hack module in slice.rs for more informationSliceIndex/// Creates a consuming iterator, that is, one that moves each value out of/// the vector (from start to end). The vector cannot be used after calling/// this./// let v = bumpalo::vec![in &b; "a".to_string(), "b".to_string()];/// for s in v.into_iter() {///     // s has type String, not &String///     println!("{}", s);spliceSplice/// Creates a splicing iterator that replaces the specified range in the vector/// with the given `replace_with` iterator and yields the removed items./// `replace_with` does not need to be the same length as `range`./// Note 1: The element range is removed even if the iterator is not/// Note 2: It is unspecified how many elements are removed from the vector,/// if the `Splice` value is leaked./// Note 3: The input iterator `replace_with` is only consumed/// when the `Splice` value is dropped./// Note 4: This is optimal if:/// * The tail (elements in the vector after `range`) is empty,/// * or `replace_with` yields fewer elements than `range`’s length/// * or the lower bound of its `size_hint()` is exact./// Otherwise, a temporary vector is allocated and the tail is moved twice./// let new = [7, 8];/// let u: Vec<_> = Vec::from_iter_in(v.splice(..2, new.iter().cloned()), &b);/// assert_eq!(v, &[7, 8, 3]);/// assert_eq!(u, &[1, 2]);/// Extend implementation that copies elements out of references before pushing them onto the Vec./// This implementation is specialized for slice iterators, where it uses [`copy_from_slice`] to/// append the entire slice at once./// [`copy_from_slice`]: https://doc.rust-lang.org/std/primitive.slice.html#method.copy_from_slice__impl_slice_eq1__impl_slice_eq1_array/// Implements comparison of vectors, lexicographically./// Implements ordering of vectors, lexicographically./// An iterator that moves out of a vector./// This `struct` is created by the [`Vec::into_iter`] method/// (provided by the [`IntoIterator`] trait)./// [`IntoIterator`]: https://doc.rust-lang.org/std/iter/trait.IntoIterator.html/// let vec = bumpalo::vec![in &b; 'a', 'b', 'c'];/// let mut into_iter = vec.into_iter();/// assert_eq!(into_iter.as_slice(), &['a', 'b', 'c']);/// let _ = into_iter.next().unwrap();/// assert_eq!(into_iter.as_slice(), &['b', 'c']);/// into_iter.as_mut_slice()[2] = 'z';/// assert_eq!(into_iter.next().unwrap(), 'a');/// assert_eq!(into_iter.next().unwrap(), 'b');/// assert_eq!(into_iter.next().unwrap(), 'z');/// A draining iterator for `Vec<'bump, T>`./// This `struct` is created by the [`Vec::drain`] method.replace_with/// A splicing iterator for `Vec`./// This struct is created by the [`Vec::splice`] method. See its/// The range from `self.vec.len` to `self.tail_start` contains elements/// that have been moved out./// Fill that range as much as possible with new elements from the `replace_with` iterator./// Return whether we filled the entire range. (`replace_with.next()` didn’t return `None`.)move_tail/// Make room for inserting more elements before the tail./// Private helper methods for `Splice::drop`delold_lenpred/// An iterator produced by calling [`Vec::drain_filter`].//! A contiguous growable array type with heap-allocated contents, written//! [`Vec<'bump, T>`].//! Vectors have `O(1)` indexing, amortized `O(1)` push (to the end) and//! `O(1)` pop (from the end).//! This module is a fork of the [`std::vec`] module, that uses a bump allocator.//! [`std::vec`]: https://doc.rust-lang.org/std/vec/index.html//! You can explicitly create a [`Vec<'bump, T>`] with [`new_in`]://! use bumpalo::{Bump, collections::Vec};//! let v: Vec<i32> = Vec::new_in(&b);//! ... or by using the [`vec!`] macro://! let v: Vec<i32> = bumpalo::vec![in &b];//! let v = bumpalo::vec![in &b; 1, 2, 3, 4, 5];//! let v = bumpalo::vec![in &b; 0; 10]; // ten zeroes//! You can [`push`] values onto the end of a vector (which will grow the vector//! as needed)://! let mut v = bumpalo::vec![in &b; 1, 2];//! v.push(3);//! Popping values works in much the same way://! assert_eq!(v.pop(), Some(2));//! Vectors also support indexing (through the [`Index`] and [`IndexMut`] traits)://! let mut v = bumpalo::vec![in &b; 1, 2, 3];//! assert_eq!(v[2], 3);//! v[1] += 5;//! assert_eq!(v, [1, 7, 3]);//! [`Vec<'bump, T>`]: struct.Vec.html//! [`new_in`]: struct.Vec.html#method.new_in//! [`push`]: struct.Vec.html#method.push//! [`Index`]: https://doc.rust-lang.org/std/ops/trait.Index.html//! [`IndexMut`]: https://doc.rust-lang.org/std/ops/trait.IndexMut.html//! [`vec!`]: ../../macro.vec.html////////////////////////////////////////////////////////////////////////////////// Inherent methods// Common trait implementations for Vec// __impl_slice_eq1! { Cow<'a, [A]>, Vec<'b, B>, Clone }// Clone-on-write// impl<'a, 'bump, T: Clone> From<Vec<'bump, T>> for Cow<'a, [T]> {//     fn from(v: Vec<'bump, T>) -> Cow<'a, [T]> {//         Cow::Owned(v)// impl<'a, 'bump, T: Clone> From<&'a Vec<'bump, T>> for Cow<'a, [T]> {//     fn from(v: &'a Vec<'bump, T>) -> Cow<'a, [T]> {//         Cow::Borrowed(v.as_slice())// IteratorsAllocOrInitError/// Indicates that the initial allocation failed./// Indicates that the initializer failed with the contained error after/// allocation./// It is possible but not guaranteed that the allocated memory has been/// released back to the allocator at this point./// An error returned from [`Bump::try_alloc_try_with`].current_chunk_footerChunkFooter// The current chunk we are bump allocating within.allocation_limitMIN_ALIGN/// An arena to bump allocate into./// ## No `Drop`s/// Objects that are bump-allocated will never have their [`Drop`] implementation/// called &mdash; unless you do it manually yourself. This makes it relatively/// easy to leak memory or other resources./// If you have a type which internally manages/// * an allocation from the global heap (e.g. [`Vec<T>`]),/// * open file descriptors (e.g. [`std::fs::File`]), or/// * any other resource that must be cleaned up (e.g. an `mmap`)/// and relies on its `Drop` implementation to clean up the internal resource,/// then if you allocate that type with a `Bump`, you need to find a new way to/// clean up after it yourself./// Potential solutions are:/// * Using [`bumpalo::boxed::Box::new_in`] instead of [`Bump::alloc`], that///   will drop wrapped values similarly to [`std::boxed::Box`]. Note that this///   requires enabling the `"boxed"` Cargo feature for this crate. **This is///   often the easiest solution.**/// * Calling [`drop_in_place`][drop_in_place] or using///   [`std::mem::ManuallyDrop`][manuallydrop] to manually drop these types./// * Using [`bumpalo::collections::Vec`] instead of [`std::vec::Vec`]./// * Avoiding allocating these problematic types within a `Bump`./// Note that not calling `Drop` is memory safe! Destructors are never/// guaranteed to run in Rust, you can't rely on them for enforcing memory/// safety./// [`Drop`]: https://doc.rust-lang.org/std/ops/trait.Drop.html/// [`Vec<T>`]: https://doc.rust-lang.org/std/vec/struct.Vec.html/// [`std::fs::File`]: https://doc.rust-lang.org/std/fs/struct.File.html/// [drop_in_place]: https://doc.rust-lang.org/std/ptr/fn.drop_in_place.html/// [manuallydrop]: https://doc.rust-lang.org/std/mem/struct.ManuallyDrop.html/// [`bumpalo::collections::Vec`]: collections/vec/struct.Vec.html/// [`std::vec::Vec`]: https://doc.rust-lang.org/std/vec/struct.Vec.html/// [`bumpalo::boxed::Box::new_in`]: boxed/struct.Box.html#method.new_in/// [`std::boxed::Box`]: https://doc.rust-lang.org/std/boxed/struct.Box.html/// ## Example/// // Create a new bump arena./// // Allocate values into the arena./// let forty_two = bump.alloc(42);/// assert_eq!(*forty_two, 42);/// // Mutable references are returned from allocation./// let mut s = bump.alloc("bumpalo");/// *s = "the bump allocator; and also is a buffalo";/// ## Allocation Methods Come in Many Flavors/// There are various allocation methods on `Bump`, the simplest being/// [`alloc`][Bump::alloc]. The others exist to satisfy some combination of/// fallible allocation and initialization. The allocation methods are/// summarized in the following table:///   <thead>///     <tr>///       <th></th>///       <th>Infallible Allocation</th>///       <th>Fallible Allocation</th>///     </tr>///   </thead>///       <th>By Value</th>///       <td><a href="#method.alloc"><code>alloc</code></a></td>///       <td><a href="#method.try_alloc"><code>try_alloc</code></a></td>///       <th>Infallible Initializer Function</th>///       <td><a href="#method.alloc_with"><code>alloc_with</code></a></td>///       <td><a href="#method.try_alloc_with"><code>try_alloc_with</code></a></td>///       <th>Fallible Initializer Function</th>///       <td><a href="#method.alloc_try_with"><code>alloc_try_with</code></a></td>///       <td><a href="#method.try_alloc_try_with"><code>try_alloc_try_with</code></a></td>///   <tbody>///   </tbody>/// ### Fallible Allocation: The `try_alloc_` Method Prefix/// These allocation methods let you recover from out-of-memory (OOM)/// scenarios, rather than raising a panic on OOM./// match bump.try_alloc(MyStruct {/// }) {///     Ok(my_struct) => {///         // Allocation succeeded.///     Err(e) => {///         // Out of memory./// ### Initializer Functions: The `_with` Method Suffix/// Calling one of the generic `…alloc(x)` methods is essentially equivalent to/// the matching [`…alloc_with(|| x)`](?search=alloc_with). However if you use/// `…alloc_with`, then the closure will not be invoked until after allocating/// space for storing `x` on the heap./// This can be useful in certain edge-cases related to compiler optimizations./// When evaluating for example `bump.alloc(x)`, semantically `x` is first put/// on the stack and then moved onto the heap. In some cases, the compiler is/// able to optimize this into constructing `x` directly on the heap, however/// in many cases it does not./// The `…alloc_with` functions try to help the compiler be smarter. In most/// cases doing for example `bump.try_alloc_with(|| x)` on release mode will be/// enough to help the compiler realize that this optimization is valid and/// to construct `x` directly onto the heap./// #### Warning/// These functions critically depend on compiler optimizations to achieve their/// desired effect. This means that it is not an effective tool when compiling/// without optimizations on./// Even when optimizations are on, these functions do not **guarantee** that/// the value is constructed on the heap. To the best of our knowledge no such/// guarantee can be made in stable Rust as of 1.54./// ### Fallible Initialization: The `_try_with` Method Suffix/// The generic [`…alloc_try_with(|| x)`](?search=_try_with) methods behave/// like the purely `_with` suffixed methods explained above. However, they/// allow for fallible initialization by accepting a closure that returns a/// [`Result`] and will attempt to undo the initial allocation if this closure/// returns [`Err`]./// If the inner closure returns [`Ok`], space for the entire [`Result`] remains/// allocated inside `self`. This can be a problem especially if the [`Err`]/// variant is larger, but even otherwise there may be overhead for the/// [`Result`]'s discriminant./// <p><details><summary>Undoing the allocation in the <code>Err</code> case/// always fails if <code>f</code> successfully made any additional allocations/// in <code>self</code>.</summary>/// For example, the following will always leak also space for the [`Result`]/// into this `Bump`, even though the inner reference isn't kept and the [`Err`]/// payload is returned semantically by value:/// let bump = bumpalo::Bump::new();/// let r: Result<&mut [u8; 1000], ()> = bump.alloc_try_with(|| {///     let _ = bump.alloc(0_u8);///     Err(())/// assert!(r.is_err());///</details></p>/// Since [`Err`] payloads are first placed on the heap and then moved to the/// stack, `bump.…alloc_try_with(|| x)?` is likely to execute more slowly than/// the matching `bump.…alloc(x?)` in case of initialization failure. If this/// happens frequently, using the plain un-suffixed method may perform better./// [`Result`]: https://doc.rust-lang.org/std/result/enum.Result.html/// [`Ok`]: https://doc.rust-lang.org/std/result/enum.Result.html#variant.Ok/// ### `Bump` Allocation Limits/// `bumpalo` supports setting a limit on the maximum bytes of memory that can/// be allocated for use in a particular `Bump` arena. This limit can be set and removed with/// [`set_allocation_limit`][Bump::set_allocation_limit]./// The allocation limit is only enforced when allocating new backing chunks for/// a `Bump`. Updating the allocation limit will not affect existing allocations/// or any future allocations within the `Bump`'s current chunk./// #### Example/// assert_eq!(bump.allocation_limit(), None);/// bump.set_allocation_limit(Some(0));/// assert!(bump.try_alloc(5).is_err());/// bump.set_allocation_limit(Some(6));/// assert_eq!(bump.allocation_limit(), Some(6));/// bump.set_allocation_limit(None);/// Because of backwards compatibility, allocations that fail/// due to allocation limits will not present differently than/// errors due to resource exhaustion.// Pointer to the start of this chunk allocation. This footer is always at// the end of the chunk.layout// The layout of this chunk's allocation.prev// Link to the previous chunk.// Note that the last node in the `prev` linked list is the canonical empty// chunk, whose `prev` link points to itself.// Bump allocation finger that is always in the range `self.data..=self`.allocated_bytes// The bytes allocated in all chunks so far, the canonical empty chunk has// a size of 0 and for all other chunks, `allocated_bytes` will be// the allocated_bytes of the current chunk plus the allocated bytes// of the `prev` chunk.EmptyChunkFooter/// A wrapper type for the canonical, statically allocated empty chunk./// For the canonical empty chunk to be `static`, its type must be `Sync`, which/// is the purpose of this wrapper type. This is safe because the empty chunk is/// immutable and never actually modified.EMPTY_CHUNKas_raw_parts// Returns the start and length of the currently allocated region of this// chunk./// Is this chunk the last empty chunk?dealloc_chunk_list// `Bump`s are safe to send between threads because nothing aliases its owned// chunks until you start allocating from it. But by the time you allocate from// it, the returned references to allocations borrow the `Bump` and therefore// prevent sending the `Bump` across threads until the borrows end.is_pointer_aligned_toround_up_toround_up_to_unchecked/// Like `round_up_to` but turns overflow into undefined behavior rather than/// returning `None`.round_down_toround_mut_ptr_down_to/// Same as `round_down_to` but preserves pointer provenance.round_mut_ptr_up_to_uncheckedTYPICAL_PAGE_SIZE// The typical page size these days.// Note that we don't need to exactly match page size for correctness, and it is// okay if this is smaller than the real page size in practice. It isn't worth// the portability concerns and lack of const propagation that dynamically// looking up the actual page size implies.SUPPORTED_ITER_ALIGNMENT// We only support alignments of up to 16 bytes for iter_allocated_chunks.CHUNK_ALIGNFOOTER_SIZE_FOOTER_ALIGN_ASSERTION// Assert that `ChunkFooter` is at most the supported alignment. This will give a// compile time error if it is not the caseMALLOC_OVERHEAD// Maximum typical overhead per allocation imposed by allocators.OVERHEAD// This is the overhead from malloc, footer and alignment. For instance, if// we want to request a chunk of memory that has at least X bytes usable for// allocations (where X is aligned to CHUNK_ALIGN), then we expect that the// after adding a footer, malloc overhead and alignment, the chunk of memory// the allocator actually sets aside for us is X+OVERHEAD rounded up to the// nearest suitable size boundary.FIRST_ALLOCATION_GOAL// The target size of our first allocation, including our overhead. The// available bump capacity will be smaller.DEFAULT_CHUNK_SIZE_WITHOUT_FOOTER// The actual size of the first allocation is going to be a bit smaller than the// goal. We need to make room for the footer, and we also need take the// alignment into account. We're trying to avoid this kind of situation:// https://blog.mozilla.org/nnethercote/2011/08/05/clownshoes-available-in-sizes-2101-and-up/new_size_without_footerNewChunkMemoryDetails/// The memory size and alignment details for a potential new chunklayout_from_size_align/// Wrapper around `Layout::from_size_align` that adds debug assertions.allocation_size_overflow/// Construct a new arena to bump allocate into./// # let _ = bump;/// Attempt to construct a new arena to bump allocate into./// let bump = bumpalo::Bump::try_new();/// # let _ = bump.unwrap();/// Construct a new arena with the specified byte capacity to bump allocate/// into./// let bump = bumpalo::Bump::with_capacity(100);/// ## Panics/// Panics if allocating the initial capacity fails.try_with_capacity/// Attempt to construct a new arena with the specified byte capacity to/// bump allocate into./// Propagates errors when allocating the initial capacity./// # fn _foo() -> Result<(), bumpalo::AllocErr> {/// let bump = bumpalo::Bump::try_with_capacity(100)?;// NB: We don't have constructors as methods on `impl<N> Bump<N>` that return// `Self` because then `rustc` can't infer the `N` if it isn't explicitly// provided, even though it has a default value. There doesn't seem to be a good// workaround, other than putting constructors on the `Bump<DEFAULT>`; even// `std` does this same thing with `HashMap`, for example.with_min_align/// Create a new `Bump` that enforces a minimum alignment./// The minimum alignment must be a power of two and no larger than `16`./// Enforcing a minimum alignment can speed up allocation of objects with/// alignment less than or equal to the minimum alignment. This comes at the/// cost of introducing otherwise-unnecessary padding between allocations of/// objects with alignment less than the minimum./// type BumpAlign8 = bumpalo::Bump<8>;/// let bump = BumpAlign8::with_min_align();/// for x in 0..u8::MAX {///     let x = bump.alloc(x);///     assert_eq!((x as *mut _ as usize) % 8, 0, "x is aligned to 8");/// Panics on invalid minimum alignments.// Because of `rustc`'s poor type inference for default type/const// parameters (see the comment above the `impl Bump` block with no const// `MIN_ALIGN` parameter) and because we don't want to force everyone to// specify a minimum alignment with `Bump::new()` et al, we have a separate// constructor for specifying the minimum alignment.with_min_align_and_capacity/// Create a new `Bump` that enforces a minimum alignment and starts with/// room for at least `capacity` bytes./// let mut bump = BumpAlign8::with_min_align_and_capacity(8 * 100);/// for x in 0..100_u64 {///     bump.iter_allocated_chunks().count(), 1,///     "initial chunk had capacity for all allocations",try_with_min_align_and_capacity/// let mut bump = BumpAlign8::try_with_min_align_and_capacity(8 * 100)?;min_align/// Get this bump arena's minimum alignment./// All objects allocated in this arena get aligned to this value./// let bump2 = bumpalo::Bump::<2>::with_min_align();/// assert_eq!(bump2.min_align(), 2);/// let bump4 = bumpalo::Bump::<4>::with_min_align();/// assert_eq!(bump4.min_align(), 4);/// The allocation limit for this arena in bytes./// let bump = bumpalo::Bump::with_capacity(0);set_allocation_limit/// Set the allocation limit in bytes for this arena.allocation_limit_remaining/// How much headroom an arena has before it hits its allocation/// limit.chunk_fits_under_limit/// Whether a request to allocate a new chunk with a given size for a given/// requested layout will fit under the allocation limit set on a `Bump`.new_chunk_memory_details/// Determine the memory details including final size, alignment and final/// size without footer for a new chunk that would be allocated to fulfill/// an allocation request.new_chunk/// Allocate a new chunk and return its initialized footer./// If given, `layouts` is a tuple of the current chunk size and the/// layout of the allocation request that triggered us to fall back to/// allocating a new chunk of memory./// Reset this bump allocator./// Performs mass deallocation on everything allocated in this arena by/// resetting the pointer into the underlying chunk of memory to the start/// of the chunk. Does not run any `Drop` implementations on deallocated/// objects; see [the top-level documentation](struct.Bump.html) for details./// If this arena has allocated multiple chunks to bump allocate into, then/// the excess chunks are returned to the global allocator./// let mut bump = bumpalo::Bump::new();/// // Allocate a bunch of things.///     for i in 0..100 {///         bump.alloc(i);/// // Reset the arena./// bump.reset();/// // Allocate some new things in the space previously occupied by the/// // original things./// for j in 200..400 {///     bump.alloc(j);/// Allocate an object in this `Bump` and return an exclusive reference to/// it./// Panics if reserving space for `T` fails./// let x = bump.alloc("hello");/// assert_eq!(*x, "hello");try_alloc/// Try to allocate an object in this `Bump` and return an exclusive/// reference to it./// Errors if reserving space for `T` fails./// let x = bump.try_alloc("hello");/// assert_eq!(x, Ok(&mut "hello"));alloc_with/// Pre-allocate space for an object in this `Bump`, initializes it using/// the closure, then returns an exclusive reference to it./// See [The `_with` Method Suffix](#initializer-functions-the-_with-method-suffix) for a/// discussion on the differences between the `_with` suffixed methods and/// those methods without it, their performance characteristics, and when/// you might or might not choose a `_with` suffixed method./// let x = bump.alloc_with(|| "hello");try_alloc_with/// Tries to pre-allocate space for an object in this `Bump`, initializes/// it using the closure, then returns an exclusive reference to it./// let x = bump.try_alloc_with(|| "hello");alloc_try_with/// Pre-allocates space for a [`Result`] in this `Bump`, initializes it using/// the closure, then returns an exclusive reference to its `T` if [`Ok`]./// Iff the allocation fails, the closure is not run./// Iff [`Err`], an allocator rewind is *attempted* and the `E` instance is/// moved out of the allocator to be consumed or dropped as normal./// For caveats specific to fallible initialization, see/// [The `_try_with` Method Suffix](#fallible-initialization-the-_try_with-method-suffix)./// Iff the allocation succeeds but `f` fails, that error is forwarded by value./// Panics if reserving space for `Result<T, E>` fails./// let x = bump.alloc_try_with(|| Ok("hello"))?;/// # Result::<_, ()>::Ok(())try_alloc_try_with/// Tries to pre-allocates space for a [`Result`] in this `Bump`,/// initializes it using the closure, then returns an exclusive reference/// to its `T` if all [`Ok`]./// Iff the closure returns [`Err`], an allocator rewind is *attempted* and/// the `E` instance is moved out of the allocator to be consumed or dropped/// as normal./// Errors with the [`Alloc`](`AllocOrInitError::Alloc`) variant iff/// reserving space for `Result<T, E>` fails./// Iff the allocation succeeds but `f` fails, that error is forwarded by/// value inside the [`Init`](`AllocOrInitError::Init`) variant./// let x = bump.try_alloc_try_with(|| Ok("hello"))?;/// # Result::<_, bumpalo::AllocOrInitError<()>>::Ok(())alloc_slice_copy/// `Copy` a slice into this `Bump` and return an exclusive reference to/// the copy./// Panics if reserving space for the slice fails./// let x = bump.alloc_slice_copy(&[1, 2, 3]);/// assert_eq!(x, &[1, 2, 3]);try_alloc_slice_copy/// Like `alloc_slice_copy`, but does not panic in case of allocation failure./// let x = bump.try_alloc_slice_copy(&[1, 2, 3]);/// assert_eq!(x, Ok(&mut[1, 2, 3] as &mut [_]));/// bump.set_allocation_limit(Some(4));/// let x = bump.try_alloc_slice_copy(&[1, 2, 3, 4, 5, 6]);/// assert_eq!(x, Err(bumpalo::AllocErr)); // too bigalloc_slice_clone/// `Clone` a slice into this `Bump` and return an exclusive reference to/// the clone. Prefer [`alloc_slice_copy`](#method.alloc_slice_copy) if `T` is `Copy`./// #[derive(Clone, Debug, Eq, PartialEq)]/// struct Sheep {///     name: String,/// let originals = [///     Sheep { name: "Alice".into() },///     Sheep { name: "Bob".into() },///     Sheep { name: "Cathy".into() },/// let clones = bump.alloc_slice_clone(&originals);/// assert_eq!(originals, clones);try_alloc_slice_clone/// Like `alloc_slice_clone` but does not panic on failure.alloc_str/// `Copy` a string slice into this `Bump` and return an exclusive reference to it./// Panics if reserving space for the string fails./// let hello = bump.alloc_str("hello world");/// assert_eq!("hello world", hello);try_alloc_str/// Same as `alloc_str` but does not panic on failure./// let hello = bump.try_alloc_str("hello world").unwrap();/// bump.set_allocation_limit(Some(5));/// let hello = bump.try_alloc_str("hello world");/// assert_eq!(Err(bumpalo::AllocErr), hello);alloc_slice_fill_with/// Allocates a new slice of size `len` into this `Bump` and returns an/// exclusive reference to the copy./// The elements of the slice are initialized using the supplied closure./// The closure argument is the position in the slice./// let x = bump.alloc_slice_fill_with(5, |i| 5 * (i + 1));/// assert_eq!(x, &[5, 10, 15, 20, 25]);alloc_slice_try_fill_with/// exclusive reference to the copy, failing if the closure return an Err./// let x: Result<&mut [usize], ()> = bump.alloc_slice_try_fill_with(5, |i| Ok(5 * i));/// assert_eq!(x, Ok(bump.alloc_slice_copy(&[0, 5, 10, 15, 20])));/// let x: Result<&mut [usize], ()> = bump.alloc_slice_try_fill_with(///    5,///    |n| if n == 2 { Err(()) } else { Ok(n) }/// assert_eq!(x, Err(()));try_alloc_slice_fill_with/// let x = bump.try_alloc_slice_fill_with(5, |i| 5 * (i + 1));/// assert_eq!(x, Ok(&mut[5usize, 10, 15, 20, 25] as &mut [_]));/// let x = bump.try_alloc_slice_fill_with(10, |i| 5 * (i + 1));/// assert_eq!(x, Err(bumpalo::AllocErr));alloc_slice_fill_copy/// All elements of the slice are initialized to `value`./// let x = bump.alloc_slice_fill_copy(5, 42);/// assert_eq!(x, &[42, 42, 42, 42, 42]);try_alloc_slice_fill_copy/// Same as `alloc_slice_fill_copy` but does not panic on failure.alloc_slice_fill_clone/// Allocates a new slice of size `len` slice into this `Bump` and return an/// All elements of the slice are initialized to `value.clone()`./// let s: String = "Hello Bump!".to_string();/// let x: &[String] = bump.alloc_slice_fill_clone(2, &s);/// assert_eq!(x.len(), 2);/// assert_eq!(&x[0], &s);/// assert_eq!(&x[1], &s);try_alloc_slice_fill_clone/// Like `alloc_slice_fill_clone` but does not panic on failure.alloc_slice_fill_iter/// The elements are initialized using the supplied iterator./// Panics if reserving space for the slice fails, or if the supplied/// iterator returns fewer elements than it promised./// let x: &[i32] = bump.alloc_slice_fill_iter([2, 3, 5].iter().cloned().map(|i| i * i));/// assert_eq!(x, [4, 9, 25]);alloc_slice_try_fill_iter/// exclusive reference to the copy, failing if the iterator returns an Err./// ## Examples/// let x: Result<&mut [i32], ()> = bump.alloc_slice_try_fill_iter(///    [2, 3, 5].iter().cloned().map(|i| Ok(i * i))/// assert_eq!(x, Ok(bump.alloc_slice_copy(&[4, 9, 25])));///    [Ok(2), Err(()), Ok(5)].iter().cloned()try_alloc_slice_fill_iter/// Allocates a new slice of size `iter.len()` slice into this `Bump` and return an/// exclusive reference to the copy. Does not panic on failure./// let x: &[i32] = bump.try_alloc_slice_fill_iter([2, 3, 5]///     .iter().cloned().map(|i| i * i)).unwrap();alloc_slice_fill_default/// All elements of the slice are initialized to [`T::default()`]./// [`T::default()`]: https://doc.rust-lang.org/std/default/trait.Default.html#tymethod.default/// let x = bump.alloc_slice_fill_default::<u32>(5);/// assert_eq!(x, &[0, 0, 0, 0, 0]);try_alloc_slice_fill_default/// Like `alloc_slice_fill_default` but does not panic on failure.alloc_layout/// Allocate space for an object with the given `Layout`./// The returned pointer points at uninitialized memory, and should be/// initialized with/// [`std::ptr::write`](https://doc.rust-lang.org/std/ptr/fn.write.html)./// Panics if reserving space matching `layout` fails.try_alloc_layout/// Attempts to allocate space for an object with the given `Layout` or else returns/// an `Err`./// Errors if reserving space matching `layout` fails.try_alloc_layout_fastchunk_capacity/// Gets the remaining capacity in the current chunk (in bytes)./// let bump = Bump::with_capacity(100);/// let capacity = bump.chunk_capacity();/// assert!(capacity >= 100);alloc_layout_slow/// Slow path allocation for when we need to allocate a new chunk from the/// parent bump set because there isn't enough room in our current chunk.iter_allocated_chunksChunkIter/// Returns an iterator over each chunk of allocated memory that/// this arena has bump allocated into./// The chunks are returned ordered by allocation time, with the most/// recently allocated chunk being returned first, and the least recently/// allocated chunk being returned last./// The values inside each chunk are also ordered by allocation time, with/// the most recent allocation being earlier in the slice, and the least/// recent allocation being towards the end of the slice./// Because this method takes `&mut self`, we know that the bump arena/// reference is unique and therefore there aren't any active references to/// any of the objects we've allocated in it either. This potential aliasing/// of exclusive references is one common footgun for unsafe code that we/// don't need to worry about here./// However, there could be regions of uninitialized memory used as padding/// between allocations, which is why this iterator has items of type/// `[MaybeUninit<u8>]`, instead of simply `[u8]`./// The only way to guarantee that there is no padding between allocations/// or within allocated objects is if all of these properties hold:/// 1. Every object allocated in this arena has the same alignment,///    and that alignment is at most 16./// 2. Every object's size is a multiple of its alignment./// 3. None of the objects allocated in this arena contain any internal///    padding./// If you want to use this `iter_allocated_chunks` method, it is *your*/// responsibility to ensure that these properties hold before calling/// `MaybeUninit::assume_init` or otherwise reading the returned values./// Finally, you must also ensure that any values allocated into the bump/// arena have not had their `Drop` implementations called on them,/// e.g. after dropping a [`bumpalo::boxed::Box<T>`][crate::boxed::Box]./// // Allocate a bunch of `i32`s in this bump arena, potentially causing/// // additional memory chunks to be reserved./// for i in 0..10000 {///     bump.alloc(i);/// // Iterate over each chunk we've bump allocated into. This is safe/// // because we have only allocated `i32`s in this arena, which fulfills/// // the above requirements./// for ch in bump.iter_allocated_chunks() {///     println!("Used a chunk that is {} bytes long", ch.len());///     println!("The first byte is {:?}", unsafe {///         ch[0].assume_init()/// // Within a chunk, allocations are ordered from most recent to least/// // recent. If we allocated 'a', then 'b', then 'c', when we iterate/// // through the chunk's data, we get them in the order 'c', then 'b',/// // then 'a'./// bump.alloc(b'a');/// bump.alloc(b'b');/// bump.alloc(b'c');/// assert_eq!(bump.iter_allocated_chunks().count(), 1);/// let chunk = bump.iter_allocated_chunks().nth(0).unwrap();/// assert_eq!(chunk.len(), 3);/// // Safe because we've only allocated `u8`s in this arena, which/// // fulfills the above requirements.///     assert_eq!(chunk[0].assume_init(), b'c');///     assert_eq!(chunk[1].assume_init(), b'b');///     assert_eq!(chunk[2].assume_init(), b'a');iter_allocated_chunks_rawChunkRawIter/// Returns an iterator over raw pointers to chunks of allocated memory that/// This is an unsafe version of [`iter_allocated_chunks()`](Bump::iter_allocated_chunks),/// with the caller responsible for safe usage of the returned pointers as/// well as ensuring that the iterator is not invalidated by new/// allocations./// Allocations from this arena must not be performed while the returned/// iterator is alive. If reading the chunk data (or casting to a reference)/// the caller must ensure that there exist no mutable references to/// previously allocated data./// In addition, all of the caveats when reading the chunk data from/// [`iter_allocated_chunks()`](Bump::iter_allocated_chunks) still apply./// Calculates the number of bytes currently allocated across all chunks in/// this bump arena./// If you allocate types of different alignments or types with/// larger-than-typical alignment in the same arena, some padding/// bytes might get allocated in the bump arena. Note that those padding/// bytes will add to this method's resulting sum, so you cannot rely/// on it only counting the sum of the sizes of the things/// you've allocated in the arena./// The allocated bytes do not include the size of bumpalo's metadata,/// so the amount of memory requested from the Rust allocator is higher/// than the returned value./// let _x = bump.alloc_slice_fill_default::<u32>(5);/// let bytes = bump.allocated_bytes();/// assert!(bytes >= core::mem::size_of::<u32>() * 5);allocated_bytes_including_metadata/// Calculates the number of bytes requested from the Rust allocator for this `Bump`./// This number is equal to the [`allocated_bytes()`](Self::allocated_bytes) plus/// the size of the bump metadata.is_last_allocationshrinkgrow/// An iterator over each chunk of allocated memory that/// an arena has bump allocated into./// The chunks are returned ordered by allocation time, with the most recently/// allocated chunk being returned first./// The values inside each chunk are also ordered by allocation time, with the most/// recent allocation being earlier in the slice./// This struct is created by the [`iter_allocated_chunks`] method on/// [`Bump`]. See that function for a safety description regarding reading from the returned items./// [`Bump`]: struct.Bump.html/// [`iter_allocated_chunks`]: struct.Bump.html#method.iter_allocated_chunksfooter/// An iterator over raw pointers to chunks of allocated memory that this/// arena has bump allocated into./// See [`ChunkIter`] for details regarding the returned chunks./// This struct is created by the [`iter_allocated_chunks_raw`] method on/// [`Bump`]. See that function for a safety description regarding reading from/// the returned items./// [`iter_allocated_chunks_raw`]: struct.Bump.html#method.iter_allocated_chunks_rawoomchunk_footer_is_five_words// Uses private type `ChunkFooter`.// Uses private `DEFAULT_CHUNK_SIZE_WITHOUT_FOOTER` and `FOOTER_SIZE`.test_realloc// Uses private `alloc` module.invalid_read// Uses our private `alloc` module.// NB: Only tests which require private types, fields, or methods should be in// here. Anything that can just be tested via public API surface should be in// `bumpalo/tests/all/*`.Probeenable_cfg/// Enables `--cfg feature` for the current build.BlockTypeBlockIterBitConcat/// The result of/// [`BitsExt::bit_concat`](../trait.BitsExt.html#method.bit_concat)./// The resulting bit vector adapter concatenates the bits of the two underlying/// bit-vector-likes.bit_lenget_blockimpl_index_from_bitsimpl_bit_sliceable_adapteradapterBitSliceAdapterbit_sliceBitSliceableget_masked_blockBitFill/// Emulates a constant-valued bit-vector of a given size.get_raw_blockget_bitszeroes/// Constructs a compact bit-vector-like of `len` 0s.ones/// Constructs a compact bit-vector-like of `len` 1s.BitsMutrange_compat/// An adapter that turns any implementation of `Bits` into a slice./// This is likely less efficient than [`BitSlice`]./// [`BitSlice`]: ../struct.BitSlice.html/// Creates a new slice adaptor from the given bit-vector-like./// Takes the index of the start bit, and the length to slice./// Out of bounds if `start + len > bits.bit_len()`.reslice/// Reslices an existing slice adapter, by value./// Takes the index of the start bit, relative to the indexing/// of the adapter./// Out of bounds if `start + len > self.bit_len()`.reslice_ref/// Reslices an existing slice adapter, by reference.set_bitset_blockset_bitsget_block_addr// For a slice starting at `start`, of length `len`, finds the parameters// for extracting the `position`th block. The parameters are the bit position// of the start of the block, and the number of bits in the block.BitsPush_markerBoolAdapter/// Adapts a sequence of `bool`s (*e.g.,* `&[bool]`) to emulate a bit/// vector./// In particular, this adapter implements [`Bits`], [`BitsMut`], and/// [`BitsPush`] as appropriate. It implement `PartialEq<T>` for all/// `T: Bits<Block=Block>`. It does not, however, implement slicing, so/// slice before you adapt./// Note that a bare `Vec<bool>` or `&[bool]` already implements [`Bits`],/// etc., with a `Block` type of `u8`. This means that it is only/// compatible with other `u8`-based bit vectors. `BoolAdapter` is instead/// parametrized by the block type, so it works with bit vectors, slices,/// and adapters of any uniform block type./// [`Bits`]: ../trait.Bits.html/// [`BitsMut`]: ../trait.BitsMut.html/// [`BitsPush`]: ../trait.BitsPush.html/// Creates a new `BoolAdapter` from an underlying sequence of `bool`s./// Note that the `BoolAdapter` derefs to the underlying `bool` sequence./// use bv::BitSliceable;/// use bv::adapter::BoolAdapter;/// let array = [0b101usize];/// let bv1 = BoolAdapter::new(vec![true, false, true]);/// let bv2 = array.bit_slice(0..3);/// assert_eq!( bv1, bv2 );/// Gets the underlying `bool` sequence object back out of a `BoolAdapter`.impl_for_bool_adapterpush_bitpop_bitBitNot/// The result of [`BitsExt::bit_not`](../trait.BitsExt.html#method.bit_not)./// The resulting bit vector adapter *not*s the bits of the underlying/// bit-vector-like.BitBinOp/// The result of [`BitsExt::bit_and`](../trait.BitsExt.html#method.bit_and)./// The resulting bit vector adapter *and*s the bits of the two underlying/// The result of [`BitsExt::bit_or`](../trait.BitsExt.html#method.bit_or)./// The resulting bit vector adapter *or*s the bits of the two underlying/// The result of [`BitsExt::bit_xor`](../trait.BitsExt.html#method.bit_xor)./// The resulting bit vector adapter *xor*s the bits of the two underlyingfunBitZip/// The result of [`BitsExt::bit_zip`](../trait.BitsExt.html#method.bit_zip).op1op2/// Used to store the two operands to a bitwise logical operation on/// `Bits`es, along with the length of the result (min the length of/// the operands). (Note that `len` is derivable from `op1` and `op2`,/// but it probably makes sense to cache it.)bit1bit2block1block2impl_bits_bin_opbit_slice_adapterlogicbit_fillbit_concatbool_adapterBitsExtBitVecassert_0001simple_notsimple_andand_with_same_offsetand_with_different_offsetslice_adapterslice_adapter_mutationmixed_equality//! Lazy bit vector adapters.//! This module defines adapters for dealing with bit vectors and other//! types that implement [`Bits`]. It also defines the adaptors that//! are returned by methods of the extension trait [`BitsExt`].//! [`Bits`]: ../trait.Bits.html//! [`BitsExt`]: ../trait.BitsExt.htmlimpl_traits_for_array14181920212223252627282930315121024204840968_19216_38432_76865_536131_072262_144524_2881_048_576//! This module impls the `Bits`, `BitsMut` and `BitSliceable` traits//! for fixed-sized arrays of `BlockType`s.BitSliceBitSliceMutstoragealign_blockpush_blockInnerclone_resize// Precondition: The first `len` blocks of `self` are initialized an// in-bounds.// Precondition: `index` is in bounds. This implies that `self.0.is_some()`.// Invariant: self.invariant()/// A bit-vector, akin to `Vec<bool>` but packed./// `BitVec` stores its bits in an array of `Block`s, where `Block` is given as a type parameter/// that defaults to `usize`. You might find that a different `Block` size is preferable, but/// only benchmarking will tell./// Several useful methods are exported in traits, rather than inherent to `BitVec`. In/// particular, see:///   - [`Bits::get_bit`](trait.Bits.html#method.get_bit) and///   - [`BitsMut::set_bit`](trait.BitsMut.html#method.set_bit)./// You will likely want to `use` these traits (or `bv::*`) when you use `BitVec`./// use bv::BitVec;/// let mut bv: BitVec = BitVec::new();/// assert_eq!(bv.len(), 0);/// bv.push(true);/// bv.push(false);/// assert_eq!(bv.len(), 3);/// assert_eq!(bv[0], true);/// assert_eq!(bv[1], false);/// assert_eq!(bv[2], true);/// Creates a new, empty bit-vector with a capacity of one block./// Creates a new, empty bit-vector with the given bit capacity./// let mut bv: BitVec<u16> = BitVec::with_capacity(20);/// assert_eq!(bv.capacity(), 32);with_block_capacity/// Creates a new, empty bit-vector with the given block capacity./// let mut bv: BitVec<u16> = BitVec::with_block_capacity(8);/// assert_eq!(bv.capacity(), 128);new_fill/// Creates a new bit-vector of size `len`, filled with all 0s or 1s/// depending on `value`./// use bv::*;/// let mut bv: BitVec<u64> = BitVec::new_fill(false, 100);/// assert_eq!( bv.get(0), false );/// assert_eq!( bv.len(), 100 );new_block_fill/// Creates a new bit-vector filled with `value`, made up of `nblocks` blocks.from_blockreallocate// Reallocates to have the given capacity./// Creates a new `BitVec` from any value implementing the `Bits` trait with/// the same block type./// The number of bits in the bit-vector./// assert_eq!(bv.len(), 1);/// assert_eq!(bv.len(), 2);/// The number of blocks used by this bit-vector./// assert_eq!( bv.block_len(), 2 );/// The capacity of the bit-vector in bits./// This is the number of bits that can be held without reallocating./// let bv: BitVec<u64> = bit_vec![false; 100];/// assert_eq!( bv.capacity(), 128 );/// Note that this example holds because `bit_vec!` does not introduces excess/// capacity.block_capacity/// The capacity of the bit-vector in blocks./// let bv: BitVec<u64> = BitVec::with_capacity(250);/// assert_eq!( bv.len(), 0 );/// assert_eq!( bv.block_len(), 0 );/// assert_eq!( bv.capacity(), 256 );/// assert_eq!( bv.block_capacity(), 4 );/// Adjust the capacity to hold at least `additional` additional bits./// May reserve more to avoid frequent reallocations./// let mut bv: BitVec<u32> = bit_vec![ false, false, true ];/// assert_eq!( bv.capacity(), 32 );/// bv.reserve(100);/// assert!( bv.capacity() >= 103 );block_reserve/// Adjust the capacity to hold at least `additional` additional blocks./// assert_eq!( bv.block_capacity(), 1 );/// bv.block_reserve(3);/// assert!( bv.block_capacity() >= 4 );/// bv.reserve_exact(100);block_reserve_exact/// Adjusts the capacity to at least `additional` blocks beyond those used./// bv.block_reserve_exact(3);/// let mut bv: BitVec<u8> = BitVec::new();/// for i in 0 .. 23 {///     bv.push(i % 3 == 0);/// assert!(bv.capacity() >= 24);/// bv.shrink_to_fit();/// assert_eq!(bv.capacity(), 24);/// Converts the vector into `Box<[Block]>`./// Note that this will *not* drop any excess capacity./// let bv: BitVec<u8> = bit_vec![true, true, false, false, true, false, true, false];/// let bs = bv.into_boxed_slice();/// assert!( bs.len() >= 1 );/// assert_eq!( bs[0], 0b01010011 );/// Shortens the vector, keeping the first `len` elements and dropping the rest./// If `len` is greater than the vector's current length, this has no effect./// Note that this method has no effect on the capacity of the bit-vector./// let mut v1: BitVec = bit_vec![ true, true, false, false ];/// let     v2: BitVec = bit_vec![ true, true ];/// assert_ne!( v1, v2 );/// v1.truncate(2);/// assert_eq!( v1, v2 );/// Resizes the bit-vector, filling with `value` if it has to grow./// let     v1: BitVec = bit_vec![ true, true, false, false ];/// let mut v2: BitVec = bit_vec![ true, true ];/// let mut v3: BitVec = bit_vec![ true, true ];/// v2.resize(4, false);/// v3.resize(4, true);/// assert_ne!( v1, v3 );/// Gets a slice to a `BitVec`./// let bv: BitVec = bit_vec![true, false, true];/// let slice = bv.as_slice();/// assert_eq!( slice.len(), 3 );/// assert_eq!( slice[0], true );/// assert_eq!( slice[1], false );/// assert_eq!( slice[2], true );/// Gets a mutable slice to a `BitVec`./// let mut bv: BitVec = bit_vec![true, false, true];///     let mut slice = bv.as_mut_slice();///     slice.set_bit(1, true);/// assert_eq!( bv[1], true );/// Gets the value of the bit at the given position./// This is an alias for [`Bits::get_bit`]./// If the position is out of bounds./// [`Bits::get_bit`]: ../trait.Bits.html#get_bit.method/// Sets the value of the bit at the given position./// This is an alias for [`BitsMut::set_bit`]./// [`BitsMut::set_bit`]: ../trait.BitsMut.html#set_bit.method/// Adds the given `bool` to the end of the bit-vector./// let mut bv0: BitVec = bit_vec![ ];/// let     bv1: BitVec = bit_vec![ true ];/// let     bv2: BitVec = bit_vec![ true, false ];/// let     bv3: BitVec = bit_vec![ true, false, true ];/// assert_ne!( bv0, bv1 );/// assert_ne!( bv0, bv2 );/// assert_ne!( bv0, bv3 );/// bv0.push(true);/// assert_eq!( bv0, bv1 );/// bv0.push(false);/// assert_eq!( bv0, bv2 );/// assert_eq!( bv0, bv3 );/// Removes and returns the last element of the bit-vector, or `None` if empty./// let mut bv: BitVec = bit_vec![ true, false, true ];/// assert_eq!( bv.pop(), Some(true) );/// assert_eq!( bv.pop(), Some(false) );/// assert_eq!( bv.pop(), None );/// Removes all elements from the bit-vector./// Does not change the capacity./// let mut bv: BitVec<u32> = bit_vec![ true ];/// assert_eq!( bv.len(), 1 );/// bv.clear();/// Does the bit-vector have no elements?/// assert!( !bv.is_empty() );/// assert!(  bv.is_empty() );bit_slicingclear_and_is_emptypush_bit_and_pop_bitset_through_sliceset_bits_one_block_fastpathfrom_bits_slicedisequality/// An iterator over the blocks of a bit-vector-like./// Creates a new block iterator from a `Bits` instance./// Returns the number of *bits* remaining in the iterator.cmp_block_itereq_itersamedifferentdifferent_lengths// Invariant: pos <= bits.block_len()BitsMutExtBitSliceableMutbit_vecarray_n_implsprims//! The main type exported by the library, [`BitVec`], is a packed,//! growable bit-vector. Its API mirrors that of `Vec` where reasonable.//! The library also defines slice operations that return//! [`BitSlice`] or [`BitSliceMut`], akin to Rust’s array slices but for//! bit-vectors. A common API to bit-vectors and bit-slices is provided by the [`Bits`],//! [`BitsMut`], and [`BitsPush`] traits. These traits also allow treating a variety//! of other types as bit vectors://!  - all primitive unsigned integer types (*e.g.,* `u64`, `u32`),//!  - vectors and slices thereof (*e.g.*, `Vec<usize>`, `&[u8]`, `[u16; 4]`), and//!  - unpacked vectors and arrays of `bool` (*e.g.*, `[bool; 15]`).//! Additionally, the [`BitsExt`] trait provides adapter methods including//! bit-wise logic and concatenation. These adapters work for all types that implement//! [`Bits`].//! A first example with [`BitVec`]://! use bv::BitVec;//! let mut bv1: BitVec = BitVec::new_fill(false, 50);//! let mut bv2: BitVec = BitVec::new_fill(false, 50);//! assert_eq!(bv1, bv2);//! bv1.set(49, true);//! assert_ne!(bv1, bv2);//! assert_eq!(bv1.pop(), Some(true));//! assert_eq!(bv2.pop(), Some(false));//! Adapters, from [`BitsExt`] and [`adapter`]://! use bv::*;//! use bv::adapter::BoolAdapter;//! // Here, we use an `&[u16]` as a bit vector, and we adapt a//! // `Vec<bool>` as well.//! let array = &[0b1100u16];//! let vec   = BoolAdapter::new(vec![false, true, false, true]);//! // `xor` is not a `BitVec`, but a lazy adapter, thus, we can index//! // it or efficiently compare it to another bit vector, without//! // allocating.//! let xor   = array.bit_xor(&vec);//! assert_eq!( xor, bit_vec![false, true, true, false] );//! This function performs a three-way *or*, returning a `BitVec` without//! allocating an intermediate result://! use bv::{Bits, BitsExt, BitVec};//! fn three_way_or<T, U, V>(bv1: T, bv2: U, bv3: V) -> BitVec<T::Block>//!     where T: Bits,//!           U: Bits<Block = T::Block>,//!           V: Bits<Block = T::Block> {//!     bv1.into_bit_or(bv2).into_bit_or(bv3).to_bit_vec()//! It’s [on crates.io](https://crates.io/crates/bv), so you can add//! bv = "0.11.1"//! to your `Cargo.toml` and//! extern crate bv;//! to your crate root.//! This crate supports Rust version 1.31 and newer.//! [`BitVec`]: struct.BitVec.html//! [`Bits`]: trait.Bits.html//! [`BitsMut`]: trait.BitsMut.html//! [`BitsPush`]: trait.BitsPush.html//! [`BitSlice`]: struct.BitSlice.html//! [`BitSliceMut`]: struct.BitSliceMut.html//! [`BitsExt`]: trait.BitsExt.html//! [`adapter`]: adapter/index.html/// Like `vec!` but for [`BitVec`](struct.BitVec.html)./// The `bit_vec!` macro creates a `BitVec` literal. It takes two forms:///   - A single `bool`, followed by a semicolon and number of times to repeat. This is///     equivalent to a call to [`BitVec::new_fill`](struct.BitVec.html#method.new_fill).///   - A sequence of comma-separated `bool`s; this creates a `BitVec` and pushes each `bool` in///     turn./// # #[macro_use] extern crate bv;///     let mut bv1: BitVec = bit_vec![ true; 3 ];///     let     bv2: BitVec = bit_vec![ true, false, true ];///     assert_ne!(bv1, bv2);///     bv1.set_bit(1, false);///     assert_eq!(bv1, bv2);bit_vec_macro_allows_trailing_commatype_1_hygiene// Implements Index for any type that implements Bits.impl_bits_primu128_featureget_inclusive_boundsaligned_blocksSliceSpan// This struct describes the span of a `BitSlice` or `BitSliceMut`, starting// with of offset of `offset` bits into the array of blocks, and including// `len` bits.BlockAddressFullBlockAtSomeBitsAt// This struct describes the result of an indexing operation against a span.// We can give back a full, aligned block, or an arbitrary sequence of bits.from_block_lenfind_blockfind_bitsfind_bit/// A slice of a bit-vector; akin to `&'a [bool]` but packed./// let array = [0b00110101u16];/// let mut slice = array.bit_slice(..8);/// slice = slice.bit_slice(1..8);/// assert_eq!( slice[0], false );/// assert_eq!( slice[1], true );/// A mutable slice of a bit-vector; akin to `&'a mut [bool]` but packed./// let mut array = [0b00110101u16];///     let mut slice = BitSliceMut::from_slice(&mut array);///     assert_eq!( slice[0], true );///     assert_eq!( slice[1], false );///     slice.set_bit(0, false);/// assert_eq!( array[0], 0b00110100u16 );/// Creates a `BitSlice` from an array slice of blocks./// The size is always a multiple of/// `Block::nbits()`. If you want a different size, slice./// use bv::{BitSlice, BitSliceable};/// let v = vec![0b01010011u16, 0u16];/// let slice = BitSlice::from_slice(&v).bit_slice(..7);/// assert_eq!( slice.len(), 7 );/// assert_eq!( slice[2], false );from_raw_parts/// Creates a `BitSlice` from a pointer to its data, an offset where the bits start, and/// the number of available bits./// This is unsafe because the size of the passed-in buffer is/// not checked. It must hold at least `offset + len` bits or the resulting behavior is/// undefined./// # Precondition///   - the first `Block::ceil_div_nbits(len + offset)` words of `bits` safe///     to read./// The number of bits in the slice./// let bv: BitVec = bit_vec![ true, true, false, true ];/// let slice = bv.bit_slice(..3);/// assert_eq!( bv.len(), 4 );/// Returns whether there are no bits in the slice./// let slice0 = bv.bit_slice(3..3);/// let slice1 = bv.bit_slice(3..4);/// assert!(  slice0.is_empty() );/// assert!( !slice1.is_empty() );/// Creates a `BitSliceMut` from a mutable array slice of blocks./// The size is always a multiple of `Block::nbits()`. If you want a different size,/// Creates a `BitSliceMut` from a pointer to its data, an offset where the bits start, and///     to read and write.as_bit_slice/// Converts a mutable bit slice to immutable.get_raw_bit// Gets `bits[offset + position]`.// Precondition: Bits are in bounds.set_raw_bit// Sets `bits[offset + position]`// Precondition: Bit is in bounds.bit_slice_from_slicebit_slice_indexbit_slice_update_across_blocksdebug_for_bit_slicerange_to_inclusive// Invariant://   aligned_blocks == if offset == 0 { Block::ceil_div_nbits(len) } else { 0 }nbits/// The number of bits in a block.div_nbits/// Returns `index / Self::nbits()`, computed by shifting./// This is intended for converting a bit address into a block/// address, which is why it takes `u64` and returns `usize`./// There is no check that the result actually fits in a `usize`,/// so this should only be used when `index` is already known to/// be small enough.checked_div_nbits/// address, which is why it takes `u64` and returns `usize`. It can only fail (returning/// `None`) if `usize` is 32 bits.ceil_div_nbits/// Returns `index / Self::nbits()` rounded up, computed by shifting./// This is intended for converting a bit size into a block/// size, which is why it takes `u64` and returns `usize`.checked_ceil_div_nbitsmod_nbits/// Returns `index % Self::nbits()`, computed by masking./// This is intended for converting a bit address into a bit offset/// within a block, which is why it takes `u64` and returns `usize`.mul_nbits/// Returns `index * Self::nbits()`, computed by shifting./// This is intended for converting a block address into a bit address,/// which is why it takes a `usize` and returns a `u64`.block_bits/// The number of bits in the block at `position`, given a total bit length/// of `len`./// This will be `Self::nbits()` for all but the last block, for which it may/// be less./// `position * Self::nbits() <= len`, or the block doesn't exist and the result/// is undefined.lg_nbits/// Log-base-2 of the number of bits in a block.lg_nbits_mask/// Mask with the lowest-order `lg_nbits()` set.low_mask/// The bit mask consisting of `Self::nbits() - element_bits` zeroes/// followed by `element_bits` ones./// The default implementation has a branch, but should be overrided with/// a branchless algorithm if possible./// `element_bits <= Self::nbits()`nth_mask/// The bit mask with the `bit_index`th bit set./// Bits are indexed in little-endian style based at 0./// `bit_index < Self::nbits()`/// Extracts the value of the `bit_index`th bit./// Panics if `bit_index` is out of bounds.with_bit/// Functionally updates the value of the `bit_index`th bit to `bit_value`./// Extracts `len` bits starting at bit offset `start`./// Panics of the bit span is out of bounds.with_bits/// Functionally updates `len` bits to `value` starting at offset `start`.ceil_lg/// Returns the smallest number `n` such that `2.pow(n) >= self`.floor_lg/// Returns the largest number `n` such that `2.pow(n) <= self`.wrapping_shl/// A shift-left operation that does not overflow.wrapping_sub/// A subtraction operation that does not overflow.leading_zeros/// Returns the number of leading zero bits in the given number.to_usize/// Converts the number to a `usize`, if it fits./// Returns 0./// Returns 1.// Methods for getting and setting bits./// Interface to primitive bit storage./// Types implementing this trait can be used as the blocks of a bit-vector.if_then_elseif_thenIfThenElseimpl_block_typeblock_index/// The index of the block containing the bit in question.bit_offset/// The position of the bit in question within its block./// Represents the address of a bit, broken into a block component/// and a bit offset component./// Creates an `Address` for the given bit index for storage in/// block type `Block`./// Panics if `bit_index` divided by the block size doesn’t fit in a/// `usize`.//    /// Converts an `Address` back into a raw bit index.//    /////    /// This method and `new` should be inverses.//    #[inline]//    pub fn bit_index<Block: BlockType>(&self) -> u64 {//        Block::mul_nbits(self.block_index) + self.bit_offset as u64//    }TestResult/// The type of the slice produced./// Slices or re-slices the given object./// let array = [0b01010011u16];/// let slice = BitSlice::from_slice(&array);/// assert_eq!( slice.bit_slice(1..3), slice.bit_slice(4..6) );/// assert_eq!( slice.bit_slice(1..3), slice.bit_slice(6..8) );/// assert_ne!( slice.bit_slice(2..4), slice.bit_slice(6..8) );/// assert_eq!( slice.bit_slice(2..4), slice.bit_slice(7..9) );/// Types that support slicing by ranges./// Note that the [`bit_slice`] method takes `self` by value, which allows/// the `Slice` associated type to refer to the lifetime of `Self` in impls/// for borrowed types. For example, the impl for `&'a BitVec<u32>` has a/// `Slice` type of `BitSlice<'a, u32>`./// [`bit_slice`]: #tymethod.bit_slicebit_slice_mut/// An alias for/// [`BitSliceable::bit_slice`](trait.BitSliceable.html#tymethod.bit_slice)./// This method provides no additional functionality over `bit_slice`./// However, it can be used to force auto-ref to choose a `Self` type/// that implements `BitSliceableMut`./// Types that produce mutable slices./// Do not implement this trait; there is a blanket impl for all/// [`BitSliceable`] types whose associated `Slice` types implement `BitsMut`./// [`BitSliceable`]: trait.BitSliceable.html/// The underlying block type used to store the bits of the vector./// The length of the slice in bits./// The length of the slice in blocks./// Gets the bit at `position`/// The default implementation calls `get_block` and masks out the/// correct bit./// Panics if `position` is out of bounds./// Gets the block at `position`, masked as necessary./// The bits are laid out `Block::nbits()` per block, with the notional/// zeroth bit in the least significant position. If `self.bit_len()` is/// not a multiple of `Block::nbits()` then the last block will/// contain extra zero bits that are not part of the bit vector./// The default implementation calls [`get_raw_block`](#method.get_raw_block),/// but you can override with something more efficient, for example if masking/// is unnecessary./// Gets the block at `position`, without masking./// The default implementation of this method just delegates to [`get_block`](#method/// .get_block), which means it in fact does mask out extraneous bits. However, particular/// implementors may override this method to provide a more efficient implementation when/// one is possible./// Gets `count` bits starting at bit index `start`, interpreted as a/// little-endian integer./// Panics if the bit span goes out of bounds.to_bit_vec/// Copies the bits into a new allocated [`BitVec`]./// [`BitVec`]: ../struct.BitVec.html/// Read-only bit vector operations./// Minimal complete definition is:///   - [`bit_len`] and///   - [`get_block`] or [`get_bit`]./// Note that [`get_block`] in terms of [`get_bit`] is inefficient, and thus/// you should implement [`get_block`] directly if possible./// [`bit_len`]: #method.bit_len/// [`get_bit`]: #method.get_bit/// [`get_block`]: #method.get_block/// Gets a block using `get_raw_block` and then masks it appropriately./// This can be used to implement `get_block` in terms of `get_raw_block`.// This is bogus/// Concatenates two bit vectors, with the bits of `self` followed by the bits/// of `other`.into_bit_concat/// Consumes `self`.bit_pad/// Pads `self` with 0s on the right to reach at least `len` bits in length./// If `self` is already long enough, the length is unchanged.into_bit_padbit_not/// Returns an object that inverts the values of all the bits in `self`.into_bit_not/// Returns an object that lazily computes the bit-wise conjunction/// of two bit-vector-likes./// If the lengths of the operands differ, the result will have/// the minimum of the two.into_bit_and/// Returns an object that lazily computes the bit-wise disjunctioninto_bit_or/// Returns an object that lazily computes the bit-wise xor of twointo_bit_xorbit_zip/// Returns an object that lazily zips a function over the blocks of/// two bit-vector-like./// The third parameter to the zipping function `fun` is the number of/// bits in the block currently being processed. (This will be/// `Self::Block::nbits()` for all but the last block.)into_bit_zip/// Extension trait for adapter operations on bit slices./// The methods return lazy adapter objects that query the underlying bit vectors/// and perform operations as needed. To eagerly evaluate a result, copy/// it into a vector using the [`Bits::to_bit_vec`] method, as in the example below./// This trait is currently `pub use`d from the [`adapter`] module, but that alias/// is deprecated./// [`Bits::to_bit_vec`]: trait.Bits.html#method.to_bit_vec/// [`adapter`]: adapter/index.html/// let bv1: BitVec = bit_vec![false, false, true, true];/// let bv2: BitVec = bit_vec![false, true, false, true];/// let and_bv = bv1.bit_and(&bv2);/// assert_eq!( and_bv[0], false );/// assert_eq!( and_bv[1], false );/// assert_eq!( and_bv[2], false );/// assert_eq!( and_bv[3], true );/// let bv3 = and_bv.to_bit_vec();/// assert_eq!( bv3, bit_vec![false, false, false, true] );/// Sets the bit at `position` to `value`./// The default implementation uses `get_raw_block` and `set_block`./// Sets the block at `position` to `value`./// contain extra bits that are not part of the bit vector. Implementations/// of `set_block` should not change those trailing bits./// The default implementation sets a block by setting each of its bits/// in turn. Consider it a slow reference implementation, and override it./// Sets `count` bits starting at bit index `start`, interpreted as a/// Mutable bit vector operations that don’t affect the length./// Minimal complete definition is `set_bit` or `set_block`, since each/// is defined in terms of the other. Note that `set_block` in terms of/// `set_bit` is inefficient, and thus you should implement `set_block`/// directly if possible.bit_assign/// Assigns the bits of `other` to `self`./// If `self.bit_len() != other.bit_len()`.bit_and_assign/// Assigns the bit-wise *and* of `self` and `other` to `self`.bit_or_assign/// Assigns the bit-wise *or* of `self` and `other` to `self`.bit_xor_assign/// Assigns the bit-wise *xor* of `self` and `other` to `self`.bit_zip_assign/// Performs an op-assignment from `other` to `self`./// In particular, the given function is used to combine each/// block of `self` with a block of `other`, assigning the result/// back to `self`./// Extension trait for mutable operations on bit slices.bit_and_assign_bad_sizesbit_xor_assign_slice/// Adds the given bit to the end of the bit vector./// Removes and returns the last bit, if any./// Pushes `value` 0 or more times until the size of the bit/// vector is block-aligned./// Pushes the given block onto the end of the bit vector./// If the end of the bit vector is not currently block-aligned,/// it pads with 0s up to the next block before pushing./// The default implementation pushes the block one bit at a time;/// override it with something more efficient./// Bit vector operations that change the length.bits_extbits_mutbits_mut_extbits_pushbit_sliceablevec_u8_is_bit_vecvec_u8_is_bit_vec_mutbogus_get_bits_vec_bool_works_okaybogus_get_bits_vec_bool_oobget_block_oobset_block_slicesize_of_valNoUninitAnyBitPatterncast_box/// As [`try_cast_box`], but unwraps for you.try_cast_boxPodCastError/// Attempts to cast the content type of a [`Box`]./// On failure you get back an error along with the starting `Box`./// ## Failure/// * The start and end content type of the `Box` must have the exact same///   alignment./// * The start and end size of the `Box` must have the exact same size.try_zeroed_box/// Allocates a `Box<T>` with all of the contents being zeroed out./// This uses the global allocator to create a zeroed allocation and _then_/// turns it into a Box. In other words, it's 100% assured that the zeroed data/// won't be put temporarily on the stack. You can make a box of any size/// without fear of a stack overflow./// This fails if the allocation fails.zeroed_box/// As [`try_zeroed_box`], but unwraps for you.try_zeroed_vec/// Allocates a `Vec<T>` of length and capacity exactly equal to `length` and/// all elements zeroed./// This fails if the allocation fails, or if a layout cannot be calculated for/// the allocation.zeroed_vec/// As [`try_zeroed_vec`] but unwraps for youtry_zeroed_slice_box/// Allocates a `Box<[T]>` with all contents being zeroed out.zeroed_slice_box/// As [`try_zeroed_slice_box`], but unwraps for you.zeroed_arc/// Allocates a `Arc<T>` with all contents being zeroed out.zeroed_arc_slice/// Allocates a `Arc<[T]>` with all contents being zeroed out.zeroed_rc/// Allocates a `Rc<T>` with all contents being zeroed out.zeroed_rc_slice/// Allocates a `Rc<[T]>` with all contents being zeroed out.cast_slice_box/// As [`try_cast_slice_box`], but unwraps for you.try_cast_slice_box/// Attempts to cast the content type of a `Box<[T]>`./// On failure you get back an error along with the starting `Box<[T]>`./// * The start and end content type of the `Box<[T]>` must have the exact same/// * The start and end content size in bytes of the `Box<[T]>` must be the///   exact same.cast_vec/// As [`try_cast_vec`], but unwraps for you.try_cast_vec/// Attempts to cast the content type of a [`Vec`]./// On failure you get back an error along with the starting `Vec`./// * The start and end content type of the `Vec` must have the exact same/// * The start and end content size in bytes of the `Vec` must be the exact///   same./// * The start and end capacity in bytes of the `Vec` must be the exact same.pod_collect_to_vec/// This "collects" a slice of pod data into a vec of a different pod type./// Unlike with [`cast_slice`] and [`cast_slice_mut`], this will always work./// The output vec will be of a minimal size/capacity to hold the slice given./// # use bytemuck::*;/// let halfwords: [u16; 4] = [5, 6, 7, 8];/// let vec_of_words: Vec<u32> = pod_collect_to_vec(&halfwords);/// if cfg!(target_endian = "little") {///   assert_eq!(&vec_of_words[..], &[0x0006_0005, 0x0008_0007][..])/// } else {///   assert_eq!(&vec_of_words[..], &[0x0005_0006, 0x0007_0008][..])cast_rc/// As [`try_cast_rc`], but unwraps for you.try_cast_rc/// Attempts to cast the content type of a [`Rc`]./// On failure you get back an error along with the starting `Rc`./// The bounds on this function are the same as [`cast_mut`], because a user/// could call `Rc::get_unchecked_mut` on the output, which could be observable/// in the input./// * The start and end content type of the `Rc` must have the exact same/// * The start and end size of the `Rc` must have the exact same size.cast_arc/// As [`try_cast_arc`], but unwraps for you.try_cast_arc/// Attempts to cast the content type of a [`Arc`]./// On failure you get back an error along with the starting `Arc`./// * The start and end content type of the `Arc` must have the exact same/// * The start and end size of the `Arc` must have the exact same size.cast_slice_rc/// As [`try_cast_slice_rc`], but unwraps for you.try_cast_slice_rc/// Attempts to cast the content type of a `Rc<[T]>`./// On failure you get back an error along with the starting `Rc<[T]>`./// * The start and end content type of the `Rc<[T]>` must have the exact same/// * The start and end content size in bytes of the `Rc<[T]>` must be the exactcast_slice_arc/// As [`try_cast_slice_arc`], but unwraps for you.try_cast_slice_arc/// Attempts to cast the content type of a `Arc<[T]>`./// On failure you get back an error along with the starting `Arc<[T]>`./// * The start and end content type of the `Arc<[T]>` must have the exact same/// * The start and end content size in bytes of the `Arc<[T]>` must be thewrap_vec/// Convert a vec of the inner type into a vec of the wrapper type.wrap_box/// Convert a box to the inner type into a box to the wrapperwrap_rc/// Convert an [`Rc`] to the inner type into an `Rc` to the wrapper type.wrap_arc/// Convert an [`Arc`] to the inner type into an `Arc` to the wrapper type.peel_vec/// Convert a vec of the wrapper type into a vec of the inner type.peel_box/// Convert a box to the wrapper type into a box to the innerpeel_rc/// Convert an [`Rc`] to the wrapper type into an `Rc` to the inner type.peel_arc/// Convert an [`Arc`] to the wrapper type into an `Arc` to the inner type.TransparentWrapperAllocTransparentWrapper/// An extension trait for `TransparentWrapper` and alloc types.// SAFETY: `ptr` is aligned to `layout.align()`, points to// `layout.size()` initialized bytes, and, if `layout.size() > 0`,// is owned and was allocated with the global allocator with `layout`.BoxBytes/// As `Box<[u8]>`, but remembers the original alignment.// SAFETY: `BoxBytes` is semantically a `Box<[u8], Global>` with a different allocation alignment,// `Box<[u8], Global>` is `Send + Sync`, and changing the allocation alignment has no thread-safety implications.// SAFETY: See `Send` implBoxBytesOfbox_bytes_oftry_from_box_bytesFromBoxBytes/// Re-interprets `Box<T>` as `BoxBytes`./// `T` must be either [`Sized`] and [`NoUninit`],/// [`[U]`](slice) where `U: NoUninit`, or [`str`].from_box_bytes/// Re-interprets `BoxBytes` as `Box<T>`./// `T` must be either [`Sized`] + [`AnyBitPattern`], or/// [`[U]`](slice) where `U: AnyBitPattern`./// This is [`try_from_box_bytes`] but will panic on error and the input will be/// dropped./// Returns `Err`:/// * If the input isn't aligned for `T`./// * If `T: Sized` and the input's length isn't exactly the size of `T`./// * If `T = [U]` and the input's length isn't exactly a multiple of the size///   of `U`./// Constructs a `BoxBytes` from its raw parts./// The pointer is owned, has been allocated with the provided layout, and/// points to `layout.size()` initialized bytes.into_raw_parts/// Deconstructs a `BoxBytes` into its raw parts./// Returns the original layout.//! Stuff to boost things in the `alloc` crate.//! * You must enable the `extern_crate_alloc` feature of `bytemuck` or you will//!   not be able to use this module! This is generally done by adding the//!   feature to the dependency in Cargo.toml like so://!   `bytemuck = { version = "VERSION_YOU_ARE_USING", features =//! ["extern_crate_alloc"]}`/// Marker trait for "plain old data" types that are valid for any bit pattern./// The requirements for this is very similar to [`Pod`], except that the type/// can allow uninit (or padding) bytes. This limits what you can do with a type/// of this kind, but also broadens the included types to `repr(C)` `struct`s/// that contain padding as well as `union`s. Notably, you can only cast/// *immutable* references and *owned* values into [`AnyBitPattern`] types, not/// *mutable* references./// [`Pod`] is a subset of [`AnyBitPattern`], meaning that any `T: Pod` is also/// [`AnyBitPattern`] but any `T: AnyBitPattern` is not necessarily [`Pod`]./// [`AnyBitPattern`] is a subset of [`Zeroable`], meaning that any `T:/// AnyBitPattern` is also [`Zeroable`], but any `T: Zeroable` is not/// necessarily [`AnyBitPattern`]/// # Derive/// A `#[derive(AnyBitPattern)]` macro is provided under the `derive` feature/// flag which will automatically validate the requirements of this trait and/// implement the trait for you for both structs and enums. This is the/// recommended method for implementing the trait, however it's also possible to/// do manually. If you implement it manually, you *must* carefully follow the/// below safety rules./// * *NOTE: even `C-style`, fieldless enums are intentionally **excluded** from///   this trait, since it is **unsound** for an enum to have a discriminant///   value that is not one of its defined variants./// Similar to [`Pod`] except we disregard the rule about it must not contain/// uninit bytes. Still, this is a quite strong guarantee about a type, so *be/// careful* when implementing it manually./// * The type must be inhabited (eg: no///   [Infallible](core::convert::Infallible))./// * The type must be valid for any bit pattern of its backing memory./// * Structs need to have all fields also be `AnyBitPattern`./// * It is disallowed for types to contain pointer types, `Cell`, `UnsafeCell`,///   atomics, and any other forms of interior mutability./// * More precisely: A shared reference to the type must allow reads, and///   *only* reads. RustBelt's separation logic is based on the notion that a///   type is allowed to define a sharing predicate, its own invariant that must///   hold for shared references, and this predicate is the reasoning that allow///   it to deal with atomic and cells etc. We require the sharing predicate to///   be trivial and permit only read-only access./// * There's probably more, don't mess it up (I mean it).something_went_wrong/// `Self` *must* have the same layout as the specified `Bits` except for/// the possible invalid bit patterns being checked during/// [`is_valid_bit_pattern`]./// [`is_valid_bit_pattern`]: CheckedBitPattern::is_valid_bit_patternis_valid_bit_pattern/// If this function returns true, then it must be valid to reinterpret `bits`/// as `&Self`.CheckedBitPattern/// A marker trait that allows types that have some invalid bit patterns to be/// used in places that otherwise require [`AnyBitPattern`] or [`Pod`] types by/// performing a runtime check on a perticular set of bits. This is particularly/// useful for types like fieldless ('C-style') enums, [`char`], bool, and/// structs containing them./// To do this, we define a `Bits` type which is a type with equivalent layout/// to `Self` other than the invalid bit patterns which disallow `Self` from/// being [`AnyBitPattern`]. This `Bits` type must itself implement/// [`AnyBitPattern`]. Then, we implement a function that checks whether a/// certain instance of the `Bits` is also a valid bit pattern of `Self`. If/// this check passes, then we can allow casting from the `Bits` to `Self` (and/// therefore, any type which is able to be cast to `Bits` is also able to be/// cast to `Self`)./// [`AnyBitPattern`] is a subset of [`CheckedBitPattern`], meaning that any `T:/// AnyBitPattern` is also [`CheckedBitPattern`]. This means you can also use/// any [`AnyBitPattern`] type in the checked versions of casting functions in/// this module. If it's possible, prefer implementing [`AnyBitPattern`] for/// your type directly instead of [`CheckedBitPattern`] as it gives greater/// flexibility./// A `#[derive(CheckedBitPattern)]` macro is provided under the `derive`/// feature flag which will automatically validate the requirements of this/// trait and implement the trait for you for both enums and structs. This is/// the recommended method for implementing the trait, however it's also/// possible to do manually./// If manually implementing the trait, we can do something like so:/// use bytemuck::{CheckedBitPattern, NoUninit};/// #[repr(u32)]///     Variant0 = 0,///     Variant1 = 1,///     Variant2 = 2,/// unsafe impl CheckedBitPattern for MyEnum {///     type Bits = u32;///     fn is_valid_bit_pattern(bits: &u32) -> bool {///         match *bits {///             0 | 1 | 2 => true,///             _ => false,/// // It is often useful to also implement `NoUninit` on our `CheckedBitPattern` types./// // This will allow us to do casting of mutable references (and mutable slices)./// // It is not always possible to do so, but in this case we have no padding so it is./// unsafe impl NoUninit for MyEnum {}/// We can now use relevant casting functions. For example,/// # use bytemuck::{CheckedBitPattern, NoUninit};/// # #[repr(u32)]/// # #[derive(Copy, Clone, PartialEq, Eq, Debug)]/// # enum MyEnum {/// #     Variant0 = 0,/// #     Variant1 = 1,/// #     Variant2 = 2,/// # unsafe impl NoUninit for MyEnum {}/// # unsafe impl CheckedBitPattern for MyEnum {/// #     type Bits = u32;/// #     fn is_valid_bit_pattern(bits: &u32) -> bool {/// #         match *bits {/// #             0 | 1 | 2 => true,/// #             _ => false,/// #         }/// use bytemuck::{bytes_of, bytes_of_mut};/// use bytemuck::checked;/// let bytes = bytes_of(&2u32);/// let result = checked::try_from_bytes::<MyEnum>(bytes);/// assert_eq!(result, Ok(&MyEnum::Variant2));/// // Fails for invalid discriminant/// let bytes = bytes_of(&100u32);/// assert!(result.is_err());/// // Since we implemented NoUninit, we can also cast mutably from an original type/// // that is `NoUninit + AnyBitPattern`:/// let mut my_u32 = 2u32;///   let as_enum_mut = checked::cast_mut::<_, MyEnum>(&mut my_u32);///   assert_eq!(as_enum_mut, &mut MyEnum::Variant2);///   *as_enum_mut = MyEnum::Variant0;/// assert_eq!(my_u32, 0u32);/// * `Self` *must* have the same layout as the specified `Bits` except for the///   possible invalid bit patterns being checked during///   [`is_valid_bit_pattern`]./// * This almost certainly means your type must be `#[repr(C)]` or a similar///   specified repr, but if you think you know better, you probably don't. If///   you still think you know better, be careful and have fun. And don't mess///   it up (I mean it)./// * If [`is_valid_bit_pattern`] returns true, then the bit pattern contained///   in `bits` must also be valid for an instance of `Self`./// * Probably more, don't mess it up (I mean it 2.0)/// [`Pod`]: crate::Podimpl_checked_for_nonzero// Rust 1.70.0 documents that NonZero[int] has the same layout as [int].NonZeroIsizeCheckedCastError/// An error occurred during a true-[`Pod`] castInvalidBitPattern/// When casting to a [`CheckedBitPattern`] type, it is possible that the/// original data contains an invalid bit pattern. If so, the cast will/// fail and this error will be returned. Will never happen on casts/// between [`Pod`] types./// The things that can go wrong when casting between [`CheckedBitPattern`] data/// forms.try_from_bytes/// Re-interprets `&[u8]` as `&T`./// * If the slice isn't aligned for the new type/// * If the slice's length isn’t exactly the size of the new type/// * If the slice contains an invalid bit pattern for `T`try_from_bytes_mut/// Re-interprets `&mut [u8]` as `&mut T`.try_pod_read_unaligned/// Reads from the bytes as if they were a `T`./// * If the `bytes` length is not equal to `size_of::<T>()`.try_cast/// Try to cast `A` into `B`./// Note that for this particular type of cast, alignment isn't a factor. The/// input value is semantically copied into the function and then returned to a/// new memory location which will have whatever the required alignment of the/// output type is./// * If the types don't have the same size this fails./// * If `a` contains an invalid bit pattern for `B` this fails.try_cast_ref/// Try to convert a `&A` into `&B`./// * If the reference isn't aligned in the new type/// * If the source type and target type aren't the same size.try_cast_mut/// Try to convert a `&mut A` into `&mut B`./// As [`try_cast_ref`], but `mut`.try_cast_slice/// Try to convert `&[A]` into `&[B]` (possibly with a change in length)./// * `input.as_ptr() as usize == output.as_ptr() as usize`/// * `input.len() * size_of::<A>() == output.len() * size_of::<B>()`/// * If the target type has a greater alignment requirement and the input slice///   isn't aligned./// * If the target element type is a different size from the current element///   type, and the output slice wouldn't be a whole number of elements when///   accounting for the size change (eg: 3 `u16` values is 1.5 `u32` values, so///   that's a failure)./// * If any element of the converted slice would contain an invalid bit pattern///   for `B` this fails.try_cast_slice_mut/// Try to convert `&mut [A]` into `&mut [B]` (possibly with a change in/// length)./// As [`try_cast_slice`], but `&mut`./// This is [`try_from_bytes`] but will panic on error.from_bytes_mut/// This is [`try_from_bytes_mut`] but will panic on error.pod_read_unaligned/// Reads the slice into a `T` value./// * This is like [`try_pod_read_unaligned`] but will panic on failure./// Cast `A` into `B`/// * This is like [`try_cast`], but will panic on a size mismatch.cast_mut/// Cast `&mut A` into `&mut B`./// This is [`try_cast_mut`] but will panic on error.cast_ref/// Cast `&A` into `&B`./// This is [`try_cast_ref`] but will panic on error.cast_slice/// Cast `&[A]` into `&[B]`./// This is [`try_cast_slice`] but will panic on error.cast_slice_mut/// Cast `&mut [A]` into `&mut [B]`./// This is [`try_cast_slice_mut`] but will panic on error.//! Checked versions of the casting functions exposed in crate root//! that support [`CheckedBitPattern`] types.Int/// The primitive integer type with an identical representation to this/// Contiguous is broadly intended for use with fieldless enums, and for/// these the correct integer type is easy: The enum should have a/// `#[repr(Int)]` or `#[repr(C)]` attribute, (if it does not, it is/// *unsound* to implement `Contiguous`!)./// - For `#[repr(Int)]`, use the listed `Int`. e.g. `#[repr(u8)]` should use///   `type Int = u8`./// - For `#[repr(C)]`, use whichever type the C compiler will use to///   represent the given enum. This is usually `c_int` (from `std::os::raw`///   or `libc`), but it's up to you to make the determination as the///   implementer of the unsafe trait./// For precise rules, see the list under "Safety" above.MAX_VALUE/// The upper *inclusive* bound for valid instances of this type.MIN_VALUE/// The lower *inclusive* bound for valid instances of this type.from_integer/// If `value` is within the range for valid instances of this type,/// returns `Some(converted_value)`, otherwise, returns `None`./// This is a trait method so that you can write `value.into_integer()` in/// your code. It is a contract of this trait that if you implement/// `Contiguous` on your type you **must not** override this method./// We will not panic for any correct implementation of `Contiguous`, but/// *may* panic if we detect an incorrect one./// This is undefined behavior regardless, so it could have been the nasal/// demons at that point anyway ;).into_integer/// Perform the conversion from `C` into the underlying integral type. This/// mostly exists otherwise generic code would need unsafe for the `value as/// integer`Contiguous/// A trait indicating that:/// 1. A type has an equivalent representation to some known integral type./// 2. All instances of this type fall in a fixed range of values./// 3. Within that range, there are no gaps./// This is generally useful for fieldless enums (aka "c-style" enums), however/// it's important that it only be used for those with an explicit `#[repr]`, as/// `#[repr(Rust)]` fieldess enums have an unspecified layout./// Additionally, you shouldn't assume that all implementations are enums. Any/// type which meets the requirements above while following the rules under/// "Safety" below is valid./// # use bytemuck::Contiguous;/// #[repr(u8)]/// #[derive(Debug, Copy, Clone, PartialEq)]///   A = 0,///   B = 1,///   C = 2,///   D = 3,///   E = 4,/// unsafe impl Contiguous for Foo {///   type Int = u8;///   const MIN_VALUE: u8 = Foo::A as u8;///   const MAX_VALUE: u8 = Foo::E as u8;/// assert_eq!(Foo::from_integer(3).unwrap(), Foo::D);/// assert_eq!(Foo::from_integer(8), None);/// assert_eq!(Foo::C.into_integer(), 2);/// This is an unsafe trait, and incorrectly implementing it is undefined/// behavior./// Informally, by implementing it, you're asserting that `C` is identical to/// the integral type `C::Int`, and that every `C` falls between `C::MIN_VALUE`/// and `C::MAX_VALUE` exactly once, without any gaps./// Precisely, the guarantees you must uphold when implementing `Contiguous` for/// some type `C` are:/// 1. The size of `C` and `C::Int` must be the same, and neither may be a ZST.///    (Note: alignment is explicitly allowed to differ)/// 2. `C::Int` must be a primitive integer, and not a wrapper type. In the///    future, this may be lifted to include cases where the behavior is///    identical for a relevant set of traits (Ord, arithmetic, ...)./// 3. All `C::Int`s which are in the *inclusive* range between `C::MIN_VALUE`///    and `C::MAX_VALUE` are bitwise identical to unique valid instances of///    `C`./// 4. There exist no instances of `C` such that their bitpatterns, when///    interpreted as instances of `C::Int`, fall outside of the `MAX_VALUE` ////    `MIN_VALUE` range -- It is legal for unsafe code to assume that if it///    gets a `C` that implements `Contiguous`, it is in the appropriate range./// 5. Finally, you promise not to provide overridden implementations of///    `Contiguous::from_integer` and `Contiguous::into_integer`./// For clarity, the following rules could be derived from the above, but are/// listed explicitly:/// - `C::MAX_VALUE` must be greater or equal to `C::MIN_VALUE` (therefore, `C`///   must be an inhabited type)./// - There exist no two values between `MIN_VALUE` and `MAX_VALUE` such that///   when interpreted as a `C` they are considered identical (by, say, match).impl_contiguousIntegerEnumTagIntegerBytes/// A trait that can be used to convert the type of a byte array to an integer/// type of the same size.enum_tag_integer_impls//! This module contains some helpers for the derive macros./// Immediately panics.bytes_of/// Re-interprets `&T` as `&[u8]`./// Any ZST becomes an empty slice, and in that case the pointer value of that/// empty slice might not match the pointer value of the input reference.bytes_of_mut/// Re-interprets `&mut T` as `&mut [u8]`./// * This is like `try_pod_read_unaligned` but will panic on failure.is_aligned_to/// Checks if `ptr` is aligned to an `align` memory boundary./// * If `align` is not a power of two. This includes when `align` is zero./// * This is like [`try_cast`](try_cast), but will panic on a size mismatch.//! Internal implementation of casting functions not bound by marker traits//! and therefore marked as unsafe. This is used so that we don't need to//! duplicate the business logic contained in these functions between the//! versions exported in the crate root, `checked`, and `relaxed` modules./*

Note(Lokathor): We've switched all of the `unwrap` to `match` because there is
apparently a bug: https://github.com/rust-lang/rust/issues/68667
and it doesn't seem to show up in simple godbolt examples but has been reported
as having an impact when there's a cast mixed in with other more complicated
code around it. Rustc/LLVM ends up missing that the `Err` can't ever happen for
particular type combinations, and then it doesn't fully eliminated the panic
possibility code branch.

*/align_of// Used from macros to ensure we aren't using some locally defined name and// actually are referencing libcore. This also would allow pre-2018 edition// crates to use our macros, but I'm not sure how important that is.impl_unsafe_marker_for_array// This arm is for use in const contexts, where the borrow required to use// transmute_copy poses an issue since the compiler hedges that the type// being borrowed could have interior mutability./// A macro to transmute between two types without requiring knowing size/// statically.impl_unsafe_marker_for_simd/// A macro to implement marker traits for various simd types./// #[allow(unused)] because the impls are only compiled on relevant platforms/// with relevant cargo features enabled.maybe_const_fn/// A macro for conditionally const-ifying a function./// #[allow(unused)] because currently it is only used with the `must_cast` feature.anybitpatterncheckedzeroablezeroable_in_optionpodpod_in_optionno_uninitoffset_oftransparent// This module is just an implementation detail for the derive macros. It needs// to be public to be usable from the macros, but it shouldn't be considered// part of bytemuck's public API.ByteEqByteHashTargetAlignmentGreaterAndInputNotAligned/// You tried to cast a reference into a reference to a type with a higher/// alignment requirement but the input reference wasn't aligned.OutputSliceWouldHaveSlop/// If the element size of a slice changes, then the output slice changes/// length accordingly. If the output slice wouldn't be a whole number of/// elements, then the conversion fails.SizeMismatch/// When casting an individual `T`, `&T`, or `&mut T` value the/// source size and destination size must be an exact match.AlignmentMismatch/// For this type of cast the alignments must be exactly the same and they/// were not so now you're sad./// This error is generated **only** by operations that cast allocated types/// (such as `Box` and `Vec`), because in that case the alignment must stay/// exact./// The things that can go wrong when casting between [`Pod`] data forms./// This is like [`try_from_bytes`] but will panic on error./// This is like [`try_from_bytes_mut`] but will panic on error./// Unlike [`from_bytes`], the slice doesn't need to respect alignment of `T`,/// only sizes must match.pod_align_to/// As [`align_to`](https://doc.rust-lang.org/std/primitive.slice.html#method.align_to),/// but safe because of the [`Pod`] bound.pod_align_to_mut/// As [`align_to_mut`](https://doc.rust-lang.org/std/primitive.slice.html#method.align_to_mut),/// * Similarly, you can't convert between a [ZST](https://doc.rust-lang.org/nomicon/exotic-sizes.html#zero-sized-types-zsts)///   and a non-ZST.write_zeroes/// Fill all bytes of `target` with zeroes (see [`Zeroable`])./// This is similar to `*target = Zeroable::zeroed()`, but guarantees that any/// padding bytes in `target` are zeroed as well./// See also [`fill_zeroes`], if you have a slice rather than a single value.fill_zeroes/// Fill all bytes of `slice` with zeroes (see [`Zeroable`])./// This is similar to `slice.fill(Zeroable::zeroed())`, but guarantees that any/// padding bytes in `slice` are zeroed as well./// See also [`write_zeroes`], which zeroes all bytes of a single value rather/// than a slice.//! This crate gives small utilities for casting between plain data types.//! ## Basics//! Data comes in five basic forms in Rust, so we have five basic casting//! functions://! * `T` uses [`cast`]//! * `&T` uses [`cast_ref`]//! * `&mut T` uses [`cast_mut`]//! * `&[T]` uses [`cast_slice`]//! * `&mut [T]` uses [`cast_slice_mut`]//! Depending on the function, the [`NoUninit`] and/or [`AnyBitPattern`] traits//! are used to maintain memory safety.//! **Historical Note:** When the crate first started the [`Pod`] trait was used//! instead, and so you may hear people refer to that, but it has the strongest//! requirements and people eventually wanted the more fine-grained system, so//! here we are. All types that impl `Pod` have a blanket impl to also support//! `NoUninit` and `AnyBitPattern`. The traits unfortunately do not have a//! perfectly clean hierarchy for semver reasons.//! ## Failures//! Some casts will never fail, and other casts might fail.//! * `cast::<u32, f32>` always works (and [`f32::from_bits`]).//! * `cast_ref::<[u8; 4], u32>` might fail if the specific array reference//!   given at runtime doesn't have alignment 4.//! In addition to the "normal" forms of each function, which will panic on//! invalid input, there's also `try_` versions which will return a `Result`.//! If you would like to statically ensure that a cast will work at runtime you//! can use the `must_cast` crate feature and the `must_` casting functions. A//! "must cast" that can't be statically known to be valid will cause a//! compilation error (and sometimes a very hard to read compilation error).//! ## Using Your Own Types//! All the functions listed above are guarded by the [`Pod`] trait, which is a//! sub-trait of the [`Zeroable`] trait.//! If you enable the crate's `derive` feature then these traits can be derived//! on your own types. The derive macros will perform the necessary checks on//! your type declaration, and trigger an error if your type does not qualify.//! The derive macros might not cover all edge cases, and sometimes they will//! error when actually everything is fine. As a last resort you can impl these//! traits manually. However, these traits are `unsafe`, and you should//! carefully read the requirements before using a manual implementation.//! ## Cargo Features//! The crate supports Rust 1.34 when no features are enabled, and so there's//! cargo features for thing that you might consider "obvious".//! The cargo features **do not** promise any particular MSRV, and they may//! increase their MSRV in new versions.//! * `derive`: Provide derive macros for the various traits.//! * `extern_crate_alloc`: Provide utilities for `alloc` related types such as//!   Box and Vec.//! * `zeroable_maybe_uninit` and `zeroable_atomics`: Provide more [`Zeroable`]//!   impls.//! * `pod_saturating`: Provide more [`Pod`] and [`Zeroable`] impls.//! * `wasm_simd` and `aarch64_simd`: Support more SIMD types.//! * `min_const_generics`: Provides appropriate impls for arrays of all lengths//!   instead of just for a select list of array lengths.//! * `must_cast`: Provides the `must_` functions, which will compile error if//!   the requested cast can't be statically verified.//! * `const_zeroed`: Provides a const version of the `zeroed` function.//! ## Related Crates//! - [`pack1`](https://docs.rs/pack1), which contains `bytemuck`-compatible//!   packed little-endian, big-endian and native-endian integer and floating//!   point number types.// ^ no import, the module only has a macro_rules, which are cursed and don't// follow normal import/export rules.CastASSERT_ALIGN_GREATER_THAN_EQUALASSERT_SIZE_EQUALASSERT_SIZE_MULTIPLE_OF_OR_INPUT_ZSTmust_cast/// Cast `A` into `B` if infalliable, or fail to compile./// * If the types don't have the same size this fails to compile./// // compiles:/// let bytes: [u8; 2] = bytemuck::must_cast(12_u16);/// ```compile_fail,E0080/// // fails to compile (size mismatch):/// let bytes : [u8; 3] = bytemuck::must_cast(12_u16);must_cast_ref/// Convert `&A` into `&B` if infalliable, or fail to compile./// * If the target type has a greater alignment requirement./// let bytes: &[u8; 2] = bytemuck::must_cast_ref(&12_u16);/// let bytes : &[u8; 3] = bytemuck::must_cast_ref(&12_u16);/// // fails to compile (alignment requirements increased):/// let bytes : &u16 = bytemuck::must_cast_ref(&[1u8, 2u8]);must_cast_slice/// Convert `&[A]` into `&[B]` (possibly with a change in length) if/// infalliable, or fail to compile./// * If the target element type doesn't evenly fit into the the current element///   type (eg: 3 `u16` values is 1.5 `u32` values, so that's a failure)./// * Similarly, you can't convert from a non-[ZST](https://doc.rust-lang.org/nomicon/exotic-sizes.html#zero-sized-types-zsts)///   to a ZST (e.g. 3 `u8` values is not any number of `()` values)./// let indicies: &[u16] = &[1, 2, 3];/// let bytes: &[u8] = bytemuck::must_cast_slice(indicies);/// let zsts: &[()] = &[(), (), ()];/// let bytes: &[u8] = bytemuck::must_cast_slice(zsts);/// # let bytes : &[u8] = &[1, 0, 2, 0, 3, 0];/// // fails to compile (bytes.len() might not be a multiple of 2):/// let byte_pairs : &[[u8; 2]] = bytemuck::must_cast_slice(bytes);/// # let byte_pairs : &[[u8; 2]] = &[[1, 0], [2, 0], [3, 0]];/// let indicies : &[u16] = bytemuck::must_cast_slice(byte_pairs);/// let bytes: &[u8] = &[];/// // fails to compile: (bytes.len() might not be 0)/// let zsts: &[()] = bytemuck::must_cast_slice(bytes);/// Marker trait for "plain old data" types with no uninit (or padding) bytes./// The requirements for this is very similar to [`Pod`],/// except that it doesn't require that all bit patterns of the type are valid,/// i.e. it does not require the type to be [`Zeroable`][crate::Zeroable]./// This limits what you can do with a type of this kind, but also broadens the/// included types to things like C-style enums. Notably, you can only cast from/// *immutable* references to a [`NoUninit`] type into *immutable* references of/// any other type, no casting of mutable references or mutable references to/// slices etc./// [`Pod`] is a subset of [`NoUninit`], meaning that any `T: Pod` is also/// [`NoUninit`] but any `T: NoUninit` is not necessarily [`Pod`]. If possible,/// prefer implementing [`Pod`] directly. To get more [`Pod`]-like functionality/// for a type that is only [`NoUninit`], consider also implementing/// [`CheckedBitPattern`][crate::CheckedBitPattern]./// The rules for padding for various types and representations are documented/// in the Rust reference section on [type layout]./// A `#[derive(NoUninit)]` macro is provided under the `derive` feature flag/// which will automatically validate the requirements of this trait and/// implement the trait for you for both enums and structs. This is the/// The same as [`Pod`] except we disregard the rule about it must/// allow any bit pattern (i.e. it does not need to be/// [`Zeroable`][crate::Zeroable]). Still, this is a quite strong guarantee/// about a type, so *be careful* whem implementing it manually./// * The type must not contain any uninit (or padding) bytes, either in the///   middle or on the end (eg: no `#[repr(C)] struct Foo(u8, u16)`, which has///   padding in the middle, and also no `#[repr(C)] struct Foo(u16, u8)`, which///   has padding on the end)./// * Structs need to have all fields also be `NoUninit`./// * Structs need to be `repr(C)` or `repr(transparent)`. In the case of///   `repr(C)`, the `packed` and `align` repr modifiers can be used as long as///   all other rules end up being followed./// * Enums need to be `#[repr(Int)]`, `#[repr(C)]`, or both./// * Enums may have fields. If the enum has fields,///     * Each variant's fields must individually follow the same rules as a struct///     * All variants must be the same size, and require no padding-to-alignment///     * There must be no padding needed between the discriminant type and the///       "fields struct" of any variant/// [type layout]: <https://doc.rust-lang.org/reference/type-layout.html>/// Find the offset in bytes of the given `$field` of `$Type`. Requires an/// already initialized `$instance` value to work with./// This is similar to the macro from [`memoffset`](https://docs.rs/memoffset),/// however it uses no `unsafe` code./// This macro has a 3-argument and 2-argument version./// * In the 3-arg version you specify an instance of the type, the type itself,///   and the field name./// * In the 2-arg version the macro will call the [`default`](Default::default)///   method to make a temporary instance of the type for you./// The output of this macro is the byte offset of the field (as a `usize`). The/// calculations of the macro are fixed across the entire program, but if the/// type used is `repr(Rust)` then they're *not* fixed across compilations or/// compilers./// ### 3-arg Usage/// # use bytemuck::offset_of;/// // enums can't derive default, and for this example we don't pick one/// enum MyExampleEnum {///   A,///   B,///   C,/// // so now our struct here doesn't have Default/// struct MyNotDefaultType {///   pub counter: i32,///   pub some_field: MyExampleEnum,/// // but we provide an instance of the type and it's all good./// let val = MyNotDefaultType { counter: 5, some_field: MyExampleEnum::A };/// assert_eq!(offset_of!(val, MyNotDefaultType, some_field), 4);/// ### 2-arg Usage/// struct Vertex {///   pub loc: [f32; 3],///   pub color: [f32; 3],/// // if the type impls Default the macro can make its own default instance./// assert_eq!(offset_of!(Vertex, loc), 0);/// assert_eq!(offset_of!(Vertex, color), 12);/// # Usage with `#[repr(packed)]` structs/// Attempting to compute the offset of a `#[repr(packed)]` struct with/// `bytemuck::offset_of!` requires an `unsafe` block. We hope to relax this in/// the future, but currently it is required to work around a soundness hole in/// Rust (See [rust-lang/rust#27060])./// [rust-lang/rust#27060]: https://github.com/rust-lang/rust/issues/27060/// <p style="background:rgba(255,181,77,0.16);padding:0.75em;">/// <strong>Warning:</strong> This is only true for versions of bytemuck >/// 1.4.0. Previous versions of/// <code style="background:rgba(41,24,0,0.1);">bytemuck::offset_of!</code>/// will only emit a warning when used on the field of a packed struct in safe/// code, which can lead to unsoundness./// For example, the following will fail to compile:/// #[repr(C, packed)]/// struct Example {///   field: u32,/// // Doesn't compile:/// let _offset = bytemuck::offset_of!(Example, field);/// While the error message this generates will mention the/// `safe_packed_borrows` lint, the macro will still fail to compile even if/// that lint is `#[allow]`ed:/// # #[repr(C, packed)] #[derive(Default)] struct Example { field: u32 }/// // Still doesn't compile:/// #[allow(safe_packed_borrows)]///   let _offset = bytemuck::offset_of!(Example, field);/// This *can* be worked around by using `unsafe`, but it is only sound to do so/// if you can guarantee that taking a reference to the field is sound./// In practice, this means it only works for fields of align(1) types, or if/// you know the field's offset in advance (defeating the point of `offset_of`)/// and can prove that the struct's alignment and the field's offset are enough/// to prove the field's alignment./// Once the `raw_ref` macros are available, a future version of this crate will/// use them to lift the limitations of packed structs. For the duration of the/// `1.x` version of this crate that will be behind an on-by-default cargo/// feature (to maintain minimum rust version support)./// Marker trait for "plain old data"./// The point of this trait is that once something is marked "plain old data"/// you can really go to town with the bit fiddling and bit casting. Therefore,/// it's a relatively strong claim to make about a type. Do not add this to your/// type casually./// **Reminder:** The results of casting around bytes between data types are/// _endian dependant_. Little-endian machines are the most common, but/// big-endian machines do exist (and big-endian is also used for "network/// order" bytes)./// * The type must allow any bit pattern (eg: no `bool` or `char`, which have///   illegal bit patterns)./// * The type needs to have all fields also be `Pod`./// * The type needs to be `repr(C)` or `repr(transparent)`. In the case ofWrappingPhantomPinned4896// Note(Lokathor): MaybeUninit can NEVER be Pod.PodInOption// Note(Lokathor): This is the neat part!!ZeroableInOption/// Trait for types which are [Pod](Pod) when wrapped in/// [Option](core::option::Option)./// * `Option<T>` must uphold the same invariants as [Pod](Pod)./// * **Reminder:** pointers are **not** pod! **Do not** mix this trait with a///   newtype over [NonNull](core::ptr::NonNull).wrap/// Convert the inner type into the wrapper type.wrap_ref/// Convert a reference to the inner type into a reference to the wrapperwrap_mut/// Convert a mutable reference to the inner type into a mutable reference to/// the wrapper type.wrap_slice/// Convert a slice to the inner type into a slice to the wrapper type.wrap_slice_mut/// Convert a mutable slice to the inner type into a mutable slice to the/// wrapper type.peel/// Convert the wrapper type into the inner type.peel_ref/// Convert a reference to the wrapper type into a reference to the innerpeel_mut/// Convert a mutable reference to the wrapper type into a mutable reference/// to the inner type.peel_slice/// Convert a slice to the wrapped type into a slice to the inner type.peel_slice_mut/// Convert a mutable slice to the wrapped type into a mutable slice to the/// inner type./// A trait which indicates that a type is a `#[repr(transparent)]` wrapper/// around the `Inner` value./// This allows safely copy transmuting between the `Inner` type and the/// `TransparentWrapper` type. Functions like `wrap_{}` convert from the inner/// type to the wrapper type and `peel_{}` functions do the inverse conversion/// from the wrapper type to the inner type. We deliberately do not call the/// wrapper-removing methods "unwrap" because at this point that word is too/// strongly tied to the Option/ Result methods./// The safety contract of `TransparentWrapper` is relatively simple:/// For a given `Wrapper` which implements `TransparentWrapper<Inner>`:/// 1. `Wrapper` must be a wrapper around `Inner` with an identical data///    representations. This    either means that it must be a///    `#[repr(transparent)]` struct which    contains a either a field of type///    `Inner` (or a field of some other    transparent wrapper for `Inner`) as///    the only non-ZST field./// 2. Any fields *other* than the `Inner` field must be trivially constructable///    ZSTs, for example `PhantomData`, `PhantomPinned`, etc. (When deriving///    `TransparentWrapper` on a type with ZST fields, the ZST fields must be///    [`Zeroable`])./// 3. The `Wrapper` may not impose additional alignment requirements over///    `Inner`.///     - Note: this is currently guaranteed by `repr(transparent)`, but there///       have been discussions of lifting it, so it's stated here explicitly./// 4. All functions on `TransparentWrapper` **may not** be overridden./// ## Caveats/// If the wrapper imposes additional constraints upon the inner type which are/// required for safety, it's responsible for ensuring those still hold -- this/// generally requires preventing access to instances of the inner type, as/// implementing `TransparentWrapper<U> for T` means anybody can call/// `T::cast_ref(any_instance_of_u)`./// For example, it would be invalid to implement TransparentWrapper for `str`/// to implement `TransparentWrapper` around `[u8]` because of this./// ## Basic/// use bytemuck::TransparentWrapper;/// # #[derive(Default)]/// # struct SomeStruct(u32);/// #[repr(transparent)]/// struct MyWrapper(SomeStruct);/// unsafe impl TransparentWrapper<SomeStruct> for MyWrapper {}/// // interpret a reference to &SomeStruct as a &MyWrapper/// let thing = SomeStruct::default();/// let inner_ref: &MyWrapper = MyWrapper::wrap_ref(&thing);/// // Works with &mut too./// let mut mut_thing = SomeStruct::default();/// let inner_mut: &mut MyWrapper = MyWrapper::wrap_mut(&mut mut_thing);/// # let _ = (inner_ref, inner_mut); // silence warnings/// ## Use with dynamically sized types/// struct Slice<T>([T]);/// unsafe impl<T> TransparentWrapper<[T]> for Slice<T> {}/// let s = Slice::wrap_ref(&[1u32, 2, 3]);/// assert_eq!(&s.0, &[1, 2, 3]);/// let mut buf = [1, 2, 3u8];/// let sm = Slice::wrap_mut(&mut buf);/// ## Deriving/// When deriving, the non-wrapped fields must uphold all the normal/// requirements, and must also be `Zeroable`./// use std::marker::PhantomData;/// #[derive(TransparentWrapper)]/// #[transparent(usize)]/// struct Wrapper<T: ?Sized>(usize, PhantomData<T>); // PhantomData<T> implements Zeroable for all T/// Here, an error will occur, because `MyZst` does not implement `Zeroable`./// struct MyZst;/// struct Wrapper(usize, MyZst); // MyZst does not implement Zeroable/// Calls [`zeroed`](core::mem::zeroed)./// This is a trait method so that you can write `MyType::zeroed()` in your/// code. It is a contract of this trait that if you implement it on your type/// you **must not** override this method./// Trait for types that can be safely created with/// [`zeroed`](core::mem::zeroed)./// An all-zeroes value may or may not be the same value as the/// [Default](core::default::Default) value of the type./// * Your type must be inhabited (eg: no/// * Your type must be allowed to be an "all zeroes" bit pattern (eg: no///   [`NonNull<T>`](core::ptr::NonNull))./// ## Features/// Some `impl`s are feature gated due to the MSRV policy:/// * `MaybeUninit<T>` was not available in 1.34.0, but is available under the///   `zeroable_maybe_uninit` feature flag./// * `Atomic*` types require Rust 1.60.0 or later to work on certain platforms,///   but is available under the `zeroable_atomics` feature flag./// * `[T; N]` for arbitrary `N` requires the `min_const_generics` feature flag.// Note: we can't implement this for all `T: ?Sized` types because it would// create NULL pointers for vtables.// Maybe one day this could be changed to be implemented for// `T: ?Sized where <T as core::ptr::Pointee>::Metadata: Zeroable`.UnsafeCell/// Trait for types which are [Zeroable](Zeroable) when wrapped in/// * `Option<YourType>` must uphold the same invariants as///   [Zeroable](Zeroable).// Note: this does not create NULL vtable because we get `None` anyway.impl_for_fn"system"bytemuck_crate_nameDerivablederive_pod/// Derive the `Pod` trait for a struct/// The macro ensures that the struct follows all the the safety requirements/// for the `Pod` trait./// The following constraints need to be satisfied for the macro to succeed/// - All fields in the struct must implement `Pod`/// - The struct must be `#[repr(C)]` or `#[repr(transparent)]`/// - The struct must not contain any padding bytes/// - The struct contains no generic parameters, if it is not///   `#[repr(transparent)]`/// # use std::marker::PhantomData;/// # use bytemuck_derive::{Pod, Zeroable};/// #[derive(Copy, Clone, Pod, Zeroable)]/// struct Test {///   a: u16,///   b: u16,/// struct Generic<A, B> {///   a: A,///   b: PhantomData<B>,/// If the struct is generic, it must be `#[repr(transparent)]` also./// # use bytemuck::{Pod, Zeroable};/// #[repr(C)] // must be `#[repr(transparent)]`/// struct Generic<A> {/// If the struct is generic and `#[repr(transparent)]`, then it is only `Pod`/// when all of its generics are `Pod`, not just its fields./// let _: u32 = bytemuck::cast(Generic { a: 4u32, b: PhantomData::<u32> });/// # #[derive(Copy, Clone, Pod, Zeroable)]/// # #[repr(transparent)]/// # struct Generic<A, B> {/// #   a: A,/// #   b: PhantomData<B>,/// struct NotPod;/// let _: u32 = bytemuck::cast(Generic { a: 4u32, b: PhantomData::<NotPod> });derive_anybitpattern/// Derive the `AnyBitPattern` trait for a struct/// for the `AnyBitPattern` trait./// - All fields in the struct must to implement `AnyBitPattern`derive_zeroable/// Derive the `Zeroable` trait for a type./// The macro ensures that the type follows all the the safety requirements/// for the `Zeroable` trait./// The following constraints need to be satisfied for the macro to succeed on a/// struct:/// - All fields in the struct must implement `Zeroable`/// The following constraints need to be satisfied for the macro to succeed on/// an enum:/// - The enum has an explicit `#[repr(Int)]`, `#[repr(C)]`, or `#[repr(C,///   Int)]`./// - The enum has a variant with discriminant 0 (explicitly or implicitly)./// - All fields in the variant with discriminant 0 (if any) must implement///   `Zeroable`/// The macro always succeeds on unions./// # use bytemuck_derive::{Zeroable};/// #[derive(Copy, Clone, Zeroable)]/// #[repr(i32)]/// enum Values {/// #[derive(Clone, Zeroable)]/// enum Implicit {///   A(bool, u8, char),///   B(String),///   C(std::num::NonZeroU8),/// # Custom bounds/// Custom bounds for the derived `Zeroable` impl can be given using the/// `#[zeroable(bound = "")]` helper attribute./// Using this attribute additionally opts-in to "perfect derive" semantics,/// where instead of adding bounds for each generic type parameter, bounds are/// added for each field's type./// # use bytemuck::Zeroable;/// #[zeroable(bound = "")]/// struct AlwaysZeroable<T> {///   a: PhantomData<T>,/// AlwaysZeroable::<std::num::NonZeroU8>::zeroed();/// # use bytemuck::{Zeroable};/// enum MyOption<T> {///   None,///   Some(T),/// assert!(matches!(MyOption::<std::num::NonZeroU8>::zeroed(), MyOption::None));/// ```rust,compile_fail/// #[zeroable(bound = "T: Copy")]/// struct ZeroableWhenTIsCopy<T> {/// ZeroableWhenTIsCopy::<String>::zeroed();/// The restriction that all fields must be Zeroable is still applied, and this/// is enforced using the mentioned "perfect derive" semantics./// struct ZeroableWhenTIsZeroable<T> {///   a: T,/// ZeroableWhenTIsZeroable::<u32>::zeroed();/// # #[derive(Clone, Zeroable)]/// # #[zeroable(bound = "")]/// # struct ZeroableWhenTIsZeroable<T> {/// #   a: T,/// ZeroableWhenTIsZeroable::<String>::zeroed();derive_no_uninit/// Derive the `NoUninit` trait for a struct or enum/// for the `NoUninit` trait./// (the rest of the constraints are guaranteed by the `NoUninit` subtrait/// bounds, i.e. the type must be `Sized + Copy + 'static`):/// If applied to a struct:/// - All fields in the struct must implement `NoUninit`/// - The struct must contain no generic parameters/// If applied to an enum:/// - The enum must be explicit `#[repr(Int)]`, `#[repr(C)]`, or both/// - If the enum has fields:///   - All fields must implement `NoUninit`///   - All variants must not contain any padding bytes///   - All variants must be of the the same size///   - There must be no padding bytes between the discriminant and any of the///     variant fields/// - The enum must contain no generic parametersderive_maybe_pod/// Derive the `CheckedBitPattern` trait for a struct or enum./// for the `CheckedBitPattern` trait and derives the required `Bits` type/// definition and `is_valid_bit_pattern` method for the type automatically./// The following constraints need to be satisfied for the macro to succeed:/// - All fields must implement `CheckedBitPattern`/// - The enum must be explicit `#[repr(Int)]`/// - All fields in variants must implement `CheckedBitPattern`derive_transparent/// Derive the `TransparentWrapper` trait for a struct/// for the `TransparentWrapper` trait./// - The struct must be `#[repr(transparent)]`/// - The struct must contain the `Wrapped` type/// - Any ZST fields must be [`Zeroable`][derive@Zeroable]./// If the struct only contains a single field, the `Wrapped` type will/// automatically be determined. If there is more then one field in the struct,/// you need to specify the `Wrapped` type using `#[transparent(T)]`/// # use bytemuck_derive::TransparentWrapper;/// #[derive(Copy, Clone, TransparentWrapper)]/// #[transparent(u16)]/// struct Test<T> {///   inner: u16,///   extra: PhantomData<T>,/// If the struct contains more than one field, the `Wrapped` type must be/// explicitly specified./// // missing `#[transparent(u16)]`/// Any ZST fields must be `Zeroable`./// struct NonTransparentSafeZST;///   another_extra: NonTransparentSafeZST, // not `Zeroable`derive_contiguous/// Derive the `Contiguous` trait for an enum/// The macro ensures that the enum follows all the the safety requirements/// for the `Contiguous` trait./// - The enum must be `#[repr(Int)]`/// - The enum must be fieldless/// - The enum discriminants must form a contiguous range/// # use bytemuck_derive::{Contiguous};/// #[derive(Copy, Clone, Contiguous)]/// enum Test {derive_byte_eq/// Derive the `PartialEq` and `Eq` trait for a type/// The macro implements `PartialEq` and `Eq` by casting both sides of the/// comparison to a byte slice and then compares those./// ## Warning/// Since this implements a byte wise comparison, the behavior of floating point/// numbers does not match their usual comparison behavior. Additionally other/// custom comparison behaviors of the individual fields are also ignored. This/// also does not implement `StructuralPartialEq` / `StructuralEq` like/// `PartialEq` / `Eq` would. This means you can't pattern match on the values./// # use bytemuck_derive::{ByteEq, NoUninit};/// #[derive(Copy, Clone, NoUninit, ByteEq)]///   a: u32,///   b: char,///   c: f32,/// # use bytemuck_derive::ByteEq;/// # use bytemuck::NoUninit;/// #[derive(Copy, Clone, ByteEq)]/// struct Test<const N: usize> {///   a: [u32; N],/// unsafe impl<const N: usize> NoUninit for Test<N> {}derive_byte_hash/// Derive the `Hash` trait for a type/// The macro implements `Hash` by casting the value to a byte slice and hashing/// that./// The hash does not match the standard library's `Hash` derive./// # use bytemuck_derive::{ByteHash, NoUninit};/// #[derive(Copy, Clone, NoUninit, ByteHash)]/// # use bytemuck_derive::ByteHash;/// #[derive(Copy, Clone, ByteHash)]derive_marker_trait/// Basic wrapper for error handlingParserfind_and_parse_helper_attributes/// Find `#[name(key = "value")]` helper attributes on the struct, and return/// their `"value"`s parsed with `parser`./// Returns an error if any attributes with the given `name` do not match the/// expected format. Returns `Ok([])` if no attributes with `name` are found.derive_marker_trait_inneradd_trait_marker/// Add a trait marker to the generics if it is not already present//! Derive macros for [bytemuck](https://docs.rs/bytemuck) traits.implies_traitassertstrait_implrequires_where_clauseexplicit_bounds_attribute_nameperfect_derive_fields/// If this trait has a custom meaning for "perfect derive", this function/// should be overridden to return `Some`./// The default is "the fields of a struct; unions and enums not supported".get_zero_variantDataEnum/// Helper function to get the variant with discriminant zero (implicit or/// explicit).get_wrapper_typeget_struct_fieldsget_fields/// Extract the `Fields` off a `DeriveInput`, or, in the `enum` case, off/// those of the `enum_variant`, when provided (e.g., for `Zeroable`)./// We purposely allow not providing an `enum_variant` for cases where/// the caller wants to reject supporting `enum`s (e.g., `NoPadding`).get_enum_variantsget_field_typesgenerate_checked_bit_pattern_structgenerate_checked_bit_pattern_enumgenerate_checked_bit_pattern_enum_without_fieldsgenerate_checked_bit_pattern_enum_with_fieldsgenerate_assert_no_padding/// Check that a struct or enum has no padding by asserting that the size of/// the type is equal to the sum of the size of it's fields and discriminant/// (for enums, this must be asserted for each variant).generate_fields_are_trait/// Check that all fields implement a given traitget_enum_discriminant/// Get the type of an enum's discriminant./// For `repr(int)` and `repr(C, int)` enums, this will return the known bare/// integer type specified./// For `repr(C)` enums, this will extract the underlying size chosen by rustc./// It will return a token stream which is a type expression that evaluates to/// a primitive integer type of this size, using our `EnumTagIntegerBytes`/// For fieldless `repr(C)` enums, we can feed the size of the enum directly/// into the trait./// For `repr(C)` enums with fields, we generate a new fieldless `repr(C)` enum/// with the same variants, then use that in the calculation. This is the/// specified behavior, see https://doc.rust-lang.org/stable/reference/type-layout.html#reprc-enums-with-fields/// Returns a tuple of (type ident, auxiliary definitions)generate_enum_discriminantget_ident_from_streamget_simple_attr/// get a simple #[foo(bar)] attribute, returning "bar"get_reprRepresentationmk_reprIntegerReprIsize// whereCWithDiscriminantas_integerenum_has_fieldslast_valueVariantDiscriminantIteratorparse_int_exprparse_basic_reprparse_advanced_reprGENERATED_TYPE_DOCUMENTATION/// Reads an unsigned 8 bit integer from the underlying reader./// Note that since this reads a single byte, no byte order conversions/// are used. It is included for completeness./// This method returns the same errors as [`Read::read_exact`]./// [`Read::read_exact`]: https://doc.rust-lang.org/std/io/trait.Read.html#method.read_exact/// Read unsigned 8 bit integers from a `Read`:/// use byteorder::ReadBytesExt;/// let mut rdr = Cursor::new(vec![2, 5]);/// assert_eq!(2, rdr.read_u8().unwrap());/// assert_eq!(5, rdr.read_u8().unwrap());/// Reads a signed 8 bit integer from the underlying reader./// Read signed 8 bit integers from a `Read`:/// let mut rdr = Cursor::new(vec![0x02, 0xfb]);/// assert_eq!(2, rdr.read_i8().unwrap());/// assert_eq!(-5, rdr.read_i8().unwrap());/// Reads an unsigned 16 bit integer from the underlying reader./// Read unsigned 16 bit big-endian integers from a `Read`:/// use byteorder::{BigEndian, ReadBytesExt};/// let mut rdr = Cursor::new(vec![2, 5, 3, 0]);/// assert_eq!(517, rdr.read_u16::<BigEndian>().unwrap());/// assert_eq!(768, rdr.read_u16::<BigEndian>().unwrap());/// Reads a signed 16 bit integer from the underlying reader./// Read signed 16 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0x00, 0xc1, 0xff, 0x7c]);/// assert_eq!(193, rdr.read_i16::<BigEndian>().unwrap());/// assert_eq!(-132, rdr.read_i16::<BigEndian>().unwrap());read_u24/// Reads an unsigned 24 bit integer from the underlying reader./// Read unsigned 24 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0x00, 0x01, 0x0b]);/// assert_eq!(267, rdr.read_u24::<BigEndian>().unwrap());read_i24/// Reads a signed 24 bit integer from the underlying reader./// Read signed 24 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0xff, 0x7a, 0x33]);/// assert_eq!(-34253, rdr.read_i24::<BigEndian>().unwrap());/// Reads an unsigned 32 bit integer from the underlying reader./// Read unsigned 32 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0x00, 0x00, 0x01, 0x0b]);/// assert_eq!(267, rdr.read_u32::<BigEndian>().unwrap());/// Reads a signed 32 bit integer from the underlying reader./// Read signed 32 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0xff, 0xff, 0x7a, 0x33]);/// assert_eq!(-34253, rdr.read_i32::<BigEndian>().unwrap());read_u48/// Reads an unsigned 48 bit integer from the underlying reader./// Read unsigned 48 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0xb6, 0x71, 0x6b, 0xdc, 0x2b, 0x31]);/// assert_eq!(200598257150769, rdr.read_u48::<BigEndian>().unwrap());read_i48/// Reads a signed 48 bit integer from the underlying reader./// Read signed 48 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0x9d, 0x71, 0xab, 0xe7, 0x97, 0x8f]);/// assert_eq!(-108363435763825, rdr.read_i48::<BigEndian>().unwrap());/// Reads an unsigned 64 bit integer from the underlying reader./// Read an unsigned 64 bit big-endian integer from a `Read`:/// let mut rdr = Cursor::new(vec![0x00, 0x03, 0x43, 0x95, 0x4d, 0x60, 0x86, 0x83]);/// assert_eq!(918733457491587, rdr.read_u64::<BigEndian>().unwrap());/// Reads a signed 64 bit integer from the underlying reader./// Read a signed 64 bit big-endian integer from a `Read`:/// let mut rdr = Cursor::new(vec![0x80, 0, 0, 0, 0, 0, 0, 0]);/// assert_eq!(i64::min_value(), rdr.read_i64::<BigEndian>().unwrap());/// Reads an unsigned 128 bit integer from the underlying reader./// Read an unsigned 128 bit big-endian integer from a `Read`:/// let mut rdr = Cursor::new(vec![///     0x00, 0x03, 0x43, 0x95, 0x4d, 0x60, 0x86, 0x83,///     0x00, 0x03, 0x43, 0x95, 0x4d, 0x60, 0x86, 0x83/// assert_eq!(16947640962301618749969007319746179, rdr.read_u128::<BigEndian>().unwrap());/// Reads a signed 128 bit integer from the underlying reader./// Read a signed 128 bit big-endian integer from a `Read`:/// let mut rdr = Cursor::new(vec![0x80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]);/// assert_eq!(i128::min_value(), rdr.read_i128::<BigEndian>().unwrap());read_uint/// Reads an unsigned n-bytes integer from the underlying reader./// Read an unsigned n-byte big-endian integer from a `Read`:/// let mut rdr = Cursor::new(vec![0x80, 0x74, 0xfa]);/// assert_eq!(8418554, rdr.read_uint::<BigEndian>(3).unwrap());read_int/// Reads a signed n-bytes integer from the underlying reader./// let mut rdr = Cursor::new(vec![0xc1, 0xff, 0x7c]);/// assert_eq!(-4063364, rdr.read_int::<BigEndian>(3).unwrap());read_uint128read_int128/// Reads a IEEE754 single-precision (4 bytes) floating point number from/// the underlying reader./// Read a big-endian single-precision floating point number from a `Read`:/// use std::f32;///     0x40, 0x49, 0x0f, 0xdb,/// assert_eq!(f32::consts::PI, rdr.read_f32::<BigEndian>().unwrap());/// Reads a IEEE754 double-precision (8 bytes) floating point number from/// Read a big-endian double-precision floating point number from a `Read`:/// use std::f64;///     0x40, 0x09, 0x21, 0xfb, 0x54, 0x44, 0x2d, 0x18,/// assert_eq!(f64::consts::PI, rdr.read_f64::<BigEndian>().unwrap());read_u16_into/// Reads a sequence of unsigned 16 bit integers from the underlying/// reader./// The given buffer is either filled completely or an error is returned./// If an error is returned, the contents of `dst` are unspecified./// Read a sequence of unsigned 16 bit big-endian integers from a `Read`:/// let mut dst = [0; 2];/// rdr.read_u16_into::<BigEndian>(&mut dst).unwrap();/// assert_eq!([517, 768], dst);read_u32_into/// Reads a sequence of unsigned 32 bit integers from the underlying/// Read a sequence of unsigned 32 bit big-endian integers from a `Read`:/// let mut rdr = Cursor::new(vec![0, 0, 2, 5, 0, 0, 3, 0]);/// rdr.read_u32_into::<BigEndian>(&mut dst).unwrap();read_u64_into/// Reads a sequence of unsigned 64 bit integers from the underlying/// Read a sequence of unsigned 64 bit big-endian integers from a `Read`:///     0, 0, 0, 0, 0, 0, 2, 5,///     0, 0, 0, 0, 0, 0, 3, 0,/// rdr.read_u64_into::<BigEndian>(&mut dst).unwrap();read_u128_into/// Reads a sequence of unsigned 128 bit integers from the underlying/// Read a sequence of unsigned 128 bit big-endian integers from a `Read`:///     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5,///     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0,/// rdr.read_u128_into::<BigEndian>(&mut dst).unwrap();read_i8_into/// Reads a sequence of signed 8 bit integers from the underlying reader./// Note that since each `i8` is a single byte, no byte order conversions/// are used. This method is included because it provides a safe, simple/// way for the caller to read into a `&mut [i8]` buffer. (Without this/// method, the caller would have to either use `unsafe` code or convert/// each byte to `i8` individually.)/// Read a sequence of signed 8 bit integers from a `Read`:/// let mut rdr = Cursor::new(vec![2, 251, 3]);/// let mut dst = [0; 3];/// rdr.read_i8_into(&mut dst).unwrap();/// assert_eq!([2, -5, 3], dst);read_i16_into/// Reads a sequence of signed 16 bit integers from the underlying/// Read a sequence of signed 16 bit big-endian integers from a `Read`:/// rdr.read_i16_into::<BigEndian>(&mut dst).unwrap();read_i32_into/// Reads a sequence of signed 32 bit integers from the underlying/// Read a sequence of signed 32 bit big-endian integers from a `Read`:/// rdr.read_i32_into::<BigEndian>(&mut dst).unwrap();read_i64_into/// Reads a sequence of signed 64 bit integers from the underlying/// Read a sequence of signed 64 bit big-endian integers from a `Read`:/// rdr.read_i64_into::<BigEndian>(&mut dst).unwrap();read_i128_into/// Reads a sequence of signed 128 bit integers from the underlying/// Read a sequence of signed 128 bit big-endian integers from a `Read`:/// rdr.read_i128_into::<BigEndian>(&mut dst).unwrap();read_f32_into/// Reads a sequence of IEEE754 single-precision (4 bytes) floating/// point numbers from the underlying reader./// Read a sequence of big-endian single-precision floating point number/// from a `Read`:///     0x3f, 0x80, 0x00, 0x00,/// let mut dst = [0.0; 2];/// rdr.read_f32_into::<BigEndian>(&mut dst).unwrap();/// assert_eq!([f32::consts::PI, 1.0], dst);read_f32_into_unchecked/// **DEPRECATED**./// This method is deprecated. Use `read_f32_into` instead./// rdr.read_f32_into_unchecked::<BigEndian>(&mut dst).unwrap();read_f64_into/// Reads a sequence of IEEE754 double-precision (8 bytes) floating///     0x3f, 0xF0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,/// rdr.read_f64_into::<BigEndian>(&mut dst).unwrap();/// assert_eq!([f64::consts::PI, 1.0], dst);read_f64_into_unchecked/// This method is deprecated. Use `read_f64_into` instead./// This method is unsafe because there are no guarantees made about the/// floating point values. In particular, this method does not check for/// signaling NaNs, which may result in undefined behavior./// rdr.read_f64_into_unchecked::<BigEndian>(&mut dst).unwrap();/// Extends [`Read`] with methods for reading numbers. (For `std::io`.)/// Most of the methods defined here have an unconstrained type parameter that/// must be explicitly instantiated. Typically, it is instantiated with either/// the [`BigEndian`] or [`LittleEndian`] types defined in this crate./// Read unsigned 16 bit big-endian integers from a [`Read`]:/// [`BigEndian`]: enum.BigEndian.html/// [`LittleEndian`]: enum.LittleEndian.html/// [`Read`]: https://doc.rust-lang.org/std/io/trait.Read.html/// All types that implement `Read` get methods defined in `ReadBytesExt`/// for free./// Writes an unsigned 8 bit integer to the underlying writer./// Note that since this writes a single byte, no byte order conversions/// This method returns the same errors as [`Write::write_all`]./// [`Write::write_all`]: https://doc.rust-lang.org/std/io/trait.Write.html#method.write_all/// Write unsigned 8 bit integers to a `Write`:/// use byteorder::WriteBytesExt;/// let mut wtr = Vec::new();/// wtr.write_u8(2).unwrap();/// wtr.write_u8(5).unwrap();/// assert_eq!(wtr, b"\x02\x05");/// Writes a signed 8 bit integer to the underlying writer./// Write signed 8 bit integers to a `Write`:/// wtr.write_i8(2).unwrap();/// wtr.write_i8(-5).unwrap();/// assert_eq!(wtr, b"\x02\xfb");/// Writes an unsigned 16 bit integer to the underlying writer./// Write unsigned 16 bit big-endian integers to a `Write`:/// use byteorder::{BigEndian, WriteBytesExt};/// wtr.write_u16::<BigEndian>(517).unwrap();/// wtr.write_u16::<BigEndian>(768).unwrap();/// assert_eq!(wtr, b"\x02\x05\x03\x00");/// Writes a signed 16 bit integer to the underlying writer./// Write signed 16 bit big-endian integers to a `Write`:/// wtr.write_i16::<BigEndian>(193).unwrap();/// wtr.write_i16::<BigEndian>(-132).unwrap();/// assert_eq!(wtr, b"\x00\xc1\xff\x7c");write_u24/// Writes an unsigned 24 bit integer to the underlying writer./// Write unsigned 24 bit big-endian integers to a `Write`:/// wtr.write_u24::<BigEndian>(267).unwrap();/// wtr.write_u24::<BigEndian>(120111).unwrap();/// assert_eq!(wtr, b"\x00\x01\x0b\x01\xd5\x2f");write_i24/// Writes a signed 24 bit integer to the underlying writer./// Write signed 24 bit big-endian integers to a `Write`:/// wtr.write_i24::<BigEndian>(-34253).unwrap();/// wtr.write_i24::<BigEndian>(120111).unwrap();/// assert_eq!(wtr, b"\xff\x7a\x33\x01\xd5\x2f");/// Writes an unsigned 32 bit integer to the underlying writer./// Write unsigned 32 bit big-endian integers to a `Write`:/// wtr.write_u32::<BigEndian>(267).unwrap();/// wtr.write_u32::<BigEndian>(1205419366).unwrap();/// assert_eq!(wtr, b"\x00\x00\x01\x0b\x47\xd9\x3d\x66");/// Writes a signed 32 bit integer to the underlying writer./// Write signed 32 bit big-endian integers to a `Write`:/// wtr.write_i32::<BigEndian>(-34253).unwrap();/// wtr.write_i32::<BigEndian>(1205419366).unwrap();/// assert_eq!(wtr, b"\xff\xff\x7a\x33\x47\xd9\x3d\x66");write_u48/// Writes an unsigned 48 bit integer to the underlying writer./// Write unsigned 48 bit big-endian integers to a `Write`:/// wtr.write_u48::<BigEndian>(52360336390828).unwrap();/// wtr.write_u48::<BigEndian>(541).unwrap();/// assert_eq!(wtr, b"\x2f\x9f\x17\x40\x3a\xac\x00\x00\x00\x00\x02\x1d");write_i48/// Writes a signed 48 bit integer to the underlying writer./// Write signed 48 bit big-endian integers to a `Write`:/// wtr.write_i48::<BigEndian>(-108363435763825).unwrap();/// wtr.write_i48::<BigEndian>(77).unwrap();/// assert_eq!(wtr, b"\x9d\x71\xab\xe7\x97\x8f\x00\x00\x00\x00\x00\x4d");/// Writes an unsigned 64 bit integer to the underlying writer./// Write unsigned 64 bit big-endian integers to a `Write`:/// wtr.write_u64::<BigEndian>(918733457491587).unwrap();/// wtr.write_u64::<BigEndian>(143).unwrap();/// assert_eq!(wtr, b"\x00\x03\x43\x95\x4d\x60\x86\x83\x00\x00\x00\x00\x00\x00\x00\x8f");/// Writes a signed 64 bit integer to the underlying writer./// Write signed 64 bit big-endian integers to a `Write`:/// wtr.write_i64::<BigEndian>(i64::min_value()).unwrap();/// wtr.write_i64::<BigEndian>(i64::max_value()).unwrap();/// assert_eq!(wtr, b"\x80\x00\x00\x00\x00\x00\x00\x00\x7f\xff\xff\xff\xff\xff\xff\xff");/// Writes an unsigned 128 bit integer to the underlying writer./// Writes a signed 128 bit integer to the underlying writer.write_uint/// Writes an unsigned n-bytes integer to the underlying writer./// If the given integer is not representable in the given number of bytes,/// this method panics. If `nbytes > 8`, this method panics./// Write unsigned 40 bit big-endian integers to a `Write`:/// wtr.write_uint::<BigEndian>(312550384361, 5).unwrap();/// wtr.write_uint::<BigEndian>(43, 5).unwrap();/// assert_eq!(wtr, b"\x48\xc5\x74\x62\xe9\x00\x00\x00\x00\x2b");write_int/// Writes a signed n-bytes integer to the underlying writer./// Write signed 56 bit big-endian integers to a `Write`:/// wtr.write_int::<BigEndian>(-3548172039376767, 7).unwrap();/// wtr.write_int::<BigEndian>(43, 7).unwrap();/// assert_eq!(wtr, b"\xf3\x64\xf4\xd1\xfd\xb0\x81\x00\x00\x00\x00\x00\x00\x2b");write_uint128/// this method panics. If `nbytes > 16`, this method panics.write_int128/// Writes a IEEE754 single-precision (4 bytes) floating point number to/// the underlying writer./// Write a big-endian single-precision floating point number to a `Write`:/// wtr.write_f32::<BigEndian>(f32::consts::PI).unwrap();/// assert_eq!(wtr, b"\x40\x49\x0f\xdb");/// Writes a IEEE754 double-precision (8 bytes) floating point number to/// Write a big-endian double-precision floating point number to a `Write`:/// wtr.write_f64::<BigEndian>(f64::consts::PI).unwrap();/// assert_eq!(wtr, b"\x40\x09\x21\xfb\x54\x44\x2d\x18");/// Extends [`Write`] with methods for writing numbers. (For `std::io`.)/// Write unsigned 16 bit big-endian integers to a [`Write`]:/// let mut wtr = vec![];/// assert_eq!(wtr, vec![2, 5, 3, 0]);/// [`Write`]: https://doc.rust-lang.org/std/io/trait.Write.html/// All types that implement `Write` get methods defined in `WriteBytesExt`slice_to_u8_mut/// Convert a slice of T (where T is plain old data) to its mutable binary/// This function is wildly unsafe because it permits arbitrary modification of/// the binary representation of any `Copy` type. Use with care. It's intended/// to be called only where `T` is a numeric type.extend_signextend_sign128unextend_signunextend_sign128pack_sizepack_size128/// Sealed stops crates other than byteorder from implementing any traits/// that use it./// Reads an unsigned 16 bit integer from `buf`./// Panics when `buf.len() < 2`./// Reads an unsigned 24 bit integer from `buf`, stored in u32./// Panics when `buf.len() < 3`./// Write and read 24 bit `u32` numbers in little endian order:/// use byteorder::{ByteOrder, LittleEndian};/// let mut buf = [0; 3];/// LittleEndian::write_u24(&mut buf, 1_000_000);/// assert_eq!(1_000_000, LittleEndian::read_u24(&buf));/// Reads an unsigned 32 bit integer from `buf`./// Panics when `buf.len() < 4`./// Write and read `u32` numbers in little endian order:/// let mut buf = [0; 4];/// LittleEndian::write_u32(&mut buf, 1_000_000);/// assert_eq!(1_000_000, LittleEndian::read_u32(&buf));/// Reads an unsigned 48 bit integer from `buf`, stored in u64./// Panics when `buf.len() < 6`./// Write and read 48 bit `u64` numbers in little endian order:/// let mut buf = [0; 6];/// LittleEndian::write_u48(&mut buf, 1_000_000_000_000);/// assert_eq!(1_000_000_000_000, LittleEndian::read_u48(&buf));/// Reads an unsigned 64 bit integer from `buf`./// Panics when `buf.len() < 8`./// Write and read `u64` numbers in little endian order:/// let mut buf = [0; 8];/// LittleEndian::write_u64(&mut buf, 1_000_000);/// assert_eq!(1_000_000, LittleEndian::read_u64(&buf));/// Reads an unsigned 128 bit integer from `buf`./// Panics when `buf.len() < 16`./// Write and read `u128` numbers in little endian order:/// let mut buf = [0; 16];/// LittleEndian::write_u128(&mut buf, 1_000_000);/// assert_eq!(1_000_000, LittleEndian::read_u128(&buf));/// Reads an unsigned n-bytes integer from `buf`./// Panics when `nbytes < 1` or `nbytes > 8` or/// `buf.len() < nbytes`/// Write and read an n-byte number in little endian order:/// LittleEndian::write_uint(&mut buf, 1_000_000, 3);/// assert_eq!(1_000_000, LittleEndian::read_uint(&buf, 3));/// Panics when `nbytes < 1` or `nbytes > 16` or/// LittleEndian::write_uint128(&mut buf, 1_000_000, 3);/// assert_eq!(1_000_000, LittleEndian::read_uint128(&buf, 3));/// Writes an unsigned 16 bit integer `n` to `buf`./// Write and read `u16` numbers in little endian order:/// let mut buf = [0; 2];/// LittleEndian::write_u16(&mut buf, 1_000);/// assert_eq!(1_000, LittleEndian::read_u16(&buf));/// Writes an unsigned 24 bit integer `n` to `buf`, stored in u32./// Writes an unsigned 32 bit integer `n` to `buf`./// Writes an unsigned 48 bit integer `n` to `buf`, stored in u64./// Writes an unsigned 64 bit integer `n` to `buf`./// Writes an unsigned 128 bit integer `n` to `buf`./// Writes an unsigned integer `n` to `buf` using only `nbytes`./// If `n` is not representable in `nbytes`, or if `nbytes` is `> 8`, then/// this method panics./// If `n` is not representable in `nbytes`, or if `nbytes` is `> 16`, then/// Reads a signed 16 bit integer from `buf`./// Write and read `i16` numbers in little endian order:/// LittleEndian::write_i16(&mut buf, -1_000);/// assert_eq!(-1_000, LittleEndian::read_i16(&buf));/// Reads a signed 24 bit integer from `buf`, stored in i32./// Write and read 24 bit `i32` numbers in little endian order:/// LittleEndian::write_i24(&mut buf, -1_000_000);/// assert_eq!(-1_000_000, LittleEndian::read_i24(&buf));/// Reads a signed 32 bit integer from `buf`./// Write and read `i32` numbers in little endian order:/// LittleEndian::write_i32(&mut buf, -1_000_000);/// assert_eq!(-1_000_000, LittleEndian::read_i32(&buf));/// Reads a signed 48 bit integer from `buf`, stored in i64./// Write and read 48 bit `i64` numbers in little endian order:/// LittleEndian::write_i48(&mut buf, -1_000_000_000_000);/// assert_eq!(-1_000_000_000_000, LittleEndian::read_i48(&buf));/// Reads a signed 64 bit integer from `buf`./// Write and read `i64` numbers in little endian order:/// LittleEndian::write_i64(&mut buf, -1_000_000_000);/// assert_eq!(-1_000_000_000, LittleEndian::read_i64(&buf));/// Reads a signed 128 bit integer from `buf`./// Write and read `i128` numbers in little endian order:/// LittleEndian::write_i128(&mut buf, -1_000_000_000);/// assert_eq!(-1_000_000_000, LittleEndian::read_i128(&buf));/// Reads a signed n-bytes integer from `buf`./// Write and read n-length signed numbers in little endian order:/// LittleEndian::write_int(&mut buf, -1_000, 3);/// assert_eq!(-1_000, LittleEndian::read_int(&buf, 3));/// LittleEndian::write_int128(&mut buf, -1_000, 3);/// assert_eq!(-1_000, LittleEndian::read_int128(&buf, 3));/// Reads a IEEE754 single-precision (4 bytes) floating point number./// Write and read `f32` numbers in little endian order:/// let e = 2.71828;/// LittleEndian::write_f32(&mut buf, e);/// assert_eq!(e, LittleEndian::read_f32(&buf));/// Reads a IEEE754 double-precision (8 bytes) floating point number./// Write and read `f64` numbers in little endian order:/// let phi = 1.6180339887;/// LittleEndian::write_f64(&mut buf, phi);/// assert_eq!(phi, LittleEndian::read_f64(&buf));/// Writes a signed 16 bit integer `n` to `buf`./// Writes a signed 24 bit integer `n` to `buf`, stored in i32./// Writes a signed 32 bit integer `n` to `buf`./// Writes a signed 48 bit integer `n` to `buf`, stored in i64./// Writes a signed 64 bit integer `n` to `buf`./// Writes a signed 128 bit integer `n` to `buf`./// Write and read n-byte `i128` numbers in little endian order:/// Writes a signed integer `n` to `buf` using only `nbytes`./// Writes a IEEE754 single-precision (4 bytes) floating point number./// Writes a IEEE754 double-precision (8 bytes) floating point number./// Reads unsigned 16 bit integers from `src` into `dst`./// Panics when `src.len() != 2*dst.len()`./// let mut bytes = [0; 8];/// let numbers_given = [1, 2, 0xf00f, 0xffee];/// LittleEndian::write_u16_into(&numbers_given, &mut bytes);/// let mut numbers_got = [0; 4];/// LittleEndian::read_u16_into(&bytes, &mut numbers_got);/// assert_eq!(numbers_given, numbers_got);/// Reads unsigned 32 bit integers from `src` into `dst`./// Panics when `src.len() != 4*dst.len()`./// let mut bytes = [0; 16];/// LittleEndian::write_u32_into(&numbers_given, &mut bytes);/// LittleEndian::read_u32_into(&bytes, &mut numbers_got);/// Reads unsigned 64 bit integers from `src` into `dst`./// Panics when `src.len() != 8*dst.len()`./// let mut bytes = [0; 32];/// LittleEndian::write_u64_into(&numbers_given, &mut bytes);/// LittleEndian::read_u64_into(&bytes, &mut numbers_got);/// Reads unsigned 128 bit integers from `src` into `dst`./// Panics when `src.len() != 16*dst.len()`./// let mut bytes = [0; 64];/// LittleEndian::write_u128_into(&numbers_given, &mut bytes);/// LittleEndian::read_u128_into(&bytes, &mut numbers_got);/// Reads signed 16 bit integers from `src` to `dst`./// Panics when `buf.len() != 2*dst.len()`./// let numbers_given = [1, 2, 0x0f, 0xee];/// LittleEndian::write_i16_into(&numbers_given, &mut bytes);/// LittleEndian::read_i16_into(&bytes, &mut numbers_got);/// Reads signed 32 bit integers from `src` into `dst`./// LittleEndian::write_i32_into(&numbers_given, &mut bytes);/// LittleEndian::read_i32_into(&bytes, &mut numbers_got);/// Reads signed 64 bit integers from `src` into `dst`./// LittleEndian::write_i64_into(&numbers_given, &mut bytes);/// LittleEndian::read_i64_into(&bytes, &mut numbers_got);/// Reads signed 128 bit integers from `src` into `dst`./// LittleEndian::write_i128_into(&numbers_given, &mut bytes);/// LittleEndian::read_i128_into(&bytes, &mut numbers_got);/// Reads IEEE754 single-precision (4 bytes) floating point numbers from/// `src` into `dst`./// let numbers_given = [1.0, 2.0, 31.312e31, -11.32e19];/// LittleEndian::write_f32_into(&numbers_given, &mut bytes);/// let mut numbers_got = [0.0; 4];/// LittleEndian::read_f32_into(&bytes, &mut numbers_got);/// LittleEndian::read_f32_into_unchecked(&bytes, &mut numbers_got);/// let numbers_given = [1.0, 2.0, 31.312e211, -11.32e91];/// LittleEndian::write_f64_into(&numbers_given, &mut bytes);/// LittleEndian::read_f64_into(&bytes, &mut numbers_got);/// LittleEndian::read_f64_into_unchecked(&bytes, &mut numbers_got);write_u16_into/// Writes unsigned 16 bit integers from `src` into `dst`./// Panics when `dst.len() != 2*src.len()`.write_u32_into/// Writes unsigned 32 bit integers from `src` into `dst`./// Panics when `dst.len() != 4*src.len()`.write_u64_into/// Writes unsigned 64 bit integers from `src` into `dst`./// Panics when `dst.len() != 8*src.len()`.write_u128_into/// Writes unsigned 128 bit integers from `src` into `dst`./// Panics when `dst.len() != 16*src.len()`.write_i8_into/// Writes signed 8 bit integers from `src` into `dst`./// way for the caller to write from a `&[i8]` buffer. (Without this/// each byte to `u8` individually.)/// Panics when `buf.len() != src.len()`./// Write and read `i8` numbers in little endian order:/// use byteorder::{ByteOrder, LittleEndian, ReadBytesExt};/// let mut bytes = [0; 4];/// let numbers_given = [1, 2, 0xf, 0xe];/// LittleEndian::write_i8_into(&numbers_given, &mut bytes);/// bytes.as_ref().read_i8_into(&mut numbers_got);write_i16_into/// Writes signed 16 bit integers from `src` into `dst`./// Panics when `buf.len() != 2*src.len()`.write_i32_into/// Writes signed 32 bit integers from `src` into `dst`.write_i64_into/// Writes signed 64 bit integers from `src` into `dst`.write_i128_into/// Writes signed 128 bit integers from `src` into `dst`.write_f32_into/// Writes IEEE754 single-precision (4 bytes) floating point numbers fromwrite_f64_into/// Writes IEEE754 double-precision (8 bytes) floating point numbers fromfrom_slice_u16/// Converts the given slice of unsigned 16 bit integers to a particular/// endianness./// If the endianness matches the endianness of the host platform, then/// this is a no-op./// Convert the host platform's endianness to big-endian:/// use byteorder::{ByteOrder, BigEndian};/// let mut numbers = [5, 65000];/// BigEndian::from_slice_u16(&mut numbers);/// assert_eq!(numbers, [5u16.to_be(), 65000u16.to_be()]);from_slice_u32/// Converts the given slice of unsigned 32 bit integers to a particular/// BigEndian::from_slice_u32(&mut numbers);/// assert_eq!(numbers, [5u32.to_be(), 65000u32.to_be()]);from_slice_u64/// Converts the given slice of unsigned 64 bit integers to a particular/// BigEndian::from_slice_u64(&mut numbers);/// assert_eq!(numbers, [5u64.to_be(), 65000u64.to_be()]);from_slice_u128/// Converts the given slice of unsigned 128 bit integers to a particular/// BigEndian::from_slice_u128(&mut numbers);/// assert_eq!(numbers, [5u128.to_be(), 65000u128.to_be()]);from_slice_i16/// Converts the given slice of signed 16 bit integers to a particular/// let mut numbers = [5, 6500];/// BigEndian::from_slice_i16(&mut numbers);/// assert_eq!(numbers, [5i16.to_be(), 6500i16.to_be()]);from_slice_i32/// Converts the given slice of signed 32 bit integers to a particular/// BigEndian::from_slice_i32(&mut numbers);/// assert_eq!(numbers, [5i32.to_be(), 65000i32.to_be()]);from_slice_i64/// Converts the given slice of signed 64 bit integers to a particular/// BigEndian::from_slice_i64(&mut numbers);/// assert_eq!(numbers, [5i64.to_be(), 65000i64.to_be()]);from_slice_i128/// Converts the given slice of signed 128 bit integers to a particular/// BigEndian::from_slice_i128(&mut numbers);/// assert_eq!(numbers, [5i128.to_be(), 65000i128.to_be()]);from_slice_f32/// Converts the given slice of IEEE754 single-precision (4 bytes) floating/// point numbers to a particular endianness.from_slice_f64/// Converts the given slice of IEEE754 double-precision (8 bytes) floating/// `ByteOrder` describes types that can serialize integers as bytes./// Note that `Self` does not appear anywhere in this trait's definition!/// Therefore, in order to use it, you'll need to use syntax like/// `T::read_u16(&[0, 1])` where `T` implements `ByteOrder`./// This crate provides two types that implement `ByteOrder`: [`BigEndian`]/// and [`LittleEndian`]./// This trait is sealed and cannot be implemented for callers to avoid/// breaking backwards compatibility when adding new derived traits./// Write and read `i16` numbers in big endian order:/// BigEndian::write_i16(&mut buf, -5_000);/// assert_eq!(-5_000, BigEndian::read_i16(&buf));/// Defines big-endian serialization./// Note that this type has no value constructor. It is used purely at the/// type level./// Write and read `u32` numbers in big endian order:/// BigEndian::write_u32(&mut buf, 1_000_000);/// assert_eq!(1_000_000, BigEndian::read_u32(&buf));BE/// A type alias for [`BigEndian`]./// Defines little-endian serialization.LE/// A type alias for [`LittleEndian`].NetworkEndian/// Defines network byte order serialization./// Network byte order is defined by [RFC 1700][1] to be big-endian, and is/// referred to in several protocol specifications.  This type is an alias of/// [`BigEndian`]./// [1]: https://tools.ietf.org/html/rfc1700/// use byteorder::{ByteOrder, NetworkEndian, BigEndian};/// assert_eq!(-5_000, NetworkEndian::read_i16(&buf));/// Defines system native-endian serialization./// On this platform, this is an alias for [`LittleEndian`].read_slice/// Copies a &[u8] $src into a &mut [$ty] $dst for the endianness given by/// $from_bytes (must be either from_be_bytes or from_le_bytes)./// Panics if $src.len() != $dst.len() * size_of::<$ty>().write_slice/// Copies a &[$ty] $src into a &mut [u8] $dst for the endianness given by/// Panics if $src.len() * size_of::<$ty>() != $dst.len().GenQuickCheckStdGenTestablethread_rngU24_MAXI24_MAXU48_MAXI48_MAXU64_MAXI64_MAXcalc_maxWi128qc_sizedqc_byte_orderprop_u16prop_i16prop_u24prop_i24prop_u32prop_i32prop_u48prop_i48prop_u64prop_i64prop_f32prop_f64prop_u128prop_i128prop_uint_1prop_uint_2prop_uint_3prop_uint_4prop_uint_5prop_uint_6prop_uint_7prop_uint_8prop_uint128_1prop_uint128_2prop_uint128_3prop_uint128_4prop_uint128_5prop_uint128_6prop_uint128_7prop_uint128_8prop_uint128_9prop_uint128_10prop_uint128_11prop_uint128_12prop_uint128_13prop_uint128_14prop_uint128_15prop_uint128_16prop_int_1prop_int_2prop_int_3prop_int_4prop_int_5prop_int_6prop_int_7prop_int_8prop_int128_1prop_int128_2prop_int128_3prop_int128_4prop_int128_5prop_int128_6prop_int128_7prop_int128_8prop_int128_9prop_int128_10prop_int128_11prop_int128_12prop_int128_13prop_int128_14prop_int128_15prop_int128_16too_small// Test that all of the byte conversion functions panic when given a// buffer that is too small.// These tests are critical to ensure safety, otherwise we might end up// with a buffer overflow.read_big_endianread_little_endianread_native_endianwrite_big_endianwrite_little_endianwrite_native_endiansmall_u16small_i16small_u32small_i32small_u64small_i64small_f32small_f64small_u128small_i128small_uint_1small_uint_2small_uint_3small_uint_4small_uint_5small_uint_6small_uint_7small_uint128_1small_uint128_2small_uint128_3small_uint128_4small_uint128_5small_uint128_6small_uint128_7small_uint128_8small_uint128_9small_uint128_10small_uint128_11small_uint128_12small_uint128_13small_uint128_14small_uint128_15small_int_1small_int_2small_int_3small_int_4small_int_5small_int_6small_int_7small_int128_1small_int128_2small_int128_3small_int128_4small_int128_5small_int128_6small_int128_7small_int128_8small_int128_9small_int128_10small_int128_11small_int128_12small_int128_13small_int128_14small_int128_15slice_lengths// Test that reading/writing slices enforces the correct lengths.slice_len_too_small_u16slice_len_too_big_u16slice_len_too_small_i16slice_len_too_big_i16slice_len_too_small_u32slice_len_too_big_u32slice_len_too_small_i32slice_len_too_big_i32slice_len_too_small_u64slice_len_too_big_u64slice_len_too_small_i64slice_len_too_big_i64slice_len_too_small_u128slice_len_too_big_u128slice_len_too_small_i128slice_len_too_big_i128uint_bigger_bufferregression173_array_implqc_unsizedqc_bytes_extprop_ext_u16prop_ext_i16prop_ext_u32prop_ext_i32prop_ext_u64prop_ext_i64prop_ext_f32prop_ext_f64prop_ext_u128prop_ext_i128prop_ext_uint_1prop_ext_uint_2prop_ext_uint_3prop_ext_uint_4prop_ext_uint_5prop_ext_uint_6prop_ext_uint_7prop_ext_uint_8prop_ext_uint128_1prop_ext_uint128_2prop_ext_uint128_3prop_ext_uint128_4prop_ext_uint128_5prop_ext_uint128_6prop_ext_uint128_7prop_ext_uint128_8prop_ext_uint128_9prop_ext_uint128_10prop_ext_uint128_11prop_ext_uint128_12prop_ext_uint128_13prop_ext_uint128_14prop_ext_uint128_15prop_ext_uint128_16prop_ext_int_1prop_ext_int_2prop_ext_int_3prop_ext_int_4prop_ext_int_5prop_ext_int_6prop_ext_int_7prop_ext_int_8prop_ext_int128_1prop_ext_int128_2prop_ext_int128_3prop_ext_int128_4prop_ext_int128_5prop_ext_int128_6prop_ext_int128_7prop_ext_int128_8prop_ext_int128_9prop_ext_int128_10prop_ext_int128_11prop_ext_int128_12prop_ext_int128_13prop_ext_int128_14prop_ext_int128_15prop_ext_int128_16qc_slice// Test slice serialization/deserialization.prop_slice_u16prop_slice_i16prop_slice_u32prop_slice_i32prop_slice_u64prop_slice_i64prop_slice_u128prop_slice_i128prop_slice_f32prop_slice_f64stdtests/*!
This crate provides convenience methods for encoding and decoding numbers in
either [big-endian or little-endian order].

The organization of the crate is pretty simple. A trait, [`ByteOrder`], specifies
byte conversion methods for each type of number in Rust (sans numbers that have
a platform dependent size like `usize` and `isize`). Two types, [`BigEndian`]
and [`LittleEndian`] implement these methods. Finally, [`ReadBytesExt`] and
[`WriteBytesExt`] provide convenience methods available to all types that
implement [`Read`] and [`Write`].

An alias, [`NetworkEndian`], for [`BigEndian`] is provided to help improve
code clarity.

An additional alias, [`NativeEndian`], is provided for the endianness of the
local platform. This is convenient when serializing data for use and
conversions are not desired.

# Examples

Read unsigned 16 bit big-endian integers from a [`Read`] type:

```rust
use std::io::Cursor;
use byteorder::{BigEndian, ReadBytesExt};

let mut rdr = Cursor::new(vec![2, 5, 3, 0]);
// Note that we use type parameters to indicate which kind of byte order
// we want!
assert_eq!(517, rdr.read_u16::<BigEndian>().unwrap());
assert_eq!(768, rdr.read_u16::<BigEndian>().unwrap());
```

Write unsigned 16 bit little-endian integers to a [`Write`] type:

```rust
use byteorder::{LittleEndian, WriteBytesExt};

let mut wtr = vec![];
wtr.write_u16::<LittleEndian>(517).unwrap();
wtr.write_u16::<LittleEndian>(768).unwrap();
assert_eq!(wtr, vec![5, 2, 0, 3]);
```

# Optional Features

This crate optionally provides support for 128 bit values (`i128` and `u128`)
when built with the `i128` feature enabled.

This crate can also be used without the standard library.

# Alternatives

Note that as of Rust 1.32, the standard numeric types provide built-in methods
like `to_le_bytes` and `from_le_bytes`, which support some of the same use
cases.

[big-endian or little-endian order]: https://en.wikipedia.org/wiki/Endianness
[`ByteOrder`]: trait.ByteOrder.html
[`BigEndian`]: enum.BigEndian.html
[`LittleEndian`]: enum.LittleEndian.html
[`ReadBytesExt`]: trait.ReadBytesExt.html
[`WriteBytesExt`]: trait.WriteBytesExt.html
[`NetworkEndian`]: type.NetworkEndian.html
[`NativeEndian`]: type.NativeEndian.html
[`Read`]: https://doc.rust-lang.org/std/io/trait.Read.html
[`Write`]: https://doc.rust-lang.org/std/io/trait.Write.html
*/// When testing under miri, we disable tests that take too long. But this// provokes lots of dead code warnings. So we just squash them.ChildChildStderrAtomicBoolObjectwarningsOutputKindchecked_dbg_varCargoOutputForward/// Forward the output to this process' stdout ([`Stdio::inherit()`])Discard/// Discard the output ([`Stdio::null()`])Capture/// Capture the result (`[Stdio::piped()`])/// Different strategies for handling compiler output (to stdout)print_metadataprint_warningprint_debugstdio_for_warningsstdio_for_outputis_non_blockingbytes_available_failedbytes_buffered/// number of bytes buffered in innerStderrForwarderMIN_BUFFER_CAPACITYforward_availableset_non_blockingforward_allwrite_warningwait_on_childobjects_from_files/// Find the destination object path for each file in the input source files,/// and store them in the output Object.run_outputspawncudais_assembler_msvcmsvcclanggnuis_asmCmdAddOutputFileArgscommand_add_output_filetry_wait_on_child//! Miscellaneous helpers for running commandsOsStrComponentRwLockShlexparallelwindowsTargetInfofind_toolswindows_registry// Regardless of whether this should be in this crate's public API,// it has been since 2015, so don't break it.command_helperstoolToolToolFamilytempfileutilitiescompilerflagCompilerFlagEnvenv_cacheapple_sdk_root_cacheapple_versions_cachecached_compiler_familyknown_flag_support_status_cachetarget_info_parserTargetInfoParserBuildCacheinclude_directoriesobjectsflags_supportedar_flagsasm_flagsno_default_flagsfilescppcpp_link_stdlibcpp_set_stdlibcudartccbinhost/// The host compiler./// Try to not access this directly, and instead prefer `cfg!(...)`.opt_levelforce_frame_pointerarchiverranlibcargo_outputlink_lib_modifierspicuse_pltstatic_crtshared_flagstatic_flagwarnings_into_errorsextra_warningsemit_rerun_if_env_changedshell_escaped_flagsbuild_cache/// A builder for compilation of a native library./// A `Build` is the main type of the `cc` crate and is used to control all the/// various configuration options and such of a compile. You'll find more/// documentation on each method itself.IOError/// Error occurred while performing I/O.EnvVarNotFound/// Environment variable not found, with the var in question as extra info.ToolExecError/// Error occurred while using external tools (ie: invocation of compiler).ToolNotFound/// Error occurred due to missing external tools.InvalidArgument/// One of the function arguments failed validation.ToolFamilyMacroNotFound/// No known macro is defined for the compiler when discovering tool familyInvalidTarget/// Invalid targetJobserverHelpThreadError/// jobserver helpthread failure/// Represents the types of errors that may occur while using cc-rs./// Describes the kind of error that occurred.message/// More explanation of error that occurred./// Represents an internal error that occurred, with an explanation.src/// Represents an object./// This is a source file -> object file pair./// Create a new source file -> object file pair./// Construct a new instance of a blank set of configuration./// This builder is finished with the [`compile`] function./// [`compile`]: struct.Build.html#method.compileinclude/// Add a directory to the `-I` or include path for headers/// let library_path = Path::new("/path/to/library");/// cc::Build::new()///     .file("src/foo.c")///     .include(library_path)///     .include("src")///     .compile("foo");includes/// Add multiple directories to the `-I` include path./// # use std::path::Path;/// # let condition = true;/// let mut extra_dir = None;/// if condition {///     extra_dir = Some(Path::new("/path/to"));///     .includes(extra_dir)define/// Specify a `-D` variable with an optional value.///     .define("FOO", "BAR")///     .define("BAZ", None)object/// Add an arbitrary object file to link in/// Add arbitrary object files to link in/// Add an arbitrary flag to the invocation of the compiler///     .flag("-ffunction-sections")remove_flag/// Removes a compiler flag that was added by [`Build::flag`]./// Will not remove flags added by other means (default flags,/// flags from env, and so on).///     .flag("unwanted_flag")///     .remove_flag("unwanted_flag");ar_flag/// Add a flag to the invocation of the ar///     .file("src/bar.c")///     .ar_flag("/NODEFAULTLIB:libc.dll")asm_flag/// Add a flag that will only be used with assembly files./// The flag will be applied to input files with either a `.s` or/// `.asm` extension (case insensitive).///     .asm_flag("-Wa,-defsym,abc=1")///     .file("src/foo.S")  // The asm flag will be applied here///     .file("src/bar.c")  // The asm flag will not be applied hereensure_check_fileis_flag_supported/// Run the compiler to test if it accepts the given flag./// For a convenience method for setting flags conditionally,/// see `flag_if_supported()`./// It may return error if it's unable to run the compiler with a test file/// (e.g. the compiler is missing or a write to the `out_dir` failed)./// Note: Once computed, the result of this call is stored in the/// `known_flag_support` field. If `is_flag_supported(flag)`/// is called again, the result will be read from the hash table.is_flag_supported_innerflag_if_supported/// Add an arbitrary flag to the invocation of the compiler if it supports it///     .flag_if_supported("-Wlogical-op") // only supported by GCC///     .flag_if_supported("-Wunreachable-code") // only supported by clangtry_flags_from_environment/// Add flags from the specified environment variable./// Normally the `cc` crate will consult with the standard set of environment/// variables (such as `CFLAGS` and `CXXFLAGS`) to construct the compiler invocation. Use of/// this method provides additional levers for the end user to use when configuring the build/// process./// Just like the standard variables, this method will search for an environment variable with/// appropriate target prefixes, when appropriate./// This method is particularly beneficial in introducing the ability to specify crate-specific/// flags.///     .try_flags_from_environment(concat!(env!("CARGO_PKG_NAME"), "_CFLAGS"))///     .expect("the environment variable must be specified and UTF-8")/// Set the `-shared` flag./// When enabled, the compiler will produce a shared object which can/// then be linked with other objects to form an executable.///     .shared_flag(true)///     .compile("libfoo.so");/// Set the `-static` flag./// When enabled on systems that support dynamic linking, this prevents/// linking with the shared libraries.///     .static_flag(true)/// Disables the generation of default compiler flags. The default compiler/// flags may cause conflicts in some cross compiling scenarios./// Setting the `CRATE_CC_NO_DEFAULTS` environment variable has the same/// effect as setting this to `true`. The presence of the environment/// variable and the value of `no_default_flags` will be OR'd together./// Add a file which will be compiled/// Add files which will be compiledget_files/// Get the files which will be compiled/// Set C++ support./// The other `cpp_*` options will only become active if this is set to/// `true`./// The name of the C++ standard library to link is decided by:/// 1. If [`cpp_link_stdlib`](Build::cpp_link_stdlib) is set, use its value./// 2. Else if the `CXXSTDLIB` environment variable is set, use its value./// 3. Else the default is `c++` for OS X and BSDs, `c++_shared` for Android,///    `None` for MSVC and `stdc++` for anything else./// Set CUDA C++ support./// Enabling CUDA will invoke the CUDA compiler, NVCC. While NVCC accepts/// the most common compiler flags, e.g. `-std=c++17`, some project-specific/// flags might have to be prefixed with "-Xcompiler" flag, for example as/// `.flag("-Xcompiler").flag("-fpermissive")`. See the documentation for/// `nvcc`, the CUDA compiler driver, at <https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/>/// If enabled, this also implicitly enables C++ support./// Link CUDA run-time./// This option mimics the `--cudart` NVCC command-line option. Just like/// the original it accepts `{none|shared|static}`, with default being/// `static`. The method has to be invoked after `.cuda(true)`, or not/// at all, if the default is right for the project./// Set CUDA host compiler./// By default, a `-ccbin` flag will be passed to NVCC to specify the/// underlying host compiler. The value of `-ccbin` is the same as the/// chosen C++ compiler. This is not always desired, because NVCC might/// not support that compiler. In this case, you can remove the `-ccbin`/// flag so that NVCC will choose the host compiler by itself./// Specify the C or C++ language standard version./// These values are common to modern versions of GCC, Clang and MSVC:/// - `c11` for ISO/IEC 9899:2011/// - `c17` for ISO/IEC 9899:2018/// - `c++14` for ISO/IEC 14882:2014/// - `c++17` for ISO/IEC 14882:2017/// - `c++20` for ISO/IEC 14882:2020/// Other values have less broad support, e.g. MSVC does not support `c++11`/// (`c++14` is the minimum), `c89` (omit the flag instead) or `c99`./// For compiling C++ code, you should also set `.cpp(true)`./// The default is that no standard flag is passed to the compiler, so the/// language version will be the compiler's default.///     .file("src/modern.cpp")///     .cpp(true)///     .std("c++17")///     .compile("modern");/// Set warnings into errors flag./// Disabled by default./// Warning: turning warnings into errors only make sense/// if you are a developer of the crate using cc-rs./// Some warnings only appear on some architecture or/// specific version of the compiler. Any user of this crate,/// or any other crate depending on it, could fail during///     .warnings_into_errors(true)///     .compile("libfoo.a");/// Set warnings flags./// Adds some flags:/// - "-Wall" for MSVC./// - "-Wall", "-Wextra" for GNU and Clang./// Enabled by default.///     .warnings(false)/// Set extra warnings flags./// - nothing for MSVC./// - "-Wextra" for GNU and Clang./// // Disables -Wextra, -Wall remains enabled:///     .extra_warnings(false)/// Set the standard library to link against when compiling with C++/// support./// If the `CXXSTDLIB` environment variable is set, its value will/// override the default value, but not the value explicitly set by calling/// A value of `None` indicates that no automatic linking should happen,/// otherwise cargo will link against the specified library./// The given library name must not contain the `lib` prefix./// Common values:/// - `stdc++` for GNU/// - `c++` for Clang/// - `c++_shared` or `c++_static` for Android///     .cpp_link_stdlib("stdc++")/// Force the C++ compiler to use the specified standard library./// Setting this option will automatically set `cpp_link_stdlib` to the same/// The default value of this option is always `None`./// This option has no effect when compiling for a Visual Studio based/// target./// This option sets the `-stdlib` flag, which is only supported by some/// compilers (clang, icc) but not by others (gcc). The library will not/// detect which compiler is used, as such it is the responsibility of the/// caller to ensure that this option is only used in conjunction with a/// compiler which supports the `-stdlib` flag./// A value of `None` indicates that no specific C++ standard library should/// be used, otherwise `-stdlib` is added to the compile invocation.///     .cpp_set_stdlib("c++")/// Configures the target this configuration will be compiling for./// This option is automatically scraped from the `TARGET` environment/// variable by build scripts, so it's not required to call this function.///     .target("aarch64-linux-android")/// Configures the host assumed by this configuration./// This option is automatically scraped from the `HOST` environment///     .host("arm-linux-gnueabihf")/// Configures the optimization level of the generated object files./// This option is automatically scraped from the `OPT_LEVEL` environmentopt_level_str/// Configures whether the compiler will emit debug information when/// generating object files./// This option is automatically scraped from the `DEBUG` environment/// Configures whether the compiler will emit instructions to store/// frame pointers during codegen./// This option is automatically enabled when debug information is emitted./// Otherwise the target platform compiler's default will be used./// You can use this option to force a specific setting./// Configures the output directory where all object files and static/// libraries will be located./// This option is automatically scraped from the `OUT_DIR` environment/// Configures the compiler to be used to produce output./// This option is automatically determined from the target platform or a/// number of environment variables, so it's not required to call this/// Configures the tool used to assemble archives./// Configures the tool used to index archives.cargo_metadata/// Define whether metadata should be emitted for cargo allowing it to/// automatically link the binary. Defaults to `true`./// The emitted metadata is:///  - `rustc-link-lib=static=`*compiled lib*///  - `rustc-link-search=native=`*target folder*///  - When target is MSVC, the ATL-MFC libs are added via `rustc-link-search=native=`///  - When C++ is enabled, the C++ stdlib is added via `rustc-link-lib`///  - If `emit_rerun_if_env_changed` is not `false`, `rerun-if-env-changed=`*env*cargo_warnings/// Define whether compile warnings should be emitted for cargo. Defaults to/// If disabled, compiler messages will not be printed./// Issues unrelated to the compilation will always produce cargo warnings regardless of this setting.cargo_debug/// Define whether debug information should be emitted for cargo. Defaults to whether/// or not the environment variable `CC_ENABLE_DEBUG_OUTPUT` is set./// If enabled, the compiler will emit debug information when generating object files,/// such as the command invoked and the exit status./// Define whether compiler output (to stdout) should be emitted. Defaults to `true`/// (forward compiler stdout to this process' stdout)/// Some compilers emit errors to stdout, so if you *really* need stdout to be clean/// you should also set this to `false`.link_lib_modifier/// Adds a native library modifier that will be added to the/// `rustc-link-lib=static:MODIFIERS=LIBRARY_NAME` metadata line/// emitted for cargo if `cargo_metadata` is enabled./// See <https://doc.rust-lang.org/rustc/command-line-arguments.html#-l-link-the-generated-crate-to-a-native-library>/// for the list of modifiers accepted by rustc./// Configures whether the compiler will emit position independent code./// This option defaults to `false` for `windows-gnu` and bare metal targets and/// to `true` for all other targets./// Configures whether the Procedure Linkage Table is used for indirect/// calls into shared libraries./// The PLT is used to provide features like lazy binding, but introduces/// a small performance loss due to extra pointer indirection. Setting/// `use_plt` to `false` can provide a small performance increase./// Note that skipping the PLT requires a recent version of GCC/Clang./// This only applies to ELF targets. It has no effect on other platforms./// Define whether metadata should be emitted for cargo to detect environment/// changes that should trigger a rebuild./// NOTE that cc does not emit metadata to detect changes for `PATH`, since it could/// be changed every comilation yet does not affect the result of compilation/// (i.e. rust-analyzer adds temporary directory to `PATH`)./// cc in general, has no way detecting changes to compiler, as there are so many ways to/// change it and sidestep the detection, for example the compiler might be wrapped in a script/// so detecting change of the file, or using checksum won't work./// We recommend users to decide for themselves, if they want rebuild if the compiler has been upgraded/// or changed, and how to detect that./// This has no effect if the `cargo_metadata` option is `false`./// This option defaults to `true`./// Configures whether the /MT flag or the /MD flag will be passed to msvc build tools./// This option defaults to `false`, and affect only msvc targets./// Configure whether *FLAGS variables are parsed using `shlex`, similarly to `make` and/// `cmake`./// This option defaults to `false`.__set_envtry_compile/// Run the compiler, generating the file `output`/// This will return a result instead of panicking; see [`Self::compile()`] for/// the complete description./// # Library name/// The `output` string argument determines the file name for the compiled/// library. The Rust compiler will create an assembly named "lib"+output+".a"./// MSVC will create a file named output+".lib"./// The choice of `output` is close to arbitrary, but:/// - must be nonempty,/// - must not contain a path separator (`/`),/// - must be unique across all `compile` invocations made by the same build///   script./// If your build script compiles a single source file, the base name of/// that source file would usually be reasonable:/// cc::Build::new().file("blobstore.c").compile("blobstore");/// Compiling multiple source files, some people use their crate's name, or/// their crate's name + "-cc"./// Otherwise, please use your imagination./// For backwards compatibility, if `output` starts with "lib" *and* ends/// with ".a", a second "lib" prefix and ".a" suffix do not get added on,/// but this usage is deprecated; please omit `lib` and `.a` in the argument/// that you pass./// Panics if `output` is not formatted correctly or if one of the underlying/// compiler commands fails. It can also panic if it fails reading file names/// or creating directories.compile_intermediates/// Run the compiler, generating intermediate files, but without linking/// them into an archive file./// This will return a list of compiled object files, in the same order/// as they were passed in as `file`/`files` methods.try_compile_intermediates/// This will return a result instead of panicking; see `compile_intermediates()` for the complete description.compile_objectscreate_compile_object_cmdtry_expand/// This will return a result instead of panicking; see [`Self::expand()`] for/// Run the compiler, returning the macro-expanded version of the input files./// This is only relevant for C and C++ files./// Panics if more than one file is present in the config, or if compiler/// path has an invalid file name./// let out = cc::Build::new().file("src/foo.c").expand();get_compiler/// Get the compiler that's in use for this configuration./// This function will return a `Tool` which represents the culmination/// of this configuration at a snapshot in time. The returned compiler can/// be inspected (e.g. the path, arguments, environment) to forward along to/// other tools, or the `to_command` method can be used to invoke the/// compiler itself./// This method will take into account all configuration such as debug/// information, optimization level, include directories, defines, etc./// Additionally, the compiler binary in use follows the standard/// conventions for this path, e.g. looking at the explicitly set compiler,/// environment variables (a number of which are inspected here), and then/// falling back to the default configuration./// Panics if an error occurred while determining the architecture.try_get_compiler/// This will return a result instead of panicking; see/// [`get_compiler()`](Self::get_compiler) for the complete description.add_default_flagshas_flagsmsvc_macro_assemblerassembleassemble_progressiveapple_flagscmdget_base_compilerrustc_wrapper_fallback/// Returns a fallback `cc_compiler_wrapper` by introspecting `RUSTC_WRAPPER`env_tool/// Returns compiler path, optional modifier name from whitelist, and arguments vecget_cpp_link_stdlib/// Returns the C++ standard library:/// 1. If [`cpp_link_stdlib`](cc::Build::cpp_link_stdlib) is set, uses its value./// 2. Else if the `CXXSTDLIB` environment variable is set, uses its value.get_arget_archiver/// Get the archiver (ar) that's in use for this configuration./// You can use [`Command::get_program`] to get just the path to the command.try_get_archiver/// Get the archiver that's in use for this configuration./// This will return a result instead of panicking;/// see [`Self::get_archiver`] for the complete description.try_get_archiver_and_flagsget_base_archiverget_ranlib/// Get the ranlib that's in use for this configuration.try_get_ranlib/// see [`Self::get_ranlib`] for the complete description.get_base_ranlibget_base_archiver_variantprefix_for_target// FIXME: Use parsed target instead of raw target.find_working_gnu_prefix/// Some platforms have multiple, compatible, canonical prefixes. Look through/// each possible prefix for a compiler that exists and return it. The prefixes/// should be ordered from most-likely to least-likely.get_targetget_raw_targetget_is_cross_compileget_opt_levelget_debugget_shell_escaped_flagsget_dwarf_versionget_force_frame_pointerget_out_dirgetenvgetenv_boolean/// get boolean flag that is either true or falsegetenv_unwrapgetenv_unwrap_strgetenv_with_target_prefixesenvflagsfix_env_for_apple_osapple_sdk_root_innerapple_sdk_rootapple_deployment_targetwasi_sysrootcuda_file_countwhichsearch_programs/// search for |prog| on 'programs' path in '|cc| -print-search-dirs' outputwindows_registry_findwindows_registry_find_toolNEW_STANDALONE_ANDROID_COMPILERS// Use by default minimum available API level// See note about naming here// https://android.googlesource.com/platform/ndk/+/refs/heads/ndk-release-r21/docs/BuildSystemMaintainers.md#Clangandroid_clang_compiler_uses_target_arg_internally// New "standalone" C/C++ cross-compiler executables from recent Android NDK// are just shell scripts that call main clang binary (from Android NDK) with// proper `--target` argument.// For example, armv7a-linux-androideabi16-clang passes// `--target=armv7a-linux-androideabi16` to clang.// So to construct proper command line check if// `--target` argument would be passed or not to clangautodetect_android_compiler// FIXME: Use parsed target.map_darwin_target_from_rust_to_compiler_architecture// Rust and clang/cc don't agree on how to name the target.AsmFileExtDotAsm/// `.asm` files. On MSVC targets, we assume these should be passed to MASM/// (`ml{,64}.exe`).DotS/// `.s` or `.S` files, which do not have the special handling on MSVC targets.from_pathtest_android_clang_compiler_uses_target_arg_internally//! A library for [Cargo build scripts](https://doc.rust-lang.org/cargo/reference/build-scripts.html)//! to compile a set of C/C++/assembly/CUDA files into a static archive for Cargo//! to link into the crate being built. This crate does not compile code itself;//! it calls out to the default compiler for the platform. This crate will//! automatically detect situations such as cross compilation and//! [various environment variables](#external-configuration-via-environment-variables) and will build code appropriately.//! First, you'll want to both add a build script for your crate (`build.rs`) and//! also add this crate to your `Cargo.toml` via://! cc = "1.0"//! Next up, you'll want to write a build script like so://! ```rust,no_run//! // build.rs//! cc::Build::new()//!     .file("foo.c")//!     .file("bar.c")//!     .compile("foo");//! And that's it! Running `cargo build` should take care of the rest and your Rust//! application will now have the C files `foo.c` and `bar.c` compiled into a file//! named `libfoo.a`. If the C files contain//! ```c//! void foo_function(void) { ... }//! and//! int32_t bar_function(int32_t x) { ... }//! you can call them from Rust by declaring them in//! your Rust code like so://! extern "C" {//!     fn foo_function();//!     fn bar_function(x: i32) -> i32;//! pub fn call() {//!     unsafe {//!         foo_function();//!         bar_function(42);//!     call();//! See [the Rustonomicon](https://doc.rust-lang.org/nomicon/ffi.html) for more details.//! # External configuration via environment variables//! To control the programs and flags used for building, the builder can set a//! number of different environment variables.//! * `CFLAGS` - a series of space separated flags passed to compilers. Note that//!   individual flags cannot currently contain spaces, so doing//!   something like: `-L=foo\ bar` is not possible.//! * `CC` - the actual C compiler used. Note that this is used as an exact//!   executable name, so (for example) no extra flags can be passed inside//!   this variable, and the builder must ensure that there aren't any//!   trailing spaces. This compiler must understand the `-c` flag. For//!   certain `TARGET`s, it also is assumed to know about other flags (most//!   common is `-fPIC`).//! * `AR` - the `ar` (archiver) executable to use to build the static library.//! * `CRATE_CC_NO_DEFAULTS` - the default compiler flags may cause conflicts in//!   some cross compiling scenarios. Setting this variable//!   will disable the generation of default compiler//!   flags.//! * `CC_ENABLE_DEBUG_OUTPUT` - if set, compiler command invocations and exit codes will//!   be logged to stdout. This is useful for debugging build script issues, but can be//!   overly verbose for normal use.//! * `CC_SHELL_ESCAPED_FLAGS` - if set, `*FLAGS` will be parsed as if they were shell//!   arguments (similar to `make` and `cmake`) rather than splitting them on each space.//!   For example, with `CFLAGS='a "b c"'`, the compiler will be invoked with 2 arguments -//!   `a` and `b c` - rather than 3: `a`, `"b` and `c"`.//! * `CXX...` - see [C++ Support](#c-support).//! Furthermore, projects using this crate may specify custom environment variables//! to be inspected, for example via the `Build::try_flags_from_environment`//! function. Consult the project’s own documentation or its use of the `cc` crate//! for any additional variables it may use.//! Each of these variables can also be supplied with certain prefixes and suffixes,//! in the following prioritized order://!   1. `<var>_<target>` - for example, `CC_x86_64-unknown-linux-gnu`//!   2. `<var>_<target_with_underscores>` - for example, `CC_x86_64_unknown_linux_gnu`//!   3. `<build-kind>_<var>` - for example, `HOST_CC` or `TARGET_CFLAGS`//!   4. `<var>` - a plain `CC`, `AR` as above.//! If none of these variables exist, cc-rs uses built-in defaults.//! In addition to the above optional environment variables, `cc-rs` has some//! functions with hard requirements on some variables supplied by [cargo's//! build-script driver][cargo] that it has the `TARGET`, `OUT_DIR`, `OPT_LEVEL`,//! and `HOST` variables.//! [cargo]: https://doc.rust-lang.org/cargo/reference/build-scripts.html#inputs-to-the-build-script//! # Optional features//! ## Parallel//! Currently cc-rs supports parallel compilation (think `make -jN`) but this//! feature is turned off by default. To enable cc-rs to compile C/C++ in parallel,//! you can change your dependency to://! cc = { version = "1.0", features = ["parallel"] }//! By default cc-rs will limit parallelism to `$NUM_JOBS`, or if not present it//! will limit it to the number of cpus on the machine. If you are using cargo,//! use `-jN` option of `build`, `test` and `run` commands as `$NUM_JOBS`//! is supplied by cargo.//! # Compile-time Requirements//! To work properly this crate needs access to a C compiler when the build script//! is being run. This crate does not ship a C compiler with it. The compiler//! required varies per platform, but there are three broad categories://! * Unix platforms require `cc` to be the C compiler. This can be found by//!   installing cc/clang on Linux distributions and Xcode on macOS, for example.//! * Windows platforms targeting MSVC (e.g. your target triple ends in `-msvc`)//!   require Visual Studio to be installed. `cc-rs` attempts to locate it, and//!   if it fails, `cl.exe` is expected to be available in `PATH`. This can be//!   set up by running the appropriate developer tools shell.//! * Windows platforms targeting MinGW (e.g. your target triple ends in `-gnu`)//!   require `cc` to be available in `PATH`. We recommend the//!   [MinGW-w64](https://www.mingw-w64.org/) distribution.//!   You may also acquire it via//!   [MSYS2](https://www.msys2.org/), as explained [here][msys2-help].  Make sure//!   to install the appropriate architecture corresponding to your installation of//!   rustc. GCC from older [MinGW](http://www.mingw.org/) project is compatible//!   only with 32-bit rust compiler.//! [msys2-help]: https://github.com/rust-lang/rust/blob/master/INSTALL.md#building-on-windows//! # C++ support//! `cc-rs` supports C++ libraries compilation by using the `cpp` method on//! `Build`://!     .cpp(true) // Switch to C++ library compilation.//!     .file("foo.cpp")//! For C++ libraries, the `CXX` and `CXXFLAGS` environment variables are used instead of `CC` and `CFLAGS`.//! The C++ standard library may be linked to the crate target. By default it's `libc++` for macOS, FreeBSD, and OpenBSD, `libc++_shared` for Android, nothing for MSVC, and `libstdc++` for anything else. It can be changed in one of two ways://! 1. by using the `cpp_link_stdlib` method on `Build`://!     .cpp(true)//!     .cpp_link_stdlib("stdc++") // use libstdc++//! 2. by setting the `CXXSTDLIB` environment variable.//! In particular, for Android you may want to [use `c++_static` if you have at most one shared library](https://developer.android.com/ndk/guides/cpp-support).//! Remember that C++ does name mangling so `extern "C"` might be required to enable Rust linker to find your functions.//! # CUDA C++ support//! `cc-rs` also supports compiling CUDA C++ libraries by using the `cuda` method//! on `Build`://!     // Switch to CUDA C++ library compilation using NVCC.//!     .cuda(true)//!     .cudart("static")//!     // Generate code for Maxwell (GTX 970, 980, 980 Ti, Titan X).//!     .flag("-gencode").flag("arch=compute_52,code=sm_52")//!     // Generate code for Maxwell (Jetson TX1).//!     .flag("-gencode").flag("arch=compute_53,code=sm_53")//!     // Generate code for Pascal (GTX 1070, 1080, 1080 Ti, Titan Xp).//!     .flag("-gencode").flag("arch=compute_61,code=sm_61")//!     // Generate code for Pascal (Tesla P100).//!     .flag("-gencode").flag("arch=compute_60,code=sm_60")//!     // Generate code for Pascal (Jetson TX2).//!     .flag("-gencode").flag("arch=compute_62,code=sm_62")//!     // Generate code in parallel//!     .flag("-t0")//!     .file("bar.cu")//!     .compile("bar");RawWakerRawWakerVTableWakerthreadtimeDurationNOOP_WAKER_VTABLENOOP_RAW_WAKERYieldOnceFut1Fut2block_on/// Execute the futures and return when they are all done./// Here we use our own homebrew async executor since cc is used in the build/// script of many popular projects, pulling in additional dependencies would/// significantly slow down its compilation.OnceLockJobTokenJobTokenServerinherited_jobserverJobServerInheritedinprocess_jobserverInProcess/// This function returns a static reference to the jobserver because///  - creating a jobserver from env is a bit fd-unsafe (e.g. the fd might///    be closed by other jobserver users in the process) and better do it///    at the start of the program.///  - in case a jobserver cannot be created from env (e.g. it's not///    present), we will create a global in-process only jobserver///    that has to be static so that it will be shared by all cc///    compilation.ActiveJobTokenServerActiveJobServeracquireasync_executormpscMutexMutexGuardPoisonErrorglobal_implicit_token/// Implicit token for this process which is obtained and will be/// released in parent. Since JobTokens only give back what they got,/// there should be at most one global implicit token in the wild./// Since Rust does not execute any `Drop` for global variables,/// we can't just put it back to jobserver and then re-acquire it at/// the end of the process./// Use `Mutex` to avoid race between acquire and release./// If an `AtomicBool` is used, then it's possible for:///  - `release_token_raw`: Tries to set `global_implicit_token` to true, but it is already///    set  to `true`, continue to release it to jobserver///  - `acquire` takes the global implicit token, set `global_implicit_token` to false///  - `release_token_raw` now writes the token back into the jobserver, while///    `global_implicit_token` is `false`/// If the program exits here, then cc effectively increases parallelism by one, which is/// incorrect, hence we use a `Mutex` here.Clientfrom_envget_global_implicit_tokenrelease_token_raw/// All tokens except for the global implicit token will be put back into the jobserver/// immediately and they cannot be cached, since Rust does not call `Drop::drop` on/// global variables.enter_activeHelperThreadrxAcquiredReceiver/// When rx is dropped, all the token stored within it will be dropped.helper_threadvarAtomicU32AcqRelAcquirejob_token/// Helpers functions for [ChildStderr].get_flagsosRawFdset_flagsc_intAsRawFdbytes_availableapple_sdk_nameapple_version_flagLIST//! This file is generated code. Please edit the generator//! in dev-tools/gen-target-info if you need to make changes.versioned_llvm_target/// The versioned LLVM/Clang target triple.guess_llvm_target_triple/// Rust and Clang don't really agree on naming, so do a best-effort/// conversion to support out-of-tree / custom target-spec targets.test_basic_llvm_triple_guessingllvmfull_archvendorabiunversioned_llvm_targetTargetInfoParserInnerfrom_cargo_environment_variables/// Parser for [`TargetInfo`], contains cached information.parse_from_cargo_environment_variablesapplegenerated/// The full architecture, including the subarchitecture./// This differs from `cfg!(target_arch)`, which only specifies the/// overall architecture, which is too coarse for certain cases./// The overall target architecture./// This is the same as the value of `cfg!(target_arch)`./// The target vendor./// This is the same as the value of `cfg!(target_vendor)`./// The operating system, or `none` on bare-metal targets./// This is the same as the value of `cfg!(target_os)`./// The environment on top of the operating system./// This is the same as the value of `cfg!(target_env)`./// The ABI on top of the operating system./// This is the same as the value of `cfg!(target_abi)`./// The unversioned LLVM/Clang target triple./// Information specific to a `rustc` target./// See <https://doc.rust-lang.org/cargo/appendix/glossary.html#target>./// This will fail when using a custom target triple unknown to `rustc`.tier1// Test tier 1 targetscannot_parse_extra// Various custom target triples not (or no longer) known by `rustc`//! Very basic parsing of `rustc` target triples.//! See the `target-lexicon` crate for a more principled approach to this.remove_fileOpenOptionstmpnamecreate_namedNamedTempfiletake_filecc_wrapper_pathcc_wrapper_argsfamilyremoved_argshas_internal_target_arg/// Configuration used to represent an invocation of a C compiler./// This can be used to figure out what compiler is in use, what the arguments/// to it are, and what the environment variables look like for the compiler./// This can be used to further configure other build systems (e.g. forward/// along CC and/or CFLAGS) or the `to_command` method can be used to run thewith_clang_driverwith_family/// Explicitly set the `ToolFamily`, skipping name-based detection.with_featuresremove_arg/// Add an argument to be stripped from the final command arguments.push_cc_arg/// Push an "exotic" flag to the end of the compiler's arguments list./// Nvidia compiler accepts only the most common compiler flags like `-D`,/// `-I`, `-c`, etc. Options meant specifically for the underlying/// host C++ compiler have to be prefixed with `-Xcompiler`./// [Another possible future application for this function is passing/// clang-specific flags to clang-cl, which otherwise accepts only/// MSVC-specific options.]is_duplicate_opt_arg/// Checks if an argument or flag has already been specified or conflicts./// Currently only checks optimization flags.push_opt_unless_duplicate/// Don't push optimization arg if it conflicts with existing args.to_command/// Converts this compiler into a `Command` that's ready to be run./// This is useful for when the compiler needs to be executed and the/// command returned will already have the initial arguments and environment/// variables configured./// Returns the path for this compiler./// Note that this may not be a path to a file on the filesystem, e.g. "cc",/// but rather something which will be resolved when a process is spawned./// Returns the default set of arguments to the compiler needed to produce/// executables for the target this compiler generates./// Returns the set of environment variables needed for this compiler to/// operate./// This is typically only used for MSVC compilers currently.cc_env/// Returns the compiler command in format of CC environment variable./// Or empty string if CC env was not present/// This is typically used by configure scriptcflags_env/// Returns the compiler flags in format of CFLAGS environment variable./// Important here - this will not be CFLAGS from env, its internal gcc's flags to use as CFLAGSis_like_gnu/// Whether the tool is GNU Compiler Collection-like.is_like_clang/// Whether the tool is Clang-like.is_xctoolchain_clang/// Whether the tool is AppleClang under .xctoolchainis_like_msvc/// Whether the tool is MSVC-like.Gnu/// Tool is GNU Compiler Collection-like.zig_ccClang/// Tool is Clang-like. It differs from the GCC in a sense that it accepts superset of flags/// and its cross-compilation approach is different.clang_clMsvc/// Tool is the MSVC cl.exe./// Represents the family of tools this tool belongs to./// Each family of tools differs in how and what arguments they accept./// Detection of a family is done on best-effort basis and may not accurately reflect the tool.add_debug_flags/// What the flag to request debug info for this family of tools look likeadd_force_frame_pointer/// What the flag to force frame pointers.warnings_flags/// What the flags to enable all warningsextra_warnings_flags/// What the flags to enable extra warningswarnings_to_errors_flag/// What the flag to turn warning into errorsverbose_stderrdelimiterJoinOsStrsOptionOsStrDisplayonceis_initializedget_or_initwinapiIUnknownwindows_sysCoInitializeExSysFreeStringSysStringLenBSTRCOINIT_MULTITHREADEDHRESULTS_FALSES_OKOsStringExtnullnull_mutinitializeComPtr/// Creates a `ComPtr` to wrap a raw pointer./// It takes ownership over the pointer which means it does __not__ call `AddRef`./// `T` __must__ be a COM interface that inherits from `IUnknown`.as_unknown/// For internal use only./// Performs `QueryInterface` fun.BStrto_osstring// Copyright © 2017 winapi-rs developers// Licensed under the Apache License, Version 2.0// <LICENSE-APACHE or https://www.apache.org/licenses/LICENSE-2.0> or the MIT license// <LICENSE-MIT or https://opensource.org/licenses/MIT>, at your option.// All files in the project carrying such notice may not be copied, modified, or distributedMSVC_FAMILYTargetArchArcedget_envEnvGetterStdEnvGetter/// Attempts to find a tool within an MSVC installation using the Windows/// registry as a point to search from./// The `arch_or_target` argument is the architecture or the Rust target/// triple that the tool should work for (e.g. compile or link for). The/// supported architecture names are:/// - `"i586"`/// - `"i686"`/// - `"x86_64"`/// - `"arm"`/// - `"thumbv7a"`/// - `"aarch64"`/// - `"arm64ec"`/// The `tool` argument is the tool to find (e.g. `cl.exe` or `link.exe`)./// This function will return `None` if the tool could not be found, or it will/// return `Some(cmd)` which represents a command that's ready to execute the/// tool with the appropriate environment variables set./// Note that this function always returns `None` for non-MSVC targets (if a/// full target name was specified).find_tool/// Similar to the `find` function above, this function will attempt the same/// operation (finding a MSVC tool in a local install) but instead returns a/// `Tool` which may be introspected.find_tool_innerVsVersVs12/// Visual Studio 12 (2013)Vs14/// Visual Studio 14 (2015)Vs15/// Visual Studio 15 (2017)Vs16/// Visual Studio 16 (2019)Vs17/// Visual Studio 17 (2022)/// A version of Visual Studiofind_vs_version/// Find the most recent installed version of Visual Studio/// This is used by the cmake crate to figure out the correct/// generator.comregistryRegistryKeyLOCAL_MACHINEsetup_configSetupConfigurationvs_instancesVsInstancesVswhereInstanceGetMachineTypeAttributesGetProcAddressLoadLibraryAUserEnabledHMODULEIMAGE_FILE_MACHINE_AMD64MACHINE_ATTRIBUTESlibsMsvcToolLibraryHandleget_proc_address/// Get a function pointer to a function in the library./// # SAFETY/// The caller must ensure that the function signature matches the actual function./// The easiest way to do this is to add an entry to windows_sys_no_link.list and use the/// generated function for `func_signature`./// The function returned cannot be used after the handle is dropped.GetMachineTypeAttributesFuncTypeis_amd64_emulation_supported_inneris_amd64_emulation_supportedinto_toolis_vscmd_target/// Checks to see if the `VSCMD_ARG_TGT_ARCH` environment variable matches the/// given target's arch. Returns `None` if the variable does not exist.find_msvc_environment/// Attempt to find the tool using environment variables set by vcvars.find_msbuild_vs17vs16plus_instancesfind_tool_in_vs16plus_pathfind_msbuild_vs16vs15plus_instances// In MSVC 15 (2017) MS once again changed the scheme for locating// the tooling.  Now we must go through some COM interfaces, which// is super fun for Rust.// Note that much of this logic can be found [online] wrt paths, COM, etc.// [online]: https://blogs.msdn.microsoft.com/vcblog/2017/03/06/finding-the-visual-c-compiler-tools-in-visual-studio-2017/// Returns MSVC 15+ instances (15, 16 right now), the order should be consider undefined.// However, on ARM64 this method doesn't work because VS Installer fails to register COM component on ARM64.// Hence, as the last resort we try to use vswhere.exe to list available instances.vs15plus_instances_using_comvs15plus_instances_using_vswhereparse_version// Inspired from official microsoft/vswhere ParseVersionString// i.e. at most four u16 numbers separated by '.'find_msvc_15plusfind_tool_in_vs15_path// While the paths to Visual Studio 2017's devenv and MSBuild could// potentially be retrieved from the registry, finding them via// SetupConfiguration has shown to be [more reliable], and is preferred// according to Microsoft. To help head off potential regressions though,// we keep the registry method as a fallback option.// [more reliable]: https://github.com/rust-lang/cc-rs/pull/331tool_from_vs15plus_instancevs15plus_vc_pathsvs15plus_vc_read_versionuse_spectre_mitigated_libsatl_pathsfind_msvc_14// For MSVC 14 we need to find the Universal CRT as well as either// the Windows 10 SDK or Windows 8.1 SDK.add_sdksadd_envget_tool// Given a possible MSVC installation directory, we look for the linker and// then add the MSVC library path.get_vc_dir// To find MSVC we look in a specific registry key for the version we are// trying to find.get_ucrt_dir// To find the Universal CRT we look in a specific registry key for where// all the Universal CRTs are located and then sort them asciibetically to// find the newest version. While this sort of sorting isn't ideal,  it is// what vcvars does so that's good enough for us.// Returns a pair of (root, version) for the ucrt dir if foundget_sdk10_dir// Vcvars finds the correct version of the Windows 10 SDK by looking// for the include `um\Windows.h` because sometimes a given version will// only have UCRT bits without the rest of the SDK. Since we only care about// libraries and not includes, we instead look for `um\x64\kernel32.lib`.// Since the 32-bit and 64-bit libraries are always installed together we// only need to bother checking x64, making this code a tiny bit simpler.// Like we do for the Universal CRT, we sort the possibilities// asciibetically to find the newest one as that is what vcvars does.// Before doing that, we check the "WindowsSdkDir" and "WindowsSDKVersion"// environment variables set by vcvars to use the environment sdk version// if one is already configured.get_sdk81_dir// Interestingly there are several subdirectories, `win7` `win8` and// `winv6.3`. Vcvars seems to only care about `winv6.3` though, so the same// applies to us. Note that if we were targeting kernel mode drivers// instead of user mode applications, we would care.PROCESSOR_ARCHITECTURE_INTELPROCESSOR_ARCHITECTURE_AMD64PROCESSOR_ARCHITECTURE_ARM64X86X86_64AARCH64bin_subdir// When choosing the tool to use, we have to choose the one which matches// the target architecture. Otherwise we end up in situations where someone// on 32-bit Windows is trying to cross compile to 64-bit and it tries to// invoke the native 64-bit compiler which won't work.// For the return value of this function, the first member of the tuple is// the folder of the tool we will be invoking, while the second member is// the folder of the host toolchain for that tool which is essential when// using a cross linker. We return a Vec since on x64 there are often two// linkers that can target the architecture we desire. The 64-bit host// linker is preferred, and hence first, due to 64-bit allowing it more// address space to work with and potentially being faster.lib_subdirvc_lib_subdir// MSVC's x86 libraries are not in a subfolderhost_archmax_version// Given a registry key, look at all the sub keys and find the one which has// the maximal numeric value.// Returns the name of the maximal key as well as the opened maximal key.has_msbuild_versionfind_devenvfind_devenv_vs15find_msbuild// see http://stackoverflow.com/questions/328017/path-to-msbuildfind_msbuild_vs15find_old_msbuildimpl_/// Windows Implementation./// Finding msbuild.exe tool under unix system is not currently supported./// Maybe can check it using an environment variable looks like `MSBUILD_BIN`.// Finding devenv.exe tool under unix system is not currently supported.// Maybe can check it using an environment variable looks like `DEVENV_BIN`./// Non-Windows Implementation.// https://www.apache.org/licenses/LICENSE-2.0> or the MIT license// <LICENSE-MIT or https://opensource.org/licenses/MIT>, at your//! A helper module to looking for windows-specific tools://! 1. On Windows host, probe the Windows Registry if needed;//! 2. On non-Windows host, check specified environment variables.// This is used in the crate's public API, so don't use #[cfg(windows)]windows_targets//! These modules are all glue to support reading the MSVC version from//! the registry and from COM interfaces.RegCloseKeyRegEnumKeyExWRegOpenKeyExWRegQueryValueExWERROR_NO_MORE_ITEMSERROR_SUCCESSHKEYHKEY_LOCAL_MACHINEKEY_READKEY_WOW64_32KEYREG_SZ/// Must never be `HKEY_PERFORMANCE_DATA`.DWORDOwnedKeyLocalMachine/// `HKEY_LOCAL_MACHINE`./// A subkey of `HKEY_LOCAL_MACHINE`./// Note: must not encode `HKEY_PERFORMANCE_DATA` or one of its subkeys.open/// Open a sub-key of `self`.query_strIUnknownVtblLCIDLPCOLESTRLPCWSTRLPFILETIMELPSAFEARRAYPULONGLONGULONGCoCreateInstanceCLSCTX_ALLInstanceState// Bindings to the Setup.Configuration stuffeNoneeLocaleRegisteredeNoRebootRequiredeCompleteRIDLDEFINE_GUIDISetupConfiguration// Safe wrapper around the COM interfacesget_instance_for_current_processSetupInstanceenum_instancesEnumSetupInstancesenum_all_instancesISetupInstanceinstance_idinstallation_nameinstallation_pathinstallation_versionproduct_pathIEnumSetupInstancesBufReadVsInstanceComVswhereComBasedVswhereBasedit_parses_vswhere_output_correctlyit_returns_an_error_for_empty_outputit_returns_an_error_for_output_consisting_of_empty_linesit_returns_an_error_for_output_without_required_propertiestests_wchar_tFILETIMEGUIDSAFEARRAYREFIIDIIDc_ulongOLECHARWCHARULONGLONGuuidof// Copyright © 2015-2017 winapi-rs developersADVANCED_FEATURE_FLAGSBOOLCLSCTXCOINITWIN32_ERRORFALSEFARPROCdwLowDateTimedwHighDateTimeFILE_ATTRIBUTE_TEMPORARYFILE_FLAGS_AND_ATTRIBUTESdata1data2data3data4from_u128HANDLEc_voidIMAGE_FILE_MACHINEREG_SAM_FLAGSPCSTRPCWSTRPWSTRREG_VALUE_TYPEcDimsfFeaturescbElementscLockspvDatargsaboundSAFEARRAYBOUNDcElementslLboundSEMAPHORE_MODIFY_STATESYNCHRONIZATION_ACCESS_RIGHTSTHREAD_ACCESS_RIGHTSTHREAD_SYNCHRONIZEWAIT_ABANDONEDWAIT_EVENTWAIT_FAILEDWAIT_OBJECT_0WAIT_TIMEOUT// This file is autogenerated.// To add bindings, edit windows_sys.lst then run:// ```// cd generate-windows-sys/// cargo run// Bindings generated by `windows-bindgen` 0.58.0link_macro//! Provides the `link!` macro used by the generated windows bindings.//! This is a simple wrapper around an `extern` block with a `#[link]` attribute.//! It's very roughly equivalent to the windows-targets crate.branch_protectioncode_modelno_vectorize_loopsno_vectorize_slpprofile_generateprofile_usecontrol_flow_guardltorelocation_modelembed_bitcodeforce_frame_pointersno_redzonesoft_floatdwarf_versionRustcCodegenFlags'this// Parse flags obtained from CARGO_ENCODED_RUSTFLAGSset_rustc_flagcc_flags// Rust and clang/cc don't agree on what equivalent flags should look like.codegen_typeprecedencetwo_valid_prefixesthree_valid_prefixesall_rustc_flagsAtomicU8RelaxedCompilerFamilyLookupCachecpp_link_stdlib_staticinherit_rustflags/// No known macro is defined for the compiler when discovering tool family./// Invalid target.UnknownTarget/// Unknown target.InvalidFlag/// Invalid rustc flag./// `cc` has been disabled by an environment variable./// Add multiple flags to the invocation of the compiler./// This is equivalent to calling [`flag`](Self::flag) for each item in the iterator.///     .flags(["-Wall", "-Wextra"])/// Force linker to statically link C++ stdlib. By default cc-rs will emit/// rustc-link flag to link against system C++ stdlib (e.g. libstdc++.so, libc++.so)/// Provide value of `true` if linking against system library is not desired/// Note that for `wasm32` target C++ stdlib will always be linked statically///     .file("src/foo.cpp")///     .cpp_link_stdlib_static(true)/// Configures the `rustc` target this configuration will be compiling/// for./// This will fail if using a target not in a pre-compiled list taken from/// `rustc +nightly --print target-list`. The list will be updated/// periodically./// You should avoid setting this in build scripts, target information/// will instead be retrieved from the environment variables `TARGET` and/// `CARGO_CFG_TARGET_*` that Cargo sets./// Define whether metadata should be emitted for cargo to only trigger/// rebuild when detected environment changes, by default build script is/// always run on every compilation if no rerun cargo metadata is emitted./// Configure whether cc should automatically inherit compatible flags passed to rustc/// from `CARGO_ENCODED_RUSTFLAGS`./// Configure the builder.compile_objects_sequentialadd_inherited_rustflagstarget_envs/// The list of environment variables to check for a given env, in order of priority./// Get a single-valued environment variable with target variants./// Get values from CFLAGS-style environment variable.wasm_musl_sysroot/// Invoke or fetch the compiler or archiver.is_disabled/// Returns true if `cc` has been disabled by `CC_FORCE_DISABLE`.check_disabled/// Automates the `if is_disabled() { return error }` check and ensures/// we produce a consistent error message for it.//!   ccache, distcc, sccache, icecc, cachepot and buildcache are supported,//!   for sccache, simply set `CC` to `sccache cc`.//!   For other custom `CC` wrapper, just set `CC_KNOWN_WRAPPER_CUSTOM`//!   to the custom wrapper used in `CC`.//! * `CC_FORCE_DISABLE` - If set, `cc` will never run any [`Command`]s, and methods that//!   would return an [`Error`]. This is intended for use by third-party build systems//!   which want to be absolutely sure that they are in control of building all//!   dependencies. Note that operations that return [`Tool`]s such as//!   [`Build::get_compiler`] may produce less accurate results as in some cases `cc` runs//!   commands in order to locate compilers. Additionally, this does nothing to prevent//!   users from running [`Tool::to_command`] and executing the [`Command`] themselves.//! * `RUSTC_WRAPPER` - If set, the specified command will be prefixed to the compiler//!   command. This is useful for projects that want to use//!   [sccache](https://github.com/mozilla/sccache),//!   [buildcache](https://gitlab.com/bits-n-bites/buildcache), or//!   [cachepot](https://github.com/paritytech/cachepot).//! * Windows platforms targeting MSVC (e.g. your target name ends in `-msvc`)//! * Windows platforms targeting MinGW (e.g. your target name ends in `-gnu`)//! # Speed up compilation with sccache//! `cc-rs` does not handle incremental compilation like `make` or `ninja`. It//! always compiles the all sources, no matter if they have changed or not.//! This would be time-consuming in large projects. To save compilation time,//! you can use [sccache](https://github.com/mozilla/sccache) by setting//! environment variable `RUSTC_WRAPPER=sccache`, which will use cached `.o`//! files if the sources are unchanged./// released in parent. Since `JobTokens` only give back what they got,/// Helpers functions for [`ChildStderr`].LLVM_TARGETS//! This file is generated code. Please edit the generator in//! dev-tools/gen-target-info if you need to make changes, or see//! src/target/llvm.rs if you need to configure a specific LLVM triple.llvm_target/// The LLVM/Clang target triple./// See <https://clang.llvm.org/docs/CrossCompilation.html#target-triple>./// Rust and Clang don't really agree on target naming, so we first try to/// find the matching trible based on `rustc`'s output, but if no such/// triple exists, we attempt to construct the triple from scratch./// NOTE: You should never need to match on this explicitly, use the/// fields on [`TargetInfo`] instead.test_old_ios_targetbasic_llvm_triple_guessingllvm_versionuefi"not yet done"ignorellvm_for_all_rustc_targetsparse_arch/// Parse the full architecture in the target name into the simpler/// `cfg(target_arch = "...")` that `rustc` exposes.parse_envabi/// Parse environment and ABI from the last component of the target name.from_rustc_target// Test tier 1 targets.parse_extra// Various custom target names not (or no longer) known by `rustc`.target_from_rustc_cfgsunknown_env_determined_as_unknownparse_rustc_targets// Used in .github/workflows/test-rustc-targets.yml//! Parsing of `rustc` target names to match the values exposed to Cargo//! build scripts (`CARGO_CFG_*`).with_argsis_like_clang_cl/// Whether the tool is `clang-cl`-based MSVC-like.supports_path_delimiter/// Supports using `--` delimiter to separate arguments and path to source files.X64ArmArm64Arm64ec/// The target provided by the user./// Parse the `TargetArch` from a str. Returns `None` if the arch is unrecognized./// The `arch_or_target` argument is the architecture or the Rust target name/// that the tool should work for (e.g. compile or link for). The supported/// architecture names are:/// - `"x64"` or `"x86_64"`/// - `"arm64"` or `"aarch64"`/// - `"x86"`, `"i586"` or `"i686"`/// - `"arm"` or `"thumbv7a"`/// The `tool` argument is the tool to find. Supported tools include:/// - MSVC tools: `cl.exe`, `link.exe`, `lib.exe`, etc./// - `MSBuild`: `msbuild.exe`/// - Visual Studio IDE: `devenv.exe`/// - Clang/LLVM tools: `clang.exe`, `clang++.exe`, `clang-*.exe`, `llvm-*.exe`, `lld.exe`, etc.find_llvm_tool// Finding Clang/LLVM-related tools on unix systems is not currently supported.windows_linkHINSTANCEIID_IUnknownQueryInterfaceAddRefReleaseIUnknown_Vtbl// Bindings generated by `windows-bindgen` 0.62.1// match if/else chains with a final `else`// match if/else chains lacking a final `else`// Internal and recursive macro to emit all the items// Collects all the previous cfgs in a list at the beginning, so they can be// negated. After the semicolon are all the remaining items.// Internal macro to make __apply work out right for different match types,// because of how macros match/expand stuff./// The main macro provided by this crate. See crate documentation for more/// information.//! A macro for defining `#[cfg]` if-else statements.//! The macro provided by this crate, `cfg_if`, is similar to the `if/elif` C//! preprocessor macro by allowing definition of a cascade of `#[cfg]` cases,//! emitting the implementation which matches first.//! This allows you to conveniently provide a long list `#[cfg]`'d blocks of code//! without having to rewrite each clause multiple times.//! cfg_if::cfg_if! {//!     if #[cfg(unix)] {//!         fn foo() { /* unix specific functionality */ }//!     } else if #[cfg(target_pointer_width = "32")] {//!         fn foo() { /* non-unix, 32-bit functionality */ }//!     } else {//!         fn foo() { /* fallback implementation */ }//! # fn main() {}// we test with features that do not exist// Helper that just checks whether the CFG environment variable is set// Helper to check for the presense of a feature// Helper that checks whether a CFG environment contains the given value// Emitting `any(clause1,clause2,...)`: convert to `$crate::cfg_aliases!(clause1) && $crate::cfg_aliases!(clause2) && ...`// Likewise for `all(clause1,clause2,...)`.// "@clause" rules are used to parse the comma-separated lists. They munch// their inputs token-by-token and finally invoke an "@emit" rule when the// list is all grouped. The general pattern for recording the parser state// is:// $crate::cfg_aliases!(//    @clause $operation//    [{grouped-clause-1} {grouped-clause-2...}]//    [not-yet-parsed-tokens...]//    current-clause-tokens...// )// This rule must come first in this section. It fires when the next token// to parse is a comma. When this happens, we take the tokens in the// current clause and add them to the list of grouped clauses, adding// delimeters so that the grouping can be easily extracted again in the// emission stage.// This rule comes next. It fires when the next un-parsed token is *not* a// comma. In this case, we add that token to the list of tokens in the// current clause, then move on to the next one.// This rule fires when there are no more tokens to parse in this list. We// finish off the "current" token group, then delegate to the emission// rule.// `all(clause1, clause2...)` : we must parse this comma-separated list and// partner with `@emit all` to output a bunch of && terms.// Likewise for `any(clause1, clause2...)`// `not(clause)`: compute the inner clause, then just negate it.// `feature = value`: test for a feature.// `param = value`: test for equality.// Parse a lone identifier that might be an alias// Entrypoint that defines the matcher// Catch all that starts the macro/// Create `cfg` aliases/// **build.rs:**/// # use cfg_aliases::cfg_aliases;/// // Setup cfg aliases/// cfg_aliases! {///     // Platforms///     wasm: { target_arch = "wasm32" },///     android: { target_os = "android" },///     macos: { target_os = "macos" },///     linux: { target_os = "linux" },///     // Backends///     surfman: { all(unix, feature = "surfman", not(wasm)) },///     glutin: { all(feature = "glutin", not(wasm)) },///     wgl: { all(windows, feature = "wgl", not(wasm)) },///     dummy: { not(any(wasm, glutin, wgl, surfman)) },/// After you put this in your build script you can then check for those conditions like so:/// #[cfg(surfman)]///     // Do stuff related to surfman/// #[cfg(dummy)]/// println!("We're in dummy mode, specify another feature if you want a smarter app!");/// This greatly improves what would otherwise look like this without the aliases:/// #[cfg(all(unix, feature = "surfman", not(target_arch = "wasm32")))]/// #[cfg(not(any(///     target_arch = "wasm32",///     all(unix, feature = "surfman", not(target_arch = "wasm32")),///     all(windows, feature = "wgl", not(target_arch = "wasm32")),///     all(feature = "glutin", not(target_arch = "wasm32")),/// )))]//! # CFG Aliases//! CFG Aliases is a tiny utility to help save you a lot of effort with long winded `#[cfg()]` checks. This crate provides a single [`cfg_aliases!`] macro that doesn't have any dependencies and specifically avoids pulling in `syn` or `quote` so that the impact on your comile times should be negligible.//! You use the the [`cfg_aliases!`] macro in your `build.rs` script to define aliases such as `x11` that could then be used in the `cfg` attribute or macro for conditional compilation: `#[cfg(x11)]`.//! **Cargo.toml:**//! cfg_aliases = "0.1.0"//! **build.rs:**//! use cfg_aliases::cfg_aliases;//!     // Setup cfg aliases//!     cfg_aliases! {//!         // Platforms//!         wasm: { target_arch = "wasm32" },//!         android: { target_os = "android" },//!         macos: { target_os = "macos" },//!         linux: { target_os = "linux" },//!         // Backends//!         surfman: { all(unix, feature = "surfman", not(wasm)) },//!         glutin: { all(feature = "glutin", not(wasm)) },//!         wgl: { all(windows, feature = "wgl", not(wasm)) },//!         dummy: { not(any(wasm, glutin, wgl, surfman)) },//! Now that we have our aliases setup we can use them just like you would expect://! #[cfg(wasm)]//! println!("This is running in WASM");//! #[cfg(surfman)]//! {//!     // Do stuff related to surfman//! #[cfg(dummy)]//! println!("We're in dummy mode, specify another feature if you want a smarter app!");//! This greatly improves what would otherwise look like this without the aliases://! #[cfg(target_arch = "wasm32")]//! println!("We're running in WASM");//! #[cfg(all(unix, feature = "surfman", not(target_arch = "22")))]//! #[cfg(not(any(//!     target_arch = "wasm32",//!     all(unix, feature = "surfman", not(target_arch = "wasm32")),//!     all(windows, feature = "wgl", not(target_arch = "wasm32")),//!     all(feature = "glutin", not(target_arch = "wasm32")),//! )))]//! You can also use the `cfg!` macro or combine your aliases with other checks using `all()`, `not()`, and `any()`. Your aliases are genuine `cfg` flags now!//! if cfg!(glutin) {//!     // use glutin//! } else {//!     // Do something else//! #[cfg(all(glutin, surfman))]//! compile_error!("You cannot specify both `glutin` and `surfman` features");//! ## Syntax and Error Messages//! The aliase names are restricted to the same rules as rust identifiers which, for one, means that they cannot have dashes ( `-` ) in them. Additionally, if you get certain syntax elements wrong, such as the alias name, the macro will error saying that the recursion limit was reached instead of giving a clear indication of what actually went wrong. This is due to a nuance with the macro parser and it might be fixed in a later release of this crate. It is also possible that aliases with dashes in the name might be supported in a later release. Open an issue if that is something that you would like implemented.//! Finally, you can also induce an infinite recursion by having rules that both reference each-other, but this isn't a real limitation because that doesn't make logical sense anyway://! ```rust,ignore//! // This causes an error!//! cfg_aliases! {//!     test1: { not(test2) },//!     test2: { not(test1) },//! ## Attribution and Thanks//! - Thanks to my God and Father who led me through figuring this out and to whome I owe everything.//! - Thanks to @Yandros on the Rust forum for [showing me][sm] some crazy macro hacks!//! - Thanks to @sfackler for [pointing out][po] the way to make cargo add the cfg flags.//! - Thanks to the authors of the [`tectonic_cfg_support::target_cfg`] macro from which most of the cfg attribute parsing logic is taken from. Also thanks to @ratmice for [bringing it up][bip] on the Rust forum.//! [`tectonic_cfg_support::target_cfg`]: https://docs.rs/tectonic_cfg_support/0.0.1/src/tectonic_cfg_support/lib.rs.html#166-298//! [po]: https://users.rust-lang.org/t/any-such-thing-as-cfg-aliases/40100/2//! [bip]: https://users.rust-lang.org/t/any-such-thing-as-cfg-aliases/40100/13//! [sm]: https://users.rust-lang.org/t/any-such-thing-as-cfg-aliases/40100/3// In the `cfg_aliases!` macro below, all of the rules that start with @parser were derived from// the `target_cfg!` macro here:// https://docs.rs/tectonic_cfg_support/0.0.1/src/tectonic_cfg_support/lib.rs.html#166-298.// The `target_cfg!` macro is excellently commented while the one below is not very well commented// yet, so if you need some help understanding it you might benefit by reading that implementation.// Also check out this forum topic for more history on the macro development:// https://users.rust-lang.org/t/any-such-thing-as-cfg-aliases/40100?u=zicklagDelayedFormatStrftimeItemsIsoWeekNaiveDateNaiveTimeTimeZoneUtcDateTimeDatelikeTimeDeltaWeekdaydateTzOffsetDate/// ISO 8601 calendar date with time zone./// You almost certainly want to be using a [`NaiveDate`] instead of this type./// This type primarily exists to aid in the construction of DateTimes that/// have a timezone by way of the [`TimeZone`] datelike constructors (e.g./// [`TimeZone::ymd`])./// This type should be considered ambiguous at best, due to the inherent lack/// of precision required for the time zone resolution./// There are some guarantees on the usage of `Date<Tz>`:/// - If properly constructed via [`TimeZone::ymd`] and others without an error,///   the corresponding local date should exist for at least a moment.///   (It may still have a gap from the offset changes.)/// - The `TimeZone` is free to assign *any* [`Offset`](crate::offset::Offset) to the///   local date, as long as that offset did occur in given day.///   For example, if `2015-03-08T01:59-08:00` is followed by `2015-03-08T03:00-07:00`,///   it may produce either `2015-03-08-08:00` or `2015-03-08-07:00`///   but *not* `2015-03-08+00:00` and others./// - Once constructed as a full `DateTime`, [`DateTime::date`] and other associated///   methods should return those for the original `Date`. For example, if `dt =///   tz.ymd_opt(y,m,d).unwrap().hms(h,n,s)` were valid, `dt.date() == tz.ymd_opt(y,m,d).unwrap()`./// - The date is timezone-agnostic up to one day (i.e. practically always),///   so the local date and UTC date should be equal for most cases///   even though the raw calculation between `NaiveDate` and `TimeDelta` may not.MIN_DATE/// The minimum possible `Date`.MAX_DATE/// The maximum possible `Date`.from_utc/// Makes a new `Date` with given *UTC* date and offset./// The local date should be constructed via the `TimeZone` trait.and_time/// Makes a new `DateTime` from the current date and given `NaiveTime`./// The offset in the current date is preserved./// Returns `None` on invalid datetime.and_hms/// Makes a new `DateTime` from the current date, hour, minute and second./// Panics on invalid hour, minute and/or second.and_hms_opt/// Returns `None` on invalid hour, minute and/or second.and_hms_milli/// Makes a new `DateTime` from the current date, hour, minute, second and millisecond./// The millisecond part can exceed 1,000 in order to represent the leap second./// Panics on invalid hour, minute, second and/or millisecond.and_hms_milli_opt/// Returns `None` on invalid hour, minute, second and/or millisecond.and_hms_micro/// Makes a new `DateTime` from the current date, hour, minute, second and microsecond./// The microsecond part can exceed 1,000,000 in order to represent the leap second./// Panics on invalid hour, minute, second and/or microsecond.and_hms_micro_opt/// Returns `None` on invalid hour, minute, second and/or microsecond.and_hms_nano/// Makes a new `DateTime` from the current date, hour, minute, second and nanosecond./// The nanosecond part can exceed 1,000,000,000 in order to represent the leap second./// Panics on invalid hour, minute, second and/or nanosecond.and_hms_nano_opt/// Returns `None` on invalid hour, minute, second and/or nanosecond.succ/// Makes a new `Date` for the next date./// Panics when `self` is the last representable date.succ_opt/// Returns `None` when `self` is the last representable date./// Makes a new `Date` for the prior date./// Panics when `self` is the first representable date.pred_opt/// Returns `None` when `self` is the first representable date./// Retrieves an associated offset from UTC.timezone/// Retrieves an associated time zone.Tz2with_timezone/// Changes the associated time zone./// This does not change the actual `Date` (but will change the string representation).checked_add_signed/// Adds given `TimeDelta` to the current date./// Returns `None` when it will result in overflow.checked_sub_signed/// Subtracts given `TimeDelta` from the current date.signed_duration_since/// Subtracts another `Date` from the current date./// Returns a `TimeDelta` of integral numbers./// This does not overflow or underflow at all,/// as all possible output fits in the range of `TimeDelta`.naive_utc/// Returns a view to the naive UTC date.naive_local/// Returns a view to the naive local date./// This is technically the same as [`naive_utc`](#method.naive_utc)/// because the offset is restricted to never exceed one day,/// but provided for the consistency.years_since/// Returns the number of whole years from the given `base` until `self`.MIN_UTCMAX_UTCmap_local/// Maps the local date to other date with given conversion function.format_with_items/// Formats the date with the specified formatting items./// Formats the date with the specified format string./// See the [`crate::format::strftime`] module/// on the supported escape sequences.yearmonthmonth0dayday0ordinalordinal0weekdayiso_weekwith_yearwith_monthwith_month0with_daywith_day0with_ordinalwith_ordinal0// we need them as automatic impls cannot handle associated typesFixedOffsettest_date_add_assigntest_date_sub_assign// This is a part of Chrono.// See README.md and LICENSE.txt for details.//! ISO 8601 calendar date with time zone.SecondsFormatwrite_rfc2822write_rfc3339ParsedTOO_LONGparse_and_remainderparse_rfc3339DaysNaiveDateTimeLocalResultMonthsTimelikeexpecttry_optdatetime/// ISO 8601 combined date and time with time zone./// There are some constructors implemented here (the `from_*` methods), but/// the general-purpose constructors are all via the methods on the/// [`TimeZone`](./offset/trait.TimeZone.html) implementations.MIN_DATETIME/// The minimum possible `DateTime<Utc>`.MAX_DATETIME/// The maximum possible `DateTime<Utc>`.from_naive_utc_and_offset/// Makes a new `DateTime` from its components: a `NaiveDateTime` in UTC and an `Offset`./// This is a low-level method, intended for use cases such as deserializing a `DateTime` or/// passing it through FFI./// For regular use you will probably want to use a method such as/// [`TimeZone::from_local_datetime`] or [`NaiveDateTime::and_local_timezone`] instead./// # #[cfg(feature = "clock")] {/// use chrono::{DateTime, Local};/// let dt = Local::now();/// // Get components/// let naive_utc = dt.naive_utc();/// let offset = dt.offset().clone();/// // Serialize, pass through FFI... and recreate the `DateTime`:/// let dt_new = DateTime::<Local>::from_naive_utc_and_offset(naive_utc, offset);/// assert_eq!(dt, dt_new);from_local/// Makes a new `DateTime` from a `NaiveDateTime` in *local* time and an `Offset`./// Panics if the local datetime can't be converted to UTC because it would be out of range./// This can happen if `datetime` is near the end of the representable range of `NaiveDateTime`,/// and the offset from UTC pushes it beyond that./// Retrieves the date component with an associated timezone./// Unless you are immediately planning on turning this into a `DateTime`/// with the same timezone you should use the [`date_naive`](DateTime::date_naive) method./// [`NaiveDate`] is a more well-defined type, and has more traits implemented on it,/// so should be preferred to [`Date`] any time you truly want to operate on dates./// [`DateTime`] internally stores the date and time in UTC with a [`NaiveDateTime`]. This/// method will panic if the offset from UTC would push the local date outside of the/// representable range of a [`Date`].date_naive/// Retrieves the date component./// representable range of a [`NaiveDate`]./// use chrono::prelude::*;/// let date: DateTime<Utc> = Utc.with_ymd_and_hms(2020, 1, 1, 0, 0, 0).unwrap();/// let other: DateTime<FixedOffset> =///     FixedOffset::east_opt(23).unwrap().with_ymd_and_hms(2020, 1, 1, 0, 0, 0).unwrap();/// assert_eq!(date.date_naive(), other.date_naive());/// Retrieves the time component.timestamp/// Returns the number of non-leap seconds since January 1, 1970 0:00:00 UTC/// (aka "UNIX timestamp")./// The reverse operation of creating a [`DateTime`] from a timestamp can be performed/// using [`from_timestamp`](DateTime::from_timestamp) or [`TimeZone::timestamp_opt`]./// use chrono::{DateTime, TimeZone, Utc};/// let dt: DateTime<Utc> = Utc.with_ymd_and_hms(2015, 5, 15, 0, 0, 0).unwrap();/// assert_eq!(dt.timestamp(), 1431648000);/// assert_eq!(DateTime::from_timestamp(dt.timestamp(), dt.timestamp_subsec_nanos()).unwrap(), dt);timestamp_millis/// Returns the number of non-leap-milliseconds since January 1, 1970 UTC./// use chrono::{NaiveDate, Utc};/// let dt = NaiveDate::from_ymd_opt(1970, 1, 1)///     .unwrap()///     .and_hms_milli_opt(0, 0, 1, 444)///     .and_local_timezone(Utc)/// assert_eq!(dt.timestamp_millis(), 1_444);/// let dt = NaiveDate::from_ymd_opt(2001, 9, 9)///     .and_hms_milli_opt(1, 46, 40, 555)/// assert_eq!(dt.timestamp_millis(), 1_000_000_000_555);timestamp_micros/// Returns the number of non-leap-microseconds since January 1, 1970 UTC.///     .and_hms_micro_opt(0, 0, 1, 444)/// assert_eq!(dt.timestamp_micros(), 1_000_444);///     .and_hms_micro_opt(1, 46, 40, 555)/// assert_eq!(dt.timestamp_micros(), 1_000_000_000_000_555);timestamp_nanos/// Returns the number of non-leap-nanoseconds since January 1, 1970 UTC./// An `i64` with nanosecond precision can span a range of ~584 years. This function panics on/// an out of range `DateTime`./// The dates that can be represented as nanoseconds are between 1677-09-21T00:12:43.145224192/// and 2262-04-11T23:47:16.854775807.timestamp_nanos_opt/// An `i64` with nanosecond precision can span a range of ~584 years. This function returns/// `None` on an out of range `DateTime`.///     .and_hms_nano_opt(0, 0, 1, 444)/// assert_eq!(dt.timestamp_nanos_opt(), Some(1_000_000_444));///     .and_hms_nano_opt(1, 46, 40, 555)/// assert_eq!(dt.timestamp_nanos_opt(), Some(1_000_000_000_000_000_555));/// let dt = NaiveDate::from_ymd_opt(1677, 9, 21)///     .and_hms_nano_opt(0, 12, 43, 145_224_192)/// assert_eq!(dt.timestamp_nanos_opt(), Some(-9_223_372_036_854_775_808));/// let dt = NaiveDate::from_ymd_opt(2262, 4, 11)///     .and_hms_nano_opt(23, 47, 16, 854_775_807)/// assert_eq!(dt.timestamp_nanos_opt(), Some(9_223_372_036_854_775_807));///     .and_hms_nano_opt(0, 12, 43, 145_224_191)/// assert_eq!(dt.timestamp_nanos_opt(), None);///     .and_hms_nano_opt(23, 47, 16, 854_775_808)timestamp_subsec_millis/// Returns the number of milliseconds since the last second boundary./// In event of a leap second this may exceed 999.timestamp_subsec_micros/// Returns the number of microseconds since the last second boundary./// In event of a leap second this may exceed 999,999.timestamp_subsec_nanos/// Returns the number of nanoseconds since the last second boundary/// In event of a leap second this may exceed 999,999,999./// The returned `DateTime` references the same instant of time from the perspective of the/// provided time zone.fixed_offset/// Fix the offset from UTC to its current value, dropping the associated timezone information./// This it useful for converting a generic `DateTime<Tz: Timezone>` to `DateTime<FixedOffset>`.to_utc/// Turn this `DateTime` into a `DateTime<Utc>`, dropping the offset and associated timezone/// Adds given `TimeDelta` to the current date and time./// Returns `None` if the resulting date would be out of range.checked_add_months/// Adds given `Months` to the current date and time./// Uses the last day of the month if the day does not exist in the resulting month./// See [`NaiveDate::checked_add_months`] for more details on behavior./// Returns `None` if:/// - The local time at the resulting date does not exist or is ambiguous, for example during a///   daylight saving time transition./// - The resulting UTC datetime would be out of range./// - The resulting local datetime would be out of range (unless `months` is zero)./// Subtracts given `TimeDelta` from the current date and time.checked_sub_months/// Subtracts given `Months` from the current date and time./// See [`NaiveDate::checked_sub_months`] for more details on behavior.checked_add_days/// Add a duration in [`Days`] to the date part of the `DateTime`./// - The resulting local datetime would be out of range (unless `days` is zero).checked_sub_days/// Subtract a duration in [`Days`] from the date part of the `DateTime`./// Subtracts another `DateTime` from the current date and time./// This does not overflow or underflow at all./// Returns a view to the naive UTC datetime./// Returns a view to the naive local datetime./// method will panic if the offset from UTC would push the local datetime outside of the/// representable range of a [`NaiveDateTime`].overflowing_naive_local/// Returns the naive local datetime./// This makes use of the buffer space outside of the representable range of values of/// `NaiveDateTime`. The result can be used as intermediate value, but should never be exposed/// outside chrono./// Retrieve the elapsed years from now to the given [`DateTime`]./// Returns `None` if `base > self`.to_rfc2822/// Returns an RFC 2822 date and time string such as `Tue, 1 Jul 2003 10:52:37 +0200`./// Panics if the date can not be represented in this format: the year may not be negative and/// can not have more than 4 digits.to_rfc3339/// Returns an RFC 3339 and ISO 8601 date and time string such as `1996-12-19T16:39:57-08:00`.to_rfc3339_opts/// Return an RFC 3339 and ISO 8601 date and time string with subseconds/// formatted as per `SecondsFormat`./// If `use_z` is true and the timezone is UTC (offset 0), uses `Z` as/// per [`Fixed::TimezoneOffsetColonZ`]. If `use_z` is false, uses/// [`Fixed::TimezoneOffsetColon`]/// # use chrono::{FixedOffset, SecondsFormat, TimeZone, NaiveDate};/// let dt = NaiveDate::from_ymd_opt(2018, 1, 26)///     .and_hms_micro_opt(18, 30, 9, 453_829)///     .and_utc();/// assert_eq!(dt.to_rfc3339_opts(SecondsFormat::Millis, false), "2018-01-26T18:30:09.453+00:00");/// assert_eq!(dt.to_rfc3339_opts(SecondsFormat::Millis, true), "2018-01-26T18:30:09.453Z");/// assert_eq!(dt.to_rfc3339_opts(SecondsFormat::Secs, true), "2018-01-26T18:30:09Z");/// let pst = FixedOffset::east_opt(8 * 60 * 60).unwrap();/// let dt = pst///     .from_local_datetime(///         &NaiveDate::from_ymd_opt(2018, 1, 26)///             .unwrap()///             .and_hms_micro_opt(10, 30, 9, 453_829)///             .unwrap(),///     )/// assert_eq!(dt.to_rfc3339_opts(SecondsFormat::Secs, true), "2018-01-26T10:30:09+08:00");with_time/// Set the time to a new fixed time on the existing date./// Returns `LocalResult::None` if the datetime is at the edge of the representable range for a/// `DateTime`, and `with_time` would push the value in UTC out of range./// use chrono::{Local, NaiveTime};/// let noon = NaiveTime::from_hms_opt(12, 0, 0).unwrap();/// let today_noon = Local::now().with_time(noon);/// let today_midnight = Local::now().with_time(NaiveTime::MIN);/// assert_eq!(today_noon.single().unwrap().time(), noon);/// assert_eq!(today_midnight.single().unwrap().time(), NaiveTime::MIN);from_timestamp/// Makes a new `DateTime<Utc>` from the number of non-leap seconds/// since January 1, 1970 0:00:00 UTC (aka "UNIX timestamp")/// and the number of nanoseconds since the last whole non-leap second./// This is guaranteed to round-trip with regard to [`timestamp`](DateTime::timestamp) and/// [`timestamp_subsec_nanos`](DateTime::timestamp_subsec_nanos)./// If you need to create a `DateTime` with a [`TimeZone`] different from [`Utc`], use/// [`TimeZone::timestamp_opt`] or [`DateTime::with_timezone`]./// The nanosecond part can exceed 1,000,000,000 in order to represent a/// [leap second](NaiveTime#leap-second-handling), but only when `secs % 60 == 59`./// (The true "UNIX timestamp" cannot represent a leap second unambiguously.)/// Returns `None` on out-of-range number of seconds and/or/// invalid nanosecond, otherwise returns `Some(DateTime {...})`./// use chrono::DateTime;/// let dt = DateTime::from_timestamp(1431648000, 0).expect("invalid timestamp");/// assert_eq!(dt.to_string(), "2015-05-15 00:00:00 UTC");from_timestamp_millis/// Makes a new `DateTime<Utc>` from the number of non-leap milliseconds/// since January 1, 1970 0:00:00.000 UTC (aka "UNIX timestamp")./// This is guaranteed to round-trip with [`timestamp_millis`](DateTime::timestamp_millis)./// [`TimeZone::timestamp_millis_opt`] or [`DateTime::with_timezone`]./// Returns `None` on out-of-range number of milliseconds, otherwise returns `Some(DateTime {...})`./// let dt = DateTime::from_timestamp_millis(947638923004).expect("invalid timestamp");/// assert_eq!(dt.to_string(), "2000-01-12 01:02:03.004 UTC");/// assert_eq!(DateTime::from_timestamp_millis(dt.timestamp_millis()).unwrap(), dt);from_timestamp_micros/// Creates a new `DateTime<Utc>` from the number of non-leap microseconds/// This is guaranteed to round-trip with [`timestamp_micros`](DateTime::timestamp_micros)./// [`TimeZone::timestamp_micros`] or [`DateTime::with_timezone`]./// Returns `None` if the number of microseconds would be out of range for a `NaiveDateTime`/// (more than ca. 262,000 years away from common era)/// let timestamp_micros: i64 = 1662921288000000; // Sun, 11 Sep 2022 18:34:48 UTC/// let dt = DateTime::from_timestamp_micros(timestamp_micros);/// assert!(dt.is_some());/// assert_eq!(timestamp_micros, dt.expect("invalid timestamp").timestamp_micros());/// // Negative timestamps (before the UNIX epoch) are supported as well./// let timestamp_micros: i64 = -2208936075000000; // Mon, 1 Jan 1900 14:38:45 UTCfrom_timestamp_nanos/// Creates a new [`DateTime<Utc>`] from the number of non-leap nanoseconds/// This is guaranteed to round-trip with [`timestamp_nanos`](DateTime::timestamp_nanos)./// [`TimeZone::timestamp_nanos`] or [`DateTime::with_timezone`]./// The UNIX epoch starts on midnight, January 1, 1970, UTC./// An `i64` with nanosecond precision can span a range of ~584 years. Because all values can/// be represented as a `DateTime` this method never fails./// let timestamp_nanos: i64 = 1662921288_000_000_000; // Sun, 11 Sep 2022 18:34:48 UTC/// let dt = DateTime::from_timestamp_nanos(timestamp_nanos);/// assert_eq!(timestamp_nanos, dt.timestamp_nanos_opt().unwrap());/// let timestamp_nanos: i64 = -2208936075_000_000_000; // Mon, 1 Jan 1900 14:38:45 UTCUNIX_EPOCH/// The Unix Epoch, 1970-01-01 00:00:00 UTC./// Convert this `DateTime<Utc>` instance into a `DateTime<FixedOffset>` instance./// Conversion is done via [`DateTime::with_timezone`]. Note that the converted value returned by/// this will be created with a fixed timezone offset of 0./// Convert a `DateTime<Utc>` instance into a `DateTime<FixedOffset>` instance./// Convert this `DateTime<FixedOffset>` instance into a `DateTime<Utc>` instance./// Conversion is performed via [`DateTime::with_timezone`], accounting for the timezone/// difference./// Convert a `DateTime<FixedOffset>` instance into a `DateTime<Utc>` instance./// Maps the local datetime to other datetime with given conversion function.parse_from_rfc2822/// Parses an RFC 2822 date-and-time string into a `DateTime<FixedOffset>` value./// This parses valid RFC 2822 datetime strings (such as `Tue, 1 Jul 2003 10:52:37 +0200`)/// and returns a new [`DateTime`] instance with the parsed timezone as the [`FixedOffset`]./// RFC 2822 is the internet message standard that specifies the representation of times in HTTP/// and email headers. It is the 2001 revision of RFC 822, and is itself revised as RFC 5322 in/// 2008./// # Support for the obsolete date format/// - A 2-digit year is interpreted to be a year in 1950-2049./// - The standard allows comments and whitespace between many of the tokens. See [4.3] and///   [Appendix A.5]/// - Single letter 'military' time zone names are parsed as a `-0000` offset.///   They were defined with the wrong sign in RFC 822 and corrected in RFC 2822. But because///   the meaning is now ambiguous, the standard says they should be considered as `-0000`///   unless there is out-of-band information confirming their meaning.///   The exception is `Z`, which remains identical to `+0000`./// [4.3]: https://www.rfc-editor.org/rfc/rfc2822#section-4.3/// [Appendix A.5]: https://www.rfc-editor.org/rfc/rfc2822#appendix-A.5/// # use chrono::{DateTime, FixedOffset, TimeZone};///     DateTime::parse_from_rfc2822("Wed, 18 Feb 2015 23:16:09 GMT").unwrap(),///     FixedOffset::east_opt(0).unwrap().with_ymd_and_hms(2015, 2, 18, 23, 16, 9).unwrap()parse_from_rfc3339/// Parses an RFC 3339 date-and-time string into a `DateTime<FixedOffset>` value./// Parses all valid RFC 3339 values (as well as the subset of valid ISO 8601 values that are/// also valid RFC 3339 date-and-time values) and returns a new [`DateTime`] with a/// [`FixedOffset`] corresponding to the parsed timezone. While RFC 3339 values come in a wide/// variety of shapes and sizes, `1996-12-19T16:39:57-08:00` is an example of the most commonly/// encountered variety of RFC 3339 formats./// Why isn't this named `parse_from_iso8601`? That's because ISO 8601 allows representing/// values in a wide range of formats, only some of which represent actual date-and-time/// instances (rather than periods, ranges, dates, or times). Some valid ISO 8601 values are/// also simultaneously valid RFC 3339 values, but not all RFC 3339 values are valid ISO 8601/// values (or the other way around).parse_from_str/// Parses a string from a user-specified format into a `DateTime<FixedOffset>` value./// Note that this method *requires a timezone* in the input string. See/// [`NaiveDateTime::parse_from_str`](./naive/struct.NaiveDateTime.html#method.parse_from_str)/// for a version that does not require a timezone in the to-be-parsed str. The returned/// [`DateTime`] value will have a [`FixedOffset`] reflecting the parsed timezone./// See the [`format::strftime` module](crate::format::strftime) for supported format/// sequences./// use chrono::{DateTime, FixedOffset, NaiveDate, TimeZone};/// let dt = DateTime::parse_from_str("1983 Apr 13 12:09:14.274 +0000", "%Y %b %d %H:%M:%S%.3f %z");///     dt,///     Ok(FixedOffset::east_opt(0)///         .unwrap()///         .from_local_datetime(///             &NaiveDate::from_ymd_opt(1983, 4, 13)///                 .unwrap()///                 .and_hms_milli_opt(12, 9, 14, 274)///         )///         .unwrap())/// Parses a string from a user-specified format into a `DateTime<FixedOffset>` value, and a/// slice with the remaining portion of the string./// [`NaiveDateTime::parse_and_remainder`] for a version that does not/// require a timezone in `s`. The returned [`DateTime`] value will have a [`FixedOffset`]/// reflecting the parsed timezone./// See the [`format::strftime` module](./format/strftime/index.html) for supported format/// Similar to [`parse_from_str`](#method.parse_from_str)./// let (datetime, remainder) = DateTime::parse_and_remainder(///     "2015-02-18 23:16:09 +0200 trailing text",///     "%Y-%m-%d %H:%M:%S %z",/// )/// .unwrap();///     datetime,///     FixedOffset::east_opt(2 * 3600).unwrap().with_ymd_and_hms(2015, 2, 18, 23, 16, 9).unwrap()/// assert_eq!(remainder, " trailing text");/// Formats the combined date and time with the specified formatting items./// Formats the combined date and time per the specified format string./// See the [`crate::format::strftime`] module for the supported escape sequences./// let date_time: DateTime<Utc> = Utc.with_ymd_and_hms(2017, 04, 02, 12, 50, 32).unwrap();/// let formatted = format!("{}", date_time.format("%d/%m/%Y %H:%M"));/// assert_eq!(formatted, "02/04/2017 12:50");/// Makes a new `DateTime` with the year number changed, while keeping the same month and day./// See also the [`NaiveDate::with_year`] method./// - The resulting date does not exist (February 29 in a non-leap year)./// - The resulting local datetime would be out of range (unless the year remains the same)./// Makes a new `DateTime` with the month number (starting from 1) changed./// Don't combine multiple `Datelike::with_*` methods. The intermediate value may not exist./// See also the [`NaiveDate::with_month`] method./// - The resulting date does not exist (for example `month(4)` when day of the month is 31)./// - The value for `month` is invalid./// Makes a new `DateTime` with the month number (starting from 0) changed./// See also the [`NaiveDate::with_month0`] method./// - The resulting date does not exist (for example `month0(3)` when day of the month is 31)./// - The value for `month0` is invalid./// Makes a new `DateTime` with the day of month (starting from 1) changed./// See also the [`NaiveDate::with_day`] method./// - The resulting date does not exist (for example `day(31)` in April)./// - The value for `day` is invalid./// Makes a new `DateTime` with the day of month (starting from 0) changed./// See also the [`NaiveDate::with_day0`] method./// - The resulting date does not exist (for example `day(30)` in April)./// - The value for `day0` is invalid./// Makes a new `DateTime` with the day of year (starting from 1) changed./// See also the [`NaiveDate::with_ordinal`] method./// - The resulting date does not exist (`with_ordinal(366)` in a non-leap year)./// - The value for `ordinal` is invalid./// Makes a new `DateTime` with the day of year (starting from 0) changed./// See also the [`NaiveDate::with_ordinal0`] method./// - The resulting date does not exist (`with_ordinal0(365)` in a non-leap year)./// - The value for `ordinal0` is invalid.hourminutenanosecondwith_hour/// Makes a new `DateTime` with the hour number changed./// See also the [`NaiveTime::with_hour`] method./// - The value for `hour` is invalid.with_minute/// Makes a new `DateTime` with the minute number changed./// See also the [`NaiveTime::with_minute`] method./// - The value for `minute` is invalid.with_second/// Makes a new `DateTime` with the second number changed./// As with the [`second`](#method.second) method,/// the input range is restricted to 0 through 59./// See also the [`NaiveTime::with_second`] method./// - The value for `second` is invalid.with_nanosecond/// Makes a new `DateTime` with nanoseconds since the whole non-leap second changed./// Returns `None` when the resulting `NaiveDateTime` would be invalid./// As with the [`NaiveDateTime::nanosecond`] method,/// the input range can exceed 1,000,000,000 for leap seconds./// See also the [`NaiveTime::with_nanosecond`] method./// Returns `None` if `nanosecond >= 2,000,000,000`.// We don't store a field with the `Tz` type, so it doesn't need to influence whether `DateTime` can// be `Copy`. Implement it manually if the two types we do have are `Copy`./// Compare two DateTimes based on their true time, ignoring time zones/// let earlier = Utc///     .with_ymd_and_hms(2015, 5, 15, 2, 0, 0)///     .with_timezone(&FixedOffset::west_opt(1 * 3600).unwrap());/// let later = Utc///     .with_ymd_and_hms(2015, 5, 15, 3, 0, 0)///     .with_timezone(&FixedOffset::west_opt(5 * 3600).unwrap());/// assert_eq!(earlier.to_string(), "2015-05-15 01:00:00 -01:00");/// assert_eq!(later.to_string(), "2015-05-14 22:00:00 -05:00");/// assert!(later > earlier);/// Add `TimeDelta` to `DateTime`./// As a part of Chrono's [leap second handling], the addition assumes that **there is no leap/// second ever**, except when the `NaiveDateTime` itself represents a leap  second in which case/// the assumption becomes that **there is exactly a single leap second ever**./// Panics if the resulting date would be out of range./// Consider using [`DateTime<Tz>::checked_add_signed`] to get an `Option` instead./// Add `std::time::Duration` to `DateTime`./// Add-assign `chrono::Duration` to `DateTime`./// Add-assign `std::time::Duration` to `DateTime`./// Add `FixedOffset` to the datetime value of `DateTime` (offset remains unchanged)./// Add `Months` to `DateTime`./// The result will be clamped to valid days in the resulting month, see `checked_add_months` for/// details./// Panics if:/// - The resulting date would be out of range./// Strongly consider using [`DateTime<Tz>::checked_add_months`] to get an `Option` instead./// Subtract `TimeDelta` from `DateTime`./// This is the same as the addition with a negated `TimeDelta`./// As a part of Chrono's [leap second handling] the subtraction assumes that **there is no leap/// second ever**, except when the `DateTime` itself represents a leap second in which case/// Consider using [`DateTime<Tz>::checked_sub_signed`] to get an `Option` instead./// Subtract `std::time::Duration` from `DateTime`./// Subtract-assign `TimeDelta` from `DateTime`./// second ever**, except when the `DateTime` itself represents a leap  second in which case/// Subtract-assign `std::time::Duration` from `DateTime`./// Subtract `FixedOffset` from the datetime value of `DateTime` (offset remains unchanged)./// Subtract `Months` from `DateTime`./// The result will be clamped to valid days in the resulting month, see/// [`DateTime<Tz>::checked_sub_months`] for details./// Strongly consider using [`DateTime<Tz>::checked_sub_months`] to get an `Option` instead./// Add `Days` to `NaiveDateTime`./// Strongly consider using `DateTime<Tz>::checked_add_days` to get an `Option` instead./// Subtract `Days` from `DateTime`./// Strongly consider using `DateTime<Tz>::checked_sub_days` to get an `Option` instead./// Accepts a relaxed form of RFC3339./// A space or a 'T' are accepted as the separator between the date and time/// parts./// All of these examples are equivalent:/// # use chrono::{DateTime, Utc};/// "2012-12-12T12:12:12Z".parse::<DateTime<Utc>>()?;/// "2012-12-12 12:12:12Z".parse::<DateTime<Utc>>()?;/// "2012-12-12 12:12:12+0000".parse::<DateTime<Utc>>()?;/// "2012-12-12 12:12:12+00:00".parse::<DateTime<Utc>>()?;/// # Ok::<(), chrono::ParseError>(())UNIX_EPOCH_DAY/// Number of days between Januari 1, 1970 and December 31, 1 BCE which we define to be day 0./// 4 full leap year cycles until December 31, 1600     4 * 146097 = 584388/// 1 day until January 1, 1601                                           1/// 369 years until Januari 1, 1970                      369 * 365 = 134685/// of which floor(369 / 4) are leap years          floor(369 / 4) =     92/// except for 1700, 1800 and 1900                                       -3 +///                                                                  --------///                                                                  719163//! ISO 8601 date and time with time zone.LocalSecondsTimestampVisitorNanoSecondsTimestampVisitorMicroSecondsTimestampVisitorMilliSecondsTimestampVisitor/// Serialize to an RFC 3339 formatted string/// As an extension to RFC 3339 this can serialize `DateTime`s outside the range of 0-9999 years/// using an ISO 8601 syntax (which prepends an `-` or `+`)./// See [the `serde` module](crate::serde) for alternate serializations.DateTimeVisitorexpectingvisit_str/// Deserialize an RFC 3339 formatted string into a `DateTime<FixedOffset>`/// As an extension to RFC 3339 this can deserialize to `DateTime`s outside the range of 0-9999/// years using an ISO 8601 syntax (which prepends an `-` or `+`)./// See [the `serde` module](crate::serde) for alternate deserialization formats./// Deserialize an RFC 3339 formatted string into a `DateTime<Utc>`/// If the value contains an offset from UTC that is not zero, the value will be converted to UTC./// Deserialize an RFC 3339 formatted string into a `DateTime<Local>`/// The value will remain the same instant in UTC, but the offset will be recalculated to match/// that of the `Local` platform time zone.invalid_ts/// Serialize a UTC datetime into an integer number of nanoseconds since the epoch/// Intended for use with `serde`s `serialize_with` attribute./// An `i64` with nanosecond precision can span a range of ~584 years. This function returns an/// error on an out of range `DateTime`./// The dates that can be represented as nanoseconds are between 1677-09-21T00:12:44.0 and/// 2262-04-11T23:47:16.854775804./// # Example:/// # use chrono::{DateTime, Utc, NaiveDate};/// # use serde_derive::Serialize;/// use chrono::serde::ts_nanoseconds::serialize as to_nano_ts;/// #[derive(Serialize)]/// struct S {///     #[serde(serialize_with = "to_nano_ts")]///     time: DateTime<Utc>,/// let my_s = S {///     time: NaiveDate::from_ymd_opt(2018, 5, 17)///         .and_hms_nano_opt(02, 04, 59, 918355733)///         .and_utc(),/// let as_string = serde_json::to_string(&my_s)?;/// assert_eq!(as_string, r#"{"time":1526522699918355733}"#);/// # Ok::<(), serde_json::Error>(())/// Deserialize a [`DateTime`] from a nanosecond timestamp/// Intended for use with `serde`s `deserialize_with` attribute./// # use chrono::{DateTime, TimeZone, Utc};/// # use serde_derive::Deserialize;/// use chrono::serde::ts_nanoseconds::deserialize as from_nano_ts;/// #[derive(Debug, PartialEq, Deserialize)]///     #[serde(deserialize_with = "from_nano_ts")]/// let my_s: S = serde_json::from_str(r#"{ "time": 1526522699918355733 }"#)?;/// assert_eq!(my_s, S { time: Utc.timestamp_opt(1526522699, 918355733).unwrap() });/// let my_s: S = serde_json::from_str(r#"{ "time": -1 }"#)?;/// assert_eq!(my_s, S { time: Utc.timestamp_opt(-1, 999_999_999).unwrap() });visit_i64/// Deserialize a timestamp in nanoseconds since the epochvisit_u64ts_nanoseconds/// Ser/de to/from timestamps in nanoseconds/// Intended for use with `serde`'s `with` attribute./// # use serde_derive::{Deserialize, Serialize};/// use chrono::serde::ts_nanoseconds;/// #[derive(Deserialize, Serialize)]///     #[serde(with = "ts_nanoseconds")]/// let time = NaiveDate::from_ymd_opt(2018, 5, 17)///     .and_hms_nano_opt(02, 04, 59, 918355733)/// let my_s = S { time: time.clone() };/// let my_s: S = serde_json::from_str(&as_string)?;/// assert_eq!(my_s.time, time);/// Serialize a UTC datetime into an integer number of nanoseconds since the epoch or none/// use chrono::serde::ts_nanoseconds_option::serialize as to_nano_tsopt;///     #[serde(serialize_with = "to_nano_tsopt")]///     time: Option<DateTime<Utc>>,///     time: Some(///         NaiveDate::from_ymd_opt(2018, 5, 17)///             .and_hms_nano_opt(02, 04, 59, 918355733)///             .and_utc(),///     ),/// Deserialize a `DateTime` from a nanosecond timestamp or none/// use chrono::serde::ts_nanoseconds_option::deserialize as from_nano_tsopt;///     #[serde(deserialize_with = "from_nano_tsopt")]/// assert_eq!(my_s, S { time: Utc.timestamp_opt(1526522699, 918355733).single() });OptionNanoSecondsTimestampVisitorvisit_somevisit_nonevisit_unitts_nanoseconds_option/// Ser/de to/from optional timestamps in nanoseconds/// use chrono::serde::ts_nanoseconds_option;///     #[serde(with = "ts_nanoseconds_option")]/// let time = Some(///     NaiveDate::from_ymd_opt(2018, 5, 17)/// Serialize a UTC datetime into an integer number of microseconds since the epoch/// use chrono::serde::ts_microseconds::serialize as to_micro_ts;///     #[serde(serialize_with = "to_micro_ts")]///         .and_hms_micro_opt(02, 04, 59, 918355)/// assert_eq!(as_string, r#"{"time":1526522699918355}"#);/// Deserialize a `DateTime` from a microsecond timestamp/// use chrono::serde::ts_microseconds::deserialize as from_micro_ts;///     #[serde(deserialize_with = "from_micro_ts")]/// let my_s: S = serde_json::from_str(r#"{ "time": 1526522699918355 }"#)?;/// assert_eq!(my_s, S { time: Utc.timestamp_opt(1526522699, 918355000).unwrap() });/// assert_eq!(my_s, S { time: Utc.timestamp_opt(-1, 999_999_000).unwrap() });/// Deserialize a timestamp in milliseconds since the epochts_microseconds/// Ser/de to/from timestamps in microseconds/// use chrono::serde::ts_microseconds;///     #[serde(with = "ts_microseconds")]///     .and_hms_micro_opt(02, 04, 59, 918355)/// Serialize a UTC datetime into an integer number of microseconds since the epoch or none/// use chrono::serde::ts_microseconds_option::serialize as to_micro_tsopt;///     #[serde(serialize_with = "to_micro_tsopt")]///             .and_hms_micro_opt(02, 04, 59, 918355)/// Deserialize a `DateTime` from a microsecond timestamp or none/// use chrono::serde::ts_microseconds_option::deserialize as from_micro_tsopt;///     #[serde(deserialize_with = "from_micro_tsopt")]/// assert_eq!(my_s, S { time: Utc.timestamp_opt(1526522699, 918355000).single() });OptionMicroSecondsTimestampVisitor/// Deserialize a timestamp in microseconds since the epochts_microseconds_option/// Ser/de to/from optional timestamps in microseconds/// use chrono::serde::ts_microseconds_option;///     #[serde(with = "ts_microseconds_option")]/// Serialize a UTC datetime into an integer number of milliseconds since the epoch/// use chrono::serde::ts_milliseconds::serialize as to_milli_ts;///     #[serde(serialize_with = "to_milli_ts")]///         .and_hms_milli_opt(02, 04, 59, 918)/// assert_eq!(as_string, r#"{"time":1526522699918}"#);/// Deserialize a `DateTime` from a millisecond timestamp/// use chrono::serde::ts_milliseconds::deserialize as from_milli_ts;///     #[serde(deserialize_with = "from_milli_ts")]/// let my_s: S = serde_json::from_str(r#"{ "time": 1526522699918 }"#)?;/// assert_eq!(my_s, S { time: Utc.timestamp_opt(1526522699, 918000000).unwrap() });/// assert_eq!(my_s, S { time: Utc.timestamp_opt(-1, 999_000_000).unwrap() });ts_milliseconds/// Ser/de to/from timestamps in milliseconds/// Intended for use with `serde`s `with` attribute./// use chrono::serde::ts_milliseconds;///     #[serde(with = "ts_milliseconds")]///     .and_hms_milli_opt(02, 04, 59, 918)/// Serialize a UTC datetime into an integer number of milliseconds since the epoch or none/// use chrono::serde::ts_milliseconds_option::serialize as to_milli_tsopt;///     #[serde(serialize_with = "to_milli_tsopt")]///             .and_hms_milli_opt(02, 04, 59, 918)/// Deserialize a `DateTime` from a millisecond timestamp or none/// # use chrono::{TimeZone, DateTime, Utc};/// use chrono::serde::ts_milliseconds_option::deserialize as from_milli_tsopt;/// #[derive(Deserialize, PartialEq, Debug)]/// #[serde(untagged)]/// enum E<T> {///     V(T),///     #[serde(default, deserialize_with = "from_milli_tsopt")]/// let my_s: E<S> = serde_json::from_str(r#"{ "time": 1526522699918 }"#)?;/// assert_eq!(my_s, E::V(S { time: Some(Utc.timestamp_opt(1526522699, 918000000).unwrap()) }));/// let s: E<S> = serde_json::from_str(r#"{ "time": null }"#)?;/// assert_eq!(s, E::V(S { time: None }));/// let t: E<S> = serde_json::from_str(r#"{}"#)?;/// assert_eq!(t, E::V(S { time: None }));OptionMilliSecondsTimestampVisitorts_milliseconds_option/// Ser/de to/from optional timestamps in milliseconds/// use chrono::serde::ts_milliseconds_option;///     #[serde(with = "ts_milliseconds_option")]/// Serialize a UTC datetime into an integer number of seconds since the epoch/// use chrono::serde::ts_seconds::serialize as to_ts;///     #[serde(serialize_with = "to_ts")]/// let my_s = S { time: Utc.with_ymd_and_hms(2015, 5, 15, 10, 0, 0).unwrap() };/// assert_eq!(as_string, r#"{"time":1431684000}"#);/// Deserialize a `DateTime` from a seconds timestamp/// use chrono::serde::ts_seconds::deserialize as from_ts;///     #[serde(deserialize_with = "from_ts")]/// let my_s: S = serde_json::from_str(r#"{ "time": 1431684000 }"#)?;/// assert_eq!(my_s, S { time: Utc.timestamp_opt(1431684000, 0).unwrap() });/// Deserialize a timestamp in seconds since the epochts_seconds/// Ser/de to/from timestamps in seconds/// use chrono::serde::ts_seconds;///     #[serde(with = "ts_seconds")]/// let time = Utc.with_ymd_and_hms(2015, 5, 15, 10, 0, 0).unwrap();/// Serialize a UTC datetime into an integer number of seconds since the epoch or none/// use chrono::serde::ts_seconds_option::serialize as to_tsopt;///     #[serde(serialize_with = "to_tsopt")]/// let my_s = S { time: Some(Utc.with_ymd_and_hms(2015, 5, 15, 10, 0, 0).unwrap()) };/// Deserialize a `DateTime` from a seconds timestamp or none/// use chrono::serde::ts_seconds_option::deserialize as from_tsopt;///     #[serde(deserialize_with = "from_tsopt")]/// assert_eq!(my_s, S { time: Utc.timestamp_opt(1431684000, 0).single() });OptionSecondsTimestampVisitorts_seconds_option/// Ser/de to/from optional timestamps in seconds/// use chrono::serde::ts_seconds_option;///     #[serde(with = "ts_seconds_option")]/// let time = Some(Utc.with_ymd_and_hms(2015, 5, 15, 10, 0, 0).unwrap());test_serde_serializetest_serde_deserializetest_serde_bincodetest_serde_no_offset_debugMappedLocalTimeDstTesterwinter_offsetsummer_offsetTO_WINTER_MONTH_DAYTO_SUMMER_MONTH_DAYtransition_start_localfrom_offsetoffset_from_local_dateoffset_from_local_datetimeoffset_from_utc_dateoffset_from_utc_datetimetest_datetime_from_timestamp_millistest_datetime_from_timestamp_microstest_datetime_from_timestamp_nanostest_datetime_from_timestamptest_datetime_timestamptest_nanosecond_rangetest_datetime_add_daystest_datetime_sub_daystest_datetime_add_monthstest_datetime_sub_monthsymdhms// local helper function to easily create a DateTime<FixedOffset>ymdhms_milliymdhms_microymdhms_nanoymdhms_utc// local helper function to easily create a DateTime<Utc>ymdhms_milli_utctest_datetime_offsetsigned_duration_since_autoreftest_datetime_date_and_timetest_datetime_rfc2822test_datetime_rfc3339test_rfc3339_optstest_rfc3339_opts_nonexhaustivetest_datetime_from_strtest_parse_datetime_utctest_parse_from_strtest_datetime_parse_from_strtest_to_string_round_triptest_datetime_is_send_and_copytest_subsecond_parttest_datetime_from_localtest_datetime_add_assigntest_datetime_sub_assigntest_min_max_getterstest_min_max_setterstest_min_max_add_daystest_min_max_add_monthstest_local_beyond_min_datetimetest_local_beyond_max_datetimetest_core_duration_opstest_core_duration_maxtest_datetime_fixed_offsettest_datetime_to_utctest_add_sub_monthstest_auto_conversionnano_roundrip/// This is an extended test for <https://github.com/chronotope/chrono/issues/1289>.localesColonsOffsetFormatOffsetPrecisionPadInternalFixedInternalInternalNumeric/// The date view, if any./// The time view, if any.off/// The name and local-to-UTC difference for the offset (timezone), if any./// An iterator returning formatting items.localeLocale/// Locale used for text./// ZST if the `unstable-locales` feature is not enabled./// A *temporary* object which can be used as an argument to `format!` or others./// This is normally constructed via `format` methods of each date and time type./// Makes a new `DelayedFormat` value out of local date and time.Offnew_with_offset/// Makes a new `DelayedFormat` value out of local date and time and UTC offset./// Formats `DelayedFormat` into a `core::fmt::Write` instance./// This function returns a `core::fmt::Error` if formatting into the `core::fmt::Write` instance fails./// ### Writing to a String/// let dt = chrono::DateTime::from_timestamp(1643723400, 123456789).unwrap();/// let df = dt.format("%Y-%m-%d %H:%M:%S%.9f");/// let mut buffer = String::new();/// let _ = df.write_to(&mut buffer);format_numericformat_fixed/// Tries to format given arguments with given formatting items./// Internally used by `DelayedFormat`.format_item/// Formats single formatting item/// Writes an offset from UTC with the format defined by `self`.Secs/// Format whole seconds only, with no decimal point nor subseconds.Millis/// Use fixed 3 subsecond digits. This corresponds to [Fixed::Nanosecond3].Micros/// Use fixed 6 subsecond digits. This corresponds to [Fixed::Nanosecond6].Nanos/// Use fixed 9 subsecond digits. This corresponds to [Fixed::Nanosecond9].AutoSi/// Automatically select one of `Secs`, `Millis`, `Micros`, or `Nanos` to display all available/// non-zero sub-second digits.  This corresponds to [Fixed::Nanosecond].__NonExhaustive// Do not match against this./// Specific formatting options for seconds. This may be extended in the/// future, so exhaustive matching in external code is not recommended./// See the `TimeZone::to_rfc3339_opts` function for usage./// Writes the date, time and offset to the string. same as `%Y-%m-%dT%H:%M:%S%.f%:z`/// write datetimes like `Tue, 1 Jul 2003 10:52:37 +0200`, same as `%a, %d %b %Y %H:%M:%S %z`write_hundreds/// Equivalent to `{:02}` formatting for n < 100.test_delayed_write_totest_date_formattest_time_formattest_datetime_formattest_datetime_format_alignmenttest_offset_formatting//! Date and time formatting routines.default_localeshort_monthslong_monthsshort_weekdayslong_weekdaysam_pmdecimal_pointunlocalizedMonthParseMonthErrorParseWeekdayErrorformattingparsed// due to the size of parsing routines, they are in separate modules.scanstrftime// TODO: remove '#[allow(unused)]' once we use this module for parsing or something else that does// not require `alloc`.Void/// An uninhabited type used for `InternalNumeric` and `InternalFixed` below./// No padding./// Zero (`0`) padding./// Space padding./// Padding characters for numeric items.Year/// Full Gregorian year (FW=4, PW=∞)./// May accept years before 1 BCE or after 9999 CE, given an initial sign (+/-).YearDiv100/// Gregorian year divided by 100 (century number; FW=PW=2). Implies the non-negative year.YearMod100/// Gregorian year modulo 100 (FW=PW=2). Cannot be negative.IsoYear/// Year in the ISO week date (FW=4, PW=∞)./// May accept years before 1 BCE or after 9999 CE, given an initial sign.IsoYearDiv100/// Year in the ISO week date, divided by 100 (FW=PW=2). Implies the non-negative year.IsoYearMod100/// Year in the ISO week date, modulo 100 (FW=PW=2). Cannot be negative.Quarter/// Quarter (FW=PW=1)./// Month (FW=PW=2).Day/// Day of the month (FW=PW=2).WeekFromSun/// Week number, where the week 1 starts at the first Sunday of January (FW=PW=2).WeekFromMon/// Week number, where the week 1 starts at the first Monday of January (FW=PW=2)./// Week number in the ISO week date (FW=PW=2).NumDaysFromSun/// Day of the week, where Sunday = 0 and Saturday = 6 (FW=PW=1).WeekdayFromMon/// Day of the week, where Monday = 1 and Sunday = 7 (FW=PW=1).Ordinal/// Day of the year (FW=PW=3).Hour/// Hour number in the 24-hour clocks (FW=PW=2).Hour12/// Hour number in the 12-hour clocks (FW=PW=2).Minute/// The number of minutes since the last whole hour (FW=PW=2).Second/// The number of seconds since the last whole minute (FW=PW=2).Nanosecond/// The number of nanoseconds since the last whole second (FW=PW=9)./// Note that this is *not* left-aligned;/// see also [`Fixed::Nanosecond`](./enum.Fixed.html#variant.Nanosecond).Timestamp/// The number of non-leap seconds since the midnight UTC on January 1, 1970 (FW=1, PW=∞)./// For formatting, it assumes UTC upon the absence of time zone offset.InternalNumeric/// Internal uses only./// This item exists so that one can add additional internal-only formatting/// without breaking major compatibility (as enum variants cannot be selectively private)./// Numeric item types./// They have associated formatting width (FW) and parsing width (PW)./// The **formatting width** is the minimal width to be formatted./// If the number is too short, and the padding is not [`Pad::None`](./enum.Pad.html#variant.None),/// then it is left-padded./// If the number is too long or (in some cases) negative, it is printed as is./// The **parsing width** is the maximal width to be scanned./// The parser only tries to consume from one to given number of digits (greedily)./// It also trims the preceding whitespace if any./// It cannot parse the negative number, so some date and time cannot be formatted then/// parsed with the same formatting items._dummy/// An opaque type representing numeric item types for internal uses only.ShortMonthName/// Abbreviated month names./// Prints a three-letter-long name in the title case, reads the same name in any case.LongMonthName/// Full month names./// Prints a full name in the title case, reads either a short or full name in any case.ShortWeekdayName/// Abbreviated day of the week names.LongWeekdayName/// Full day of the week names.LowerAmPm/// AM/PM./// Prints in lower case, reads in any case.UpperAmPm/// Prints in upper case, reads in any case./// An optional dot plus one or more digits for left-aligned nanoseconds./// May print nothing, 3, 6 or 9 digits according to the available accuracy./// See also [`Numeric::Nanosecond`](./enum.Numeric.html#variant.Nanosecond).Nanosecond3/// Same as [`Nanosecond`](#variant.Nanosecond) but the accuracy is fixed to 3.Nanosecond6/// Same as [`Nanosecond`](#variant.Nanosecond) but the accuracy is fixed to 6.Nanosecond9/// Same as [`Nanosecond`](#variant.Nanosecond) but the accuracy is fixed to 9.TimezoneName/// Timezone name./// It does not support parsing, its use in the parser is an immediate failure.TimezoneOffsetColon/// Offset from the local time to UTC (`+09:00` or `-04:00` or `+00:00`)./// In the parser, the colon can be omitted and/or surrounded with any amount of whitespace./// The offset is limited from `-24:00` to `+24:00`,/// which is the same as [`FixedOffset`](../offset/struct.FixedOffset.html)'s range.TimezoneOffsetDoubleColon/// Offset from the local time to UTC with seconds (`+09:00:00` or `-04:00:00` or `+00:00:00`)./// The offset is limited from `-24:00:00` to `+24:00:00`,TimezoneOffsetTripleColon/// Offset from the local time to UTC without minutes (`+09` or `-04` or `+00`)./// The offset is limited from `-24` to `+24`,TimezoneOffsetColonZ/// Offset from the local time to UTC (`+09:00` or `-04:00` or `Z`)./// In the parser, the colon can be omitted and/or surrounded with any amount of whitespace,/// and `Z` can be either in upper case or in lower case.TimezoneOffset/// Same as [`TimezoneOffsetColon`](#variant.TimezoneOffsetColon) but prints no colon./// Parsing allows an optional colon.TimezoneOffsetZ/// Same as [`TimezoneOffsetColonZ`](#variant.TimezoneOffsetColonZ) but prints no colon.RFC2822/// RFC 2822 date and time syntax. Commonly used for email and MIME date and time.RFC3339/// RFC 3339 & ISO 8601 date and time syntax./// Fixed-format item types./// They have their own rules of formatting and parsing./// Otherwise noted, they print in the specified cases but parse case-insensitively.val/// An opaque type representing fixed-format item types for internal uses only.TimezoneOffsetPermissive/// Same as [`TimezoneOffsetColonZ`](#variant.TimezoneOffsetColonZ), but/// allows missing minutes (per [ISO 8601][iso8601])./// If you try to use this for printing./// [iso8601]: https://en.wikipedia.org/wiki/ISO_8601#Time_offsets_from_UTCNanosecond3NoDot/// Same as [`Nanosecond`](#variant.Nanosecond) but the accuracy is fixed to 3 and there is no leading dot.Nanosecond6NoDot/// Same as [`Nanosecond`](#variant.Nanosecond) but the accuracy is fixed to 6 and there is no leading dot.Nanosecond9NoDot/// Same as [`Nanosecond`](#variant.Nanosecond) but the accuracy is fixed to 9 and there is no leading dot.precision/// See `OffsetPrecision`.colons/// Separator between hours, minutes and seconds.allow_zulu/// Represent `+00:00` as `Z`.padding/// Pad the hour value to two digits./// Type for specifying the format of UTC offsets.Hours/// Format offset from UTC as only hours. Not recommended, it is not uncommon for timezones to/// have an offset of 30 minutes, 15 minutes, etc./// Any minutes and seconds get truncated.Minutes/// Format offset from UTC as hours and minutes./// Any seconds will be rounded to the nearest minute.Seconds/// Format offset from UTC as hours, minutes and seconds.OptionalMinutes/// Format offset from UTC as hours, and optionally with minutes.OptionalSeconds/// Format offset from UTC as hours and minutes, and optionally seconds.OptionalMinutesAndSeconds/// Format offset from UTC as hours and optionally minutes and seconds./// The precision of an offset from UTC formatting item./// No separatorColon/// Colon (`:`) as separatorMaybe/// No separator when formatting, colon allowed when parsing./// The separator between hours and minutes in an offset.Literal/// A literally printed and parsed text.OwnedLiteral/// Same as `Literal` but with the string owned by the item./// Whitespace. Prints literally but reads zero or more whitespace.OwnedSpace/// Same as `Space` but with the string owned by the item./// Numeric item. Can be optionally padded to the maximal length (if any) when formatting;/// the parser simply ignores any padded whitespace and zeroes./// Fixed-format item./// Issues a formatting error. Used to signal an invalid format string./// A single formatting item. This is used for both formatting and parsing.num0numsfixedinternal_fixedto_owned/// Convert items that contain a reference to the format string into an owned variant./// An error from the `parse` function./// The category of parse errorOutOfRange/// Given field is out of permitted range.Impossible/// There is no possible date and time value with given set of fields./// This does not include the out-of-range conditions, which are trivially invalid./// It includes the case that there are one or more fields that are inconsistent to each other.NotEnough/// Given set of fields is not enough to make a requested date and time value./// Note that there *may* be a case that given fields constrain the possible values so much/// that there is a unique possible value. Chrono only tries to be correct for/// most useful sets of fields however, as such constraint solving can be expensive./// The input string has some invalid character sequence for given formatting items.TooShort/// The input string has been prematurely ended.TooLong/// All formatting items have been read but there is a remaining input.BadFormat/// There was an error on the formatting string, or there were non-supported formatting items.__Nonexhaustive// TODO: Change this to `#[non_exhaustive]` (on the enum) with the next breaking release./// Same as `Result<T, ParseError>`.OUT_OF_RANGE// to be used in this module and submodulesIMPOSSIBLENOT_ENOUGHINVALIDTOO_SHORTBAD_FORMAT/// Parsing a `str` into a `Weekday` uses the format [`%A`](./format/strftime/index.html)./// use chrono::Weekday;/// assert_eq!("Sunday".parse::<Weekday>(), Ok(Weekday::Sun));/// assert!("any day".parse::<Weekday>().is_err());/// The parsing is case-insensitive./// # use chrono::Weekday;/// assert_eq!("mON".parse::<Weekday>(), Ok(Weekday::Mon));/// Only the shortest form (e.g. `sun`) and the longest form (e.g. `sunday`) is accepted./// assert!("thurs".parse::<Weekday>().is_err());/// Parsing a `str` into a `Month` uses the format [`%B`](./format/strftime/index.html)./// use chrono::Month;/// assert_eq!("January".parse::<Month>(), Ok(Month::January));/// assert!("any day".parse::<Month>().is_err());/// # use chrono::Month;/// assert_eq!("fEbruARy".parse::<Month>(), Ok(Month::February));/// Only the shortest form (e.g. `jan`) and the longest form (e.g. `january`) is accepted./// assert!("septem".parse::<Month>().is_err());/// assert!("Augustin".parse::<Month>().is_err());//! Formatting (and parsing) utilities for date and time.//! This module provides the common types and routines to implement,//! for example, [`DateTime::format`](../struct.DateTime.html#method.format) or//! [`DateTime::parse_from_str`](../struct.DateTime.html#method.parse_from_str) methods.//! For most cases you should use these high-level interfaces.//! Internally the formatting and parsing shares the same abstract **formatting items**,//! which are just an [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) of//! the [`Item`](./enum.Item.html) type.//! They are generated from more readable **format strings**;//! currently Chrono supports a built-in syntax closely resembling//! C's `strftime` format. The available options can be found [here](./strftime/index.html).//! # #[cfg(feature = "alloc")] {//! use chrono::{NaiveDateTime, TimeZone, Utc};//! let date_time = Utc.with_ymd_and_hms(2020, 11, 10, 0, 1, 32).unwrap();//! let formatted = format!("{}", date_time.format("%Y-%m-%d %H:%M:%S"));//! assert_eq!(formatted, "2020-11-10 00:01:32");//! let parsed = NaiveDateTime::parse_from_str(&formatted, "%Y-%m-%d %H:%M:%S")?.and_utc();//! assert_eq!(parsed, date_time);//! # Ok::<(), chrono::ParseError>(())// this implementation is here only because we need some private code from `scan`set_weekday_with_num_days_from_sundayset_weekday_with_number_from_mondayparse_rfc2822/// Tries to parse given string into `parsed` with given formatting items./// Returns `Ok` when the entire string has been parsed (otherwise `parsed` should not be used)./// There should be no trailing string after parsing;/// use a stray [`Item::Space`](./enum.Item.html#variant.Space) to trim whitespaces./// This particular date and time parser is:/// - Greedy. It will consume the longest possible prefix.///   For example, `April` is always consumed entirely when the long month name is requested;///   it equally accepts `Apr`, but prefers the longer prefix in this case./// - Padding-agnostic (for numeric items).///   The [`Pad`](./enum.Pad.html) field is completely ignored,///   so one can prepend any number of whitespace then any number of zeroes before numbers./// - (Still) obeying the intrinsic parsing width. This allows, for example, parsing `HHMMSS`./// Returns `Ok` with a slice of the unparsed remainder.///   so one can prepend any number of zeroes before numbers.parse_internal/// parts. Additional spaces are allowed between each component./// # use chrono::{DateTime, offset::FixedOffset};/// "2012-12-12T12:12:12Z".parse::<DateTime<FixedOffset>>()?;/// "2012-12-12 12:12:12Z".parse::<DateTime<FixedOffset>>()?;/// "2012-  12-12T12:  12:12Z".parse::<DateTime<FixedOffset>>()?;parse_rfc3339_relaxed/// Differences with RFC3339:/// - Values don't require padding to two digits./// - Years outside the range 0...=9999 are accepted, but they must include a sign./// - `UTC` is accepted as a valid timezone name/offset (for compatibility with the debug format of///   `DateTime<Utc>`./// - There can be spaces between any of the components./// - The colon in the offset may be missing.test_parse_whitespace_and_literaltest_parse_numerictest_parse_fixedtest_parse_fixed_nanosecondtest_parse_fixed_timezone_offsettest_parse_practical_examplesparsestest_rfc2822parse_rfc850test_rfc3339test_issue_1010// Portions copyright (c) 2015, John Nagle.//! Date and time parsing routines.year_div_100year_mod_100isoyearisoyear_div_100isoyear_mod_100quarterweek_from_sunweek_from_monisoweekhour_div_12hour_mod_12/// A type to hold parsed fields of date and time that can check all fields are consistent./// There are three classes of methods:/// - `set_*` methods to set fields you have available. They do a basic range check, and if the///   same field is set more than once it is checked for consistency./// - `to_*` methods try to make a concrete date and time value out of set fields.///   They fully check that all fields are consistent and whether the date/datetime exists./// - Methods to inspect the parsed fields./// `Parsed` is used internally by all parsing functions in chrono. It is a public type so that it/// can be used to write custom parsers that reuse the resolving algorithm, or to inspect the/// results of a string parsed with chrono without converting it to concrete types./// # Resolving algorithm/// Resolving date/time parts is littered with lots of corner cases, which is why common date/time/// parsers do not implement it correctly./// Chrono provides a complete resolution algorithm that checks all fields for consistency via the/// `Parsed` type./// As an easy example, consider RFC 2822. The [RFC 2822 date and time format] has a day of the week/// part, which should be consistent with the other date parts. But a `strptime`-based parse would/// happily accept inconsistent input:/// ```python/// >>> import time/// >>> time.strptime('Wed, 31 Dec 2014 04:26:40 +0000',///                   '%a, %d %b %Y %H:%M:%S +0000')/// time.struct_time(tm_year=2014, tm_mon=12, tm_mday=31,///                  tm_hour=4, tm_min=26, tm_sec=40,///                  tm_wday=2, tm_yday=365, tm_isdst=-1)/// >>> time.strptime('Thu, 31 Dec 2014 04:26:40 +0000',///                  tm_wday=3, tm_yday=365, tm_isdst=-1)/// [RFC 2822 date and time format]: https://tools.ietf.org/html/rfc2822#section-3.3/// Let's see how `Parsed` correctly detects the second RFC 2822 string from before is inconsistent./// # #[cfg(feature = "alloc")] {/// use chrono::format::{ParseErrorKind, Parsed};/// let mut parsed = Parsed::new();/// parsed.set_weekday(Weekday::Wed)?;/// parsed.set_day(31)?;/// parsed.set_month(12)?;/// parsed.set_year(2014)?;/// parsed.set_hour(4)?;/// parsed.set_minute(26)?;/// parsed.set_second(40)?;/// parsed.set_offset(0)?;/// let dt = parsed.to_datetime()?;/// assert_eq!(dt.to_rfc2822(), "Wed, 31 Dec 2014 04:26:40 +0000");/// parsed.set_weekday(Weekday::Thu)?; // changed to the wrong day/// let result = parsed.to_datetime();/// if let Err(error) = result {///     assert_eq!(error.kind(), ParseErrorKind::Impossible);/// The same using chrono's built-in parser for RFC 2822 (the [RFC2822 formatting item]) and/// [`format::parse()`] showing how to inspect a field on failure./// [RFC2822 formatting item]: crate::format::Fixed::RFC2822/// [`format::parse()`]: crate::format::parse()/// use chrono::format::{parse, Fixed, Item, Parsed};/// let rfc_2822 = [Item::Fixed(Fixed::RFC2822)];/// parse(&mut parsed, "Wed, 31 Dec 2014 04:26:40 +0000", rfc_2822.iter())?;/// parse(&mut parsed, "Thu, 31 Dec 2014 04:26:40 +0000", rfc_2822.iter())?;/// if result.is_err() {///     // What is the weekday?///     assert_eq!(parsed.weekday(), Some(Weekday::Thu));set_if_consistent/// Checks if `old` is either empty or has the same value as `new` (i.e. "consistent"),/// and if it is empty, set `old` to `new` as well./// Returns the initial value of parsed parts.set_year/// Set the [`year`](Parsed::year) field to the given value./// The value can be negative, unlike the [`year_div_100`](Parsed::year_div_100) and/// [`year_mod_100`](Parsed::year_mod_100) fields./// Returns `OUT_OF_RANGE` if `value` is outside the range of an `i32`./// Returns `IMPOSSIBLE` if this field was already set to a different value.set_year_div_100/// Set the [`year_div_100`](Parsed::year_div_100) field to the given value./// Returns `OUT_OF_RANGE` if `value` is negative or if it is greater than `i32::MAX`.set_year_mod_100/// Set the [`year_mod_100`](Parsed::year_mod_100) field to the given value./// When set it implies that the year is not negative./// If this field is set while the [`year_div_100`](Parsed::year_div_100) field is missing (and/// the full [`year`](Parsed::year) field is also not set), it assumes a default value for the/// [`year_div_100`](Parsed::year_div_100) field./// The default is 19 when `year_mod_100 >= 70` and 20 otherwise./// Returns `OUT_OF_RANGE` if `value` is negative or if it is greater than 99.set_isoyear/// Set the [`isoyear`](Parsed::isoyear) field, that is part of an [ISO 8601 week date], to the/// given value./// The value can be negative, unlike the [`isoyear_div_100`](Parsed::isoyear_div_100) and/// [`isoyear_mod_100`](Parsed::isoyear_mod_100) fields./// [ISO 8601 week date]: crate::NaiveDate#week-dateset_isoyear_div_100/// Set the [`isoyear_div_100`](Parsed::isoyear_div_100) field, that is part of an/// [ISO 8601 week date], to the given value.set_isoyear_mod_100/// Set the [`isoyear_mod_100`](Parsed::isoyear_mod_100) field, that is part of an/// If this field is set while the [`isoyear_div_100`](Parsed::isoyear_div_100) field is missing/// (and the full [`isoyear`](Parsed::isoyear) field is also not set), it assumes a default/// value for the [`isoyear_div_100`](Parsed::isoyear_div_100) field.set_quarter/// Set the [`quarter`](Parsed::quarter) field to the given value./// Quarter 1 starts in January./// Returns `OUT_OF_RANGE` if `value` is not in the range 1-4.set_month/// Set the [`month`](Parsed::month) field to the given value./// Returns `OUT_OF_RANGE` if `value` is not in the range 1-12.set_week_from_sun/// Set the [`week_from_sun`](Parsed::week_from_sun) week number field to the given value./// Week 1 starts at the first Sunday of January./// Returns `OUT_OF_RANGE` if `value` is not in the range 0-53.set_week_from_mon/// Set the [`week_from_mon`](Parsed::week_from_mon) week number field to the given value./// Set the 'week number starting with Monday' field to the given value./// Week 1 starts at the first Monday of January.set_isoweek/// Set the [`isoweek`](Parsed::isoweek) field for an [ISO 8601 week date] to the given value./// Returns `OUT_OF_RANGE` if `value` is not in the range 1-53.set_weekday/// Set the [`weekday`](Parsed::weekday) field to the given value.set_ordinal/// Set the [`ordinal`](Parsed::ordinal) (day of the year) field to the given value./// Returns `OUT_OF_RANGE` if `value` is not in the range 1-366.set_day/// Set the [`day`](Parsed::day) of the month field to the given value./// Returns `OUT_OF_RANGE` if `value` is not in the range 1-31.set_ampm/// Set the [`hour_div_12`](Parsed::hour_div_12) am/pm field to the given value./// `false` indicates AM and `true` indicates PM.set_hour12/// Set the [`hour_mod_12`](Parsed::hour_mod_12) field, for the hour number in 12-hour clocks,/// to the given value./// Value must be in the canonical range of 1-12./// It will internally be stored as 0-11 (`value % 12`).set_hour/// Set the [`hour_div_12`](Parsed::hour_div_12) and [`hour_mod_12`](Parsed::hour_mod_12)/// fields to the given value for a 24-hour clock./// May return `OUT_OF_RANGE` if `value` is not in the range 0-23./// Currently only checks the value is not out of range for a `u32`./// Returns `IMPOSSIBLE` one of the fields was already set to a different value.set_minute/// Set the [`minute`](Parsed::minute) field to the given value./// Returns `OUT_OF_RANGE` if `value` is not in the range 0-59.set_second/// Set the [`second`](Parsed::second) field to the given value./// The value can be 60 in the case of a leap second./// Returns `OUT_OF_RANGE` if `value` is not in the range 0-60.set_nanosecond/// Set the [`nanosecond`](Parsed::nanosecond) field to the given value./// This is the number of nanoseconds since the whole second./// Returns `OUT_OF_RANGE` if `value` is not in the range 0-999,999,999.set_timestamp/// Set the [`timestamp`](Parsed::timestamp) field to the given value./// A Unix timestamp is defined as the number of non-leap seconds since midnight UTC on/// January 1, 1970./// Set the [`offset`](Parsed::offset) field to the given value./// The offset is in seconds from local time to UTC.to_naive_date/// Returns a parsed naive date out of given fields./// This method is able to determine the date from given subset of fields:/// - Year, month, day./// - Year, day of the year (ordinal)./// - Year, week number counted from Sunday or Monday, day of the week./// - ISO week date./// Gregorian year and ISO week date year can have their century number (`*_div_100`) omitted,/// the two-digit year is used to guess the century number then./// It checks all given date fields are consistent with each other./// This method returns:/// - `IMPOSSIBLE` if any of the date fields conflict./// - `NOT_ENOUGH` if there are not enough fields set in `Parsed` for a complete date./// - `OUT_OF_RANGE`///   - if any of the date fields of `Parsed` are set to a value beyond their acceptable range.///   - if the value would be outside the range of a [`NaiveDate`].///   - if the date does not exist.to_naive_time/// Returns a parsed naive time out of given fields./// This method is able to determine the time from given subset of fields:/// - Hour, minute. (second and nanosecond assumed to be 0)/// - Hour, minute, second. (nanosecond assumed to be 0)/// - Hour, minute, second, nanosecond./// It is able to handle leap seconds when given second is 60./// - `OUT_OF_RANGE` if any of the time fields of `Parsed` are set to a value beyond///   their acceptable range./// - `NOT_ENOUGH` if an hour field is missing, if AM/PM is missing in a 12-hour clock,///   if minutes are missing, or if seconds are missing while the nanosecond field is present.to_naive_datetime_with_offset/// Returns a parsed naive date and time out of given fields, except for the offset field./// The offset is assumed to have a given value. It is not compared against the offset field set/// in the `Parsed` type, so it is allowed to be inconsistent./// This method is able to determine the combined date and time from date and time fields or/// from a single timestamp field. It checks all fields are consistent with each other./// - `IMPOSSIBLE`  if any of the date fields conflict, or if a timestamp conflicts with any of///   the other fields./// - `NOT_ENOUGH` if there are not enough fields set in `Parsed` for a complete datetime.///   - if any of the date or time fields of `Parsed` are set to a value beyond their acceptable///     range.///   - if the value would be outside the range of a [`NaiveDateTime`].to_fixed_offset/// Returns a parsed fixed time zone offset out of given fields./// - `OUT_OF_RANGE` if the offset is out of range for a `FixedOffset`./// - `NOT_ENOUGH` if the offset field is not set.to_datetime/// Returns a parsed timezone-aware date and time out of given fields./// This method is able to determine the combined date and time from date, time and offset/// fields, and/or from a single timestamp field. It checks all fields are consistent with each/// other./// - `NOT_ENOUGH` if there are not enough fields set in `Parsed` for a complete datetime///   including offset from UTC.///   - if any of the fields of `Parsed` are set to a value beyond their acceptable///   - if the value would be outside the range of a [`NaiveDateTime`] or [`FixedOffset`].to_datetime_with_timezone/// Returns a parsed timezone-aware date and time out of given fields,/// with an additional [`TimeZone`] used to interpret and validate the local date./// This method is able to determine the combined date and time from date and time, and/or from/// a single timestamp field. It checks all fields are consistent with each other./// If the parsed fields include an UTC offset, it also has to be consistent with the offset in/// the provided `tz` time zone for that datetime./// - `IMPOSSIBLE`///   - if any of the date fields conflict, if a timestamp conflicts with any of the other///     fields, or if the offset field is set but differs from the offset at that time in the///     `tz` time zone.///   - if the local datetime does not exists in the provided time zone (because it falls in a///     transition due to for example DST)./// - `NOT_ENOUGH` if there are not enough fields set in `Parsed` for a complete datetime, or if///   the local time in the provided time zone is ambiguous (because it falls in a transition///   due to for example DST) while there is no offset field or timestamp field set.///   - if any of the fields of `Parsed` are set to a value beyond their acceptable range./// Get the `year` field if set./// See also [`set_year()`](Parsed::set_year)./// Get the `year_div_100` field if set./// See also [`set_year_div_100()`](Parsed::set_year_div_100)./// Get the `year_mod_100` field if set./// See also [`set_year_mod_100()`](Parsed::set_year_mod_100)./// Get the `isoyear` field that is part of an [ISO 8601 week date] if set./// See also [`set_isoyear()`](Parsed::set_isoyear)./// Get the `isoyear_div_100` field that is part of an [ISO 8601 week date] if set./// See also [`set_isoyear_div_100()`](Parsed::set_isoyear_div_100)./// Get the `isoyear_mod_100` field that is part of an [ISO 8601 week date] if set./// See also [`set_isoyear_mod_100()`](Parsed::set_isoyear_mod_100)./// Get the `quarter` field if set./// See also [`set_quarter()`](Parsed::set_quarter)./// Get the `month` field if set./// See also [`set_month()`](Parsed::set_month)./// Get the `week_from_sun` field if set./// See also [`set_week_from_sun()`](Parsed::set_week_from_sun)./// Get the `week_from_mon` field if set./// See also [`set_week_from_mon()`](Parsed::set_week_from_mon)./// Get the `isoweek` field that is part of an [ISO 8601 week date] if set./// See also [`set_isoweek()`](Parsed::set_isoweek)./// Get the `weekday` field if set./// See also [`set_weekday()`](Parsed::set_weekday)./// Get the `ordinal` (day of the year) field if set./// See also [`set_ordinal()`](Parsed::set_ordinal)./// Get the `day` of the month field if set./// See also [`set_day()`](Parsed::set_day)./// Get the `hour_div_12` field (am/pm) if set./// 0 indicates AM and 1 indicates PM./// See also [`set_ampm()`](Parsed::set_ampm) and [`set_hour()`](Parsed::set_hour)./// Get the `hour_mod_12` field if set./// See also [`set_hour12()`](Parsed::set_hour12) and [`set_hour()`](Parsed::set_hour)./// Get the `minute` field if set./// See also [`set_minute()`](Parsed::set_minute)./// Get the `second` field if set./// See also [`set_second()`](Parsed::set_second)./// Get the `nanosecond` field if set./// See also [`set_nanosecond()`](Parsed::set_nanosecond)./// Get the `timestamp` field if set./// See also [`set_timestamp()`](Parsed::set_timestamp)./// Get the `offset` field if set./// See also [`set_offset()`](Parsed::set_offset).resolve_week_date/// Create a `NaiveDate` when given a year, week, weekday, and the definition at which day of the/// week a week starts./// Returns `IMPOSSIBLE` if `week` is `0` or `53` and the `weekday` falls outside the year.test_parsed_set_fieldstest_parsed_set_rangetest_parsed_to_naive_datetest_parsed_to_naive_timetest_parsed_to_naive_datetime_with_offsettest_parsed_to_datetimetest_parsed_to_datetime_with_timezoneissue_551//! A collection of parsed date and time items.//! They can be constructed incrementally while being checked for consistency./// Tries to parse the non-negative number from `min` to `max` digits./// The absence of digits at all is an unconditional error./// More than `max` digits are consumed up to the first `max` digits./// Any number that does not fit in `i64` is an error./// Tries to consume at least one digits as a fractional second./// Returns the number of whole nanoseconds (0--999,999,999).nanosecond_fixed/// Tries to consume a fixed number of digits as a fractional second.short_month0/// Tries to parse the month index (0 through 11) with the first three ASCII letters.short_weekday/// Tries to parse the weekday with the first three ASCII letters.short_or_long_month0/// Tries to parse the month index (0 through 11) with short or long month names./// It prefers long month names to short month names when both are possible.short_or_long_weekday/// Tries to parse the weekday with short or long weekday names./// It prefers long weekday names to short weekday names when both are possible./// Tries to consume exactly one given character./// Tries to consume one or more whitespace.colon_or_space/// Consumes any number (including zero) of colon or spaces.timezone_offset/// Parse a timezone from `s` and return the offset in seconds./// The `consume_colon` function is used to parse a mandatory or optional `:`/// separator between hours offset and minutes offset./// The `allow_missing_minutes` flag allows the timezone minutes offset to be/// missing from `s`./// The `allow_tz_minus_sign` flag allows the timezone offset negative character/// to also be `−` MINUS SIGN (U+2212) in addition to the typical/// ASCII-compatible `-` HYPHEN-MINUS (U+2D)./// This is part of [RFC 3339 & ISO 8601]./// [RFC 3339 & ISO 8601]: https://en.wikipedia.org/w/index.php?title=ISO_8601&oldid=1114309368#Time_offsets_from_UTCtimezone_offset_2822/// Same as `timezone_offset` but also allows for RFC 2822 legacy timezones./// May return `None` which indicates an insufficient offset data (i.e. `-0000`)./// See [RFC 2822 Section 4.3]./// [RFC 2822 Section 4.3]: https://tools.ietf.org/html/rfc2822#section-4.3comment_2822/// Tries to consume an RFC2822 comment including preceding ` `./// Returns the remaining string after the closing parenthesis.CommentStateStartNextEscapetest_rfc2822_commentstest_timezone_offset_2822test_short_or_long_month0test_short_or_long_weekdaytest_nanosecond_fixedtest_nanosecond/*!
 * Various scanning routines for the parser.
 */remainder/// Remaining portion of the string.queue/// If the current specifier is composed of multiple formatting items (e.g. `%+`),/// `queue` stores a slice of `Item`s that have to be returned one by one.lenient/// Parsing iterator for `strftime`-like format strings./// See the [`format::strftime` module](crate::format::strftime) for supported formatting/// specifiers./// `StrftimeItems` is used in combination with more low-level methods such as [`format::parse()`]/// or [`format_with_items`]./// If formatting or parsing date and time values is not performance-critical, the methods/// [`parse_from_str`] and [`format`] on types such as [`DateTime`](crate::DateTime) are easier to/// use./// [`format`]: crate::DateTime::format/// [`format_with_items`]: crate::DateTime::format/// [`parse_from_str`]: crate::DateTime::parse_from_str/// [`DateTime`]: crate::DateTime/// Creates a new parsing iterator from a `strftime`-like format string./// While iterating [`Item::Error`] will be returned if the format string contains an invalid/// or unrecognized formatting specifier./// use chrono::format::*;/// let strftime_parser = StrftimeItems::new("%F"); // %F: year-month-day (ISO 8601)/// const ISO8601_YMD_ITEMS: &[Item<'static>] = &[///     Item::Numeric(Numeric::Year, Pad::Zero),///     Item::Literal("-"),///     Item::Numeric(Numeric::Month, Pad::Zero),///     Item::Numeric(Numeric::Day, Pad::Zero),/// assert!(strftime_parser.eq(ISO8601_YMD_ITEMS.iter().cloned()));new_lenient/// The same as [`StrftimeItems::new`], but returns [`Item::Literal`] instead of [`Item::Error`]./// Useful for formatting according to potentially invalid format strings./// let strftime_parser = StrftimeItems::new_lenient("%Y-%Q"); // %Y: year, %Q: invalid/// const ITEMS: &[Item<'static>] = &[///     Item::Literal("%"),///     Item::Literal("Q"),/// println!("{:?}", strftime_parser.clone().collect::<Vec<_>>());/// assert!(strftime_parser.eq(ITEMS.iter().cloned()));/// Parse format string into a `Vec` of formatting [`Item`]'s./// If you need to format or parse multiple values with the same format string, it is more/// efficient to convert it to a `Vec` of formatting [`Item`]'s than to re-parse the format/// string on every use./// The `format_with_items` methods on [`DateTime`], [`NaiveDateTime`], [`NaiveDate`] and/// [`NaiveTime`] accept the result for formatting. [`format::parse()`] can make use of it for/// parsing./// [`DateTime`]: crate::DateTime::format_with_items/// [`NaiveDateTime`]: crate::NaiveDateTime::format_with_items/// [`NaiveDate`]: crate::NaiveDate::format_with_items/// [`NaiveTime`]: crate::NaiveTime::format_with_items/// Returns an error if the format string contains an invalid or unrecognized formatting/// specifier and the [`StrftimeItems`] wasn't constructed with [`new_lenient`][Self::new_lenient]./// use chrono::format::{parse, Parsed, StrftimeItems};/// use chrono::NaiveDate;/// let fmt_items = StrftimeItems::new("%e %b %Y %k.%M").parse()?;/// let datetime = NaiveDate::from_ymd_opt(2023, 7, 11).unwrap().and_hms_opt(9, 0, 0).unwrap();/// // Formatting///     datetime.format_with_items(fmt_items.as_slice().iter()).to_string(),///     "11 Jul 2023  9.00"/// // Parsing/// parse(&mut parsed, "11 Jul 2023  9.00", fmt_items.as_slice().iter())?;/// let parsed_dt = parsed.to_naive_datetime_with_offset(0)?;/// assert_eq!(parsed_dt, datetime);parse_to_owned/// Parse format string into a `Vec` of [`Item`]'s that contain no references to slices of the/// format string./// A `Vec` created with [`StrftimeItems::parse`] contains references to the format string,/// binding the lifetime of the `Vec` to that string. [`StrftimeItems::parse_to_owned`] will/// convert the references to owned types./// use chrono::format::{Item, ParseError, StrftimeItems};/// fn format_items(date_fmt: &str, time_fmt: &str) -> Result<Vec<Item<'static>>, ParseError> {///     // `fmt_string` is dropped at the end of this function.///     let fmt_string = format!("{} {}", date_fmt, time_fmt);///     StrftimeItems::new(&fmt_string).parse_to_owned()/// let fmt_items = format_items("%e %b %Y", "%k.%M")?;/// # Ok::<(), ParseError>(())HAVE_ALTERNATESparse_next_itemtest_strftime_itemstest_strftime_docstest_parse_only_timezone_offset_permissive_no_panic/// Ensure parsing a timestamp with the parse-only stftime formatter "%#z" does/// not cause a panic./// See <https://github.com/chronotope/chrono/issues/1139>.test_strftime_parsetest_strftime_parse_lenient/*!
`strftime`/`strptime`-inspired date and time formatting syntax.

## Specifiers

The following specifiers are available both to formatting and parsing.

| Spec. | Example  | Description                                                                |
|-------|----------|----------------------------------------------------------------------------|
|       |          | **DATE SPECIFIERS:**                                                       |
| `%Y`  | `2001`   | The full proleptic Gregorian year, zero-padded to 4 digits. chrono supports years from -262144 to 262143. Note: years before 1 BCE or after 9999 CE, require an initial sign (+/-).|
| `%C`  | `20`     | The proleptic Gregorian year divided by 100, zero-padded to 2 digits. [^1] |
| `%y`  | `01`     | The proleptic Gregorian year modulo 100, zero-padded to 2 digits. [^1]     |
|       |          |                                                                            |
| `%q`  | `1`      | Quarter of year (1-4)                                                      |
| `%m`  | `07`     | Month number (01--12), zero-padded to 2 digits.                            |
| `%b`  | `Jul`    | Abbreviated month name. Always 3 letters.                                  |
| `%B`  | `July`   | Full month name. Also accepts corresponding abbreviation in parsing.       |
| `%h`  | `Jul`    | Same as `%b`.                                                              |
|       |          |                                                                            |
| `%d`  | `08`     | Day number (01--31), zero-padded to 2 digits.                              |
| `%e`  | ` 8`     | Same as `%d` but space-padded. Same as `%_d`.                              |
|       |          |                                                                            |
| `%a`  | `Sun`    | Abbreviated weekday name. Always 3 letters.                                |
| `%A`  | `Sunday` | Full weekday name. Also accepts corresponding abbreviation in parsing.     |
| `%w`  | `0`      | Sunday = 0, Monday = 1, ..., Saturday = 6.                                 |
| `%u`  | `7`      | Monday = 1, Tuesday = 2, ..., Sunday = 7. (ISO 8601)                       |
|       |          |                                                                            |
| `%U`  | `28`     | Week number starting with Sunday (00--53), zero-padded to 2 digits. [^2]   |
| `%W`  | `27`     | Same as `%U`, but week 1 starts with the first Monday in that year instead.|
|       |          |                                                                            |
| `%G`  | `2001`   | Same as `%Y` but uses the year number in ISO 8601 week date. [^3]          |
| `%g`  | `01`     | Same as `%y` but uses the year number in ISO 8601 week date. [^3]          |
| `%V`  | `27`     | Same as `%U` but uses the week number in ISO 8601 week date (01--53). [^3] |
|       |          |                                                                            |
| `%j`  | `189`    | Day of the year (001--366), zero-padded to 3 digits.                       |
|       |          |                                                                            |
| `%D`  | `07/08/01`    | Month-day-year format. Same as `%m/%d/%y`.                            |
| `%x`  | `07/08/01`    | Locale's date representation (e.g., 12/31/99).                        |
| `%F`  | `2001-07-08`  | Year-month-day format (ISO 8601). Same as `%Y-%m-%d`.                 |
| `%v`  | ` 8-Jul-2001` | Day-month-year format. Same as `%e-%b-%Y`.                            |
|       |          |                                                                            |
|       |          | **TIME SPECIFIERS:**                                                       |
| `%H`  | `00`     | Hour number (00--23), zero-padded to 2 digits.                             |
| `%k`  | ` 0`     | Same as `%H` but space-padded. Same as `%_H`.                              |
| `%I`  | `12`     | Hour number in 12-hour clocks (01--12), zero-padded to 2 digits.           |
| `%l`  | `12`     | Same as `%I` but space-padded. Same as `%_I`.                              |
|       |          |                                                                            |
| `%P`  | `am`     | `am` or `pm` in 12-hour clocks.                                            |
| `%p`  | `AM`     | `AM` or `PM` in 12-hour clocks.                                            |
|       |          |                                                                            |
| `%M`  | `34`     | Minute number (00--59), zero-padded to 2 digits.                           |
| `%S`  | `60`     | Second number (00--60), zero-padded to 2 digits. [^4]                      |
| `%f`  | `26490000`    | Number of nanoseconds since last whole second. [^7]                   |
| `%.f` | `.026490`| Decimal fraction of a second. Consumes the leading dot. [^7]               |
| `%.3f`| `.026`        | Decimal fraction of a second with a fixed length of 3.                |
| `%.6f`| `.026490`     | Decimal fraction of a second with a fixed length of 6.                |
| `%.9f`| `.026490000`  | Decimal fraction of a second with a fixed length of 9.                |
| `%3f` | `026`         | Decimal fraction of a second like `%.3f` but without the leading dot. |
| `%6f` | `026490`      | Decimal fraction of a second like `%.6f` but without the leading dot. |
| `%9f` | `026490000`   | Decimal fraction of a second like `%.9f` but without the leading dot. |
|       |               |                                                                       |
| `%R`  | `00:34`       | Hour-minute format. Same as `%H:%M`.                                  |
| `%T`  | `00:34:60`    | Hour-minute-second format. Same as `%H:%M:%S`.                        |
| `%X`  | `00:34:60`    | Locale's time representation (e.g., 23:13:48).                        |
| `%r`  | `12:34:60 AM` | Locale's 12 hour clock time. (e.g., 11:11:04 PM). Falls back to `%X` if the locale does not have a 12 hour clock format. |
|       |          |                                                                            |
|       |          | **TIME ZONE SPECIFIERS:**                                                  |
| `%Z`  | `ACST`   | Local time zone name. Skips all non-whitespace characters during parsing. Identical to `%:z` when formatting. [^8] |
| `%z`  | `+0930`  | Offset from the local time to UTC (with UTC being `+0000`).                |
| `%:z` | `+09:30` | Same as `%z` but with a colon.                                             |
|`%::z`|`+09:30:00`| Offset from the local time to UTC with seconds.                            |
|`%:::z`| `+09`    | Offset from the local time to UTC without minutes.                         |
| `%#z` | `+09`    | *Parsing only:* Same as `%z` but allows minutes to be missing or present.  |
|       |          |                                                                            |
|       |          | **DATE & TIME SPECIFIERS:**                                                |
|`%c`|`Sun Jul  8 00:34:60 2001`|Locale's date and time (e.g., Thu Mar  3 23:05:25 2005).       |
| `%+`  | `2001-07-08T00:34:60.026490+09:30` | ISO 8601 / RFC 3339 date & time format. [^5]     |
|       |               |                                                                       |
| `%s`  | `994518299`   | UNIX timestamp, the number of seconds since 1970-01-01 00:00 UTC. [^6]|
|       |          |                                                                            |
|       |          | **SPECIAL SPECIFIERS:**                                                    |
| `%t`  |          | Literal tab (`\t`).                                                        |
| `%n`  |          | Literal newline (`\n`).                                                    |
| `%%`  |          | Literal percent sign.                                                      |

It is possible to override the default padding behavior of numeric specifiers `%?`.
This is not allowed for other specifiers and will result in the `BAD_FORMAT` error.

Modifier | Description
-------- | -----------
`%-?`    | Suppresses any padding including spaces and zeroes. (e.g. `%j` = `012`, `%-j` = `12`)
`%_?`    | Uses spaces as a padding. (e.g. `%j` = `012`, `%_j` = ` 12`)
`%0?`    | Uses zeroes as a padding. (e.g. `%e` = ` 9`, `%0e` = `09`)

Notes:

[^1]: `%C`, `%y`:
   This is floor division, so 100 BCE (year number -99) will print `-1` and `99` respectively.
   For `%y`, values greater or equal to 70 are interpreted as being in the 20th century,
   values smaller than 70 in the 21st century.

[^2]: `%U`:
   Week 1 starts with the first Sunday in that year.
   It is possible to have week 0 for days before the first Sunday.

[^3]: `%G`, `%g`, `%V`:
   Week 1 is the first week with at least 4 days in that year.
   Week 0 does not exist, so this should be used with `%G` or `%g`.

[^4]: `%S`:
   It accounts for leap seconds, so `60` is possible.

[^5]: `%+`: Same as `%Y-%m-%dT%H:%M:%S%.f%:z`, i.e. 0, 3, 6 or 9 fractional
   digits for seconds and colons in the time zone offset.
   <br>
   <br>
   This format also supports having a `Z` or `UTC` in place of `%:z`. They
   are equivalent to `+00:00`.
   <br>
   <br>
   Note that all `T`, `Z`, and `UTC` are parsed case-insensitively.
   <br>
   <br>
   The typical `strftime` implementations have different (and locale-dependent)
   formats for this specifier. While Chrono's format for `%+` is far more
   stable, it is best to avoid this specifier if you want to control the exact
   output.

[^6]: `%s`:
   This is not padded and can be negative.
   For the purpose of Chrono, it only accounts for non-leap seconds
   so it slightly differs from ISO C `strftime` behavior.

[^7]: `%f`, `%.f`:
   <br>
   `%f` and `%.f` are notably different formatting specifiers.<br>
   `%f` counts the number of nanoseconds since the last whole second, while `%.f` is a fraction of a
   second.<br>
   Example: 7μs is formatted as `7000` with `%f`, and formatted as `.000007` with `%.f`.

[^8]: `%Z`:
   Since `chrono` is not aware of timezones beyond their offsets, this specifier
   **only prints the offset** when used for formatting. The timezone abbreviation
   will NOT be printed. See [this issue](https://github.com/chronotope/chrono/issues/960)
   for more information.
   <br>
   <br>
   Offset will not be populated from the parsed data, nor will it be validated.
   Timezone is completely ignored. Similar to the glibc `strptime` treatment of
   this format code.
   <br>
   <br>
   It is not possible to reliably convert from an abbreviation to an offset,
   for example CDT can mean either Central Daylight Time (North America) or
   China Daylight Time.
*/time_delta/// Alias of [`TimeDelta`].SubsecRound/// A convenience module appropriate for glob imports (`use chrono::prelude::*;`).NaiveWeekDurationRoundRoundingErrorweekday_setWeekdaySet_private/// Out of range error type used in various converting APIs/// Workaround because `?` is not (yet) available in const context./// Workaround because `.expect()` is not (yet) available in const context.//! # Chrono: Date and Time for Rust//! Chrono aims to provide all functionality needed to do correct operations on dates and times in//! the [proleptic Gregorian calendar]://! * The [`DateTime`] type is timezone-aware by default, with separate timezone-naive types.//! * Operations that may produce an invalid or ambiguous date and time return `Option` or//!   [`MappedLocalTime`].//! * Configurable parsing and formatting with a `strftime` inspired date and time formatting//!   syntax.//! * The [`Local`] timezone works with the current timezone of the OS.//! * Types and operations are implemented to be reasonably efficient.//! Timezone data is not shipped with chrono by default to limit binary sizes. Use the companion//! crate [Chrono-TZ] or [`tzfile`] for full timezone support.//! [proleptic Gregorian calendar]: https://en.wikipedia.org/wiki/Proleptic_Gregorian_calendar//! [Chrono-TZ]: https://crates.io/crates/chrono-tz//! [`tzfile`]: https://crates.io/crates/tzfile//! ### Features//! Chrono supports various runtime environments and operating systems, and has several features//! that may be enabled or disabled.//! Default features://! - `alloc`: Enable features that depend on allocation (primarily string formatting).//! - `std`: Enables functionality that depends on the standard library. This is a superset of//!   `alloc` and adds interoperation with standard library types and traits.//! - `clock`: Enables reading the local timezone (`Local`). This is a superset of `now`.//! - `now`: Enables reading the system time (`now`).//! - `wasmbind`: Interface with the JS Date API for the `wasm32` target.//! Optional features://! - `serde`: Enable serialization/deserialization via [serde].//! - `rkyv`: Deprecated, use the `rkyv-*` features.//! - `rkyv-16`: Enable serialization/deserialization via [rkyv],//!   using 16-bit integers for integral `*size` types.//! - `rkyv-32`: Enable serialization/deserialization via [rkyv],//!   using 32-bit integers for integral `*size` types.//! - `rkyv-64`: Enable serialization/deserialization via [rkyv],//!   using 64-bit integers for integral `*size` types.//! - `rkyv-validation`: Enable rkyv validation support using `bytecheck`.//! - `arbitrary`: Construct arbitrary instances of a type with the Arbitrary crate.//! - `unstable-locales`: Enable localization. This adds various methods with a `_localized` suffix.//!   The implementation and API may change or even be removed in a patch release. Feedback welcome.//! - `oldtime`: This feature no longer has any effect; it used to offer compatibility with the//!   `time` 0.1 crate.//! Note: The `rkyv{,-16,-32,-64}` features are mutually exclusive.//! See the [cargo docs] for examples of specifying features.//! [serde]: https://github.com/serde-rs/serde//! [rkyv]: https://github.com/rkyv/rkyv//! [cargo docs]: https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#choosing-features//! ## Overview//! ### Time delta / Duration//! Chrono has a [`TimeDelta`] type to represent the magnitude of a time span. This is an "accurate"//! duration represented as seconds and nanoseconds, and does not represent "nominal" components//! such as days or months.//! The [`TimeDelta`] type was previously named `Duration` (and is still available as a type alias//! with that name). A notable difference with the similar [`core::time::Duration`] is that it is a//! signed value instead of unsigned.//! Chrono currently only supports a small number of operations with [`core::time::Duration`].//! You can convert between both types with the [`TimeDelta::from_std`] and [`TimeDelta::to_std`]//! methods.//! ### Date and Time//! Chrono provides a [`DateTime`] type to represent a date and a time in a timezone.//! For more abstract moment-in-time tracking such as internal timekeeping that is unconcerned with//! timezones, consider [`std::time::SystemTime`], which tracks your system clock, or//! [`std::time::Instant`], which is an opaque but monotonically-increasing representation of a//! moment in time.//! [`DateTime`] is timezone-aware and must be constructed from a [`TimeZone`] object, which defines//! how the local date is converted to and back from the UTC date.//! There are three well-known [`TimeZone`] implementations://! * [`Utc`] specifies the UTC time zone. It is most efficient.//! * [`Local`] specifies the system local time zone.//! * [`FixedOffset`] specifies an arbitrary, fixed time zone such as UTC+09:00 or UTC-10:30.//!   This often results from the parsed textual date and time. Since it stores the most information//!   and does not depend on the system environment, you would want to normalize other `TimeZone`s//!   into this type.//! [`DateTime`]s with different [`TimeZone`] types are distinct and do not mix, but can be//! converted to each other using the [`DateTime::with_timezone`] method.//! You can get the current date and time in the UTC time zone ([`Utc::now()`]) or in the local time//! zone ([`Local::now()`]).//! # #[cfg(feature = "now")] {//! use chrono::prelude::*;//! let utc: DateTime<Utc> = Utc::now(); // e.g. `2014-11-28T12:45:59.324310806Z`//! # let _ = utc;//! # #[cfg(feature = "clock")] {//! let local: DateTime<Local> = Local::now(); // e.g. `2014-11-28T21:45:59.324310806+09:00`//! # let _ = local;//! Alternatively, you can create your own date and time. This is a bit verbose due to Rust's lack//! of function and method overloading, but in turn we get a rich combination of initialization//! use chrono::offset::MappedLocalTime;//! # fn doctest() -> Option<()> {//! let dt = Utc.with_ymd_and_hms(2014, 7, 8, 9, 10, 11).unwrap(); // `2014-07-08T09:10:11Z`//! assert_eq!(//!     dt,//!     NaiveDate::from_ymd_opt(2014, 7, 8)?//!         .and_hms_opt(9, 10, 11)?//!         .and_utc()//! );//! // July 8 is 188th day of the year 2014 (`o` for "ordinal")//! assert_eq!(dt, NaiveDate::from_yo_opt(2014, 189)?.and_hms_opt(9, 10, 11)?.and_utc());//! // July 8 is Tuesday in ISO week 28 of the year 2014.//!     NaiveDate::from_isoywd_opt(2014, 28, Weekday::Tue)?.and_hms_opt(9, 10, 11)?.and_utc()//! let dt = NaiveDate::from_ymd_opt(2014, 7, 8)?//!     .and_hms_milli_opt(9, 10, 11, 12)?//!     .and_utc(); // `2014-07-08T09:10:11.012Z`//!         .and_hms_micro_opt(9, 10, 11, 12_000)?//!         .and_hms_nano_opt(9, 10, 11, 12_000_000)?//! // dynamic verification//!     Utc.with_ymd_and_hms(2014, 7, 8, 21, 15, 33),//!     MappedLocalTime::Single(//!         NaiveDate::from_ymd_opt(2014, 7, 8)?.and_hms_opt(21, 15, 33)?.and_utc()//!     )//! assert_eq!(Utc.with_ymd_and_hms(2014, 7, 8, 80, 15, 33), MappedLocalTime::None);//! assert_eq!(Utc.with_ymd_and_hms(2014, 7, 38, 21, 15, 33), MappedLocalTime::None);//! // other time zone objects can be used to construct a local datetime.//! // obviously, `local_dt` is normally different from `dt`, but `fixed_dt` should be identical.//! let local_dt = Local//!     .from_local_datetime(//!         &NaiveDate::from_ymd_opt(2014, 7, 8).unwrap().and_hms_milli_opt(9, 10, 11, 12).unwrap(),//! let fixed_dt = FixedOffset::east_opt(9 * 3600)//!     .unwrap()//!         &NaiveDate::from_ymd_opt(2014, 7, 8)//!             .unwrap()//!             .and_hms_milli_opt(18, 10, 11, 12)//!             .unwrap(),//! assert_eq!(dt, fixed_dt);//! # let _ = local_dt;//! # Some(())//! # doctest().unwrap();//! Various properties are available to the date and time, and can be altered individually. Most of//! them are defined in the traits [`Datelike`] and [`Timelike`] which you should `use` before.//! Addition and subtraction is also supported.//! The following illustrates most supported operations to the date and time://! use chrono::TimeDelta;//! // assume this returned `2014-11-28T21:45:59.324310806+09:00`://! let dt = FixedOffset::east_opt(9 * 3600)//!         &NaiveDate::from_ymd_opt(2014, 11, 28)//!             .and_hms_nano_opt(21, 45, 59, 324310806)//! // property accessors//! assert_eq!((dt.year(), dt.month(), dt.day()), (2014, 11, 28));//! assert_eq!((dt.month0(), dt.day0()), (10, 27)); // for unfortunate souls//! assert_eq!((dt.hour(), dt.minute(), dt.second()), (21, 45, 59));//! assert_eq!(dt.weekday(), Weekday::Fri);//! assert_eq!(dt.weekday().number_from_monday(), 5); // Mon=1, ..., Sun=7//! assert_eq!(dt.ordinal(), 332); // the day of year//! assert_eq!(dt.num_days_from_ce(), 735565); // the number of days from and including Jan 1, 1//! // time zone accessor and manipulation//! assert_eq!(dt.offset().fix().local_minus_utc(), 9 * 3600);//! assert_eq!(dt.timezone(), FixedOffset::east_opt(9 * 3600).unwrap());//!     dt.with_timezone(&Utc),//!     NaiveDate::from_ymd_opt(2014, 11, 28)//!         .unwrap()//!         .and_hms_nano_opt(12, 45, 59, 324310806)//! // a sample of property manipulations (validates dynamically)//! assert_eq!(dt.with_day(29).unwrap().weekday(), Weekday::Sat); // 2014-11-29 is Saturday//! assert_eq!(dt.with_day(32), None);//! assert_eq!(dt.with_year(-300).unwrap().num_days_from_ce(), -109606); // November 29, 301 BCE//! // arithmetic operations//! let dt1 = Utc.with_ymd_and_hms(2014, 11, 14, 8, 9, 10).unwrap();//! let dt2 = Utc.with_ymd_and_hms(2014, 11, 14, 10, 9, 8).unwrap();//! assert_eq!(dt1.signed_duration_since(dt2), TimeDelta::try_seconds(-2 * 3600 + 2).unwrap());//! assert_eq!(dt2.signed_duration_since(dt1), TimeDelta::try_seconds(2 * 3600 - 2).unwrap());//!     Utc.with_ymd_and_hms(1970, 1, 1, 0, 0, 0).unwrap()//!         + TimeDelta::try_seconds(1_000_000_000).unwrap(),//!     Utc.with_ymd_and_hms(2001, 9, 9, 1, 46, 40).unwrap()//!         - TimeDelta::try_seconds(1_000_000_000).unwrap(),//!     Utc.with_ymd_and_hms(1938, 4, 24, 22, 13, 20).unwrap()//! ### Formatting and Parsing//! Formatting is done via the [`format`](DateTime::format()) method, which format is equivalent to//! the familiar `strftime` format.//! See [`format::strftime`](format::strftime#specifiers) documentation for full syntax and list of//! specifiers.//! The default `to_string` method and `{:?}` specifier also give a reasonable representation.//! Chrono also provides [`to_rfc2822`](DateTime::to_rfc2822) and//! [`to_rfc3339`](DateTime::to_rfc3339) methods for well-known formats.//! Chrono now also provides date formatting in almost any language without the help of an//! additional C library. This functionality is under the feature `unstable-locales`://! chrono = { version = "0.4", features = ["unstable-locales"] }//! The `unstable-locales` feature requires and implies at least the `alloc` feature.//! # #[allow(unused_imports)]//! # #[cfg(all(feature = "unstable-locales", feature = "alloc"))]//! # fn test() {//! let dt = Utc.with_ymd_and_hms(2014, 11, 28, 12, 0, 9).unwrap();//! assert_eq!(dt.format("%Y-%m-%d %H:%M:%S").to_string(), "2014-11-28 12:00:09");//! assert_eq!(dt.format("%a %b %e %T %Y").to_string(), "Fri Nov 28 12:00:09 2014");//!     dt.format_localized("%A %e %B %Y, %T", Locale::fr_BE).to_string(),//!     "vendredi 28 novembre 2014, 12:00:09"//! assert_eq!(dt.format("%a %b %e %T %Y").to_string(), dt.format("%c").to_string());//! assert_eq!(dt.to_string(), "2014-11-28 12:00:09 UTC");//! assert_eq!(dt.to_rfc2822(), "Fri, 28 Nov 2014 12:00:09 +0000");//! assert_eq!(dt.to_rfc3339(), "2014-11-28T12:00:09+00:00");//! assert_eq!(format!("{:?}", dt), "2014-11-28T12:00:09Z");//! // Note that milli/nanoseconds are only printed if they are non-zero//! let dt_nano = NaiveDate::from_ymd_opt(2014, 11, 28)//!     .and_hms_nano_opt(12, 0, 9, 1)//!     .and_utc();//! assert_eq!(format!("{:?}", dt_nano), "2014-11-28T12:00:09.000000001Z");//! # #[cfg(not(all(feature = "unstable-locales", feature = "alloc")))]//! # fn test() {}//! # if cfg!(all(feature = "unstable-locales", feature = "alloc")) {//! #    test();//! Parsing can be done with two methods://! 1. The standard [`FromStr`](std::str::FromStr) trait (and [`parse`](str::parse) method on a//!    string) can be used for parsing `DateTime<FixedOffset>`, `DateTime<Utc>` and//!    `DateTime<Local>` values. This parses what the `{:?}` ([`std::fmt::Debug`] format specifier//!    prints, and requires the offset to be present.//! 2. [`DateTime::parse_from_str`] parses a date and time with offsets and returns//!    `DateTime<FixedOffset>`. This should be used when the offset is a part of input and the//!    caller cannot guess that. It *cannot* be used when the offset can be missing.//!    [`DateTime::parse_from_rfc2822`] and [`DateTime::parse_from_rfc3339`] are similar but for//!    well-known formats.//! More detailed control over the parsing process is available via [`format`](mod@format) module.//! let fixed_dt = dt.with_timezone(&FixedOffset::east_opt(9 * 3600).unwrap());//! // method 1//! assert_eq!("2014-11-28T12:00:09Z".parse::<DateTime<Utc>>(), Ok(dt.clone()));//! assert_eq!("2014-11-28T21:00:09+09:00".parse::<DateTime<Utc>>(), Ok(dt.clone()));//! assert_eq!("2014-11-28T21:00:09+09:00".parse::<DateTime<FixedOffset>>(), Ok(fixed_dt.clone()));//! // method 2//!     DateTime::parse_from_str("2014-11-28 21:00:09 +09:00", "%Y-%m-%d %H:%M:%S %z"),//!     Ok(fixed_dt.clone())//!     DateTime::parse_from_rfc2822("Fri, 28 Nov 2014 21:00:09 +0900"),//! assert_eq!(DateTime::parse_from_rfc3339("2014-11-28T21:00:09+09:00"), Ok(fixed_dt.clone()));//! // oops, the year is missing!//! assert!(DateTime::parse_from_str("Fri Nov 28 12:00:09", "%a %b %e %T %Y").is_err());//! // oops, the format string does not include the year at all!//! assert!(DateTime::parse_from_str("Fri Nov 28 12:00:09", "%a %b %e %T").is_err());//! // oops, the weekday is incorrect!//! assert!(DateTime::parse_from_str("Sat Nov 28 12:00:09 2014", "%a %b %e %T %Y").is_err());//! Again: See [`format::strftime`](format::strftime#specifiers) documentation for full syntax and//! list of specifiers.//! ### Conversion from and to EPOCH timestamps//! Use [`DateTime::from_timestamp(seconds, nanoseconds)`](DateTime::from_timestamp)//! to construct a [`DateTime<Utc>`] from a UNIX timestamp//! (seconds, nanoseconds that passed since January 1st 1970).//! Use [`DateTime.timestamp`](DateTime::timestamp) to get the timestamp (in seconds)//! from a [`DateTime`]. Additionally, you can use//! [`DateTime.timestamp_subsec_nanos`](DateTime::timestamp_subsec_nanos)//! to get the number of additional number of nanoseconds.//! // We need the trait in scope to use Utc::timestamp().//! use chrono::{DateTime, Utc};//! // Construct a datetime from epoch://! let dt: DateTime<Utc> = DateTime::from_timestamp(1_500_000_000, 0).unwrap();//! assert_eq!(dt.to_rfc2822(), "Fri, 14 Jul 2017 02:40:00 +0000");//! // Get epoch value from a datetime://! let dt = DateTime::parse_from_rfc2822("Fri, 14 Jul 2017 02:40:00 +0000").unwrap();//! assert_eq!(dt.timestamp(), 1_500_000_000);//! ### Naive date and time//! Chrono provides naive counterparts to `Date`, (non-existent) `Time` and `DateTime` as//! [`NaiveDate`], [`NaiveTime`] and [`NaiveDateTime`] respectively.//! They have almost equivalent interfaces as their timezone-aware twins, but are not associated to//! time zones obviously and can be quite low-level. They are mostly useful for building blocks for//! higher-level types.//! Timezone-aware `DateTime` and `Date` types have two methods returning naive versions://! [`naive_local`](DateTime::naive_local) returns a view to the naive local time,//! and [`naive_utc`](DateTime::naive_utc) returns a view to the naive UTC time.//! ## Limitations//! * Only the proleptic Gregorian calendar (i.e. extended to support older dates) is supported.//! * Date types are limited to about +/- 262,000 years from the common epoch.//! * Time types are limited to nanosecond accuracy.//! * Leap seconds can be represented, but Chrono does not fully support them.//!   See [Leap Second Handling](NaiveTime#leap-second-handling).//! ## Rust version requirements//! The Minimum Supported Rust Version (MSRV) is currently **Rust 1.61.0**.//! The MSRV is explicitly tested in CI. It may be bumped in minor releases, but this is not done//! lightly.//! ## Relation between chrono and time 0.1//! Rust first had a `time` module added to `std` in its 0.7 release. It later moved to//! `libextra`, and then to a `libtime` library shipped alongside the standard library. In 2014//! work on chrono started in order to provide a full-featured date and time library in Rust.//! Some improvements from chrono made it into the standard library; notably, `chrono::Duration`//! was included as `std::time::Duration` ([rust#15934]) in 2014.//! In preparation of Rust 1.0 at the end of 2014 `libtime` was moved out of the Rust distro and//! into the `time` crate to eventually be redesigned ([rust#18832], [rust#18858]), like the//! `num` and `rand` crates. Of course chrono kept its dependency on this `time` crate. `time`//! started re-exporting `std::time::Duration` during this period. Later, the standard library was//! changed to have a more limited unsigned `Duration` type ([rust#24920], [RFC 1040]), while the//! `time` crate kept the full functionality with `time::Duration`. `time::Duration` had been a//! part of chrono's public API.//! By 2016 `time` 0.1 lived under the `rust-lang-deprecated` organisation and was not actively//! maintained ([time#136]). chrono absorbed the platform functionality and `Duration` type of the//! `time` crate in [chrono#478] (the work started in [chrono#286]). In order to preserve//! compatibility with downstream crates depending on `time` and `chrono` sharing a `Duration`//! type, chrono kept depending on time 0.1. chrono offered the option to opt out of the `time`//! dependency by disabling the `oldtime` feature (swapping it out for an effectively similar//! chrono type). In 2019, @jhpratt took over maintenance on the `time` crate and released what//! amounts to a new crate as `time` 0.2.//! [rust#15934]: https://github.com/rust-lang/rust/pull/15934//! [rust#18832]: https://github.com/rust-lang/rust/pull/18832#issuecomment-62448221//! [rust#18858]: https://github.com/rust-lang/rust/pull/18858//! [rust#24920]: https://github.com/rust-lang/rust/pull/24920//! [RFC 1040]: https://rust-lang.github.io/rfcs/1040-duration-reform.html//! [time#136]: https://github.com/time-rs/time/issues/136//! [chrono#286]: https://github.com/chronotope/chrono/pull/286//! [chrono#478]: https://github.com/chronotope/chrono/pull/478//! ## Security advisories//! In November of 2020 [CVE-2020-26235] and [RUSTSEC-2020-0071] were opened against the `time` crate.//! @quininer had found that calls to `localtime_r` may be unsound ([chrono#499]). Eventually, almost//! a year later, this was also made into a security advisory against chrono as [RUSTSEC-2020-0159],//! which had platform code similar to `time`.//! On Unix-like systems a process is given a timezone id or description via the `TZ` environment//! variable. We need this timezone data to calculate the current local time from a value that is//! in UTC, such as the time from the system clock. `time` 0.1 and chrono used the POSIX function//! `localtime_r` to do the conversion to local time, which reads the `TZ` variable.//! Rust assumes the environment to be writable and uses locks to access it from multiple threads.//! Some other programming languages and libraries use similar locking strategies, but these are//! typically not shared across languages. More importantly, POSIX declares modifying the//! environment in a multi-threaded process as unsafe, and `getenv` in libc can't be changed to//! take a lock because it returns a pointer to the data (see [rust#27970] for more discussion).//! Since version 4.20 chrono no longer uses `localtime_r`, instead using Rust code to query the//! timezone (from the `TZ` variable or via `iana-time-zone` as a fallback) and work with data//! from the system timezone database directly. The code for this was forked from the [tz-rs crate]//! by @x-hgg-x. As such, chrono now respects the Rust lock when reading the `TZ` environment//! variable. In general, code should avoid modifying the environment.//! [CVE-2020-26235]: https://nvd.nist.gov/vuln/detail/CVE-2020-26235//! [RUSTSEC-2020-0071]: https://rustsec.org/advisories/RUSTSEC-2020-0071//! [chrono#499]: https://github.com/chronotope/chrono/pull/499//! [RUSTSEC-2020-0159]: https://rustsec.org/advisories/RUSTSEC-2020-0159.html//! [rust#27970]: https://github.com/rust-lang/rust/issues/27970//! [chrono#677]: https://github.com/chronotope/chrono/pull/677//! [tz-rs crate]: https://crates.io/crates/tz-rs//! ## Removing time 0.1//! Because time 0.1 has been unmaintained for years, however, the security advisory mentioned//! above has not been addressed. While chrono maintainers were careful not to break backwards//! compatibility with the `time::Duration` type, there has been a long stream of issues from//! users inquiring about the time 0.1 dependency with the vulnerability. We investigated the//! potential breakage of removing the time 0.1 dependency in [chrono#1095] using a crater-like//! experiment and determined that the potential for breaking (public) dependencies is very low.//! We reached out to those few crates that did still depend on compatibility with time 0.1.//! As such, for chrono 0.4.30 we have decided to swap out the time 0.1 `Duration` implementation//! for a local one that will offer a strict superset of the existing API going forward. This//! will prevent most downstream users from being affected by the security vulnerability in time//! 0.1 while minimizing the ecosystem impact of semver-incompatible version churn.//! [chrono#1095]: https://github.com/chronotope/chrono/pull/1095January/// JanuaryFebruary/// FebruaryMarch/// MarchApril/// AprilMay/// MayJune/// JuneJuly/// JulyAugust/// AugustSeptember/// SeptemberOctober/// OctoberNovember/// NovemberDecember/// December/// The month of the year./// This enum is just a convenience implementation./// The month in dates created by DateLike objects does not return this enum./// It is possible to convert from a date to a month independently/// let date = Utc.with_ymd_and_hms(2019, 10, 28, 9, 10, 11).unwrap();/// // `2019-10-28T09:10:11Z`/// let month = Month::try_from(u8::try_from(date.month()).unwrap()).ok();/// assert_eq!(month, Some(Month::October))/// Or from a Month to an integer usable by dates/// # use chrono::prelude::*;/// let month = Month::January;/// let dt = Utc.with_ymd_and_hms(2019, month.number_from_month(), 28, 9, 10, 11).unwrap();/// assert_eq!((dt.year(), dt.month(), dt.day()), (2019, 1, 28));/// Allows mapping from and to month, from 1-January to 12-December./// Can be Serialized/Deserialized with serde// Actual implementation is zero-indexed, API intended as 1-indexed for more intuitive behavior./// The next month./// `m`:        | `January`  | `February` | `...` | `December`/// ----------- | ---------  | ---------- | --- | ---------/// `m.succ()`: | `February` | `March`    | `...` | `January`/// The previous month./// `m.pred()`: | `December` | `January`  | `...` | `November`number_from_month/// Returns a month-of-year number starting from January = 1./// `m`:                     | `January` | `February` | `...` | `December`/// -------------------------| --------- | ---------- | --- | -----/// `m.number_from_month()`: | 1         | 2          | `...` | 12/// Get the name of the month/// assert_eq!(Month::January.name(), "January")num_days/// Get the length in days of the month/// Yields `None` if `year` is out of range for `NaiveDate`.from_u64/// Returns an `Option<Month>` from a i64, assuming a 1-index, January = 1./// `Month::from_i64(n: i64)`: | `1`                  | `2`                   | ... | `12`/// ---------------------------| -------------------- | --------------------- | ... | -----/// ``:                        | Some(Month::January) | Some(Month::February) | ... | Some(Month::December)from_i64from_u32FromPrimitive/// A duration in calendar months/// Construct a new `Months` from a number of months/// Returns the total number of months in the `Months` instance./// An error resulting from reading `<Month>` value with `FromStr`.test_month_enum_try_fromtest_month_enum_primitive_parsetest_month_enum_succ_predtest_month_partial_ordtest_months_as_u32MdfYearFlagsyof// (year << 13) | of/// ISO 8601 calendar date without timezone./// Allows for every [proleptic Gregorian date] from Jan 1, 262145 BCE to Dec 31, 262143 CE./// Also supports the conversion from ISO 8601 ordinal and week date./// # Calendar Date/// The ISO 8601 **calendar date** follows the proleptic Gregorian calendar./// It is like a normal civil calendar but note some slight differences:/// * Dates before the Gregorian calendar's inception in 1582 are defined via the extrapolation.///   Be careful, as historical dates are often noted in the Julian calendar and others///   and the transition to Gregorian may differ across countries (as late as early 20C).///   (Some example: Both Shakespeare from Britain and Cervantes from Spain seemingly died///   on the same calendar date---April 23, 1616---but in the different calendar.///   Britain used the Julian calendar at that time, so Shakespeare's death is later.)/// * ISO 8601 calendars have the year 0, which is 1 BCE (a year before 1 CE).///   If you need a typical BCE/BC and CE/AD notation for year numbers,///   use the [`Datelike::year_ce`] method./// # Week Date/// The ISO 8601 **week date** is a triple of year number, week number/// and [day of the week](Weekday) with the following rules:/// * A week consists of Monday through Sunday, and is always numbered within some year.///   The week number ranges from 1 to 52 or 53 depending on the year./// * The week 1 of given year is defined as the first week containing January 4 of that year,///   or equivalently, the first week containing four or more days in that year./// * The year number in the week date may *not* correspond to the actual Gregorian year.///   For example, January 3, 2016 (Sunday) was on the last (53rd) week of 2015./// Chrono's date types default to the ISO 8601 [calendar date](#calendar-date), but/// [`Datelike::iso_week`] and [`Datelike::weekday`] methods can be used to get the corresponding/// week date./// # Ordinal Date/// The ISO 8601 **ordinal date** is a pair of year number and day of the year ("ordinal")./// The ordinal number ranges from 1 to 365 or 366 depending on the year./// The year number is the same as that of the [calendar date](#calendar-date)./// This is currently the internal format of Chrono's date types./// [proleptic Gregorian date]: crate::NaiveDate#calendar-date/// The minimum possible `NaiveDate` (January 1, 262145 BCE)./// The maximum possible `NaiveDate` (December 31, 262143 CE).weeks_fromfrom_ordinal_and_flags/// Makes a new `NaiveDate` from year, ordinal and flags./// Does not check whether the flags are correct for the provided year.from_mdf/// Makes a new `NaiveDate` from year and packed month-day-flags.from_ymd/// Makes a new `NaiveDate` from the [calendar date](#calendar-date)/// (year, month and day)./// Panics if the specified calendar day does not exist, on invalid values for `month` or `day`,/// or if `year` is out of range for `NaiveDate`.from_ymd_opt/// - The specified calendar day does not exist (for example 2023-04-31)./// - The value for `month` or `day` is invalid./// - `year` is out of range for `NaiveDate`./// let from_ymd_opt = NaiveDate::from_ymd_opt;/// assert!(from_ymd_opt(2015, 3, 14).is_some());/// assert!(from_ymd_opt(2015, 0, 14).is_none());/// assert!(from_ymd_opt(2015, 2, 29).is_none());/// assert!(from_ymd_opt(-4, 2, 29).is_some()); // 5 BCE is a leap year/// assert!(from_ymd_opt(400000, 1, 1).is_none());/// assert!(from_ymd_opt(-400000, 1, 1).is_none());from_yo/// Makes a new `NaiveDate` from the [ordinal date](#ordinal-date)/// (year and day of the year)./// Panics if the specified ordinal day does not exist, on invalid values for `ordinal`, or if/// `year` is out of range for `NaiveDate`.from_yo_opt/// - The specified ordinal day does not exist (for example 2023-366)./// - The value for `ordinal` is invalid (for example: `0`, `400`)./// let from_yo_opt = NaiveDate::from_yo_opt;/// assert!(from_yo_opt(2015, 100).is_some());/// assert!(from_yo_opt(2015, 0).is_none());/// assert!(from_yo_opt(2015, 365).is_some());/// assert!(from_yo_opt(2015, 366).is_none());/// assert!(from_yo_opt(-4, 366).is_some()); // 5 BCE is a leap year/// assert!(from_yo_opt(400000, 1).is_none());/// assert!(from_yo_opt(-400000, 1).is_none());from_isoywd/// Makes a new `NaiveDate` from the [ISO week date](#week-date)/// (year, week number and day of the week)./// The resulting `NaiveDate` may have a different year from the input year./// Panics if the specified week does not exist in that year, on invalid values for `week`, or/// if the resulting date is out of range for `NaiveDate`.from_isoywd_opt/// - The specified week does not exist in that year (for example 2023 week 53)./// - The value for `week` is invalid (for example: `0`, `60`)./// - If the resulting date is out of range for `NaiveDate`./// use chrono::{NaiveDate, Weekday};/// let from_ymd = |y, m, d| NaiveDate::from_ymd_opt(y, m, d).unwrap();/// let from_isoywd_opt = NaiveDate::from_isoywd_opt;/// assert_eq!(from_isoywd_opt(2015, 0, Weekday::Sun), None);/// assert_eq!(from_isoywd_opt(2015, 10, Weekday::Sun), Some(from_ymd(2015, 3, 8)));/// assert_eq!(from_isoywd_opt(2015, 30, Weekday::Mon), Some(from_ymd(2015, 7, 20)));/// assert_eq!(from_isoywd_opt(2015, 60, Weekday::Mon), None);/// assert_eq!(from_isoywd_opt(400000, 10, Weekday::Fri), None);/// assert_eq!(from_isoywd_opt(-400000, 10, Weekday::Sat), None);/// The year number of ISO week date may differ from that of the calendar date./// # use chrono::{NaiveDate, Weekday};/// # let from_ymd = |y, m, d| NaiveDate::from_ymd_opt(y, m, d).unwrap();/// # let from_isoywd_opt = NaiveDate::from_isoywd_opt;/// //           Mo Tu We Th Fr Sa Su/// // 2014-W52  22 23 24 25 26 27 28    has 4+ days of new year,/// // 2015-W01  29 30 31  1  2  3  4 <- so this is the first week/// assert_eq!(from_isoywd_opt(2014, 52, Weekday::Sun), Some(from_ymd(2014, 12, 28)));/// assert_eq!(from_isoywd_opt(2014, 53, Weekday::Mon), None);/// assert_eq!(from_isoywd_opt(2015, 1, Weekday::Mon), Some(from_ymd(2014, 12, 29)));/// // 2015-W52  21 22 23 24 25 26 27    has 4+ days of old year,/// // 2015-W53  28 29 30 31  1  2  3 <- so this is the last week/// // 2016-W01   4  5  6  7  8  9 10/// assert_eq!(from_isoywd_opt(2015, 52, Weekday::Sun), Some(from_ymd(2015, 12, 27)));/// assert_eq!(from_isoywd_opt(2015, 53, Weekday::Sun), Some(from_ymd(2016, 1, 3)));/// assert_eq!(from_isoywd_opt(2015, 54, Weekday::Mon), None);/// assert_eq!(from_isoywd_opt(2016, 1, Weekday::Mon), Some(from_ymd(2016, 1, 4)));from_num_days_from_ce/// Makes a new `NaiveDate` from a day's number in the proleptic Gregorian calendar, with/// January 1, 1 being day 1./// Panics if the date is out of range.from_num_days_from_ce_opt/// Returns `None` if the date is out of range./// let from_ndays_opt = NaiveDate::from_num_days_from_ce_opt;/// assert_eq!(from_ndays_opt(730_000), Some(from_ymd(1999, 9, 3)));/// assert_eq!(from_ndays_opt(1), Some(from_ymd(1, 1, 1)));/// assert_eq!(from_ndays_opt(0), Some(from_ymd(0, 12, 31)));/// assert_eq!(from_ndays_opt(-1), Some(from_ymd(0, 12, 30)));/// assert_eq!(from_ndays_opt(100_000_000), None);/// assert_eq!(from_ndays_opt(-100_000_000), None);from_weekday_of_month/// Makes a new `NaiveDate` by counting the number of occurrences of a particular day-of-week/// since the beginning of the given month. For instance, if you want the 2nd Friday of March/// 2017, you would use `NaiveDate::from_weekday_of_month(2017, 3, Weekday::Fri, 2)`./// `n` is 1-indexed./// Panics if the specified day does not exist in that month, on invalid values for `month` or/// `n`, or if `year` is out of range for `NaiveDate`.from_weekday_of_month_opt/// - The specified day does not exist in that month (for example the 5th Monday of Apr. 2023)./// - The value for `month` or `n` is invalid.///     NaiveDate::from_weekday_of_month_opt(2017, 3, Weekday::Fri, 2),///     NaiveDate::from_ymd_opt(2017, 3, 10)/// Parses a string with the specified format string and returns a new `NaiveDate`./// See the [`format::strftime` module](crate::format::strftime)/// let parse_from_str = NaiveDate::parse_from_str;///     parse_from_str("2015-09-05", "%Y-%m-%d"),///     Ok(NaiveDate::from_ymd_opt(2015, 9, 5).unwrap())///     parse_from_str("5sep2015", "%d%b%Y"),/// Time and offset is ignored for the purpose of parsing./// # use chrono::NaiveDate;/// # let parse_from_str = NaiveDate::parse_from_str;///     parse_from_str("2014-5-17T12:34:56+09:30", "%Y-%m-%dT%H:%M:%S%z"),///     Ok(NaiveDate::from_ymd_opt(2014, 5, 17).unwrap())/// Out-of-bound dates or insufficient fields are errors./// assert!(parse_from_str("2015/9", "%Y/%m").is_err());/// assert!(parse_from_str("2015/9/31", "%Y/%m/%d").is_err());/// All parsed fields should be consistent to each other, otherwise it's an error./// assert!(parse_from_str("Sat, 09 Aug 2013", "%a, %d %b %Y").is_err());/// Parses a string from a user-specified format into a new `NaiveDate` value, and a slice with/// the remaining portion of the string./// # use chrono::{NaiveDate};/// let (date, remainder) =///     NaiveDate::parse_and_remainder("2015-02-18 trailing text", "%Y-%m-%d").unwrap();/// assert_eq!(date, NaiveDate::from_ymd_opt(2015, 2, 18).unwrap());/// Add a duration in [`Months`] to the date/// # use chrono::{NaiveDate, Months};///     NaiveDate::from_ymd_opt(2022, 2, 20).unwrap().checked_add_months(Months::new(6)),///     Some(NaiveDate::from_ymd_opt(2022, 8, 20).unwrap())///     NaiveDate::from_ymd_opt(2022, 7, 31).unwrap().checked_add_months(Months::new(2)),///     Some(NaiveDate::from_ymd_opt(2022, 9, 30).unwrap())/// Subtract a duration in [`Months`] from the date///     NaiveDate::from_ymd_opt(2022, 2, 20).unwrap().checked_sub_months(Months::new(6)),///     Some(NaiveDate::from_ymd_opt(2021, 8, 20).unwrap())///     NaiveDate::from_ymd_opt(2014, 1, 1)///         .checked_sub_months(Months::new(core::i32::MAX as u32 + 1)),diff_months/// Add a duration in [`Days`] to the date/// # use chrono::{NaiveDate, Days};///     NaiveDate::from_ymd_opt(2022, 2, 20).unwrap().checked_add_days(Days::new(9)),///     Some(NaiveDate::from_ymd_opt(2022, 3, 1).unwrap())///     NaiveDate::from_ymd_opt(2022, 7, 31).unwrap().checked_add_days(Days::new(2)),///     Some(NaiveDate::from_ymd_opt(2022, 8, 2).unwrap())///     NaiveDate::from_ymd_opt(2022, 7, 31).unwrap().checked_add_days(Days::new(1000000000000)),/// Subtract a duration in [`Days`] from the date///     NaiveDate::from_ymd_opt(2022, 2, 20).unwrap().checked_sub_days(Days::new(6)),///     Some(NaiveDate::from_ymd_opt(2022, 2, 14).unwrap())///     NaiveDate::from_ymd_opt(2022, 2, 20).unwrap().checked_sub_days(Days::new(1000000000000)),add_days/// Add a duration of `i32` days to the date./// Makes a new `NaiveDateTime` from the current date and given `NaiveTime`./// use chrono::{NaiveDate, NaiveDateTime, NaiveTime};/// let d = NaiveDate::from_ymd_opt(2015, 6, 3).unwrap();/// let t = NaiveTime::from_hms_milli_opt(12, 34, 56, 789).unwrap();/// let dt: NaiveDateTime = d.and_time(t);/// assert_eq!(dt.date(), d);/// assert_eq!(dt.time(), t);/// Makes a new `NaiveDateTime` from the current date, hour, minute and second./// No [leap second](./struct.NaiveTime.html#leap-second-handling) is allowed here;/// use `NaiveDate::and_hms_*` methods with a subsecond parameter instead./// use `NaiveDate::and_hms_*_opt` methods with a subsecond parameter instead./// assert!(d.and_hms_opt(12, 34, 56).is_some());/// assert!(d.and_hms_opt(12, 34, 60).is_none()); // use `and_hms_milli_opt` instead/// assert!(d.and_hms_opt(12, 60, 56).is_none());/// assert!(d.and_hms_opt(24, 34, 56).is_none());/// Makes a new `NaiveDateTime` from the current date, hour, minute, second and millisecond./// The millisecond part is allowed to exceed 1,000,000,000 in order to represent a [leap second](/// ./struct.NaiveTime.html#leap-second-handling), but only when `sec == 59`./// assert!(d.and_hms_milli_opt(12, 34, 56, 789).is_some());/// assert!(d.and_hms_milli_opt(12, 34, 59, 1_789).is_some()); // leap second/// assert!(d.and_hms_milli_opt(12, 34, 59, 2_789).is_none());/// assert!(d.and_hms_milli_opt(12, 34, 60, 789).is_none());/// assert!(d.and_hms_milli_opt(12, 60, 56, 789).is_none());/// assert!(d.and_hms_milli_opt(24, 34, 56, 789).is_none());/// Makes a new `NaiveDateTime` from the current date, hour, minute, second and microsecond./// The microsecond part is allowed to exceed 1,000,000,000 in order to represent a [leap second](/// use chrono::{Datelike, NaiveDate, NaiveDateTime, Timelike, Weekday};/// let dt: NaiveDateTime = d.and_hms_micro_opt(12, 34, 56, 789_012).unwrap();/// assert_eq!(dt.year(), 2015);/// assert_eq!(dt.weekday(), Weekday::Wed);/// assert_eq!(dt.second(), 56);/// assert_eq!(dt.nanosecond(), 789_012_000);/// The microsecond part is allowed to exceed 1,000,000 in order to represent a [leap second](/// assert!(d.and_hms_micro_opt(12, 34, 56, 789_012).is_some());/// assert!(d.and_hms_micro_opt(12, 34, 59, 1_789_012).is_some()); // leap second/// assert!(d.and_hms_micro_opt(12, 34, 59, 2_789_012).is_none());/// assert!(d.and_hms_micro_opt(12, 34, 60, 789_012).is_none());/// assert!(d.and_hms_micro_opt(12, 60, 56, 789_012).is_none());/// assert!(d.and_hms_micro_opt(24, 34, 56, 789_012).is_none());/// Makes a new `NaiveDateTime` from the current date, hour, minute, second and nanosecond./// The nanosecond part is allowed to exceed 1,000,000,000 in order to represent a [leap second](/// assert!(d.and_hms_nano_opt(12, 34, 56, 789_012_345).is_some());/// assert!(d.and_hms_nano_opt(12, 34, 59, 1_789_012_345).is_some()); // leap second/// assert!(d.and_hms_nano_opt(12, 34, 59, 2_789_012_345).is_none());/// assert!(d.and_hms_nano_opt(12, 34, 60, 789_012_345).is_none());/// assert!(d.and_hms_nano_opt(12, 60, 56, 789_012_345).is_none());/// assert!(d.and_hms_nano_opt(24, 34, 56, 789_012_345).is_none());mdf/// Returns the packed month-day-flags.with_mdf/// Makes a new `NaiveDate` with the packed month-day-flags changed./// Returns `None` when the resulting `NaiveDate` would be invalid./// Makes a new `NaiveDate` for the next calendar date.///     NaiveDate::from_ymd_opt(2015, 6, 3).unwrap().succ_opt(),///     Some(NaiveDate::from_ymd_opt(2015, 6, 4).unwrap())/// assert_eq!(NaiveDate::MAX.succ_opt(), None);/// Makes a new `NaiveDate` for the previous calendar date.///     NaiveDate::from_ymd_opt(2015, 6, 3).unwrap().pred_opt(),///     Some(NaiveDate::from_ymd_opt(2015, 6, 2).unwrap())/// assert_eq!(NaiveDate::MIN.pred_opt(), None);/// Adds the number of whole days in the given `TimeDelta` to the current date./// use chrono::{NaiveDate, TimeDelta};/// let d = NaiveDate::from_ymd_opt(2015, 9, 5).unwrap();///     d.checked_add_signed(TimeDelta::try_days(40).unwrap()),///     Some(NaiveDate::from_ymd_opt(2015, 10, 15).unwrap())///     d.checked_add_signed(TimeDelta::try_days(-40).unwrap()),///     Some(NaiveDate::from_ymd_opt(2015, 7, 27).unwrap())/// assert_eq!(d.checked_add_signed(TimeDelta::try_days(1_000_000_000).unwrap()), None);/// assert_eq!(d.checked_add_signed(TimeDelta::try_days(-1_000_000_000).unwrap()), None);/// assert_eq!(NaiveDate::MAX.checked_add_signed(TimeDelta::try_days(1).unwrap()), None);/// Subtracts the number of whole days in the given `TimeDelta` from the current date.///     d.checked_sub_signed(TimeDelta::try_days(40).unwrap()),///     d.checked_sub_signed(TimeDelta::try_days(-40).unwrap()),/// assert_eq!(d.checked_sub_signed(TimeDelta::try_days(1_000_000_000).unwrap()), None);/// assert_eq!(d.checked_sub_signed(TimeDelta::try_days(-1_000_000_000).unwrap()), None);/// assert_eq!(NaiveDate::MIN.checked_sub_signed(TimeDelta::try_days(1).unwrap()), None);/// Subtracts another `NaiveDate` from the current date./// let since = NaiveDate::signed_duration_since;/// assert_eq!(since(from_ymd(2014, 1, 1), from_ymd(2014, 1, 1)), TimeDelta::zero());///     since(from_ymd(2014, 1, 1), from_ymd(2013, 12, 31)),///     TimeDelta::try_days(1).unwrap()/// assert_eq!(since(from_ymd(2014, 1, 1), from_ymd(2014, 1, 2)), TimeDelta::try_days(-1).unwrap());///     since(from_ymd(2014, 1, 1), from_ymd(2013, 9, 23)),///     TimeDelta::try_days(100).unwrap()///     since(from_ymd(2014, 1, 1), from_ymd(2013, 1, 1)),///     TimeDelta::try_days(365).unwrap()///     since(from_ymd(2014, 1, 1), from_ymd(2010, 1, 1)),///     TimeDelta::try_days(365 * 4 + 1).unwrap()///     since(from_ymd(2014, 1, 1), from_ymd(1614, 1, 1)),///     TimeDelta::try_days(365 * 400 + 97).unwrap()/// Otherwise it is the same as the ordinary `format` method./// The `Iterator` of items should be `Clone`able,/// since the resulting `DelayedFormat` value may be formatted multiple times./// use chrono::format::strftime::StrftimeItems;/// let fmt = StrftimeItems::new("%Y-%m-%d");/// assert_eq!(d.format_with_items(fmt.clone()).to_string(), "2015-09-05");/// assert_eq!(d.format("%Y-%m-%d").to_string(), "2015-09-05");/// The resulting `DelayedFormat` can be formatted directly via the `Display` trait./// # use chrono::format::strftime::StrftimeItems;/// # let fmt = StrftimeItems::new("%Y-%m-%d").clone();/// # let d = NaiveDate::from_ymd_opt(2015, 9, 5).unwrap();/// assert_eq!(format!("{}", d.format_with_items(fmt)), "2015-09-05");/// This returns a `DelayedFormat`,/// which gets converted to a string only when actual formatting happens./// You may use the `to_string` method to get a `String`,/// or just feed it into `print!` and other formatting macros./// (In this way it avoids the redundant memory allocation.)/// Converting or formatting the returned `DelayedFormat` panics if the format string is wrong./// Because of this delayed failure, you are recommended to immediately use the `DelayedFormat`/// assert_eq!(d.format("%A, %-d %B, %C%y").to_string(), "Saturday, 5 September, 2015");/// assert_eq!(format!("{}", d.format("%Y-%m-%d")), "2015-09-05");/// assert_eq!(format!("{}", d.format("%A, %-d %B, %C%y")), "Saturday, 5 September, 2015");iter_daysNaiveDateDaysIterator/// Returns an iterator that steps by days across all representable dates./// let expected = [///     NaiveDate::from_ymd_opt(2016, 2, 27).unwrap(),///     NaiveDate::from_ymd_opt(2016, 2, 28).unwrap(),///     NaiveDate::from_ymd_opt(2016, 2, 29).unwrap(),///     NaiveDate::from_ymd_opt(2016, 3, 1).unwrap(),/// let mut count = 0;/// for (idx, d) in NaiveDate::from_ymd_opt(2016, 2, 27).unwrap().iter_days().take(4).enumerate() {///     assert_eq!(d, expected[idx]);///     count += 1;/// assert_eq!(count, 4);/// for d in NaiveDate::from_ymd_opt(2016, 3, 1).unwrap().iter_days().rev().take(4) {///     count -= 1;///     assert_eq!(d, expected[count]);iter_weeksNaiveDateWeeksIterator/// Returns an iterator that steps by weeks across all representable dates.///     NaiveDate::from_ymd_opt(2016, 3, 5).unwrap(),///     NaiveDate::from_ymd_opt(2016, 3, 12).unwrap(),///     NaiveDate::from_ymd_opt(2016, 3, 19).unwrap(),/// for (idx, d) in NaiveDate::from_ymd_opt(2016, 2, 27).unwrap().iter_weeks().take(4).enumerate() {/// for d in NaiveDate::from_ymd_opt(2016, 3, 19).unwrap().iter_weeks().rev().take(4) {week/// Returns the [`NaiveWeek`] that the date belongs to, starting with the [`Weekday`]/// specified.leap_year/// Returns `true` if this is a leap year./// assert_eq!(NaiveDate::from_ymd_opt(2000, 1, 1).unwrap().leap_year(), true);/// assert_eq!(NaiveDate::from_ymd_opt(2001, 1, 1).unwrap().leap_year(), false);/// assert_eq!(NaiveDate::from_ymd_opt(2002, 1, 1).unwrap().leap_year(), false);/// assert_eq!(NaiveDate::from_ymd_opt(2003, 1, 1).unwrap().leap_year(), false);/// assert_eq!(NaiveDate::from_ymd_opt(2004, 1, 1).unwrap().leap_year(), true);/// assert_eq!(NaiveDate::from_ymd_opt(2100, 1, 1).unwrap().leap_year(), false);// This duplicates `Datelike::year()`, because trait methods can't be const yet./// Returns the day of year starting from 1.// This duplicates `Datelike::ordinal()`, because trait methods can't be const yet.// This duplicates `Datelike::month()`, because trait methods can't be const yet.// This duplicates `Datelike::day()`, because trait methods can't be const yet./// Returns the day of week.// This duplicates `Datelike::weekday()`, because trait methods can't be const yet.year_flagsnum_days_from_ce/// Counts the days in the proleptic Gregorian calendar, with January 1, Year 1 (CE) as day 1.// This duplicates `Datelike::num_days_from_ce()`, because trait methods can't be const yet.from_yof/// Create a new `NaiveDate` from a raw year-ordinal-flags `i32`./// In a valid value an ordinal is never `0`, and neither are the year flags. This method/// doesn't do any validation in release builds./// Get the raw year-ordinal-flags `i32`.MIN/// The minimum possible `NaiveDate` (January 1, 262144 BCE)./// The maximum possible `NaiveDate` (December 31, 262142 CE).BEFORE_MIN/// One day before the minimum possible `NaiveDate` (December 31, 262145 BCE).AFTER_MAX/// One day after the maximum possible `NaiveDate` (January 1, 262143 CE)./// Returns the year number in the [calendar date](#calendar-date)./// use chrono::{Datelike, NaiveDate};/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().year(), 2015);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().year(), -308); // 309 BCE/// Returns the month number starting from 1./// The return value ranges from 1 to 12./// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().month(), 9);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().month(), 3);/// Returns the month number starting from 0./// The return value ranges from 0 to 11./// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().month0(), 8);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().month0(), 2);/// Returns the day of month starting from 1./// The return value ranges from 1 to 31. (The last day of month differs by months.)/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().day(), 8);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().day(), 14);/// Combined with [`NaiveDate::pred_opt`](#method.pred_opt),/// one can determine the number of days in a particular month./// (Note that this panics when `year` is out of range.)/// fn ndays_in_month(year: i32, month: u32) -> u32 {///     // the first day of the next month...///     let (y, m) = if month == 12 { (year + 1, 1) } else { (year, month + 1) };///     let d = NaiveDate::from_ymd_opt(y, m, 1).unwrap();///     // ...is preceded by the last day of the original month///     d.pred_opt().unwrap().day()/// assert_eq!(ndays_in_month(2015, 8), 31);/// assert_eq!(ndays_in_month(2015, 9), 30);/// assert_eq!(ndays_in_month(2015, 12), 31);/// assert_eq!(ndays_in_month(2016, 2), 29);/// assert_eq!(ndays_in_month(2017, 2), 28);/// Returns the day of month starting from 0./// The return value ranges from 0 to 30. (The last day of month differs by months.)/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().day0(), 7);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().day0(), 13);/// The return value ranges from 1 to 366. (The last day of year differs by years.)/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().ordinal(), 251);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().ordinal(), 74);/// one can determine the number of days in a particular year./// fn ndays_in_year(year: i32) -> u32 {///     // the first day of the next year...///     let d = NaiveDate::from_ymd_opt(year + 1, 1, 1).unwrap();///     // ...is preceded by the last day of the original year///     d.pred_opt().unwrap().ordinal()/// assert_eq!(ndays_in_year(2015), 365);/// assert_eq!(ndays_in_year(2016), 366);/// assert_eq!(ndays_in_year(2017), 365);/// assert_eq!(ndays_in_year(2000), 366);/// assert_eq!(ndays_in_year(2100), 365);/// Returns the day of year starting from 0./// The return value ranges from 0 to 365. (The last day of year differs by years.)/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().ordinal0(), 250);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().ordinal0(), 73);/// use chrono::{Datelike, NaiveDate, Weekday};/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().weekday(), Weekday::Tue);/// assert_eq!(NaiveDate::from_ymd_opt(-308, 3, 14).unwrap().weekday(), Weekday::Fri);/// Makes a new `NaiveDate` with the year number changed, while keeping the same month and day./// This method assumes you want to work on the date as a year-month-day value. Don't use it if/// you want the ordinal to stay the same after changing the year, of if you want the week and/// weekday values to stay the same./// - The year is out of range for a `NaiveDate`.///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_year(2016),///     Some(NaiveDate::from_ymd_opt(2016, 9, 8).unwrap())///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_year(-308),///     Some(NaiveDate::from_ymd_opt(-308, 9, 8).unwrap())/// A leap day (February 29) is a case where this method can return `None`./// # use chrono::{NaiveDate, Datelike};/// assert!(NaiveDate::from_ymd_opt(2016, 2, 29).unwrap().with_year(2015).is_none());/// assert!(NaiveDate::from_ymd_opt(2016, 2, 29).unwrap().with_year(2020).is_some());/// Don't use `with_year` if you want the ordinal date to stay the same:/// # use chrono::{Datelike, NaiveDate};/// assert_ne!(///     NaiveDate::from_yo_opt(2020, 100).unwrap().with_year(2023).unwrap(),///     NaiveDate::from_yo_opt(2023, 100).unwrap() // result is 2023-101/// Makes a new `NaiveDate` with the month number (starting from 1) changed.///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_month(10),///     Some(NaiveDate::from_ymd_opt(2015, 10, 8).unwrap())/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_month(13), None); // No month 13/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 30).unwrap().with_month(2), None); // No Feb 30/// fn with_year_month(date: NaiveDate, year: i32, month: u32) -> Option<NaiveDate> {///     date.with_year(year)?.with_month(month)/// let d = NaiveDate::from_ymd_opt(2020, 2, 29).unwrap();/// assert!(with_year_month(d, 2019, 1).is_none()); // fails because of invalid intermediate value/// // Correct version:/// fn with_year_month_fixed(date: NaiveDate, year: i32, month: u32) -> Option<NaiveDate> {///     NaiveDate::from_ymd_opt(year, month, date.day())/// assert_eq!(with_year_month_fixed(d, 2019, 1), NaiveDate::from_ymd_opt(2019, 1, 29));/// Makes a new `NaiveDate` with the month number (starting from 0) changed.///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_month0(9),/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_month0(12), None); // No month 12/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 30).unwrap().with_month0(1), None); // No Feb 30/// Makes a new `NaiveDate` with the day of month (starting from 1) changed.///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_day(30),///     Some(NaiveDate::from_ymd_opt(2015, 9, 30).unwrap())/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_day(31), None);/// // no September 31/// Makes a new `NaiveDate` with the day of month (starting from 0) changed.///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_day0(29),/// assert_eq!(NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().with_day0(30), None);/// Makes a new `NaiveDate` with the day of year (starting from 1) changed./// use chrono::{NaiveDate, Datelike};/// assert_eq!(NaiveDate::from_ymd_opt(2015, 1, 1).unwrap().with_ordinal(60),///            Some(NaiveDate::from_ymd_opt(2015, 3, 1).unwrap()));/// assert_eq!(NaiveDate::from_ymd_opt(2015, 1, 1).unwrap().with_ordinal(366),///            None); // 2015 had only 365 days/// assert_eq!(NaiveDate::from_ymd_opt(2016, 1, 1).unwrap().with_ordinal(60),///            Some(NaiveDate::from_ymd_opt(2016, 2, 29).unwrap()));/// assert_eq!(NaiveDate::from_ymd_opt(2016, 1, 1).unwrap().with_ordinal(366),///            Some(NaiveDate::from_ymd_opt(2016, 12, 31).unwrap()));/// Makes a new `NaiveDate` with the day of year (starting from 0) changed./// assert_eq!(NaiveDate::from_ymd_opt(2015, 1, 1).unwrap().with_ordinal0(59),/// assert_eq!(NaiveDate::from_ymd_opt(2015, 1, 1).unwrap().with_ordinal0(365),/// assert_eq!(NaiveDate::from_ymd_opt(2016, 1, 1).unwrap().with_ordinal0(59),/// assert_eq!(NaiveDate::from_ymd_opt(2016, 1, 1).unwrap().with_ordinal0(365),/// Add `TimeDelta` to `NaiveDate`./// This discards the fractional days in `TimeDelta`, rounding to the closest integral number of/// days towards `TimeDelta::zero()`./// Consider using [`NaiveDate::checked_add_signed`] to get an `Option` instead./// assert_eq!(from_ymd(2014, 1, 1) + TimeDelta::zero(), from_ymd(2014, 1, 1));/// assert_eq!(from_ymd(2014, 1, 1) + TimeDelta::try_seconds(86399).unwrap(), from_ymd(2014, 1, 1));///     from_ymd(2014, 1, 1) + TimeDelta::try_seconds(-86399).unwrap(),///     from_ymd(2014, 1, 1)/// assert_eq!(from_ymd(2014, 1, 1) + TimeDelta::try_days(1).unwrap(), from_ymd(2014, 1, 2));/// assert_eq!(from_ymd(2014, 1, 1) + TimeDelta::try_days(-1).unwrap(), from_ymd(2013, 12, 31));/// assert_eq!(from_ymd(2014, 1, 1) + TimeDelta::try_days(364).unwrap(), from_ymd(2014, 12, 31));///     from_ymd(2014, 1, 1) + TimeDelta::try_days(365 * 4 + 1).unwrap(),///     from_ymd(2018, 1, 1)///     from_ymd(2014, 1, 1) + TimeDelta::try_days(365 * 400 + 97).unwrap(),///     from_ymd(2414, 1, 1)/// [`NaiveDate::checked_add_signed`]: crate::NaiveDate::checked_add_signed/// Add-assign of `TimeDelta` to `NaiveDate`./// This discards the fractional days in `TimeDelta`, rounding to the closest integral number of days/// towards `TimeDelta::zero()`./// Add `Months` to `NaiveDate`./// Consider using `NaiveDate::checked_add_months` to get an `Option` instead./// use chrono::{Months, NaiveDate};/// assert_eq!(from_ymd(2014, 1, 1) + Months::new(1), from_ymd(2014, 2, 1));/// assert_eq!(from_ymd(2014, 1, 1) + Months::new(11), from_ymd(2014, 12, 1));/// assert_eq!(from_ymd(2014, 1, 1) + Months::new(12), from_ymd(2015, 1, 1));/// assert_eq!(from_ymd(2014, 1, 1) + Months::new(13), from_ymd(2015, 2, 1));/// assert_eq!(from_ymd(2014, 1, 31) + Months::new(1), from_ymd(2014, 2, 28));/// assert_eq!(from_ymd(2020, 1, 31) + Months::new(1), from_ymd(2020, 2, 29));/// Subtract `Months` from `NaiveDate`./// The result will be clamped to valid days in the resulting month, see `checked_sub_months` for/// Consider using `NaiveDate::checked_sub_months` to get an `Option` instead./// assert_eq!(from_ymd(2014, 1, 1) - Months::new(11), from_ymd(2013, 2, 1));/// assert_eq!(from_ymd(2014, 1, 1) - Months::new(12), from_ymd(2013, 1, 1));/// assert_eq!(from_ymd(2014, 1, 1) - Months::new(13), from_ymd(2012, 12, 1));/// Add `Days` to `NaiveDate`./// Consider using `NaiveDate::checked_add_days` to get an `Option` instead./// Subtract `Days` from `NaiveDate`./// Consider using `NaiveDate::checked_sub_days` to get an `Option` instead./// Subtract `TimeDelta` from `NaiveDate`./// It is the same as the addition with a negated `TimeDelta`./// Consider using [`NaiveDate::checked_sub_signed`] to get an `Option` instead./// assert_eq!(from_ymd(2014, 1, 1) - TimeDelta::zero(), from_ymd(2014, 1, 1));/// assert_eq!(from_ymd(2014, 1, 1) - TimeDelta::try_seconds(86399).unwrap(), from_ymd(2014, 1, 1));///     from_ymd(2014, 1, 1) - TimeDelta::try_seconds(-86399).unwrap(),/// assert_eq!(from_ymd(2014, 1, 1) - TimeDelta::try_days(1).unwrap(), from_ymd(2013, 12, 31));/// assert_eq!(from_ymd(2014, 1, 1) - TimeDelta::try_days(-1).unwrap(), from_ymd(2014, 1, 2));/// assert_eq!(from_ymd(2014, 1, 1) - TimeDelta::try_days(364).unwrap(), from_ymd(2013, 1, 2));///     from_ymd(2014, 1, 1) - TimeDelta::try_days(365 * 4 + 1).unwrap(),///     from_ymd(2010, 1, 1)///     from_ymd(2014, 1, 1) - TimeDelta::try_days(365 * 400 + 97).unwrap(),///     from_ymd(1614, 1, 1)/// [`NaiveDate::checked_sub_signed`]: crate::NaiveDate::checked_sub_signed/// Subtract-assign `TimeDelta` from `NaiveDate`./// The implementation is a wrapper around/// [`NaiveDate::signed_duration_since`](#method.signed_duration_since)./// assert_eq!(from_ymd(2014, 1, 1) - from_ymd(2014, 1, 1), TimeDelta::zero());/// assert_eq!(from_ymd(2014, 1, 1) - from_ymd(2013, 12, 31), TimeDelta::try_days(1).unwrap());/// assert_eq!(from_ymd(2014, 1, 1) - from_ymd(2014, 1, 2), TimeDelta::try_days(-1).unwrap());/// assert_eq!(from_ymd(2014, 1, 1) - from_ymd(2013, 9, 23), TimeDelta::try_days(100).unwrap());/// assert_eq!(from_ymd(2014, 1, 1) - from_ymd(2013, 1, 1), TimeDelta::try_days(365).unwrap());///     from_ymd(2014, 1, 1) - from_ymd(2010, 1, 1),///     from_ymd(2014, 1, 1) - from_ymd(1614, 1, 1),/// Iterator over `NaiveDate` with a step size of one day./// Iterator over `NaiveDate` with a step size of one week./// The `Debug` output of the naive date `d` is the same as/// [`d.format("%Y-%m-%d")`](crate::format::strftime)./// The string printed can be readily parsed via the `parse` method on `str`./// assert_eq!(format!("{:?}", NaiveDate::from_ymd_opt(2015, 9, 5).unwrap()), "2015-09-05");/// assert_eq!(format!("{:?}", NaiveDate::from_ymd_opt(0, 1, 1).unwrap()), "0000-01-01");/// assert_eq!(format!("{:?}", NaiveDate::from_ymd_opt(9999, 12, 31).unwrap()), "9999-12-31");/// ISO 8601 requires an explicit sign for years before 1 BCE or after 9999 CE./// assert_eq!(format!("{:?}", NaiveDate::from_ymd_opt(-1, 1, 1).unwrap()), "-0001-01-01");/// assert_eq!(format!("{:?}", NaiveDate::from_ymd_opt(10000, 12, 31).unwrap()), "+10000-12-31");/// The `Display` output of the naive date `d` is the same as/// assert_eq!(format!("{}", NaiveDate::from_ymd_opt(2015, 9, 5).unwrap()), "2015-09-05");/// assert_eq!(format!("{}", NaiveDate::from_ymd_opt(0, 1, 1).unwrap()), "0000-01-01");/// assert_eq!(format!("{}", NaiveDate::from_ymd_opt(9999, 12, 31).unwrap()), "9999-12-31");/// assert_eq!(format!("{}", NaiveDate::from_ymd_opt(-1, 1, 1).unwrap()), "-0001-01-01");/// assert_eq!(format!("{}", NaiveDate::from_ymd_opt(10000, 12, 31).unwrap()), "+10000-12-31");/// Parsing a `str` into a `NaiveDate` uses the same format,/// [`%Y-%m-%d`](crate::format::strftime), as in `Debug` and `Display`./// let d = NaiveDate::from_ymd_opt(2015, 9, 18).unwrap();/// assert_eq!("2015-09-18".parse::<NaiveDate>(), Ok(d));/// let d = NaiveDate::from_ymd_opt(12345, 6, 7).unwrap();/// assert_eq!("+12345-6-7".parse::<NaiveDate>(), Ok(d));/// assert!("foo".parse::<NaiveDate>().is_err());/// The default value for a NaiveDate is 1st of January 1970./// let default_date = NaiveDate::default();/// assert_eq!(default_date, NaiveDate::from_ymd_opt(1970, 1, 1).unwrap());cycle_to_yoyo_to_cyclediv_mod_floorMAX_YEAR/// MAX_YEAR is one year less than the type is capable of representing. Internally we may sometimes/// use the headroom, notably to handle cases where the offset of a `DateTime` constructed with/// `NaiveDate::MAX` pushes it beyond the valid, representable range.MIN_YEAR/// MIN_YEAR is one year more than the type is capable of representing. Internally we may sometimes/// `NaiveDate::MIN` pushes it beyond the valid, representable range.ORDINAL_MASKLEAP_YEAR_MASKOL_MASK// OL: ordinal and leap year flag.// With only these parts of the date an ordinal 366 in a common year would be encoded as// `((366 << 1) | 1) << 3`, and in a leap year as `((366 << 1) | 0) << 3`, which is less.// This allows for efficiently checking the ordinal exists depending on whether this is a leap year.MAX_OLWEEKDAY_FLAGS_MASK// Weekday of the last day in the preceding year.// Allows for quick day of week calculation from the 1-based ordinal.YEAR_FLAGS_MASKYEAR_DELTAS401//! ISO 8601 calendar date without timezone.//! The implementation is optimized for determining year, month, day and day of week.//! Format of `NaiveDate`://! `YYYY_YYYY_YYYY_YYYY_YYYO_OOOO_OOOO_LWWW`//! `Y`: Year//! `O`: Ordinal//! `L`: leap year flag (1 = common year, 0 is leap year)//! `W`: weekday before the first day of the year//! `LWWW`: will also be referred to as the year flags (`F`)AGBACBDCEDFEGFtest_date_bounds// as it is hard to verify year flags in `NaiveDate::MIN` and `NaiveDate::MAX`,// we use a separate run-time test.test_readme_doomsdaytest_date_from_ymdtest_date_from_yotest_date_from_isoywdtest_date_from_isoywd_and_iso_weektest_date_from_num_days_from_cetest_date_from_weekday_of_month_opttest_date_fieldstest_date_weekdaytest_date_with_fieldstest_date_with_ordinaltest_date_num_days_from_cetest_date_succtest_date_predtest_date_checked_add_signedtest_date_signed_duration_sincetest_date_add_daystest_date_sub_daystest_date_addassignmenttest_date_subassignmenttest_date_fmttest_date_from_strtest_date_parse_from_strtest_day_iterator_limittest_week_iterator_limittest_weeks_fromtest_with_0_overflowtest_leap_yeartest_date_yearflagstest_weekday_with_yearflagstest_isoweekdate_with_yearflagstest_date_to_mdf_to_dateYEAR_FLAGS// Used for testing some methods with all combinations of `YearFlags`.// (year, flags, first weekday of year)MAX_DAYS_FROM_YEAR_0//   MAX_YEAR-12-31 minus 0000-01-01// = (MAX_YEAR-12-31 minus 0000-12-31) + (0000-12-31 - 0000-01-01)// = MAX_YEAR * 365 + (# of leap years from 0001 to MAX_YEAR) + 365// = (MAX_YEAR + 1) * 365 + (# of leap years from 0001 to MAX_YEAR)MIN_DAYS_FROM_YEAR_0//   MIN_YEAR-01-01 minus 0000-01-01// = MIN_YEAR * 365 + (# of leap years from MIN_YEAR to 0000)MAX_BITS// only used for testing, but duplicated in naive::datetimeNANOS_PER_SEC/// The minimum possible `NaiveDateTime`./// The maximum possible `NaiveDateTime`./// ISO 8601 combined date and time without timezone./// `NaiveDateTime` is commonly created from [`NaiveDate`]./// use chrono::{NaiveDate, NaiveDateTime};/// let dt: NaiveDateTime =///     NaiveDate::from_ymd_opt(2016, 7, 8).unwrap().and_hms_opt(9, 10, 11).unwrap();/// # let _ = dt;/// You can use typical [date-like](Datelike) and [time-like](Timelike) methods,/// provided that relevant traits are in the scope./// # use chrono::{NaiveDate, NaiveDateTime};/// # let dt: NaiveDateTime = NaiveDate::from_ymd_opt(2016, 7, 8).unwrap().and_hms_opt(9, 10, 11).unwrap();/// use chrono::{Datelike, Timelike, Weekday};/// assert_eq!(dt.weekday(), Weekday::Fri);/// assert_eq!(dt.num_seconds_from_midnight(), 33011);/// Makes a new `NaiveDateTime` from date and time components./// Equivalent to [`date.and_time(time)`](./struct.NaiveDate.html#method.and_time)/// and many other helper constructors on `NaiveDate`./// let dt = NaiveDateTime::new(d, t);/// Makes a new `NaiveDateTime` corresponding to a UTC date and time,/// from the number of non-leap seconds/// since the midnight UTC on January 1, 1970 (aka "UNIX timestamp")/// For a non-naive version of this function see [`TimeZone::timestamp`]./// Panics if the number of seconds would be out of range for a `NaiveDateTime` (more than/// ca. 262,000 years away from common era), and panics on an invalid nanosecond (2 seconds or/// more)./// Creates a new [NaiveDateTime] from milliseconds since the UNIX epoch./// Returns `None` if the number of milliseconds would be out of range for a `NaiveDateTime`/// Creates a new [NaiveDateTime] from microseconds since the UNIX epoch./// Creates a new [NaiveDateTime] from nanoseconds since the UNIX epoch./// Returns `None` if the number of nanoseconds would be out of range for a `NaiveDateTime`from_timestamp_opt/// Returns `None` if the number of seconds would be out of range for a `NaiveDateTime` (more/// than ca. 262,000 years away from common era), and panics on an invalid nanosecond/// (2 seconds or more)./// Parses a string with the specified format string and returns a new `NaiveDateTime`./// let parse_from_str = NaiveDateTime::parse_from_str;///     parse_from_str("2015-09-05 23:56:04", "%Y-%m-%d %H:%M:%S"),///     Ok(NaiveDate::from_ymd_opt(2015, 9, 5).unwrap().and_hms_opt(23, 56, 4).unwrap())///     parse_from_str("5sep2015pm012345.6789", "%d%b%Y%p%I%M%S%.f"),///     Ok(NaiveDate::from_ymd_opt(2015, 9, 5)///         .and_hms_micro_opt(13, 23, 45, 678_900)/// Offset is ignored for the purpose of parsing./// # use chrono::{NaiveDateTime, NaiveDate};/// # let parse_from_str = NaiveDateTime::parse_from_str;///     Ok(NaiveDate::from_ymd_opt(2014, 5, 17).unwrap().and_hms_opt(12, 34, 56).unwrap())/// [Leap seconds](./struct.NaiveTime.html#leap-second-handling) are correctly handled by/// treating any time of the form `hh:mm:60` as a leap second./// (This equally applies to the formatting, so the round trip is possible.)///     parse_from_str("2015-07-01 08:59:60.123", "%Y-%m-%d %H:%M:%S%.f"),///     Ok(NaiveDate::from_ymd_opt(2015, 7, 1)///         .and_hms_milli_opt(8, 59, 59, 1_123)/// Missing seconds are assumed to be zero,/// but out-of-bound times or insufficient fields are errors otherwise.///     parse_from_str("94/9/4 7:15", "%y/%m/%d %H:%M"),///     Ok(NaiveDate::from_ymd_opt(1994, 9, 4).unwrap().and_hms_opt(7, 15, 0).unwrap())/// assert!(parse_from_str("04m33s", "%Mm%Ss").is_err());/// assert!(parse_from_str("94/9/4 12", "%y/%m/%d %H").is_err());/// assert!(parse_from_str("94/9/4 17:60", "%y/%m/%d %H:%M").is_err());/// assert!(parse_from_str("94/9/4 24:00:00", "%y/%m/%d %H:%M:%S").is_err());/// # use chrono::NaiveDateTime;/// let fmt = "%Y-%m-%d %H:%M:%S = UNIX timestamp %s";/// assert!(parse_from_str("2001-09-09 01:46:39 = UNIX timestamp 999999999", fmt).is_ok());/// assert!(parse_from_str("1970-01-01 00:00:00 = UNIX timestamp 1", fmt).is_err());/// Years before 1 BCE or after 9999 CE, require an initial sign/// let fmt = "%Y-%m-%d %H:%M:%S";/// assert!(parse_from_str("10000-09-09 01:46:39", fmt).is_err());/// assert!(parse_from_str("+10000-09-09 01:46:39", fmt).is_ok());/// Parses a string with the specified format string and returns a new `NaiveDateTime`, and a/// let (datetime, remainder) = NaiveDateTime::parse_and_remainder(///     "2015-02-18 23:16:09 trailing text",///     "%Y-%m-%d %H:%M:%S",///     NaiveDate::from_ymd_opt(2015, 2, 18).unwrap().and_hms_opt(23, 16, 9).unwrap()/// Retrieves a date component./// let dt = NaiveDate::from_ymd_opt(2016, 7, 8).unwrap().and_hms_opt(9, 10, 11).unwrap();/// assert_eq!(dt.date(), NaiveDate::from_ymd_opt(2016, 7, 8).unwrap());/// Retrieves a time component./// use chrono::{NaiveDate, NaiveTime};/// assert_eq!(dt.time(), NaiveTime::from_hms_opt(9, 10, 11).unwrap());/// Returns the number of non-leap seconds since the midnight on January 1, 1970./// Note that this does *not* account for the timezone!/// The true "UNIX timestamp" would count seconds since the midnight *UTC* on the epoch./// Returns the number of non-leap *milliseconds* since midnight on January 1, 1970./// Returns the number of non-leap *microseconds* since midnight on January 1, 1970./// Returns the number of non-leap *nanoseconds* since midnight on January 1, 1970./// an out of range `NaiveDateTime`./// `None` on an out of range `NaiveDateTime`./// Returns the number of milliseconds since the last whole non-leap second./// The return value ranges from 0 to 999,/// or for [leap seconds](./struct.NaiveTime.html#leap-second-handling), to 1,999./// Returns the number of microseconds since the last whole non-leap second./// The return value ranges from 0 to 999,999,/// or for [leap seconds](./struct.NaiveTime.html#leap-second-handling), to 1,999,999./// Returns the number of nanoseconds since the last whole non-leap second./// The return value ranges from 0 to 999,999,999,/// or for [leap seconds](./struct.NaiveTime.html#leap-second-handling), to 1,999,999,999./// As a part of Chrono's [leap second handling](./struct.NaiveTime.html#leap-second-handling),/// the addition assumes that **there is no leap second ever**,/// except when the `NaiveDateTime` itself represents a leap second/// in which case the assumption becomes that **there is exactly a single leap second ever**./// let d = from_ymd(2016, 7, 8);/// let hms = |h, m, s| d.and_hms_opt(h, m, s).unwrap();/// assert_eq!(hms(3, 5, 7).checked_add_signed(TimeDelta::zero()), Some(hms(3, 5, 7)));///     hms(3, 5, 7).checked_add_signed(TimeDelta::try_seconds(1).unwrap()),///     Some(hms(3, 5, 8))///     hms(3, 5, 7).checked_add_signed(TimeDelta::try_seconds(-1).unwrap()),///     Some(hms(3, 5, 6))///     hms(3, 5, 7).checked_add_signed(TimeDelta::try_seconds(3600 + 60).unwrap()),///     Some(hms(4, 6, 7))///     hms(3, 5, 7).checked_add_signed(TimeDelta::try_seconds(86_400).unwrap()),///     Some(from_ymd(2016, 7, 9).and_hms_opt(3, 5, 7).unwrap())/// let hmsm = |h, m, s, milli| d.and_hms_milli_opt(h, m, s, milli).unwrap();///     hmsm(3, 5, 7, 980).checked_add_signed(TimeDelta::try_milliseconds(450).unwrap()),///     Some(hmsm(3, 5, 8, 430))/// Overflow returns `None`./// # use chrono::{TimeDelta, NaiveDate};/// # let hms = |h, m, s| NaiveDate::from_ymd_opt(2016, 7, 8).unwrap().and_hms_opt(h, m, s).unwrap();/// assert_eq!(hms(3, 5, 7).checked_add_signed(TimeDelta::try_days(1_000_000_000).unwrap()), None);/// Leap seconds are handled,/// but the addition assumes that it is the only leap second happened./// # let hmsm = |h, m, s, milli| from_ymd(2016, 7, 8).and_hms_milli_opt(h, m, s, milli).unwrap();/// let leap = hmsm(3, 5, 59, 1_300);/// assert_eq!(leap.checked_add_signed(TimeDelta::zero()),///            Some(hmsm(3, 5, 59, 1_300)));/// assert_eq!(leap.checked_add_signed(TimeDelta::try_milliseconds(-500).unwrap()),///            Some(hmsm(3, 5, 59, 800)));/// assert_eq!(leap.checked_add_signed(TimeDelta::try_milliseconds(500).unwrap()),///            Some(hmsm(3, 5, 59, 1_800)));/// assert_eq!(leap.checked_add_signed(TimeDelta::try_milliseconds(800).unwrap()),///            Some(hmsm(3, 6, 0, 100)));/// assert_eq!(leap.checked_add_signed(TimeDelta::try_seconds(10).unwrap()),///            Some(hmsm(3, 6, 9, 300)));/// assert_eq!(leap.checked_add_signed(TimeDelta::try_seconds(-10).unwrap()),///            Some(hmsm(3, 5, 50, 300)));/// assert_eq!(leap.checked_add_signed(TimeDelta::try_days(1).unwrap()),///            Some(from_ymd(2016, 7, 9).and_hms_milli_opt(3, 5, 59, 300).unwrap()));///         .and_hms_opt(1, 0, 0)///         .checked_add_months(Months::new(1)),///     Some(NaiveDate::from_ymd_opt(2014, 2, 1).unwrap().and_hms_opt(1, 0, 0).unwrap())///         .checked_add_months(Months::new(core::i32::MAX as u32 + 1)),checked_add_offset/// Adds given `FixedOffset` to the current datetime./// Returns `None` if the result would be outside the valid range for [`NaiveDateTime`]./// This method is similar to [`checked_add_signed`](#method.checked_add_offset), but preserves/// leap seconds.checked_sub_offset/// Subtracts given `FixedOffset` from the current datetime./// This method is similar to [`checked_sub_signed`](#method.checked_sub_signed), but preservesoverflowing_add_offset/// The resulting value may be outside the valid range of [`NaiveDateTime`]./// This can be useful for intermediate values, but the resulting out-of-range `NaiveDate`/// should not be exposed to library users.overflowing_sub_offset// currently only used in `Local` but not on all platforms/// the subtraction assumes that **there is no leap second ever**,/// assert_eq!(hms(3, 5, 7).checked_sub_signed(TimeDelta::zero()), Some(hms(3, 5, 7)));///     hms(3, 5, 7).checked_sub_signed(TimeDelta::try_seconds(1).unwrap()),///     hms(3, 5, 7).checked_sub_signed(TimeDelta::try_seconds(-1).unwrap()),///     hms(3, 5, 7).checked_sub_signed(TimeDelta::try_seconds(3600 + 60).unwrap()),///     Some(hms(2, 4, 7))///     hms(3, 5, 7).checked_sub_signed(TimeDelta::try_seconds(86_400).unwrap()),///     Some(from_ymd(2016, 7, 7).and_hms_opt(3, 5, 7).unwrap())///     hmsm(3, 5, 7, 450).checked_sub_signed(TimeDelta::try_milliseconds(670).unwrap()),///     Some(hmsm(3, 5, 6, 780))/// assert_eq!(hms(3, 5, 7).checked_sub_signed(TimeDelta::try_days(1_000_000_000).unwrap()), None);/// but the subtraction assumes that it is the only leap second happened./// assert_eq!(leap.checked_sub_signed(TimeDelta::zero()),/// assert_eq!(leap.checked_sub_signed(TimeDelta::try_milliseconds(200).unwrap()),///            Some(hmsm(3, 5, 59, 1_100)));/// assert_eq!(leap.checked_sub_signed(TimeDelta::try_milliseconds(500).unwrap()),/// assert_eq!(leap.checked_sub_signed(TimeDelta::try_seconds(60).unwrap()),///            Some(hmsm(3, 5, 0, 300)));/// assert_eq!(leap.checked_sub_signed(TimeDelta::try_days(1).unwrap()),///            Some(from_ymd(2016, 7, 7).and_hms_milli_opt(3, 6, 0, 300).unwrap()));///         .checked_sub_months(Months::new(1)),///     Some(NaiveDate::from_ymd_opt(2013, 12, 1).unwrap().and_hms_opt(1, 0, 0).unwrap())/// Add a duration in [`Days`] to the date part of the `NaiveDateTime`/// Subtract a duration in [`Days`] from the date part of the `NaiveDateTime`/// Subtracts another `NaiveDateTime` from the current date and time./// except when any of the `NaiveDateTime`s themselves represents a leap second/// in which case the assumption becomes that/// **there are exactly one (or two) leap second(s) ever**.///     d.and_hms_opt(3, 5, 7).unwrap().signed_duration_since(d.and_hms_opt(2, 4, 6).unwrap()),///     TimeDelta::try_seconds(3600 + 60 + 1).unwrap()/// // July 8 is 190th day in the year 2016/// let d0 = from_ymd(2016, 1, 1);///     d.and_hms_milli_opt(0, 7, 6, 500)///         .signed_duration_since(d0.and_hms_opt(0, 0, 0).unwrap()),///     TimeDelta::try_seconds(189 * 86_400 + 7 * 60 + 6).unwrap()///         + TimeDelta::try_milliseconds(500).unwrap()/// Leap seconds are handled, but the subtraction assumes that/// there were no other leap seconds happened./// let leap = from_ymd(2015, 6, 30).and_hms_milli_opt(23, 59, 59, 1_500).unwrap();///     leap.signed_duration_since(from_ymd(2015, 6, 30).and_hms_opt(23, 0, 0).unwrap()),///     TimeDelta::try_seconds(3600).unwrap() + TimeDelta::try_milliseconds(500).unwrap()///     from_ymd(2015, 7, 1).and_hms_opt(1, 0, 0).unwrap().signed_duration_since(leap),///     TimeDelta::try_seconds(3600).unwrap() - TimeDelta::try_milliseconds(500).unwrap()/// Otherwise it is the same as the ordinary [`format`](#method.format) method./// let fmt = StrftimeItems::new("%Y-%m-%d %H:%M:%S");/// let dt = NaiveDate::from_ymd_opt(2015, 9, 5).unwrap().and_hms_opt(23, 56, 4).unwrap();/// assert_eq!(dt.format_with_items(fmt.clone()).to_string(), "2015-09-05 23:56:04");/// assert_eq!(dt.format("%Y-%m-%d %H:%M:%S").to_string(), "2015-09-05 23:56:04");/// # let fmt = StrftimeItems::new("%Y-%m-%d %H:%M:%S").clone();/// # let dt = NaiveDate::from_ymd_opt(2015, 9, 5).unwrap().and_hms_opt(23, 56, 4).unwrap();/// assert_eq!(format!("{}", dt.format_with_items(fmt)), "2015-09-05 23:56:04");/// Formats the combined date and time with the specified format string./// A wrong format string does *not* issue an error immediately./// Rather, converting or formatting the `DelayedFormat` fails./// You are recommended to immediately use `DelayedFormat` for this reason./// assert_eq!(dt.format("around %l %p on %b %-d").to_string(), "around 11 PM on Sep 5");/// assert_eq!(format!("{}", dt.format("%Y-%m-%d %H:%M:%S")), "2015-09-05 23:56:04");/// assert_eq!(format!("{}", dt.format("around %l %p on %b %-d")), "around 11 PM on Sep 5");and_local_timezone/// Converts the `NaiveDateTime` into a timezone-aware `DateTime<Tz>` with the provided/// time zone./// use chrono::{FixedOffset, NaiveDate};/// let hour = 3600;/// let tz = FixedOffset::east_opt(5 * hour).unwrap();/// let dt = NaiveDate::from_ymd_opt(2015, 9, 5)///     .and_hms_opt(23, 56, 4)///     .and_local_timezone(tz)/// assert_eq!(dt.timezone(), tz);and_utc/// Converts the `NaiveDateTime` into the timezone-aware `DateTime<Utc>`./// let dt =///     NaiveDate::from_ymd_opt(2023, 1, 30).unwrap().and_hms_opt(19, 32, 33).unwrap().and_utc();/// assert_eq!(dt.timezone(), Utc);/// The datetime of the Unix Epoch, 1970-01-01 00:00:00./// Note that while this may look like the UNIX epoch, it is missing the/// time zone. The actual UNIX epoch cannot be expressed by this type,/// however it is available as [`DateTime::UNIX_EPOCH`]./// Converts a `NaiveDate` to a `NaiveDateTime` of the same date but at midnight./// let nd = NaiveDate::from_ymd_opt(2016, 5, 28).unwrap();/// let ndt = NaiveDate::from_ymd_opt(2016, 5, 28).unwrap().and_hms_opt(0, 0, 0).unwrap();/// assert_eq!(ndt, NaiveDateTime::from(nd));/// Returns the year number in the [calendar date](./struct.NaiveDate.html#calendar-date)./// See also the [`NaiveDate::year`](./struct.NaiveDate.html#method.year) method./// use chrono::{Datelike, NaiveDate, NaiveDateTime};///     NaiveDate::from_ymd_opt(2015, 9, 25).unwrap().and_hms_opt(12, 34, 56).unwrap();/// See also the [`NaiveDate::month`](./struct.NaiveDate.html#method.month) method./// assert_eq!(dt.month(), 9);/// See also the [`NaiveDate::month0`] method./// assert_eq!(dt.month0(), 8);/// See also the [`NaiveDate::day`](./struct.NaiveDate.html#method.day) method./// assert_eq!(dt.day(), 25);/// See also the [`NaiveDate::day0`] method./// assert_eq!(dt.day0(), 24);/// See also the [`NaiveDate::ordinal`](./struct.NaiveDate.html#method.ordinal) method./// assert_eq!(dt.ordinal(), 268);/// See also the [`NaiveDate::ordinal0`] method./// assert_eq!(dt.ordinal0(), 267);/// See also the [`NaiveDate::weekday`](./struct.NaiveDate.html#method.weekday) method./// use chrono::{Datelike, NaiveDate, NaiveDateTime, Weekday};/// Makes a new `NaiveDateTime` with the year number changed, while keeping the same month and/// day.///     dt.with_year(2016),///     Some(NaiveDate::from_ymd_opt(2016, 9, 25).unwrap().and_hms_opt(12, 34, 56).unwrap())///     dt.with_year(-308),///     Some(NaiveDate::from_ymd_opt(-308, 9, 25).unwrap().and_hms_opt(12, 34, 56).unwrap())/// Makes a new `NaiveDateTime` with the month number (starting from 1) changed.///     NaiveDate::from_ymd_opt(2015, 9, 30).unwrap().and_hms_opt(12, 34, 56).unwrap();///     dt.with_month(10),///     Some(NaiveDate::from_ymd_opt(2015, 10, 30).unwrap().and_hms_opt(12, 34, 56).unwrap())/// assert_eq!(dt.with_month(13), None); // No month 13/// assert_eq!(dt.with_month(2), None); // No February 30/// Makes a new `NaiveDateTime` with the month number (starting from 0) changed.///     dt.with_month0(9),/// assert_eq!(dt.with_month0(12), None); // No month 13/// assert_eq!(dt.with_month0(1), None); // No February 30/// Makes a new `NaiveDateTime` with the day of month (starting from 1) changed.///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().and_hms_opt(12, 34, 56).unwrap();///     dt.with_day(30),///     Some(NaiveDate::from_ymd_opt(2015, 9, 30).unwrap().and_hms_opt(12, 34, 56).unwrap())/// assert_eq!(dt.with_day(31), None); // no September 31/// Makes a new `NaiveDateTime` with the day of month (starting from 0) changed.///     dt.with_day0(29),/// assert_eq!(dt.with_day0(30), None); // no September 31/// Makes a new `NaiveDateTime` with the day of year (starting from 1) changed.///     dt.with_ordinal(60),///     Some(NaiveDate::from_ymd_opt(2015, 3, 1).unwrap().and_hms_opt(12, 34, 56).unwrap())/// assert_eq!(dt.with_ordinal(366), None); // 2015 had only 365 days///     NaiveDate::from_ymd_opt(2016, 9, 8).unwrap().and_hms_opt(12, 34, 56).unwrap();///     Some(NaiveDate::from_ymd_opt(2016, 2, 29).unwrap().and_hms_opt(12, 34, 56).unwrap())///     dt.with_ordinal(366),///     Some(NaiveDate::from_ymd_opt(2016, 12, 31).unwrap().and_hms_opt(12, 34, 56).unwrap())/// Makes a new `NaiveDateTime` with the day of year (starting from 0) changed.///     dt.with_ordinal0(59),/// assert_eq!(dt.with_ordinal0(365), None); // 2015 had only 365 days///     dt.with_ordinal0(365),/// Returns the hour number from 0 to 23./// See also the [`NaiveTime::hour`] method./// use chrono::{NaiveDate, NaiveDateTime, Timelike};///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().and_hms_milli_opt(12, 34, 56, 789).unwrap();/// assert_eq!(dt.hour(), 12);/// Returns the minute number from 0 to 59./// See also the [`NaiveTime::minute`] method./// assert_eq!(dt.minute(), 34);/// Returns the second number from 0 to 59./// See also the [`NaiveTime::second`] method./// Returns the number of nanoseconds since the whole non-leap second./// The range from 1,000,000,000 to 1,999,999,999 represents/// the [leap second](./struct.NaiveTime.html#leap-second-handling)./// See also the [`NaiveTime#method.nanosecond`] method./// assert_eq!(dt.nanosecond(), 789_000_000);/// Makes a new `NaiveDateTime` with the hour number changed./// Returns `None` if the value for `hour` is invalid.///     dt.with_hour(7),///     Some(///         NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().and_hms_milli_opt(7, 34, 56, 789).unwrap()/// assert_eq!(dt.with_hour(24), None);/// Makes a new `NaiveDateTime` with the minute number changed./// Returns `None` if the value for `minute` is invalid.///     dt.with_minute(45),///         NaiveDate::from_ymd_opt(2015, 9, 8)///             .and_hms_milli_opt(12, 45, 56, 789)/// assert_eq!(dt.with_minute(60), None);/// Makes a new `NaiveDateTime` with the second number changed./// Returns `None` if the value for `second` is invalid.///     dt.with_second(17),///             .and_hms_milli_opt(12, 34, 17, 789)/// assert_eq!(dt.with_second(60), None);/// Makes a new `NaiveDateTime` with nanoseconds since the whole non-leap second changed.///     NaiveDate::from_ymd_opt(2015, 9, 8).unwrap().and_hms_milli_opt(12, 34, 59, 789).unwrap();///     dt.with_nanosecond(333_333_333),///             .and_hms_nano_opt(12, 34, 59, 333_333_333)///     dt.with_nanosecond(1_333_333_333), // leap second///             .and_hms_nano_opt(12, 34, 59, 1_333_333_333)/// assert_eq!(dt.with_nanosecond(2_000_000_000), None);/// Add `TimeDelta` to `NaiveDateTime`./// Consider using [`NaiveDateTime::checked_add_signed`] to get an `Option` instead./// assert_eq!(hms(3, 5, 7) + TimeDelta::zero(), hms(3, 5, 7));/// assert_eq!(hms(3, 5, 7) + TimeDelta::try_seconds(1).unwrap(), hms(3, 5, 8));/// assert_eq!(hms(3, 5, 7) + TimeDelta::try_seconds(-1).unwrap(), hms(3, 5, 6));/// assert_eq!(hms(3, 5, 7) + TimeDelta::try_seconds(3600 + 60).unwrap(), hms(4, 6, 7));///     hms(3, 5, 7) + TimeDelta::try_seconds(86_400).unwrap(),///     from_ymd(2016, 7, 9).and_hms_opt(3, 5, 7).unwrap()///     hms(3, 5, 7) + TimeDelta::try_days(365).unwrap(),///     from_ymd(2017, 7, 8).and_hms_opt(3, 5, 7).unwrap()/// assert_eq!(hmsm(3, 5, 7, 980) + TimeDelta::try_milliseconds(450).unwrap(), hmsm(3, 5, 8, 430));/// assert_eq!(leap + TimeDelta::zero(), hmsm(3, 5, 59, 1_300));/// assert_eq!(leap + TimeDelta::try_milliseconds(-500).unwrap(), hmsm(3, 5, 59, 800));/// assert_eq!(leap + TimeDelta::try_milliseconds(500).unwrap(), hmsm(3, 5, 59, 1_800));/// assert_eq!(leap + TimeDelta::try_milliseconds(800).unwrap(), hmsm(3, 6, 0, 100));/// assert_eq!(leap + TimeDelta::try_seconds(10).unwrap(), hmsm(3, 6, 9, 300));/// assert_eq!(leap + TimeDelta::try_seconds(-10).unwrap(), hmsm(3, 5, 50, 300));/// assert_eq!(leap + TimeDelta::try_days(1).unwrap(),///            from_ymd(2016, 7, 9).and_hms_milli_opt(3, 5, 59, 300).unwrap());/// [leap second handling]: crate::NaiveTime#leap-second-handling/// Add `std::time::Duration` to `NaiveDateTime`./// Add-assign `TimeDelta` to `NaiveDateTime`./// Add-assign `std::time::Duration` to `NaiveDateTime`./// Add `FixedOffset` to `NaiveDateTime`./// Consider using `checked_add_offset` to get an `Option` instead./// Add `Months` to `NaiveDateTime`./// Consider using `checked_add_months` to get an `Option` instead.///     NaiveDate::from_ymd_opt(2014, 1, 1).unwrap().and_hms_opt(1, 0, 0).unwrap() + Months::new(1),///     NaiveDate::from_ymd_opt(2014, 2, 1).unwrap().and_hms_opt(1, 0, 0).unwrap()///     NaiveDate::from_ymd_opt(2014, 1, 1).unwrap().and_hms_opt(0, 2, 0).unwrap()///         + Months::new(11),///     NaiveDate::from_ymd_opt(2014, 12, 1).unwrap().and_hms_opt(0, 2, 0).unwrap()///     NaiveDate::from_ymd_opt(2014, 1, 1).unwrap().and_hms_opt(0, 0, 3).unwrap()///         + Months::new(12),///     NaiveDate::from_ymd_opt(2015, 1, 1).unwrap().and_hms_opt(0, 0, 3).unwrap()///     NaiveDate::from_ymd_opt(2014, 1, 1).unwrap().and_hms_opt(0, 0, 4).unwrap()///         + Months::new(13),///     NaiveDate::from_ymd_opt(2015, 2, 1).unwrap().and_hms_opt(0, 0, 4).unwrap()///     NaiveDate::from_ymd_opt(2014, 1, 31).unwrap().and_hms_opt(0, 5, 0).unwrap()///         + Months::new(1),///     NaiveDate::from_ymd_opt(2014, 2, 28).unwrap().and_hms_opt(0, 5, 0).unwrap()///     NaiveDate::from_ymd_opt(2020, 1, 31).unwrap().and_hms_opt(6, 0, 0).unwrap()///     NaiveDate::from_ymd_opt(2020, 2, 29).unwrap().and_hms_opt(6, 0, 0).unwrap()/// Subtract `TimeDelta` from `NaiveDateTime`./// second ever**, except when the `NaiveDateTime` itself represents a leap second in which case/// Consider using [`NaiveDateTime::checked_sub_signed`] to get an `Option` instead./// assert_eq!(hms(3, 5, 7) - TimeDelta::zero(), hms(3, 5, 7));/// assert_eq!(hms(3, 5, 7) - TimeDelta::try_seconds(1).unwrap(), hms(3, 5, 6));/// assert_eq!(hms(3, 5, 7) - TimeDelta::try_seconds(-1).unwrap(), hms(3, 5, 8));/// assert_eq!(hms(3, 5, 7) - TimeDelta::try_seconds(3600 + 60).unwrap(), hms(2, 4, 7));///     hms(3, 5, 7) - TimeDelta::try_seconds(86_400).unwrap(),///     from_ymd(2016, 7, 7).and_hms_opt(3, 5, 7).unwrap()///     hms(3, 5, 7) - TimeDelta::try_days(365).unwrap(),///     from_ymd(2015, 7, 9).and_hms_opt(3, 5, 7).unwrap()/// assert_eq!(hmsm(3, 5, 7, 450) - TimeDelta::try_milliseconds(670).unwrap(), hmsm(3, 5, 6, 780));/// assert_eq!(leap - TimeDelta::zero(), hmsm(3, 5, 59, 1_300));/// assert_eq!(leap - TimeDelta::try_milliseconds(200).unwrap(), hmsm(3, 5, 59, 1_100));/// assert_eq!(leap - TimeDelta::try_milliseconds(500).unwrap(), hmsm(3, 5, 59, 800));/// assert_eq!(leap - TimeDelta::try_seconds(60).unwrap(), hmsm(3, 5, 0, 300));/// assert_eq!(leap - TimeDelta::try_days(1).unwrap(),///            from_ymd(2016, 7, 7).and_hms_milli_opt(3, 6, 0, 300).unwrap());/// Subtract `std::time::Duration` from `NaiveDateTime`./// Subtract-assign `TimeDelta` from `NaiveDateTime`./// Subtract-assign `std::time::Duration` from `NaiveDateTime`./// Subtract `FixedOffset` from `NaiveDateTime`./// Consider using `checked_sub_offset` to get an `Option` instead./// Subtract `Months` from `NaiveDateTime`./// [`NaiveDateTime::checked_sub_months`] for details./// Consider using [`NaiveDateTime::checked_sub_months`] to get an `Option` instead.///     NaiveDate::from_ymd_opt(2014, 01, 01).unwrap().and_hms_opt(01, 00, 00).unwrap()///         - Months::new(11),///     NaiveDate::from_ymd_opt(2013, 02, 01).unwrap().and_hms_opt(01, 00, 00).unwrap()///     NaiveDate::from_ymd_opt(2014, 01, 01).unwrap().and_hms_opt(00, 02, 00).unwrap()///         - Months::new(12),///     NaiveDate::from_ymd_opt(2013, 01, 01).unwrap().and_hms_opt(00, 02, 00).unwrap()///     NaiveDate::from_ymd_opt(2014, 01, 01).unwrap().and_hms_opt(00, 00, 03).unwrap()///         - Months::new(13),///     NaiveDate::from_ymd_opt(2012, 12, 01).unwrap().and_hms_opt(00, 00, 03).unwrap()/// The implementation is a wrapper around [`NaiveDateTime::signed_duration_since`].///     d.and_hms_opt(3, 5, 7).unwrap() - d.and_hms_opt(2, 4, 6).unwrap(),///     d.and_hms_milli_opt(0, 7, 6, 500).unwrap() - d0.and_hms_opt(0, 0, 0).unwrap(),/// Leap seconds are handled, but the subtraction assumes that no other leap/// seconds happened.///     leap - from_ymd(2015, 6, 30).and_hms_opt(23, 0, 0).unwrap(),///     from_ymd(2015, 7, 1).and_hms_opt(1, 0, 0).unwrap() - leap,/// Consider using `checked_add_days` to get an `Option` instead./// Subtract `Days` from `NaiveDateTime`./// Consider using `checked_sub_days` to get an `Option` instead./// The `Debug` output of the naive date and time `dt` is the same as/// [`dt.format("%Y-%m-%dT%H:%M:%S%.f")`](crate::format::strftime)./// It should be noted that, for leap seconds not on the minute boundary,/// it may print a representation not distinguishable from non-leap seconds./// This doesn't matter in practice, since such leap seconds never happened./// (By the time of the first leap second on 1972-06-30,/// every time zone offset around the world has standardized to the 5-minute alignment.)/// let dt = NaiveDate::from_ymd_opt(2016, 11, 15).unwrap().and_hms_opt(7, 39, 24).unwrap();/// assert_eq!(format!("{:?}", dt), "2016-11-15T07:39:24");/// Leap seconds may also be used.///     NaiveDate::from_ymd_opt(2015, 6, 30).unwrap().and_hms_milli_opt(23, 59, 59, 1_500).unwrap();/// assert_eq!(format!("{:?}", dt), "2015-06-30T23:59:60.500");/// The `Display` output of the naive date and time `dt` is the same as/// [`dt.format("%Y-%m-%d %H:%M:%S%.f")`](crate::format::strftime)./// assert_eq!(format!("{}", dt), "2016-11-15 07:39:24");/// assert_eq!(format!("{}", dt), "2015-06-30 23:59:60.500");/// Parsing a `str` into a `NaiveDateTime` uses the same format,/// [`%Y-%m-%dT%H:%M:%S%.f`](crate::format::strftime), as in `Debug`./// use chrono::{NaiveDateTime, NaiveDate};/// let dt = NaiveDate::from_ymd_opt(2015, 9, 18).unwrap().and_hms_opt(23, 56, 4).unwrap();/// assert_eq!("2015-09-18T23:56:04".parse::<NaiveDateTime>(), Ok(dt));/// let dt = NaiveDate::from_ymd_opt(12345, 6, 7).unwrap().and_hms_milli_opt(7, 59, 59, 1_500).unwrap(); // leap second/// assert_eq!("+12345-6-7T7:59:60.5".parse::<NaiveDateTime>(), Ok(dt));/// assert!("foo".parse::<NaiveDateTime>().is_err());/// The default value for a NaiveDateTime is 1st of January 1970 at 00:00:00.//! ISO 8601 date and time without timezone./// Serialize a `NaiveDateTime` as an ISO 8601 string/// See [the `naive::serde` module](crate::naive::serde) for alternate serialization formats.NaiveDateTimeVisitor/// Serialize a datetime into an integer number of nanoseconds since the epoch/// use chrono::naive::serde::ts_nanoseconds::serialize as to_nano_ts;///     time: NaiveDateTime,///         .unwrap(),/// Deserialize a `NaiveDateTime` from a nanoseconds timestamp/// # use chrono::{DateTime, NaiveDateTime};/// use chrono::naive::serde::ts_nanoseconds::deserialize as from_nano_ts;/// let expected = DateTime::from_timestamp(1526522699, 918355733).unwrap().naive_utc();/// assert_eq!(my_s, S { time: expected });/// let expected = DateTime::from_timestamp(-1, 999_999_999).unwrap().naive_utc();/// Used to serialize/deserialize from nanosecond-precision timestamps/// use chrono::naive::serde::ts_nanoseconds;/// Serialize a datetime into an integer number of nanoseconds since the epoch or none/// # use chrono::naive::{NaiveDate, NaiveDateTime};/// use chrono::naive::serde::ts_nanoseconds_option::serialize as to_nano_tsopt;///     time: Option<NaiveDateTime>,/// Deserialize a `NaiveDateTime` from a nanosecond timestamp or none/// use chrono::naive::serde::ts_nanoseconds_option::deserialize as from_nano_tsopt;/// assert_eq!(my_s, S { time: Some(expected) });/// use chrono::naive::serde::ts_nanoseconds_option;/// Serialize a datetime into an integer number of microseconds since the epoch/// use chrono::naive::serde::ts_microseconds::serialize as to_micro_ts;/// Deserialize a `NaiveDateTime` from a microseconds timestamp/// use chrono::naive::serde::ts_microseconds::deserialize as from_micro_ts;/// let expected = DateTime::from_timestamp(1526522699, 918355000).unwrap().naive_utc();/// let expected = DateTime::from_timestamp(-1, 999_999_000).unwrap().naive_utc();/// Used to serialize/deserialize from microsecond-precision timestamps/// use chrono::naive::serde::ts_microseconds;/// Serialize a datetime into an integer number of microseconds since the epoch or none/// use chrono::naive::serde::ts_microseconds_option::serialize as to_micro_tsopt;/// use chrono::naive::serde::ts_microseconds_option::deserialize as from_micro_tsopt;/// use chrono::naive::serde::ts_microseconds_option;/// Serialize a datetime into an integer number of milliseconds since the epoch/// use chrono::naive::serde::ts_milliseconds::serialize as to_milli_ts;/// Deserialize a `NaiveDateTime` from a milliseconds timestamp/// use chrono::naive::serde::ts_milliseconds::deserialize as from_milli_ts;/// let expected = DateTime::from_timestamp(1526522699, 918000000).unwrap().naive_utc();/// let expected = DateTime::from_timestamp(-1, 999_000_000).unwrap().naive_utc();/// Used to serialize/deserialize from millisecond-precision timestamps/// use chrono::naive::serde::ts_milliseconds;/// let time =///     NaiveDate::from_ymd_opt(2018, 5, 17).unwrap().and_hms_milli_opt(02, 04, 59, 918).unwrap();/// Serialize a datetime into an integer number of milliseconds since the epoch or none/// use chrono::naive::serde::ts_milliseconds_option::serialize as to_milli_tsopt;/// Deserialize a `NaiveDateTime` from a millisecond timestamp or none/// use chrono::naive::serde::ts_milliseconds_option::deserialize as from_milli_tsopt;///     #[serde(deserialize_with = "from_milli_tsopt")]/// use chrono::naive::serde::ts_milliseconds_option;///     NaiveDate::from_ymd_opt(2018, 5, 17).unwrap().and_hms_milli_opt(02, 04, 59, 918).unwrap(),/// Serialize a datetime into an integer number of seconds since the epoch/// use chrono::naive::serde::ts_seconds::serialize as to_ts;/// let my_s =///     S { time: NaiveDate::from_ymd_opt(2015, 5, 15).unwrap().and_hms_opt(10, 0, 0).unwrap() };/// Deserialize a `NaiveDateTime` from a seconds timestamp/// use chrono::naive::serde::ts_seconds::deserialize as from_ts;/// let expected = DateTime::from_timestamp(1431684000, 0).unwrap().naive_utc();/// Used to serialize/deserialize from second-precision timestamps/// use chrono::naive::serde::ts_seconds;/// let time = NaiveDate::from_ymd_opt(2015, 5, 15).unwrap().and_hms_opt(10, 0, 0).unwrap();/// Serialize a datetime into an integer number of seconds since the epoch or none/// use chrono::naive::serde::ts_seconds_option::serialize as to_tsopt;/// let expected = NaiveDate::from_ymd_opt(2018, 5, 17).unwrap().and_hms_opt(02, 04, 59).unwrap();/// let my_s = S { time: Some(expected) };/// assert_eq!(as_string, r#"{"time":1526522699}"#);/// Deserialize a `NaiveDateTime` from a second timestamp or none/// use chrono::naive::serde::ts_seconds_option::deserialize as from_tsopt;/// use chrono::naive::serde::ts_seconds_option;/// let time = Some(NaiveDate::from_ymd_opt(2018, 5, 17).unwrap().and_hms_opt(02, 04, 59).unwrap());// Bincode is relevant to test separately from JSON because// it is not self-describing.test_serde_bincode_optionaltest_datetime_addtest_datetime_subtest_datetime_addassignmenttest_datetime_subassignmenttest_datetime_parse_from_str_with_spacestest_datetime_add_sub_invarianttest_and_local_timezonetest_and_utctest_checked_add_offsettest_checked_sub_offsettest_overflowing_add_offsettest_and_timezone_min_max_dates/// Year flags (aka the dominical letter)./// `YearFlags` are used as the last four bits of `NaiveDate`, `Mdf` and `IsoWeek`./// There are 14 possible classes of year in the Gregorian calendar:/// common and leap years starting with Monday through Sunday./// The `YearFlags` stores this information into 4 bits `LWWW`. `L` is the leap year flag, with `1`/// for the common year (this simplifies validating an ordinal in `NaiveDate`). `WWW` is a non-zero/// `Weekday` of the last day in the preceding year.// public as an alias for benchmarks onlyYEAR_STARTS_AFTER_MONDAYYEAR_STARTS_AFTER_THUESDAY// non-zero to allow use with `NonZero*`.YEAR_STARTS_AFTER_WEDNESDAYYEAR_STARTS_AFTER_THURSDAYYEAR_STARTS_AFTER_FRIDAYYEAR_STARTS_AFTER_SATURDAYYEAR_STARTS_AFTER_SUNDAYCOMMON_YEARLEAP_YEARYEAR_TO_FLAGS400from_year// for benchmarks onlyfrom_year_mod_400ndaysisoweek_deltanisoweeks// OL: (ordinal << 1) | leap year flagMAX_MDL// `(366 << 1) | 1` would be day 366 in a non-leap yearXX// The next table are adjustment values to convert a date encoded as month-day-leapyear to// ordinal-leapyear. OL = MDL - adjustment.// Dates that do not exist are encoded as `XX`.MDL_TO_OLOL_TO_MDL/// Month, day of month and year flags: `(month << 9) | (day << 4) | flags`/// `M_MMMD_DDDD_LFFF`/// The whole bits except for the least 3 bits are referred as `Mdl` (month, day of month, and leap/// year flag), which is an index to the `MDL_TO_OL` lookup table./// The conversion between the packed calendar date (`Mdf`) and the ordinal date (`NaiveDate`) is/// based on the moderately-sized lookup table (~1.5KB) and the packed representation is chosen for/// efficient lookup./// The methods of `Mdf` validate their inputs as late as possible. Dates that can't exist, like/// February 30, can still be represented. This allows the validation to be combined with the final/// table lookup, which is good for performance./// Makes a new `Mdf` value from month, day and `YearFlags`./// This method doesn't fully validate the range of the `month` and `day` parameters, only as/// much as what can't be deferred until later. The year `flags` are trusted to be correct./// Returns `None` if `month > 12` or `day > 31`.from_ol/// Makes a new `Mdf` value from an `i32` with an ordinal and a leap year flag, and year/// `flags`./// The `ol` is trusted to be valid, and the `flags` are trusted to match it./// Returns the month of this `Mdf`./// Replaces the month of this `Mdf`, keeping the day and flags./// Returns `None` if `month > 12`./// Returns the day of this `Mdf`./// Replaces the day of this `Mdf`, keeping the month and flags./// Returns `None` if `day > 31`.with_flags/// Replaces the flags of this `Mdf`, keeping the month and day./// Returns the ordinal that corresponds to this `Mdf`./// This does a table lookup to calculate the corresponding ordinal. It will return an error if/// the `Mdl` turns out not to be a valid date./// Returns `None` if `month == 0` or `day == 0`, or if a the given day does not exist in the/// given month./// Returns the year flags of this `Mdf`.ordinal_and_flags/// Returns the ordinal that corresponds to this `Mdf`, encoded as a value including year flags.NONLEAP_FLAGSLEAP_FLAGStest_year_flags_ndays_from_yeartest_year_flags_nisoweekstest_mdf_validtest_mdf_fieldstest_mdf_with_fieldstest_mdf_new_range//! Internal helper types for working with dates.ywf// Note that this allows for larger year range than `NaiveDate`.// This is crucial because we have an edge case for the first and last week supported,// which year number might not match the calendar year number.// (year << 10) | (week << 4) | flag/// ISO 8601 week./// This type, combined with [`Weekday`](../enum.Weekday.html),/// constitutes the ISO 8601 [week date](./struct.NaiveDate.html#week-date)./// One can retrieve this type from the existing [`Datelike`](../trait.Datelike.html) types/// via the [`Datelike::iso_week`](../trait.Datelike.html#tymethod.iso_week) method./// Returns the corresponding `IsoWeek` from the year and the `Of` internal value.// Internal use only. We don't expose the public constructor for `IsoWeek` for now// because the year range for the week date and the calendar date do not match, and// it is confusing to have a date that is out of range in one and not in another.// Currently we sidestep this issue by making `IsoWeek` fully dependent of `Datelike`./// Returns the year number for this ISO week./// let d = NaiveDate::from_isoywd_opt(2015, 1, Weekday::Mon).unwrap();/// assert_eq!(d.iso_week().year(), 2015);/// This year number might not match the calendar year number./// Continuing the example.../// # use chrono::{NaiveDate, Datelike, Weekday};/// # let d = NaiveDate::from_isoywd_opt(2015, 1, Weekday::Mon).unwrap();/// assert_eq!(d.year(), 2014);/// assert_eq!(d, NaiveDate::from_ymd_opt(2014, 12, 29).unwrap());/// Returns the ISO week number starting from 1./// The return value ranges from 1 to 53. (The last week of year differs by years.)/// let d = NaiveDate::from_isoywd_opt(2015, 15, Weekday::Mon).unwrap();/// assert_eq!(d.iso_week().week(), 15);week0/// Returns the ISO week number starting from 0./// The return value ranges from 0 to 52. (The last week of year differs by years.)/// assert_eq!(d.iso_week().week0(), 14);/// The `Debug` output of the ISO week `w` is the same as/// [`d.format("%G-W%V")`](../format/strftime/index.html)/// where `d` is any `NaiveDate` value in that week.///     format!("{:?}", NaiveDate::from_ymd_opt(2015, 9, 5).unwrap().iso_week()),///     "2015-W36"/// assert_eq!(format!("{:?}", NaiveDate::from_ymd_opt(0, 1, 3).unwrap().iso_week()), "0000-W01");///     format!("{:?}", NaiveDate::from_ymd_opt(9999, 12, 31).unwrap().iso_week()),///     "9999-W52"/// assert_eq!(format!("{:?}", NaiveDate::from_ymd_opt(0, 1, 2).unwrap().iso_week()), "-0001-W52");///     format!("{:?}", NaiveDate::from_ymd_opt(10000, 12, 31).unwrap().iso_week()),///     "+10000-W52"test_iso_week_extremestest_iso_week_equivalence_for_first_weektest_iso_week_equivalence_for_last_weektest_iso_week_ordering_for_first_weektest_iso_week_ordering_for_last_week//! ISO 8601 week./// A week represented by a [`NaiveDate`] and a [`Weekday`] which is the first/// day of the week./// Create a new `NaiveWeek`first_day/// Returns a date representing the first day of the week./// Panics if the first day of the week happens to fall just out of range of `NaiveDate`/// (more than ca. 262,000 years away from common era)./// let date = NaiveDate::from_ymd_opt(2022, 4, 18).unwrap();/// let week = date.week(Weekday::Mon);/// assert!(week.first_day() <= date);checked_first_day/// Returns a date representing the first day of the week or/// `None` if the date is out of `NaiveDate`'s range/// let date = NaiveDate::MIN;/// if let Some(first_day) = week.checked_first_day() {///     assert!(first_day == date);///     // error handling code///     return;last_day/// Returns a date representing the last day of the week./// Panics if the last day of the week happens to fall just out of range of `NaiveDate`/// assert!(week.last_day() >= date);checked_last_day/// Returns a date representing the last day of the week or/// let date = NaiveDate::MAX;/// if let Some(last_day) = week.checked_last_day() {///     assert!(last_day == date);days/// Returns a [`RangeInclusive<T>`] representing the whole week bounded by/// [first_day](NaiveWeek::first_day) and [last_day](NaiveWeek::last_day) functions./// Panics if the either the first or last day of the week happens to fall just out of range of/// `NaiveDate` (more than ca. 262,000 years away from common era)./// let days = week.days();/// assert!(days.contains(&date));checked_days/// Returns an [`Option<RangeInclusive<T>>`] representing the whole week bounded by/// [checked_first_day](NaiveWeek::checked_first_day) and/// [checked_last_day](NaiveWeek::checked_last_day) functions./// Returns `None` if either of the boundaries are out of `NaiveDate`'s range/// let _days = match week.checked_days() {///     Some(d) => d,///     None => {///         // error handling code///         return;/// A duration in calendar days./// This is useful because when using `TimeDelta` it is possible that adding `TimeDelta::days(1)`/// doesn't increment the day value as expected due to it being a fixed number of seconds. This/// difference applies only when dealing with `DateTime<TimeZone>` data types and in other cases/// `TimeDelta::days(n)` and `Days::new(n)` are equivalent./// Construct a new `Days` from a number of daysDefaultHashertest_naiveweektest_naiveweek_min_maxtest_naiveweek_checked_no_panictest_naiveweek_eqtest_naiveweek_hash//! Date and time types unconcerned with timezones.//! They are primarily building blocks for other types//! (e.g. [`TimeZone`](../offset/trait.TimeZone.html)),//! but can be also used for the simpler date and time handling.secsfrac/// ISO 8601 time without timezone./// Allows for the nanosecond precision and optional leap second representation./// # Leap Second Handling/// Since 1960s, the manmade atomic clock has been so accurate that/// it is much more accurate than Earth's own motion./// It became desirable to define the civil time in terms of the atomic clock,/// but that risks the desynchronization of the civil time from Earth./// To account for this, the designers of the Coordinated Universal Time (UTC)/// made that the UTC should be kept within 0.9 seconds of the observed Earth-bound time./// When the mean solar day is longer than the ideal (86,400 seconds),/// the error slowly accumulates and it is necessary to add a **leap second**/// to slow the UTC down a bit./// (We may also remove a second to speed the UTC up a bit, but it never happened.)/// The leap second, if any, follows 23:59:59 of June 30 or December 31 in the UTC./// Fast forward to the 21st century,/// we have seen 26 leap seconds from January 1972 to December 2015./// Yes, 26 seconds. Probably you can read this paragraph within 26 seconds./// But those 26 seconds, and possibly more in the future, are never predictable,/// and whether to add a leap second or not is known only before 6 months./// Internet-based clocks (via NTP) do account for known leap seconds,/// but the system API normally doesn't (and often can't, with no network connection)/// and there is no reliable way to retrieve leap second information./// Chrono does not try to accurately implement leap seconds; it is impossible./// Rather, **it allows for leap seconds but behaves as if there are *no other* leap seconds.**/// Various operations will ignore any possible leap second(s)/// except when any of the operands were actually leap seconds./// If you cannot tolerate this behavior,/// you must use a separate `TimeZone` for the International Atomic Time (TAI)./// TAI is like UTC but has no leap seconds, and thus slightly differs from UTC./// Chrono does not yet provide such implementation, but it is planned./// ## Representing Leap Seconds/// The leap second is indicated via fractional seconds more than 1 second./// This makes possible to treat a leap second as the prior non-leap second/// if you don't care about sub-second accuracy./// You should use the proper formatting to get the raw leap second./// All methods accepting fractional seconds will accept such values./// let t = NaiveTime::from_hms_milli_opt(8, 59, 59, 1_000).unwrap();/// let dt1 = NaiveDate::from_ymd_opt(2015, 7, 1)///     .and_hms_micro_opt(8, 59, 59, 1_000_000)/// let dt2 = NaiveDate::from_ymd_opt(2015, 6, 30)///     .and_hms_nano_opt(23, 59, 59, 1_000_000_000)/// # let _ = (t, dt1, dt2);/// Note that the leap second can happen anytime given an appropriate time zone;/// 2015-07-01 01:23:60 would be a proper leap second if UTC+01:24 had existed./// Practically speaking, though, by the time of the first leap second on 1972-06-30,/// every time zone offset around the world has standardized to the 5-minute alignment./// ## Date And Time Arithmetic/// As a concrete example, let's assume that `03:00:60` and `04:00:60` are leap seconds./// In reality, of course, leap seconds are separated by at least 6 months./// We will also use some intuitive concise notations for the explanation./// `Time + TimeDelta`/// (short for [`NaiveTime::overflowing_add_signed`](#method.overflowing_add_signed)):/// - `03:00:00 + 1s = 03:00:01`./// - `03:00:59 + 60s = 03:01:59`./// - `03:00:59 + 61s = 03:02:00`./// - `03:00:59 + 1s = 03:01:00`./// - `03:00:60 + 1s = 03:01:00`.///   Note that the sum is identical to the previous./// - `03:00:60 + 60s = 03:01:59`./// - `03:00:60 + 61s = 03:02:00`./// - `03:00:60.1 + 0.8s = 03:00:60.9`./// `Time - TimeDelta`/// (short for [`NaiveTime::overflowing_sub_signed`](#method.overflowing_sub_signed)):/// - `03:00:00 - 1s = 02:59:59`./// - `03:01:00 - 1s = 03:00:59`./// - `03:01:00 - 60s = 03:00:00`./// - `03:00:60 - 60s = 03:00:00`.///   Note that the result is identical to the previous./// - `03:00:60.7 - 0.4s = 03:00:60.3`./// - `03:00:60.7 - 0.9s = 03:00:59.8`./// `Time - Time`/// (short for [`NaiveTime::signed_duration_since`](#method.signed_duration_since)):/// - `04:00:00 - 03:00:00 = 3600s`./// - `03:01:00 - 03:00:00 = 60s`./// - `03:00:60 - 03:00:00 = 60s`.///   Note that the difference is identical to the previous./// - `03:00:60.6 - 03:00:59.4 = 1.2s`./// - `03:01:00 - 03:00:59.8 = 0.2s`./// - `03:01:00 - 03:00:60.5 = 0.5s`.///   Note that the difference is larger than the previous,///   even though the leap second clearly follows the previous whole second./// - `04:00:60.9 - 03:00:60.1 =///   (04:00:60.9 - 04:00:00) + (04:00:00 - 03:01:00) + (03:01:00 - 03:00:60.1) =///   60.9s + 3540s + 0.9s = 3601.8s`./// In general,/// - `Time + TimeDelta` unconditionally equals to `TimeDelta + Time`./// - `Time - TimeDelta` unconditionally equals to `Time + (-TimeDelta)`./// - `Time1 - Time2` unconditionally equals to `-(Time2 - Time1)`./// - Associativity does not generally hold, because///   `(Time + TimeDelta1) - TimeDelta2` no longer equals to `Time + (TimeDelta1 - TimeDelta2)`///   for two positive durations.///     - As a special case, `(Time + TimeDelta) - TimeDelta` also does not equal to `Time`.///     - If you can assume that all durations have the same sign, however,///       then the associativity holds:///       `(Time + TimeDelta1) + TimeDelta2` equals to `Time + (TimeDelta1 + TimeDelta2)`///       for two positive durations./// ## Reading And Writing Leap Seconds/// The "typical" leap seconds on the minute boundary are/// correctly handled both in the formatting and parsing./// The leap second in the human-readable representation/// will be represented as the second part being 60, as required by ISO 8601./// let dt = NaiveDate::from_ymd_opt(2015, 6, 30)///     .and_hms_milli_opt(23, 59, 59, 1_000)/// assert_eq!(format!("{:?}", dt), "2015-06-30T23:59:60Z");/// There are hypothetical leap seconds not on the minute boundary nevertheless supported by Chrono./// They are allowed for the sake of completeness and consistency; there were several "exotic" time/// zone offsets with fractional minutes prior to UTC after all./// For such cases the human-readable representation is ambiguous and would be read back to the next/// non-leap second./// A `NaiveTime` with a leap second that is not on a minute boundary can only be created from a/// [`DateTime`](crate::DateTime) with fractional minutes as offset, or using/// [`Timelike::with_nanosecond()`]./// use chrono::{FixedOffset, NaiveDate, TimeZone};/// let paramaribo_pre1945 = FixedOffset::east_opt(-13236).unwrap(); // -03:40:36/// let leap_sec_2015 =///     NaiveDate::from_ymd_opt(2015, 6, 30).unwrap().and_hms_milli_opt(23, 59, 59, 1_000).unwrap();/// let dt1 = paramaribo_pre1945.from_utc_datetime(&leap_sec_2015);/// assert_eq!(format!("{:?}", dt1), "2015-06-30T20:19:24-03:40:36");/// assert_eq!(format!("{:?}", dt1.time()), "20:19:24");/// let next_sec = NaiveDate::from_ymd_opt(2015, 7, 1).unwrap().and_hms_opt(0, 0, 0).unwrap();/// let dt2 = paramaribo_pre1945.from_utc_datetime(&next_sec);/// assert_eq!(format!("{:?}", dt2), "2015-06-30T20:19:24-03:40:36");/// assert_eq!(format!("{:?}", dt2.time()), "20:19:24");/// assert!(dt1.time() != dt2.time());/// assert!(dt1.time().to_string() == dt2.time().to_string());/// Since Chrono alone cannot determine any existence of leap seconds,/// **there is absolutely no guarantee that the leap second read has actually happened**.from_hms/// Makes a new `NaiveTime` from hour, minute and second./// No [leap second](#leap-second-handling) is allowed here;/// use `NaiveTime::from_hms_*` methods with a subsecond parameter instead.from_hms_opt/// The millisecond part is allowed to exceed 1,000,000,000 in order to represent a/// [leap second](#leap-second-handling), but only when `sec == 59`./// use chrono::NaiveTime;/// let from_hms_opt = NaiveTime::from_hms_opt;/// assert!(from_hms_opt(0, 0, 0).is_some());/// assert!(from_hms_opt(23, 59, 59).is_some());/// assert!(from_hms_opt(24, 0, 0).is_none());/// assert!(from_hms_opt(23, 60, 0).is_none());/// assert!(from_hms_opt(23, 59, 60).is_none());from_hms_milli/// Makes a new `NaiveTime` from hour, minute, second and millisecond./// The millisecond part can exceed 1,000/// in order to represent the [leap second](#leap-second-handling).from_hms_milli_opt/// let from_hmsm_opt = NaiveTime::from_hms_milli_opt;/// assert!(from_hmsm_opt(0, 0, 0, 0).is_some());/// assert!(from_hmsm_opt(23, 59, 59, 999).is_some());/// assert!(from_hmsm_opt(23, 59, 59, 1_999).is_some()); // a leap second after 23:59:59/// assert!(from_hmsm_opt(24, 0, 0, 0).is_none());/// assert!(from_hmsm_opt(23, 60, 0, 0).is_none());/// assert!(from_hmsm_opt(23, 59, 60, 0).is_none());/// assert!(from_hmsm_opt(23, 59, 59, 2_000).is_none());from_hms_micro/// Makes a new `NaiveTime` from hour, minute, second and microsecond./// The microsecond part is allowed to exceed 1,000,000,000 in order to represent afrom_hms_micro_opt/// let from_hmsu_opt = NaiveTime::from_hms_micro_opt;/// assert!(from_hmsu_opt(0, 0, 0, 0).is_some());/// assert!(from_hmsu_opt(23, 59, 59, 999_999).is_some());/// assert!(from_hmsu_opt(23, 59, 59, 1_999_999).is_some()); // a leap second after 23:59:59/// assert!(from_hmsu_opt(24, 0, 0, 0).is_none());/// assert!(from_hmsu_opt(23, 60, 0, 0).is_none());/// assert!(from_hmsu_opt(23, 59, 60, 0).is_none());/// assert!(from_hmsu_opt(23, 59, 59, 2_000_000).is_none());from_hms_nano/// Makes a new `NaiveTime` from hour, minute, second and nanosecond./// The nanosecond part is allowed to exceed 1,000,000,000 in order to represent afrom_hms_nano_opt/// let from_hmsn_opt = NaiveTime::from_hms_nano_opt;/// assert!(from_hmsn_opt(0, 0, 0, 0).is_some());/// assert!(from_hmsn_opt(23, 59, 59, 999_999_999).is_some());/// assert!(from_hmsn_opt(23, 59, 59, 1_999_999_999).is_some()); // a leap second after 23:59:59/// assert!(from_hmsn_opt(24, 0, 0, 0).is_none());/// assert!(from_hmsn_opt(23, 60, 0, 0).is_none());/// assert!(from_hmsn_opt(23, 59, 60, 0).is_none());/// assert!(from_hmsn_opt(23, 59, 59, 2_000_000_000).is_none());from_num_seconds_from_midnight/// Makes a new `NaiveTime` from the number of seconds since midnight and nanosecond./// [leap second](#leap-second-handling), but only when `secs % 60 == 59`./// Panics on invalid number of seconds and/or nanosecond.from_num_seconds_from_midnight_opt/// Returns `None` on invalid number of seconds and/or nanosecond./// let from_nsecs_opt = NaiveTime::from_num_seconds_from_midnight_opt;/// assert!(from_nsecs_opt(0, 0).is_some());/// assert!(from_nsecs_opt(86399, 999_999_999).is_some());/// assert!(from_nsecs_opt(86399, 1_999_999_999).is_some()); // a leap second after 23:59:59/// assert!(from_nsecs_opt(86_400, 0).is_none());/// assert!(from_nsecs_opt(86399, 2_000_000_000).is_none());/// Parses a string with the specified format string and returns a new `NaiveTime`./// let parse_from_str = NaiveTime::parse_from_str;///     parse_from_str("23:56:04", "%H:%M:%S"),///     Ok(NaiveTime::from_hms_opt(23, 56, 4).unwrap())///     parse_from_str("pm012345.6789", "%p%I%M%S%.f"),///     Ok(NaiveTime::from_hms_micro_opt(13, 23, 45, 678_900).unwrap())/// Date and offset is ignored for the purpose of parsing./// # use chrono::NaiveTime;/// # let parse_from_str = NaiveTime::parse_from_str;///     Ok(NaiveTime::from_hms_opt(12, 34, 56).unwrap())/// [Leap seconds](#leap-second-handling) are correctly handled by///     parse_from_str("08:59:60.123", "%H:%M:%S%.f"),///     Ok(NaiveTime::from_hms_milli_opt(8, 59, 59, 1_123).unwrap())/// assert_eq!(parse_from_str("7:15", "%H:%M"), Ok(NaiveTime::from_hms_opt(7, 15, 0).unwrap()));/// assert!(parse_from_str("12", "%H").is_err());/// assert!(parse_from_str("17:60", "%H:%M").is_err());/// assert!(parse_from_str("24:00:00", "%H:%M:%S").is_err());/// Here `%H` is for 24-hour clocks, unlike `%I`,/// and thus can be independently determined without AM/PM./// assert!(parse_from_str("13:07 AM", "%H:%M %p").is_err());/// Parses a string from a user-specified format into a new `NaiveTime` value, and a slice with/// # use chrono::{NaiveTime};/// let (time, remainder) =///     NaiveTime::parse_and_remainder("3h4m33s trailing text", "%-Hh%-Mm%-Ss").unwrap();/// assert_eq!(time, NaiveTime::from_hms_opt(3, 4, 33).unwrap());overflowing_add_signed/// Adds given `TimeDelta` to the current time, and also returns the number of *seconds*/// in the integral number of days ignored from the addition./// use chrono::{NaiveTime, TimeDelta};/// let from_hms = |h, m, s| NaiveTime::from_hms_opt(h, m, s).unwrap();///     from_hms(3, 4, 5).overflowing_add_signed(TimeDelta::try_hours(11).unwrap()),///     (from_hms(14, 4, 5), 0)///     from_hms(3, 4, 5).overflowing_add_signed(TimeDelta::try_hours(23).unwrap()),///     (from_hms(2, 4, 5), 86_400)///     from_hms(3, 4, 5).overflowing_add_signed(TimeDelta::try_hours(-7).unwrap()),///     (from_hms(20, 4, 5), -86_400)overflowing_sub_signed/// Subtracts given `TimeDelta` from the current time, and also returns the number of *seconds*/// in the integral number of days ignored from the subtraction.///     from_hms(3, 4, 5).overflowing_sub_signed(TimeDelta::try_hours(2).unwrap()),///     (from_hms(1, 4, 5), 0)///     from_hms(3, 4, 5).overflowing_sub_signed(TimeDelta::try_hours(17).unwrap()),///     (from_hms(10, 4, 5), 86_400)///     from_hms(3, 4, 5).overflowing_sub_signed(TimeDelta::try_hours(-22).unwrap()),///     (from_hms(1, 4, 5), -86_400)/// Subtracts another `NaiveTime` from the current time./// Returns a `TimeDelta` within +/- 1 day./// As a part of Chrono's [leap second handling](#leap-second-handling),/// except when any of the `NaiveTime`s themselves represents a leap second/// let from_hmsm = |h, m, s, milli| NaiveTime::from_hms_milli_opt(h, m, s, milli).unwrap();/// let since = NaiveTime::signed_duration_since;/// assert_eq!(since(from_hmsm(3, 5, 7, 900), from_hmsm(3, 5, 7, 900)), TimeDelta::zero());///     since(from_hmsm(3, 5, 7, 900), from_hmsm(3, 5, 7, 875)),///     TimeDelta::try_milliseconds(25).unwrap()///     since(from_hmsm(3, 5, 7, 900), from_hmsm(3, 5, 6, 925)),///     TimeDelta::try_milliseconds(975).unwrap()///     since(from_hmsm(3, 5, 7, 900), from_hmsm(3, 5, 0, 900)),///     TimeDelta::try_seconds(7).unwrap()///     since(from_hmsm(3, 5, 7, 900), from_hmsm(3, 0, 7, 900)),///     TimeDelta::try_seconds(5 * 60).unwrap()///     since(from_hmsm(3, 5, 7, 900), from_hmsm(0, 5, 7, 900)),///     TimeDelta::try_seconds(3 * 3600).unwrap()///     since(from_hmsm(3, 5, 7, 900), from_hmsm(4, 5, 7, 900)),///     TimeDelta::try_seconds(-3600).unwrap()///     since(from_hmsm(3, 5, 7, 900), from_hmsm(2, 4, 6, 800)),///     TimeDelta::try_seconds(3600 + 60 + 1).unwrap() + TimeDelta::try_milliseconds(100).unwrap()/// # use chrono::{TimeDelta, NaiveTime};/// # let from_hmsm = |h, m, s, milli| { NaiveTime::from_hms_milli_opt(h, m, s, milli).unwrap() };/// # let since = NaiveTime::signed_duration_since;/// assert_eq!(since(from_hmsm(3, 0, 59, 1_000), from_hmsm(3, 0, 59, 0)),///            TimeDelta::try_seconds(1).unwrap());/// assert_eq!(since(from_hmsm(3, 0, 59, 1_500), from_hmsm(3, 0, 59, 0)),///            TimeDelta::try_milliseconds(1500).unwrap());/// assert_eq!(since(from_hmsm(3, 0, 59, 1_000), from_hmsm(3, 0, 0, 0)),///            TimeDelta::try_seconds(60).unwrap());/// assert_eq!(since(from_hmsm(3, 0, 0, 0), from_hmsm(2, 59, 59, 1_000)),/// assert_eq!(since(from_hmsm(3, 0, 59, 1_000), from_hmsm(2, 59, 59, 1_000)),///            TimeDelta::try_seconds(61).unwrap());/// Adds given `FixedOffset` to the current time, and returns the number of days that should be/// added to a date as a result of the offset (either `-1`, `0`, or `1` because the offset is/// always less than 24h)./// This method is similar to [`overflowing_add_signed`](#method.overflowing_add_signed), but/// preserves leap seconds./// Subtracts given `FixedOffset` from the current time, and returns the number of days that/// should be added to a date as a result of the offset (either `-1`, `0`, or `1` because the/// offset is always less than 24h)./// This method is similar to [`overflowing_sub_signed`](#method.overflowing_sub_signed), but/// Formats the time with the specified formatting items./// let fmt = StrftimeItems::new("%H:%M:%S");/// let t = NaiveTime::from_hms_opt(23, 56, 4).unwrap();/// assert_eq!(t.format_with_items(fmt.clone()).to_string(), "23:56:04");/// assert_eq!(t.format("%H:%M:%S").to_string(), "23:56:04");/// # let fmt = StrftimeItems::new("%H:%M:%S").clone();/// # let t = NaiveTime::from_hms_opt(23, 56, 4).unwrap();/// assert_eq!(format!("{}", t.format_with_items(fmt)), "23:56:04");/// Formats the time with the specified format string./// let t = NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap();/// assert_eq!(t.format("%H:%M:%S%.6f").to_string(), "23:56:04.012345");/// assert_eq!(t.format("%-I:%M %p").to_string(), "11:56 PM");/// # let t = NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap();/// assert_eq!(format!("{}", t.format("%H:%M:%S")), "23:56:04");/// assert_eq!(format!("{}", t.format("%H:%M:%S%.6f")), "23:56:04.012345");/// assert_eq!(format!("{}", t.format("%-I:%M %p")), "11:56 PM");hms/// Returns a triple of the hour, minute and second numbers.num_seconds_from_midnight/// Returns the number of non-leap seconds past the last midnight.// This duplicates `Timelike::num_seconds_from_midnight()`, because trait methods can't be const// yet.// This duplicates `Timelike::nanosecond()`, because trait methods can't be const yet./// The earliest possible `NaiveTime`/// use chrono::{NaiveTime, Timelike};/// assert_eq!(NaiveTime::from_hms_opt(0, 0, 0).unwrap().hour(), 0);/// assert_eq!(NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap().hour(), 23);/// assert_eq!(NaiveTime::from_hms_opt(0, 0, 0).unwrap().minute(), 0);/// assert_eq!(NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap().minute(), 56);/// assert_eq!(NaiveTime::from_hms_opt(0, 0, 0).unwrap().second(), 0);/// assert_eq!(NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap().second(), 4);/// This method never returns 60 even when it is a leap second./// ([Why?](#leap-second-handling))/// Use the proper [formatting method](#method.format) to get a human-readable representation./// # use chrono::{NaiveTime, Timelike};/// let leap = NaiveTime::from_hms_milli_opt(23, 59, 59, 1_000).unwrap();/// assert_eq!(leap.second(), 59);/// assert_eq!(leap.format("%H:%M:%S").to_string(), "23:59:60");/// the [leap second](#leap-second-handling)./// assert_eq!(NaiveTime::from_hms_opt(0, 0, 0).unwrap().nanosecond(), 0);///     NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap().nanosecond(),///     12_345_678/// Leap seconds may have seemingly out-of-range return values./// You can reduce the range with `time.nanosecond() % 1_000_000_000`, or/// use the proper [formatting method](#method.format) to get a human-readable representation./// assert_eq!(leap.nanosecond(), 1_000_000_000);/// assert_eq!(leap.format("%H:%M:%S%.9f").to_string(), "23:59:60.000000000");/// Makes a new `NaiveTime` with the hour number changed./// let dt = NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap();/// assert_eq!(dt.with_hour(7), Some(NaiveTime::from_hms_nano_opt(7, 56, 4, 12_345_678).unwrap()));/// Makes a new `NaiveTime` with the minute number changed.///     Some(NaiveTime::from_hms_nano_opt(23, 45, 4, 12_345_678).unwrap())/// Makes a new `NaiveTime` with the second number changed.///     Some(NaiveTime::from_hms_nano_opt(23, 56, 17, 12_345_678).unwrap())/// Makes a new `NaiveTime` with nanoseconds since the whole non-leap second changed./// As with the [`nanosecond`](#method.nanosecond) method,///     Some(NaiveTime::from_hms_nano_opt(23, 56, 4, 333_333_333).unwrap())/// Leap seconds can theoretically follow *any* whole second./// The following would be a proper leap second at the time zone offset of UTC-00:03:57/// (there are several historical examples comparable to this "non-sense" offset),/// and therefore is allowed./// let strange_leap_second = dt.with_nanosecond(1_333_333_333).unwrap();/// assert_eq!(strange_leap_second.nanosecond(), 1_333_333_333);/// assert_eq!(NaiveTime::from_hms_opt(1, 2, 3).unwrap().num_seconds_from_midnight(), 3723);///     NaiveTime::from_hms_nano_opt(23, 56, 4, 12_345_678).unwrap().num_seconds_from_midnight(),///     86164///     NaiveTime::from_hms_milli_opt(23, 59, 59, 1_000).unwrap().num_seconds_from_midnight(),///     86399/// Add `TimeDelta` to `NaiveTime`./// This wraps around and never overflows or underflows./// In particular the addition ignores integral number of days./// second ever**, except when the `NaiveTime` itself represents a leap second in which case the/// assumption becomes that **there is exactly a single leap second ever**./// assert_eq!(from_hmsm(3, 5, 7, 0) + TimeDelta::zero(), from_hmsm(3, 5, 7, 0));/// assert_eq!(from_hmsm(3, 5, 7, 0) + TimeDelta::try_seconds(1).unwrap(), from_hmsm(3, 5, 8, 0));/// assert_eq!(from_hmsm(3, 5, 7, 0) + TimeDelta::try_seconds(-1).unwrap(), from_hmsm(3, 5, 6, 0));///     from_hmsm(3, 5, 7, 0) + TimeDelta::try_seconds(60 + 4).unwrap(),///     from_hmsm(3, 6, 11, 0)///     from_hmsm(3, 5, 7, 0) + TimeDelta::try_seconds(7 * 60 * 60 - 6 * 60).unwrap(),///     from_hmsm(9, 59, 7, 0)///     from_hmsm(3, 5, 7, 0) + TimeDelta::try_milliseconds(80).unwrap(),///     from_hmsm(3, 5, 7, 80)///     from_hmsm(3, 5, 7, 950) + TimeDelta::try_milliseconds(280).unwrap(),///     from_hmsm(3, 5, 8, 230)///     from_hmsm(3, 5, 7, 950) + TimeDelta::try_milliseconds(-980).unwrap(),///     from_hmsm(3, 5, 6, 970)/// The addition wraps around./// assert_eq!(from_hmsm(3, 5, 7, 0) + TimeDelta::try_seconds(22*60*60).unwrap(), from_hmsm(1, 5, 7, 0));/// assert_eq!(from_hmsm(3, 5, 7, 0) + TimeDelta::try_seconds(-8*60*60).unwrap(), from_hmsm(19, 5, 7, 0));/// assert_eq!(from_hmsm(3, 5, 7, 0) + TimeDelta::try_days(800).unwrap(), from_hmsm(3, 5, 7, 0));/// Leap seconds are handled, but the addition assumes that it is the only leap second happened./// let leap = from_hmsm(3, 5, 59, 1_300);/// assert_eq!(leap + TimeDelta::zero(), from_hmsm(3, 5, 59, 1_300));/// assert_eq!(leap + TimeDelta::try_milliseconds(-500).unwrap(), from_hmsm(3, 5, 59, 800));/// assert_eq!(leap + TimeDelta::try_milliseconds(500).unwrap(), from_hmsm(3, 5, 59, 1_800));/// assert_eq!(leap + TimeDelta::try_milliseconds(800).unwrap(), from_hmsm(3, 6, 0, 100));/// assert_eq!(leap + TimeDelta::try_seconds(10).unwrap(), from_hmsm(3, 6, 9, 300));/// assert_eq!(leap + TimeDelta::try_seconds(-10).unwrap(), from_hmsm(3, 5, 50, 300));/// assert_eq!(leap + TimeDelta::try_days(1).unwrap(), from_hmsm(3, 5, 59, 300));/// Add-assign `TimeDelta` to `NaiveTime`./// Add `std::time::Duration` to `NaiveTime`./// Add-assign `std::time::Duration` to `NaiveTime`./// Add `FixedOffset` to `NaiveTime`./// Subtract `TimeDelta` from `NaiveTime`./// In particular the subtraction ignores integral number of days./// This is the same as addition with a negated `TimeDelta`./// As a part of Chrono's [leap second handling], the subtraction assumes that **there is no leap/// assert_eq!(from_hmsm(3, 5, 7, 0) - TimeDelta::zero(), from_hmsm(3, 5, 7, 0));/// assert_eq!(from_hmsm(3, 5, 7, 0) - TimeDelta::try_seconds(1).unwrap(), from_hmsm(3, 5, 6, 0));///     from_hmsm(3, 5, 7, 0) - TimeDelta::try_seconds(60 + 5).unwrap(),///     from_hmsm(3, 4, 2, 0)///     from_hmsm(3, 5, 7, 0) - TimeDelta::try_seconds(2 * 60 * 60 + 6 * 60).unwrap(),///     from_hmsm(0, 59, 7, 0)///     from_hmsm(3, 5, 7, 0) - TimeDelta::try_milliseconds(80).unwrap(),///     from_hmsm(3, 5, 6, 920)///     from_hmsm(3, 5, 7, 950) - TimeDelta::try_milliseconds(280).unwrap(),///     from_hmsm(3, 5, 7, 670)/// The subtraction wraps around./// assert_eq!(from_hmsm(3, 5, 7, 0) - TimeDelta::try_seconds(8*60*60).unwrap(), from_hmsm(19, 5, 7, 0));/// assert_eq!(from_hmsm(3, 5, 7, 0) - TimeDelta::try_days(800).unwrap(), from_hmsm(3, 5, 7, 0));/// Leap seconds are handled, but the subtraction assumes that it is the only leap second happened./// assert_eq!(leap - TimeDelta::zero(), from_hmsm(3, 5, 59, 1_300));/// assert_eq!(leap - TimeDelta::try_milliseconds(200).unwrap(), from_hmsm(3, 5, 59, 1_100));/// assert_eq!(leap - TimeDelta::try_milliseconds(500).unwrap(), from_hmsm(3, 5, 59, 800));/// assert_eq!(leap - TimeDelta::try_seconds(60).unwrap(), from_hmsm(3, 5, 0, 300));/// assert_eq!(leap - TimeDelta::try_days(1).unwrap(), from_hmsm(3, 6, 0, 300));/// Subtract-assign `TimeDelta` from `NaiveTime`./// Subtract `std::time::Duration` from `NaiveTime`./// Subtract-assign `std::time::Duration` from `NaiveTime`./// Subtract `FixedOffset` from `NaiveTime`./// [`NaiveTime::signed_duration_since`](#method.signed_duration_since)./// assert_eq!(from_hmsm(3, 5, 7, 900) - from_hmsm(3, 5, 7, 900), TimeDelta::zero());///     from_hmsm(3, 5, 7, 900) - from_hmsm(3, 5, 7, 875),///     from_hmsm(3, 5, 7, 900) - from_hmsm(3, 5, 6, 925),///     from_hmsm(3, 5, 7, 900) - from_hmsm(3, 5, 0, 900),///     from_hmsm(3, 5, 7, 900) - from_hmsm(3, 0, 7, 900),///     from_hmsm(3, 5, 7, 900) - from_hmsm(0, 5, 7, 900),///     from_hmsm(3, 5, 7, 900) - from_hmsm(4, 5, 7, 900),///     from_hmsm(3, 5, 7, 900) - from_hmsm(2, 4, 6, 800),/// assert_eq!(from_hmsm(3, 0, 59, 1_000) - from_hmsm(3, 0, 59, 0), TimeDelta::try_seconds(1).unwrap());/// assert_eq!(from_hmsm(3, 0, 59, 1_500) - from_hmsm(3, 0, 59, 0),/// assert_eq!(from_hmsm(3, 0, 59, 1_000) - from_hmsm(3, 0, 0, 0), TimeDelta::try_seconds(60).unwrap());/// assert_eq!(from_hmsm(3, 0, 0, 0) - from_hmsm(2, 59, 59, 1_000), TimeDelta::try_seconds(1).unwrap());/// assert_eq!(from_hmsm(3, 0, 59, 1_000) - from_hmsm(2, 59, 59, 1_000),/// The `Debug` output of the naive time `t` is the same as/// [`t.format("%H:%M:%S%.f")`](crate::format::strftime)./// assert_eq!(format!("{:?}", NaiveTime::from_hms_opt(23, 56, 4).unwrap()), "23:56:04");///     format!("{:?}", NaiveTime::from_hms_milli_opt(23, 56, 4, 12).unwrap()),///     "23:56:04.012"///     format!("{:?}", NaiveTime::from_hms_micro_opt(23, 56, 4, 1234).unwrap()),///     "23:56:04.001234"///     format!("{:?}", NaiveTime::from_hms_nano_opt(23, 56, 4, 123456).unwrap()),///     "23:56:04.000123456"///     format!("{:?}", NaiveTime::from_hms_milli_opt(6, 59, 59, 1_500).unwrap()),///     "06:59:60.500"/// The `Display` output of the naive time `t` is the same as/// assert_eq!(format!("{}", NaiveTime::from_hms_opt(23, 56, 4).unwrap()), "23:56:04");///     format!("{}", NaiveTime::from_hms_milli_opt(23, 56, 4, 12).unwrap()),///     format!("{}", NaiveTime::from_hms_micro_opt(23, 56, 4, 1234).unwrap()),///     format!("{}", NaiveTime::from_hms_nano_opt(23, 56, 4, 123456).unwrap()),///     format!("{}", NaiveTime::from_hms_milli_opt(6, 59, 59, 1_500).unwrap()),/// Parsing a `str` into a `NaiveTime` uses the same format,/// [`%H:%M:%S%.f`](crate::format::strftime), as in `Debug` and `Display`./// assert_eq!("23:56:04".parse::<NaiveTime>(), Ok(t));/// assert_eq!("23:56:4.012345678".parse::<NaiveTime>(), Ok(t));/// let t = NaiveTime::from_hms_nano_opt(23, 59, 59, 1_234_567_890).unwrap(); // leap second/// assert_eq!("23:59:60.23456789".parse::<NaiveTime>(), Ok(t));/// // Seconds are optional/// let t = NaiveTime::from_hms_opt(23, 56, 0).unwrap();/// assert_eq!("23:56".parse::<NaiveTime>(), Ok(t));/// assert!("foo".parse::<NaiveTime>().is_err());/// The default value for a NaiveTime is midnight, 00:00:00 exactly./// let default_time = NaiveTime::default();/// assert_eq!(default_time, NaiveTime::from_hms_opt(0, 0, 0).unwrap());//! ISO 8601 time without timezone.NaiveTimeVisitor// TODO not very optimized for space (binary formats would want something better)// TODO round-trip for general leap seconds (not just those with second = 60)test_time_from_hms_millitest_time_from_hms_microtest_time_hmstest_time_addtest_time_overflowing_addtest_time_addassignmenttest_time_subassignmenttest_time_subtest_time_fmttest_time_from_strtest_time_parse_from_strtest_overflowing_offsetlocal_minus_utc/// The time zone with fixed offset, from UTC-23:59:59 to UTC+23:59:59./// Using the [`TimeZone`](./trait.TimeZone.html) methods/// on a `FixedOffset` struct is the preferred way to construct/// `DateTime<FixedOffset>` instances. See the [`east_opt`](#method.east_opt) and/// [`west_opt`](#method.west_opt) methods for examples.east/// Makes a new `FixedOffset` for the Eastern Hemisphere with given timezone difference./// The negative `secs` means the Western Hemisphere./// Panics on the out-of-bound `secs`.east_opt/// Returns `None` on the out-of-bound `secs`./// use chrono::{FixedOffset, TimeZone};/// let datetime =///     FixedOffset::east_opt(5 * hour).unwrap().with_ymd_and_hms(2016, 11, 08, 0, 0, 0).unwrap();/// assert_eq!(&datetime.to_rfc3339(), "2016-11-08T00:00:00+05:00")west/// Makes a new `FixedOffset` for the Western Hemisphere with given timezone difference./// The negative `secs` means the Eastern Hemisphere.west_opt///     FixedOffset::west_opt(5 * hour).unwrap().with_ymd_and_hms(2016, 11, 08, 0, 0, 0).unwrap();/// assert_eq!(&datetime.to_rfc3339(), "2016-11-08T00:00:00-05:00")/// Returns the number of seconds to add to convert from UTC to the local time.utc_minus_local/// Returns the number of seconds to add to convert from the local time to UTC./// Parsing a `str` into a `FixedOffset` uses the format [`%z`](crate::format::strftime).fixtest_date_extreme_offsettest_parse_offset//! The time zone which has a fixed offset from UTC.rkyvArchive"unix.rs""windows.rs"win_bindingstz_info/// The local timescale./// on the Local struct is the preferred way to construct `DateTime<Local>`/// instances./// use chrono::{DateTime, Local, TimeZone};/// let dt1: DateTime<Local> = Local::now();/// let dt2: DateTime<Local> = Local.timestamp_opt(0, 0).unwrap();/// assert!(dt1 >= dt2);today/// Returns a `Date` which corresponds to the current date.now/// Returns a `DateTime<Local>` which corresponds to the current date, time and offset from/// UTC./// See also the similar [`Utc::now()`] which returns `DateTime<Utc>`, i.e. without the local/// offset./// # #![allow(unused_variables)]/// # use chrono::{DateTime, FixedOffset, Local};/// // Current local time/// let now = Local::now();/// // Current local date/// let today = now.date_naive();/// // Current local time, converted to `DateTime<FixedOffset>`/// let now_fixed_offset = Local::now().fixed_offset();/// // or/// let now_fixed_offset: DateTime<FixedOffset> = Local::now().into();/// // Current time in some timezone (let's use +05:00)/// // Note that it is usually more efficient to use `Utc::now` for this use case./// let offset = FixedOffset::east_opt(5 * 60 * 60).unwrap();/// let now_with_offset = Local::now().with_timezone(&offset);transition_utcoffset_beforeoffset_afterlookup_with_dst_transitions// Calculate the time in UTC given a local time and transitions.// `transitions` must be sorted.localverify_correct_offsetsverify_correct_offsets_distant_pastverify_correct_offsets_distant_futuretest_local_date_sanity_checktest_leap_secondtest_lookup_with_dst_transitionstest_lookup_with_dst_transitions_limitstest_rkyv_validation//! The local (system) time zone.SystemTimeErrorrule/// Date time errorFindLocalTimeType/// Local time type search errorLocalTimeType/// Local time type errorInvalidSlice/// Invalid slice for integer conversionInvalidTzFile/// Invalid Tzif fileInvalidTzString/// Invalid TZ string/// I/O error/// Out of range errorParseInt/// Integer parsing errorProjectDateTime/// Date time projection errorSystemTime/// System time error/// Time zone errorTransitionRule/// Transition rule errorUnsupportedTzFile/// Unsupported Tzif fileUnsupportedTzString/// Unsupported TZ string/// UTF-8 error/// Unified error type for everything in the crateHOURS_PER_DAY/// Number of hours in one daySECONDS_PER_HOUR/// Number of seconds in one hourSECONDS_PER_DAY/// Number of seconds in one dayDAYS_PER_WEEK/// Number of days in one weekDAY_IN_MONTHS_NORMAL_YEAR/// Month days in a normal yearCUMUL_DAY_IN_MONTHS_NORMAL_YEAR/// Cumulated month days in a normal yearLeapSecondHeadertime_size/// Time size in bytestransition_times/// Transition times data blocktransition_types/// Transition types data blocklocal_time_types/// Local time types data blocknames/// Time zone names data blockleap_seconds/// Leap seconds data blockstd_walls/// UT/local indicators data blockut_locals/// Standard/wall indicators data block/// TZif data blocks/// Read TZif data blocksparse_time/// Parse time values/// TZif versionut_local_count/// Number of UT/local indicatorsstd_wall_count/// Number of standard/wall indicatorsleap_count/// Number of leap-second recordstransition_count/// Number of transition timestype_count/// Number of local time type recordschar_count/// Number of time zone names bytes/// TZif header/// Slice representing the remaining data to be readread_count/// Number of already read bytes/// A `Cursor` contains a slice of a buffer and a read count./// Construct a new `Cursor` from remaining datapeek/// Returns remaining data/// Returns `true` if data is remainingread_be_u32seek_after/// Read exactly `count` bytes, reducing remaining data and incrementing read countread_tag/// Read bytes and compare them to the provided tagread_optional_tag/// Read bytes if the remaining data is prefixed by the provided tagread_while/// Read bytes as long as the provided predicate is true// Parse an integer out of the ASCII digitsread_until/// Read bytes until the provided predicate is trueread_be_i32read_be_i64V1/// Version 1V2/// Version 2V3/// Version 3SECONDS_PER_WEEK/// Fixed local time typeAlternateTimeAlternate/// Alternate local time types/// Transition rulefrom_tz_string/// Parse a POSIX TZ string containing a time zone description, as described in [the POSIX documentation of the `TZ` environment variable](https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap08.html)./// TZ string extensions from [RFC 8536](https://datatracker.ietf.org/doc/html/rfc8536#section-3.3.1) may be used.find_local_time_type/// Find the local time type associated to the transition rule at the specified Unix time in secondsfind_local_time_type_from_local/// Local time type for standard time/// Local time type for Daylight Saving Timedst_startRuleDay/// Start day of Daylight Saving Timedst_start_time/// Local start day time of Daylight Saving Time, in secondsdst_end/// End day of Daylight Saving Timedst_end_time/// Local end day time of Daylight Saving Time, in seconds/// Transition rule representing alternate local time types/// Construct a transition rule representing alternate local time types/// Find the local time type associated to the alternate transition rule at the specified Unix time in secondsparse_name/// Parse time zone nameparse_offset/// Parse time zone offsetparse_rule_time/// Parse transition rule timeparse_rule_time_extended/// Parse transition rule time with TZ string extensionsparse_hhmmss/// Parse hours, minutes and secondsparse_signed_hhmmss/// Parse signed hours, minutes and secondsJulian1WithoutLeap/// Julian day in `[1, 365]`, without taking occasional Feb 29 into account, which is not referenceableJulian0WithLeap/// Zero-based Julian day in `[0, 365]`, taking occasional Feb 29 into account/// Month in `[1, 12]`/// Week of the month in `[1, 5]`, with `5` representing the last week of the monthweek_day/// Day of the week in `[0, 6]` from SundayMonthWeekday/// Day represented by a month, a month week and a week day/// Transition rule day/// Parse transition rulejulian_1/// Construct a transition rule day represented by a Julian day in `[1, 365]`, without taking occasional Feb 29 into account, which is not referenceablejulian_0/// Construct a transition rule day represented by a zero-based Julian day in `[0, 365]`, taking occasional Feb 29 into accountmonth_weekday/// Construct a transition rule day represented by a month, a month week and a week daytransition_date/// Get the transition date for the provided year/// ## Outputs/// * `month`: Month in `[1, 12]`/// * `month_day`: Day of the month in `[1, 31]`unix_time/// Returns the UTC Unix time in seconds associated to the transition date for the provided year/// Yearmonth_day/// Day of the month in `[1, 31]`/// Hours since midnight in `[0, 23]`/// Minutes in `[0, 59]`/// Seconds in `[0, 60]`, with a possible leap secondUtcDateTime/// UTC date time exprimed in the [proleptic gregorian calendar](https://en.wikipedia.org/wiki/Proleptic_Gregorian_calendar)from_timespec/// Construct a UTC date time from a Unix time in seconds and nanosecondsNANOSECONDS_PER_SECOND/// Number of nanoseconds in one secondSECONDS_PER_MINUTE/// Number of seconds in one minuteMINUTES_PER_HOUR/// Number of minutes in one hourMONTHS_PER_YEAR/// Number of months in one yearDAYS_PER_NORMAL_YEAR/// Number of days in a normal yearDAYS_PER_4_YEARS/// Number of days in 4 years (including 1 leap year)DAYS_PER_100_YEARS/// Number of days in 100 years (including 24 leap years)DAYS_PER_400_YEARS/// Number of days in 400 years (including 97 leap years)UNIX_OFFSET_SECS/// Unix time at `2000-03-01T00:00:00Z` (Wednesday)OFFSET_YEAR/// Offset yearDAY_IN_MONTHS_LEAP_YEAR_FROM_MARCH/// Month days in a leap year from Marchdays_since_unix_epoch/// Compute the number of days since Unix epoch (`1970-01-01T00:00:00Z`)./// ## Inputs/// * `year`: Yearis_leap_year/// Check if a year is a leap yeartest_quotedtest_fulltest_negative_dsttest_negative_hourtest_all_year_dsttest_v3_filetest_rule_daytest_transition_ruletest_transition_rule_overflow/// List of transitions/// List of local time types (cannot be empty)/// List of leap secondsextra_rule/// Extra transition rule applicable after the last transition/// Time zone/// Returns local time zone./// This method in not supported on non-UNIX platforms, and returns the UTC time zone instead.from_posix_tz/// Construct a time zone from a POSIX TZ string, as described in [the POSIX documentation of the `TZ` environment variable](https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap08.html)./// Construct a time zonefrom_file/// Construct a time zone from the contents of a time zone filefrom_tz_data/// Parse TZif data as described in [RFC 8536](https://datatracker.ietf.org/doc/html/rfc8536)./// Construct a time zone with the specified UTC offset in secondsutc/// Construct the time zone associated to UTC/// Find the local time type associated to the time zone at the specified Unix time in secondsTimeZoneRef/// Returns a reference to the time zone/// Reference to a time zone/// Check time zone inputsunix_time_to_unix_leap_time/// Convert Unix time to Unix leap time, from the list of leap seconds in a time zoneunix_leap_time_to_unix_time/// Convert Unix leap time to Unix time, from the list of leap seconds in a time zoneUTC/// The UTC time zoneunix_leap_time/// Unix leap timelocal_time_type_index/// Index specifying the local time type of the transition/// Transition of a TZif file/// Construct a TZif file transition/// Returns Unix leap timecorrection/// Leap second correction/// Leap second of a TZif file/// Construct a TZif file leap second/// Length-prefixed string bufferTimeZoneName/// ASCII-encoded fixed-capacity string, used for storing time zone names/// Construct a time zone name/// man tzfile(5):/// Time zone designations should consist of at least three (3) and no more than six (6) ASCII/// characters from the set of alphanumerics, “-”, and “+”. This is for compatibility with/// POSIX requirements for time zone abbreviations./// Returns time zone name as a byte sliceequal/// Check if two time zone names are equalut_offset/// Offset from UTC in secondsis_dst/// Daylight Saving Time indicator/// Time zone name/// Local time type associated to a time zone/// Construct a local time typewith_offset/// Construct a local time type with the specified UTC offset in seconds/// Returns offset from UTC in seconds/// Returns daylight saving time indicatorfind_tz_file/// Open the TZif file corresponding to a TZ stringfrom_tzdata_bytesfrom_tzdata_filefind_ohos_tz_dataZONE_INFO_DIRECTORIES// Possible system timezone directories/// Number of seconds in one weekSECONDS_PER_28_DAYS/// Number of seconds in 28 daystest_no_dsttest_errortest_v1_file_with_leap_secondstest_v2_filetest_no_tz_stringtest_tz_ascii_strtest_time_zonetest_time_zone_from_posix_tztest_leap_secondstest_leap_seconds_overflow//! Types related to a time zone.thread_local// we have to store the `Cache` in an option as it can't// be initialized in a static context.mtimeLocalTimeEnvironmentzonelast_checkedCacheTZDB_LOCATIONfallback_timezonecurrent_zoneBiasStandardNameStandardDateSYSTEMTIMEStandardBiasDaylightNameDaylightDateDaylightBiasTimeZoneKeyNameDynamicDaylightTimeDisabledDYNAMIC_TIME_ZONE_INFORMATIONwYearwMonthwDayOfWeekwDaywHourwMinutewSecondwMillisecondsTIME_ZONE_INFORMATIONGetTimeZoneInformationForYear// We don't use `SystemTimeToTzSpecificLocalTime` because it doesn't support the same range of dates// as Chrono. Also it really isn't that difficult to work out the correct offset from the provided// DST rules.// This method uses `overflowing_sub_offset` because it is no problem if the transition time in UTC// falls a couple of hours inside the buffer space around the `NaiveDateTime` range (although it is// very theoretical to have a transition at midnight around `NaiveDate::(MIN|MAX)`.// We don't use `TzSpecificLocalTimeToSystemTime` because it doesn't let us choose how to handle// ambiguous cases (during a DST transition). Instead we get the timezone information for the// current year and compute it ourselves, like we do on Unix.std_offset// Offset from UTC during standard time.dst_offset// Offset from UTC during daylight saving time.std_transition// Transition from standard time to daylight saving time, given in local standard time.dst_transition// Transition from daylight saving time to standard time, given in local daylight saving time.TzInfo// The basis for Windows timezone and DST support has been in place since Windows 2000. It does not// allow for complex rules like the IANA timezone database:// - A timezone has the same base offset the whole year.// - There seem to be either zero or two DST transitions (but we support having just one).// - As of Vista(?) only years from 2004 until a few years into the future are supported.// - All other years get the base settings, which seem to be that of the current year.// These details don't matter much, we just work with the offsets and transition dates Windows// returns through `GetTimeZoneInformationForYear` for a particular year.for_yearnaive_date_time_from_system_time/// Resolve a `SYSTEMTIME` object to an `Option<NaiveDateTime>`./// A `SYSTEMTIME` within a `TIME_ZONE_INFORMATION` struct can be zero to indicate there is no/// transition./// If it has year, month and day values it is a concrete date./// If the year is missing the `SYSTEMTIME` is a rule, which this method resolves for the provided/// year. A rule has a month, weekday, and nth weekday of the month as components./// Returns `Err` if any of the values is invalid, which should never happen.SystemTimeToFileTimeTzSpecificLocalTimeToSystemTimeverify_against_tz_specific_local_time_to_system_time/// The result of mapping a local time to a concrete instant in a given time zone./// The calculation to go from a local time (wall clock time) to an instant in UTC can end up in/// three cases:/// * A single, simple result./// * An ambiguous result when the clock is turned backwards during a transition due to for example///   DST./// * No result when the clock is turned forwards during a transition due to for example DST./// When the clock is turned backwards it creates a _fold_ in local time, during which the local/// time is _ambiguous_. When the clock is turned forwards it creates a _gap_ in local time, during/// which the local time is _missing_, or does not exist./// Chrono does not return a default choice or invalid data during time zone transitions, but has/// the `MappedLocalTime` type to help deal with the result correctly./// The type of `T` is usually a [`DateTime`] but may also be only an offset./// The local time maps to a single unique result.Ambiguous/// The local time is _ambiguous_ because there is a _fold_ in the local time./// This variant contains the two possible results, in the order `(earliest, latest)`./// The local time does not exist because there is a _gap_ in the local time./// This variant may also be returned if there was an error while resolving the local time,/// caused by for example missing time zone data files, an error in an OS API, or overflow./// Old name of [`MappedLocalTime`]. See that type for more documentation.single/// Returns `Some` if the time zone mapping has a single result./// Returns `None` if local time falls in a _fold_ or _gap_ in the local time, or if there was/// Returns the earliest possible result of the time zone mapping./// Returns `None` if local time falls in a _gap_ in the local time, or if there was an error.latest/// Returns the latest possible result of the time zone mapping./// Maps a `MappedLocalTime<T>` into `MappedLocalTime<U>` with given function.and_then/// Returns `MappedLocalTime::None` if the function returns `None`./// Propagates any error. Ambiguous result would be discarded.unwrap/// Returns a single unique conversion result or panics./// `unwrap()` is best combined with time zone types where the mapping can never fail like/// [`Utc`] and [`FixedOffset`]. Note that for [`FixedOffset`] there is a rare case where a/// resulting [`DateTime`] can be out of range./// Panics if the local time falls within a _fold_ or a _gap_ in the local time, and on any/// error that may have been returned by the type implementing [`TimeZone`]./// Returns the fixed offset from UTC to the local time stored./// The offset from the local time to UTC./// An associated offset type./// This type is used to store the actual offset in date and time types./// The original `TimeZone` value can be recovered via `TimeZone::from_offset`.with_ymd_and_hms/// Make a new `DateTime` from year, month, day, time components and current time zone./// This assumes the proleptic Gregorian calendar, with the year 0 being 1 BCE./// Returns `MappedLocalTime::None` on invalid input data.ymd/// Makes a new `Date` from year, month, day and the current time zone./// The time zone normally does not affect the date (unless it is between UTC-24 and UTC+24),/// but it will propagate to the `DateTime` values constructed via this date./// Panics on the out-of-range date, invalid month and/or day.ymd_opt/// Returns `None` on the out-of-range date, invalid month and/or day.yo/// Makes a new `Date` from year, day of year (DOY or "ordinal") and the current time zone./// Panics on the out-of-range date and/or invalid DOY.yo_opt/// Returns `None` on the out-of-range date and/or invalid DOY.isoywd/// Makes a new `Date` from ISO week date (year and week number), day of the week (DOW) and/// the current time zone./// The resulting `Date` may have a different year from the input year./// Panics on the out-of-range date and/or invalid week number.isoywd_opt/// Returns `None` on the out-of-range date and/or invalid week number./// Makes a new `DateTime` from the number of non-leap seconds/// [leap second](crate::NaiveTime#leap-second-handling), but only when `secs % 60 == 59`./// Panics on the out-of-range number of seconds and/or invalid nanosecond,/// for a non-panicking version see [`timestamp_opt`](#method.timestamp_opt).timestamp_opt/// Returns `MappedLocalTime::None` on out-of-range number of seconds and/or/// invalid nanosecond, otherwise always returns `MappedLocalTime::Single`./// use chrono::{TimeZone, Utc};/// assert_eq!(Utc.timestamp_opt(1431648000, 0).unwrap().to_string(), "2015-05-15 00:00:00 UTC");/// Makes a new `DateTime` from the number of non-leap milliseconds/// since January 1, 1970 0:00:00 UTC (aka "UNIX timestamp")./// Panics on out-of-range number of milliseconds for a non-panicking/// version see [`timestamp_millis_opt`](#method.timestamp_millis_opt).timestamp_millis_opt/// Returns `MappedLocalTime::None` on out-of-range number of milliseconds/// and/or invalid nanosecond, otherwise always returns/// `MappedLocalTime::Single`./// use chrono::{MappedLocalTime, TimeZone, Utc};/// match Utc.timestamp_millis_opt(1431648000) {///     MappedLocalTime::Single(dt) => assert_eq!(dt.timestamp(), 1431648),///     _ => panic!("Incorrect timestamp_millis"),/// Makes a new `DateTime` from the number of non-leap nanoseconds/// Unlike [`timestamp_millis_opt`](#method.timestamp_millis_opt), this never fails./// assert_eq!(Utc.timestamp_nanos(1431648000000000).timestamp(), 1431648);/// Makes a new `DateTime` from the number of non-leap microseconds/// assert_eq!(Utc.timestamp_micros(1431648000000).unwrap().timestamp(), 1431648);datetime_from_str/// Parses a string with the specified format string and returns a/// `DateTime` with the current offset./// See the [`crate::format::strftime`] module on the/// supported escape sequences./// If the to-be-parsed string includes an offset, it *must* match the/// offset of the TimeZone, otherwise an error will be returned./// See also [`DateTime::parse_from_str`] which gives a [`DateTime`] with/// parsed [`FixedOffset`]./// See also [`NaiveDateTime::parse_from_str`] which gives a [`NaiveDateTime`] without/// an offset, but can be converted to a [`DateTime`] with [`NaiveDateTime::and_utc`] or/// [`NaiveDateTime::and_local_timezone`]./// Reconstructs the time zone from the offset./// Creates the offset(s) for given local `NaiveDate` if possible./// Creates the offset(s) for given local `NaiveDateTime` if possible.from_local_date/// Converts the local `NaiveDate` to the timezone-aware `Date` if possible.from_local_datetime/// Converts the local `NaiveDateTime` to the timezone-aware `DateTime` if possible./// Creates the offset for given UTC `NaiveDate`. This cannot fail./// Creates the offset for given UTC `NaiveDateTime`. This cannot fail.from_utc_date/// Converts the UTC `NaiveDate` to the local time./// The UTC is continuous and thus this cannot fail (but can give the duplicate local time).from_utc_datetime/// Converts the UTC `NaiveDateTime` to the local time./// The time zone./// The methods here are the primary constructors for the [`DateTime`] type.test_fixed_offset_min_max_datestest_negative_millistest_negative_nanostest_nanos_never_panicstest_negative_micros//! The time zone, which calculates offsets from the local time to UTC.//! There are four operations provided by the `TimeZone` trait://! 1. Converting the local `NaiveDateTime` to `DateTime<Tz>`//! 2. Converting the UTC `NaiveDateTime` to `DateTime<Tz>`//! 3. Converting `DateTime<Tz>` to the local `NaiveDateTime`//! 4. Constructing `DateTime<Tz>` objects from various offsets//! 1 is used for constructors. 2 is used for the `with_timezone` method of date and time types.//! 3 is used for other methods, e.g. `year()` or `format()`, and provided by an associated type//! which implements `Offset` (which then passed to `TimeZone` for actual implementations).//! Technically speaking `TimeZone` has a total knowledge about given timescale,//! but `Offset` is used as a cache to avoid the repeated conversion//! and provides implementations for 1 and 3.//! An `TimeZone` instance can be reconstructed from the corresponding `Offset` instance./// The UTC time zone. This is the most efficient time zone when you don't need the local time./// It is also used as an offset (which is also a dummy type)./// on the UTC struct is the preferred way to construct `DateTime<Utc>`/// let dt = DateTime::from_timestamp(61, 0).unwrap();/// assert_eq!(Utc.timestamp_opt(61, 0).unwrap(), dt);/// assert_eq!(Utc.with_ymd_and_hms(1970, 1, 1, 0, 1, 1).unwrap(), dt);//! The UTC (Coordinated Universal Time) time zone.round_subsecs/// Return a copy rounded to the specified number of subsecond digits. With/// 9 or more digits, self is returned unmodified. Halfway values are/// rounded up (away from zero)./// ``` rust/// # use chrono::{SubsecRound, Timelike, NaiveDate};/// let dt = NaiveDate::from_ymd_opt(2018, 1, 11)///     .and_hms_milli_opt(12, 0, 0, 154)/// assert_eq!(dt.round_subsecs(2).nanosecond(), 150_000_000);/// assert_eq!(dt.round_subsecs(1).nanosecond(), 200_000_000);trunc_subsecs/// Return a copy truncated to the specified number of subsecond/// digits. With 9 or more digits, self is returned unmodified./// assert_eq!(dt.trunc_subsecs(2).nanosecond(), 150_000_000);/// assert_eq!(dt.trunc_subsecs(1).nanosecond(), 100_000_000);/// Extension trait for subsecond rounding or truncation to a maximum number/// of digits. Rounding can be used to decrease the error variance when/// serializing/persisting to lower precision. Truncation is the default/// behavior in Chrono display formatting.  Either can be used to guarantee/// equality (e.g. for testing) when round-tripping through a lower precisionspan_for_digits// Return the maximum span in nanoseconds for the target number of digits./// Error that can occur in rounding or truncatingduration_round/// Return a copy rounded by TimeDelta./// # use chrono::{DurationRound, TimeDelta, NaiveDate};///     dt.duration_round(TimeDelta::try_milliseconds(10).unwrap()).unwrap().to_string(),///     "2018-01-11 12:00:00.150 UTC"///     dt.duration_round(TimeDelta::try_days(1).unwrap()).unwrap().to_string(),///     "2018-01-12 00:00:00 UTC"duration_trunc/// Return a copy truncated by TimeDelta.///     dt.duration_trunc(TimeDelta::try_milliseconds(10).unwrap()).unwrap().to_string(),///     dt.duration_trunc(TimeDelta::try_days(1).unwrap()).unwrap().to_string(),///     "2018-01-11 00:00:00 UTC"duration_round_up/// Return a copy rounded **up** by TimeDelta.///     dt.duration_round_up(TimeDelta::milliseconds(10)).unwrap().to_string(),///     "2018-01-11 12:00:00.160 UTC"///     dt.duration_round_up(TimeDelta::hours(1)).unwrap().to_string(),///     "2018-01-11 13:00:00 UTC"///     dt.duration_round_up(TimeDelta::days(1)).unwrap().to_string(),/// Extension trait for rounding or truncating a DateTime by a TimeDelta./// Both rounding and truncating are done via [`TimeDelta::num_nanoseconds`] and/// [`DateTime::timestamp_nanos_opt`]. This means that they will fail if either the/// `TimeDelta` or the `DateTime` are too big to represented as nanoseconds. They/// will also fail if the `TimeDelta` is bigger than the timestamp, negative or zero.DurationExceedsTimestamp/// Error when the TimeDelta exceeds the TimeDelta from or until the Unix epoch./// Note: this error is not produced anymore.DurationExceedsLimit/// Error when `TimeDelta.num_nanoseconds` exceeds the limit./// # use chrono::{DurationRound, TimeDelta, RoundingError, NaiveDate};/// let dt = NaiveDate::from_ymd_opt(2260, 12, 31)///     .and_hms_nano_opt(23, 59, 59, 1_75_500_000)///     dt.duration_round(TimeDelta::try_days(300 * 365).unwrap()),///     Err(RoundingError::DurationExceedsLimit)TimestampExceedsLimit/// Error when `DateTime.timestamp_nanos` exceeds the limit./// # use chrono::{DurationRound, TimeDelta, RoundingError, TimeZone, Utc};/// let dt = Utc.with_ymd_and_hms(2300, 12, 12, 0, 0, 0).unwrap();///     dt.duration_round(TimeDelta::try_days(1).unwrap()),///     Err(RoundingError::TimestampExceedsLimit)/// An error from rounding by `TimeDelta`/// See: [`DurationRound`]test_round_subsecstest_round_leap_nanostest_trunc_subsecstest_trunc_leap_nanostest_duration_roundtest_duration_round_naivetest_duration_round_pre_epochtest_duration_trunctest_duration_trunc_naivetest_duration_trunc_pre_epochissue1010test_duration_trunc_close_to_epochtest_duration_round_close_to_epochtest_duration_round_close_to_min_maxtest_duration_round_uptest_duration_round_up_naivetest_duration_round_up_pre_epochtest_duration_round_up_close_to_min_max//! Functionality for rounding or truncating a `DateTime` by a `TimeDelta`.NANOS_PER_MICRO/// The number of nanoseconds in a microsecond.NANOS_PER_MILLI/// The number of nanoseconds in a millisecond./// The number of nanoseconds in seconds.MICROS_PER_SEC/// The number of microseconds per second.MILLIS_PER_SEC/// The number of milliseconds per second.SECS_PER_MINUTE/// The number of seconds in a minute.SECS_PER_HOUR/// The number of seconds in an hour.SECS_PER_DAY/// The number of (non-leap) seconds in days.SECS_PER_WEEK/// The number of (non-leap) seconds in a week.nanos// Always 0 <= nanos < NANOS_PER_SEC/// Time duration with nanosecond precision./// This also allows for negative durations; see individual methods for details./// A `TimeDelta` is represented internally as a complement of seconds and/// nanoseconds. The range is restricted to that of `i64` milliseconds, with the/// minimum value notably being set to `-i64::MAX` rather than allowing the full/// range of `i64::MIN`. This is to allow easy flipping of sign, so that for/// instance `abs()` can be called without any checks./// The minimum possible `TimeDelta`: `-i64::MAX` milliseconds./// The maximum possible `TimeDelta`: `i64::MAX` milliseconds./// Makes a new `TimeDelta` with given number of seconds and nanoseconds./// Returns `None` when the duration is out of bounds, or if `nanos` ≥ 1,000,000,000.weeks/// Makes a new `TimeDelta` with the given number of weeks./// Equivalent to `TimeDelta::seconds(weeks * 7 * 24 * 60 * 60)` with/// overflow checks./// Panics when the duration is out of bounds.try_weeks/// Equivalent to `TimeDelta::try_seconds(weeks * 7 * 24 * 60 * 60)` with/// Returns `None` when the `TimeDelta` would be out of bounds./// Makes a new `TimeDelta` with the given number of days./// Equivalent to `TimeDelta::seconds(days * 24 * 60 * 60)` with overflow/// Panics when the `TimeDelta` would be out of bounds.try_days/// Equivalent to `TimeDelta::try_seconds(days * 24 * 60 * 60)` with overflowhours/// Makes a new `TimeDelta` with the given number of hours./// Equivalent to `TimeDelta::seconds(hours * 60 * 60)` with overflow checks.try_hours/// Equivalent to `TimeDelta::try_seconds(hours * 60 * 60)` with overflow checks.minutes/// Makes a new `TimeDelta` with the given number of minutes./// Equivalent to `TimeDelta::seconds(minutes * 60)` with overflow checks.try_minutes/// Equivalent to `TimeDelta::try_seconds(minutes * 60)` with overflow checks.seconds/// Makes a new `TimeDelta` with the given number of seconds./// Panics when `seconds` is more than `i64::MAX / 1_000` or less than `-i64::MAX / 1_000`/// (in this context, this is the same as `i64::MIN / 1_000` due to rounding).try_seconds/// Returns `None` when `seconds` is more than `i64::MAX / 1_000` or less than/// `-i64::MAX / 1_000` (in this context, this is the same as `i64::MIN / 1_000` due to/// rounding).milliseconds/// Makes a new `TimeDelta` with the given number of milliseconds./// Panics when the `TimeDelta` would be out of bounds, i.e. when `milliseconds` is more than/// `i64::MAX` or less than `-i64::MAX`. Notably, this is not the same as `i64::MIN`.try_milliseconds/// Returns `None` the `TimeDelta` would be out of bounds, i.e. when `milliseconds` is more/// than `i64::MAX` or less than `-i64::MAX`. Notably, this is not the same as `i64::MIN`.microseconds/// Makes a new `TimeDelta` with the given number of microseconds./// The number of microseconds acceptable by this constructor is less than/// the total number that can actually be stored in a `TimeDelta`, so it is/// not possible to specify a value that would be out of bounds. This/// function is therefore infallible.nanoseconds/// Makes a new `TimeDelta` with the given number of nanoseconds./// The number of nanoseconds acceptable by this constructor is less thannum_weeks/// Returns the total number of whole weeks in the `TimeDelta`./// Returns the total number of whole days in the `TimeDelta`.num_hours/// Returns the total number of whole hours in the `TimeDelta`.num_minutes/// Returns the total number of whole minutes in the `TimeDelta`.num_seconds/// Returns the total number of whole seconds in the `TimeDelta`.as_seconds_f64/// Returns the fractional number of seconds in the `TimeDelta`.as_seconds_f32num_milliseconds/// Returns the total number of whole milliseconds in the `TimeDelta`.subsec_millis/// Returns the number of milliseconds in the fractional part of the duration./// This is the number of milliseconds such that/// `subsec_millis() + num_seconds() * 1_000` is the truncated number of/// milliseconds in the duration.num_microseconds/// Returns the total number of whole microseconds in the `TimeDelta`,/// or `None` on overflow (exceeding 2^63 microseconds in either direction).subsec_micros/// Returns the number of microseconds in the fractional part of the duration./// This is the number of microseconds such that/// `subsec_micros() + num_seconds() * 1_000_000` is the truncated number of/// microseconds in the duration.num_nanoseconds/// Returns the total number of whole nanoseconds in the `TimeDelta`,/// or `None` on overflow (exceeding 2^63 nanoseconds in either direction).subsec_nanos/// Returns the number of nanoseconds in the fractional part of the duration./// This is the number of nanoseconds such that/// `subsec_nanos() + num_seconds() * 1_000_000_000` is the total number of/// nanoseconds in the `TimeDelta`.checked_add/// Add two `TimeDelta`s, returning `None` if overflow occurred.checked_sub/// Subtract two `TimeDelta`s, returning `None` if overflow occurred.checked_mul/// Multiply a `TimeDelta` with a i32, returning `None` if overflow occurred.checked_div/// Divide a `TimeDelta` with a i32, returning `None` if dividing by 0.abs/// Returns the `TimeDelta` as an absolute (non-negative) value.min_valuemax_value/// A `TimeDelta` where the stored seconds and nanoseconds are equal to zero./// Returns `true` if the `TimeDelta` equals `TimeDelta::zero()`.from_stdOutOfRangeError/// Creates a `TimeDelta` object from `std::time::Duration`/// This function errors when original duration is larger than the maximum/// value supported for this type.to_std/// Creates a `std::time::Duration` object from a `TimeDelta`./// This function errors when duration is less than zero. As standard/// library implementation is limited to non-negative values./// This duplicates `Neg::neg` because trait methods can't be const yet./// Format a `TimeDelta` using the [ISO 8601] format/// [ISO 8601]: https://en.wikipedia.org/wiki/ISO_8601#Durations/// Represents error when converting `TimeDelta` to/from a standard library/// implementation/// The `std::time::Duration` supports a range from zero to `u64::MAX`/// *seconds*, while this module supports signed range of up to/// `i64::MAX` of *milliseconds*.div_mod_floor_64test_durationtest_duration_num_daystest_duration_num_secondstest_duration_seconds_max_allowedtest_duration_seconds_max_overflowtest_duration_seconds_max_overflow_panictest_duration_seconds_min_allowedtest_duration_seconds_min_underflowtest_duration_seconds_min_underflow_panictest_duration_as_seconds_f64test_duration_as_seconds_f32test_duration_subsec_nanostest_duration_subsec_microstest_duration_subsec_millistest_duration_num_millisecondstest_duration_milliseconds_max_allowedtest_duration_milliseconds_max_overflowtest_duration_milliseconds_min_allowedtest_duration_milliseconds_min_underflowtest_duration_milliseconds_min_underflow_panictest_duration_num_microsecondstest_duration_microseconds_max_allowedtest_duration_microseconds_max_overflowtest_duration_microseconds_min_allowedtest_duration_microseconds_min_underflowtest_duration_num_nanosecondstest_duration_nanoseconds_max_allowedtest_duration_nanoseconds_max_overflowtest_duration_nanoseconds_min_allowedtest_duration_nanoseconds_min_underflowtest_maxtest_mintest_duration_ordtest_duration_checked_opstest_duration_abstest_duration_multest_duration_divtest_duration_sumtest_duration_fmttest_to_stdtest_from_stdtest_duration_const//! Temporal quantification/// Returns the year number in the [calendar date](./naive/struct.NaiveDate.html#calendar-date).year_ce/// Returns the absolute year number starting from 1 with a boolean flag,/// which is false when the year predates the epoch (BCE/BC) and true otherwise (CE/AD)./// Returns the quarter number starting from 1./// The return value ranges from 1 to 4./// Returns the ISO week./// Makes a new value with the year number changed, while keeping the same month and day./// Returns `None` when:/// - The year is out of range for [`NaiveDate`]./// - In case of [`DateTime<Tz>`] if the resulting date and time fall within a timezone///   transition such as from DST to standard time./// [`NaiveDate`]: crate::NaiveDate/// [`DateTime<Tz>`]: crate::DateTime///     NaiveDate::from_ymd_opt(2020, 5, 13).unwrap().with_year(2023).unwrap(),///     NaiveDate::from_ymd_opt(2023, 5, 13).unwrap()/// // Resulting date 2023-02-29 does not exist:/// assert!(NaiveDate::from_ymd_opt(2020, 2, 29).unwrap().with_year(2023).is_none());/// // Don't use `with_year` if you want the ordinal date to stay the same:/// Makes a new value with the month number (starting from 1) changed./// - The value for `month` is out of range.///     NaiveDate::from_ymd_opt(2023, 5, 12).unwrap().with_month(9).unwrap(),///     NaiveDate::from_ymd_opt(2023, 9, 12).unwrap()/// // Resulting date 2023-09-31 does not exist:/// assert!(NaiveDate::from_ymd_opt(2023, 5, 31).unwrap().with_month(9).is_none());/// Makes a new value with the month number (starting from 0) changed./// - The value for `month0` is out of range./// Makes a new value with the day of month (starting from 1) changed./// - The value for `day` is out of range./// Makes a new value with the day of month (starting from 0) changed./// - The resulting date does not exist (for example `day0(30)` in April)./// - The value for `day0` is out of range./// Makes a new value with the day of year (starting from 1) changed./// - The value for `ordinal` is out of range./// Makes a new value with the day of year (starting from 0) changed./// - The value for `ordinal0` is out of range./// assert_eq!(NaiveDate::from_ymd_opt(1970, 1, 1).unwrap().num_days_from_ce(), 719_163);/// assert_eq!(NaiveDate::from_ymd_opt(2, 1, 1).unwrap().num_days_from_ce(), 366);/// assert_eq!(NaiveDate::from_ymd_opt(1, 1, 1).unwrap().num_days_from_ce(), 1);/// assert_eq!(NaiveDate::from_ymd_opt(0, 1, 1).unwrap().num_days_from_ce(), -365);num_days_in_month/// The common set of methods for date component./// Methods such as [`year`], [`month`], [`day`] and [`weekday`] can be used to get basic/// information about the date./// The `with_*` methods can change the date./// The `with_*` methods can be convenient to change a single component of a date, but they must be/// used with some care. Examples to watch out for:/// - [`with_year`] changes the year component of a year-month-day value. Don't use this method if///   you want the ordinal to stay the same after changing the year, of if you want the week and///   weekday values to stay the same./// - Don't combine two `with_*` methods to change two components of the date. For example to///   change both the year and month components of a date. This could fail because an intermediate///   value does not exist, while the final date would be valid./// For more complex changes to a date, it is best to use the methods on [`NaiveDate`] to create a/// new value instead of altering an existing date./// [`year`]: Datelike::year/// [`month`]: Datelike::month/// [`day`]: Datelike::day/// [`weekday`]: Datelike::weekday/// [`with_year`]: Datelike::with_yearhour12/// Returns the hour number from 1 to 12 with a boolean flag,/// which is false for AM and true for PM./// the [leap second](./naive/struct.NaiveTime.html#leap-second-handling)./// Makes a new value with the hour number changed./// Returns `None` when the resulting value would be invalid./// Makes a new value with the minute number changed./// Makes a new value with the second number changed./// As with the [`second`](#tymethod.second) method,/// Makes a new value with nanoseconds since the whole non-leap second changed./// As with the [`nanosecond`](#tymethod.nanosecond) method,/// Every value in 00:00:00-23:59:59 maps to an integer in 0-86399./// This method is not intended to provide the real number of seconds since midnight on a given/// day. It does not take things like DST transitions into account./// The common set of methods for time component.test_num_days_from_ce_against_alternative_impl/// Tests `Datelike::num_days_from_ce` against an alternative implementation./// The alternative implementation is not as short as the current one but it is simpler to/// understand, with less unexplained magic constants.test_num_days_in_monthMon/// Monday.Tue/// Tuesday.Wed/// Wednesday.Thu/// Thursday.Fri/// Friday.Sat/// Saturday.Sun/// Sunday./// The day of week./// The order of the days of week depends on the context./// (This is why this type does *not* implement `PartialOrd` or `Ord` traits.)/// One should prefer `*_from_monday` or `*_from_sunday` methods to get the correct result./// let monday = "Monday".parse::<Weekday>().unwrap();/// assert_eq!(monday, Weekday::Mon);/// let sunday = Weekday::try_from(6).unwrap();/// assert_eq!(sunday, Weekday::Sun);/// assert_eq!(sunday.num_days_from_monday(), 6); // starts counting with Monday = 0/// assert_eq!(sunday.number_from_monday(), 7); // starts counting with Monday = 1/// assert_eq!(sunday.num_days_from_sunday(), 0); // starts counting with Sunday = 0/// assert_eq!(sunday.number_from_sunday(), 1); // starts counting with Sunday = 1/// assert_eq!(sunday.succ(), monday);/// assert_eq!(sunday.pred(), Weekday::Sat);/// The next day in the week./// `w`:        | `Mon` | `Tue` | `Wed` | `Thu` | `Fri` | `Sat` | `Sun`/// ----------- | ----- | ----- | ----- | ----- | ----- | ----- | -----/// `w.succ()`: | `Tue` | `Wed` | `Thu` | `Fri` | `Sat` | `Sun` | `Mon`/// The previous day in the week./// `w.pred()`: | `Sun` | `Mon` | `Tue` | `Wed` | `Thu` | `Fri` | `Sat`number_from_monday/// Returns a day-of-week number starting from Monday = 1. (ISO 8601 weekday number)/// `w`:                      | `Mon` | `Tue` | `Wed` | `Thu` | `Fri` | `Sat` | `Sun`/// ------------------------- | ----- | ----- | ----- | ----- | ----- | ----- | -----/// `w.number_from_monday()`: | 1     | 2     | 3     | 4     | 5     | 6     | 7number_from_sunday/// Returns a day-of-week number starting from Sunday = 1./// `w.number_from_sunday()`: | 2     | 3     | 4     | 5     | 6     | 7     | 1num_days_from_monday/// Returns a day-of-week number starting from Monday = 0./// `w`:                        | `Mon` | `Tue` | `Wed` | `Thu` | `Fri` | `Sat` | `Sun`/// --------------------------- | ----- | ----- | ----- | ----- | ----- | ----- | -----/// `w.num_days_from_monday()`: | 0     | 1     | 2     | 3     | 4     | 5     | 6/// # use chrono::{Local, Datelike};/// // MTWRFSU is occasionally used as a single-letter abbreviation of the weekdays./// // Use `num_days_from_monday` to index into the array./// const MTWRFSU: [char; 7] = ['M', 'T', 'W', 'R', 'F', 'S', 'U'];/// let today = Local::now().weekday();/// println!("{}", MTWRFSU[today.num_days_from_monday() as usize]);num_days_from_sunday/// Returns a day-of-week number starting from Sunday = 0./// `w.num_days_from_sunday()`: | 1     | 2     | 3     | 4     | 5     | 6     | 0days_since/// The number of days since the given day./// use chrono::Weekday::*;/// assert_eq!(Mon.days_since(Mon), 0);/// assert_eq!(Sun.days_since(Tue), 5);/// assert_eq!(Wed.days_since(Sun), 3);/// Any weekday can be represented as an integer from 0 to 6, which equals to/// [`Weekday::num_days_from_monday`](#method.num_days_from_monday) in this implementation./// Do not heavily depend on this though; use explicit methods whenever possible./// An error resulting from reading `Weekday` value with `FromStr`.test_days_sincetest_formatting_alignment// the actual `FromStr` implementation is in the `format` module to leverage the existing code/// A collection of [`Weekday`]s stored as a single byte./// This type is `Copy` and provides efficient set-like and slice-like operations./// Many operations are `const` as well./// Implemented as a bitmask where bits 1-7 correspond to Monday-Sunday.from_array/// Create a `WeekdaySet` from an array of [`Weekday`]s./// # use chrono::WeekdaySet;/// assert_eq!(WeekdaySet::EMPTY, WeekdaySet::from_array([]));/// assert_eq!(WeekdaySet::single(Mon), WeekdaySet::from_array([Mon]));/// assert_eq!(WeekdaySet::ALL, WeekdaySet::from_array([Mon, Tue, Wed, Thu, Fri, Sat, Sun]));/// Create a `WeekdaySet` from a single [`Weekday`].single_day/// Returns `Some(day)` if this collection contains exactly one day./// Returns `None` otherwise./// assert_eq!(WeekdaySet::single(Mon).single_day(), Some(Mon));/// assert_eq!(WeekdaySet::from_array([Mon, Tue]).single_day(), None);/// assert_eq!(WeekdaySet::EMPTY.single_day(), None);/// assert_eq!(WeekdaySet::ALL.single_day(), None);/// Adds a day to the collection./// Returns `true` if the day was new to the collection./// let mut weekdays = WeekdaySet::single(Mon);/// assert!(weekdays.insert(Tue));/// assert!(!weekdays.insert(Tue));/// Removes a day from the collection./// Returns `true` if the collection did contain the day./// assert!(weekdays.remove(Mon));/// assert!(!weekdays.remove(Mon));is_subset/// Returns `true` if `other` contains all days in `self`./// assert!(WeekdaySet::single(Mon).is_subset(WeekdaySet::ALL));/// assert!(!WeekdaySet::single(Mon).is_subset(WeekdaySet::EMPTY));/// assert!(WeekdaySet::EMPTY.is_subset(WeekdaySet::single(Mon)));/// Returns days that are in both `self` and `other`./// assert_eq!(WeekdaySet::single(Mon).intersection(WeekdaySet::single(Mon)), WeekdaySet::single(Mon));/// assert_eq!(WeekdaySet::single(Mon).intersection(WeekdaySet::single(Tue)), WeekdaySet::EMPTY);/// assert_eq!(WeekdaySet::ALL.intersection(WeekdaySet::single(Mon)), WeekdaySet::single(Mon));/// assert_eq!(WeekdaySet::ALL.intersection(WeekdaySet::EMPTY), WeekdaySet::EMPTY);/// Returns days that are in either `self` or `other`./// assert_eq!(WeekdaySet::single(Mon).union(WeekdaySet::single(Mon)), WeekdaySet::single(Mon));/// assert_eq!(WeekdaySet::single(Mon).union(WeekdaySet::single(Tue)), WeekdaySet::from_array([Mon, Tue]));/// assert_eq!(WeekdaySet::ALL.union(WeekdaySet::single(Mon)), WeekdaySet::ALL);/// assert_eq!(WeekdaySet::ALL.union(WeekdaySet::EMPTY), WeekdaySet::ALL);/// Returns days that are in `self` or `other` but not in both./// assert_eq!(WeekdaySet::single(Mon).symmetric_difference(WeekdaySet::single(Mon)), WeekdaySet::EMPTY);/// assert_eq!(WeekdaySet::single(Mon).symmetric_difference(WeekdaySet::single(Tue)), WeekdaySet::from_array([Mon, Tue]));///     WeekdaySet::ALL.symmetric_difference(WeekdaySet::single(Mon)),///     WeekdaySet::from_array([Tue, Wed, Thu, Fri, Sat, Sun]),/// assert_eq!(WeekdaySet::ALL.symmetric_difference(WeekdaySet::EMPTY), WeekdaySet::ALL);/// Returns days that are in `self` but not in `other`./// assert_eq!(WeekdaySet::single(Mon).difference(WeekdaySet::single(Mon)), WeekdaySet::EMPTY);/// assert_eq!(WeekdaySet::single(Mon).difference(WeekdaySet::single(Tue)), WeekdaySet::single(Mon));/// assert_eq!(WeekdaySet::EMPTY.difference(WeekdaySet::single(Mon)), WeekdaySet::EMPTY);/// Get the first day in the collection, starting from Monday./// Returns `None` if the collection is empty./// assert_eq!(WeekdaySet::single(Mon).first(), Some(Mon));/// assert_eq!(WeekdaySet::single(Tue).first(), Some(Tue));/// assert_eq!(WeekdaySet::ALL.first(), Some(Mon));/// assert_eq!(WeekdaySet::EMPTY.first(), None);/// Get the last day in the collection, starting from Sunday./// assert_eq!(WeekdaySet::single(Mon).last(), Some(Mon));/// assert_eq!(WeekdaySet::single(Sun).last(), Some(Sun));/// assert_eq!(WeekdaySet::from_array([Mon, Tue]).last(), Some(Tue));/// assert_eq!(WeekdaySet::EMPTY.last(), None);split_at/// Split the collection in two at the given day./// Returns a tuple `(before, after)`. `before` contains all days starting from Monday/// up to but __not__ including `weekday`. `after` contains all days starting from `weekday`/// up to and including Sunday.WeekdaySetIter/// Iterate over the [`Weekday`]s in the collection starting from a given day./// Wraps around from Sunday to Monday if necessary./// let weekdays = WeekdaySet::from_array([Mon, Wed, Fri]);/// let mut iter = weekdays.iter(Wed);/// assert_eq!(iter.next(), Some(Wed));/// assert_eq!(iter.next(), Some(Fri));/// assert_eq!(iter.next(), Some(Mon));/// assert_eq!(iter.next(), None);/// Returns `true` if the collection contains the given day./// assert!(WeekdaySet::single(Mon).contains(Mon));/// assert!(WeekdaySet::from_array([Mon, Tue]).contains(Tue));/// assert!(!WeekdaySet::single(Mon).contains(Tue));/// Returns `true` if the collection is empty./// # use chrono::{Weekday, WeekdaySet};/// assert!(WeekdaySet::EMPTY.is_empty());/// assert!(!WeekdaySet::single(Weekday::Mon).is_empty());/// Returns the number of days in the collection./// assert_eq!(WeekdaySet::single(Mon).len(), 1);/// assert_eq!(WeekdaySet::from_array([Mon, Wed, Fri]).len(), 3);/// assert_eq!(WeekdaySet::ALL.len(), 7);/// An empty `WeekdaySet`./// A `WeekdaySet` containing all seven `Weekday`s./// Print the underlying bitmask, padded to 7 bits./// assert_eq!(format!("{:?}", WeekdaySet::single(Mon)), "WeekdaySet(0000001)");/// assert_eq!(format!("{:?}", WeekdaySet::single(Tue)), "WeekdaySet(0000010)");/// assert_eq!(format!("{:?}", WeekdaySet::ALL), "WeekdaySet(1111111)");/// An iterator over a collection of weekdays, starting from a given day./// See [`WeekdaySet::iter()`]./// Print the collection as a slice-like list of weekdays./// assert_eq!("[]", WeekdaySet::EMPTY.to_string());/// assert_eq!("[Mon]", WeekdaySet::single(Mon).to_string());/// assert_eq!("[Mon, Fri, Sun]", WeekdaySet::from_array([Mon, Fri, Sun]).to_string());iter_all/// Iterate over all 128 possible sets, from `EMPTY` to `ALL`.assert_8th_bit_invariant/// Panics if the 8-th bit of `self` is not 0.debug_prints_8th_bit_if_not_zerobitwise_set_operations_preserve_8th_bit_invariantsplit_at_is_equivalent_to_iterating/// Test `split_at` on all possible arguments.// Invariant: the 8-th bit is always 0.BlockCipherKey/// Key for an algorithm that implements [`NewBlockCipher`]./// Block on which a [`BlockCipher`] operates./// Block on which a [`BlockCipher`] operates in parallel./// Key size in bytes with which cipher guaranteed to be initialized./// Create new block cipher instance from key with fixed size./// Create new block cipher instance from key with variable size./// Default implementation will accept only keys with length equal to/// `KeySize`, but some ciphers can accept range of key lengths./// Instantiate a [`BlockCipher`] algorithm./// Size of the block in bytes/// Number of blocks which can be processed in parallel by/// cipher implementation/// Trait which marks a type as being a block cipher./// Encrypt block in-place/// Encrypt several blocks in parallel using instruction level parallelism/// if possible./// If `ParBlocks` equals to 1 it's equivalent to `encrypt_block`.encrypt_blocks/// Encrypt a slice of blocks, leveraging parallelism when available./// Encrypt-only functionality for block ciphers./// Decrypt block in-place/// Decrypt several blocks in parallel using instruction level parallelism/// If `ParBlocks` equals to 1 it's equivalent to `decrypt_block`.decrypt_blocks/// Decrypt a slice of blocks, leveraging parallelism when available./// Decrypt-only functionality for block ciphers.encrypt_block_mutBlockEncryptMut/// Encrypt-only functionality for block ciphers with mutable access to `self`./// The main use case for this trait is hardware encryption engines which/// require `&mut self` access to an underlying hardware peripheral.decrypt_block_mutBlockDecryptMut/// Decrypt-only functionality for block ciphers with mutable access to `self`.//! Traits used to define functionality of [block ciphers][1].//! # About block ciphers//! Block ciphers are keyed, deterministic permutations of a fixed-sized input//! "block" providing a reversible transformation to/from an encrypted output.//! They are one of the fundamental structural components of [symmetric cryptography][2].//! [1]: https://en.wikipedia.org/wiki/Block_cipher//! [2]: https://en.wikipedia.org/wiki/Symmetric-key_algorithm// Impls of block cipher traits for reference typesCipherKeyNewCipher/// Key for an algorithm that implements [`NewCipher`]./// Nonce for an algorithm that implements [`NewCipher`]./// Key size in bytes/// Nonce size in bytes/// Create new stream cipher instance from key and nonce arrays.new_from_slices/// Create new stream cipher instance from variable length key and nonce/// given as byte slices./// Cipher creation trait./// It can be used for creation of block modes, synchronous and asynchronous stream ciphers./// Block cipherfrom_block_cipher/// Instantiate a stream cipher from a block cipher/// Trait for types which can be initialized from a block cipher and nonce.block_cipher_test/// Define block cipher testblock_cipher_bench/// Define block cipher benchmarkstream_cipher_test/// Test core functionality of synchronous stream cipherstream_cipher_seek_test/// Test stream synchronous stream cipher seeking capabilitiesstream_cipher_async_test/// Test core functionality of asynchronous stream cipherstream_cipher_sync_bench/// Create synchronous stream cipher benchmarksstream_cipher_async_bench/// Create asynchronous stream cipher benchmarksstream/// The error type returned when stream cipher has reached the end of a keystream./// The error type returned when key and/or nonce used in stream cipher/// initialization had an invalid length./// The error type returned when a cipher position can not be represented/// by the requested type.//! Error types.//! This crate defines a set of traits which describe the functionality of//! [block ciphers][1] and [stream ciphers][2].//! [2]: https://en.wikipedia.org/wiki/Stream_cipherapply_keystream/// Apply keystream to the data./// It will XOR generated keystream with the data, which can be both/// encryption and decryption./// If end of the keystream will be reached with the given data length,/// method will panic without modifying the provided `data`.try_apply_keystream/// Apply keystream to the data, but return an error if end of a keystream/// will be reached./// If end of the keystream will be achieved with the given data length,/// method will return `Err(LoopError)` without modifying provided `data`./// Synchronous stream cipher core trait.try_current_pos/// Try to get current keystream position/// Returns [`LoopError`] if position can not be represented by type `T`try_seek/// Try to seek to the given position/// Returns [`LoopError`] if provided position value is bigger than/// keystream length.current_pos/// Get current keystream position/// If position can not be represented by type `T`/// Seek to the given position/// If provided position value is bigger than keystream leangth/// Trait for seekable stream ciphers./// Methods of this trait are generic over the [`SeekNum`] trait, which is/// implemented for primitive numeric types, i.e.: `i/u8`, `i/u16`, `i/u32`,/// `i/u64`, `i/u128`, and `i/usize`./// Encrypt data in place./// Decrypt data in place.AsyncStreamCipher/// Asynchronous stream cipher core trait.from_block_byte/// Try to get position for block number `block`, byte position inside/// block `byte`, and block size `bs`.to_block_byte/// Try to get block number and bytes position for given block size `bs`./// Trait implemented for numeric types which can be used with the/// [`StreamCipherSeek`] trait./// This trait is implemented for primitive numeric types, i.e. `i/u8`,/// `u16`, `u32`, `u64`, `u128`, `usize`, and `i32`. It is not intended/// to be implemented in third-party crates.impl_seek_num//! Traits which define functionality of stream ciphers.//! See [RustCrypto/stream-ciphers](https://github.com/RustCrypto/stream-ciphers)//! for ciphers implementation.optimizer_hideconstant_time_ne/// Compares two equal-sized byte strings in constant time./// use constant_time_eq::constant_time_eq;/// assert!(constant_time_eq(b"foo", b"foo"));/// assert!(!constant_time_eq(b"foo", b"bar"));/// assert!(!constant_time_eq(b"bar", b"baz"));/// # assert!(constant_time_eq(b"", b""));/// // Not equal-sized, so won't take constant time./// assert!(!constant_time_eq(b"foo", b""));/// assert!(!constant_time_eq(b"foo", b"quux"));constant_time_ne_nconstant_time_eq_n/// Compares two fixed-size byte strings in constant time./// use constant_time_eq::constant_time_eq_n;/// assert!(constant_time_eq_n(&[3; 20], &[3; 20]));/// assert!(!constant_time_eq_n(&[3; 20], &[7; 20]));constant_time_eq_16/// Compares two 128-bit byte strings in constant time./// use constant_time_eq::constant_time_eq_16;/// assert!(constant_time_eq_16(&[3; 16], &[3; 16]));/// assert!(!constant_time_eq_16(&[3; 16], &[7; 16]));constant_time_eq_32/// Compares two 256-bit byte strings in constant time./// use constant_time_eq::constant_time_eq_32;/// assert!(constant_time_eq_32(&[3; 32], &[3; 32]));/// assert!(!constant_time_eq_32(&[3; 32], &[7; 32]));constant_time_eq_64/// Compares two 512-bit byte strings in constant time./// use constant_time_eq::constant_time_eq_64;/// assert!(constant_time_eq_64(&[3; 64], &[3; 64]));/// assert!(!constant_time_eq_64(&[3; 64], &[7; 64]));// Fixed-size array variant.// Fixed-size variants for the most common sizes.__unless_target_features// Evaluate the given `$body` expression any of the supplied target features// are not enabled. Otherwise returns true.__detect_target_features// Apple platform's runtime detection of target CPU features using `sysctlbyname`.// Apple OS (macOS, iOS, watchOS, and tvOS) `check!` macro.// NOTE: several of these instructions (e.g. `aes`, `sha2`) can be assumed to// be present on all Apple ARM64 hardware.// Newer CPU instructions now have nodes within sysctl's `hw.optional`// namespace, however the ones that do not can safely be assumed to be// present on all Apple ARM64 devices, now and for the foreseeable future.// See discussion on this issue for more information:// <https://github.com/RustCrypto/utils/issues/378>sysctlbyname/// Apple helper function for calling `sysctlbyname`.//! ARM64 CPU feature detection support.//! Unfortunately ARM instructions to detect CPU features cannot be called from//! unprivileged userspace code, so this implementation relies on OS-specific//! APIs for feature detection./// Create module with CPU feature detection code.//! This crate provides macros for runtime CPU feature detection. It's intended//! as a stopgap until Rust [RFC 2725] adding first-class target feature detection//! macros to `libcore` is implemented.//! # Supported target architectures//! *NOTE: target features with an asterisk are unstable (nightly-only) and//! subject to change to match upstream name changes in the Rust standard//! library.//! ## `aarch64`//! Linux, iOS, and macOS/ARM only (ARM64 does not support OS-independent feature detection)//! Target features://! - `aes`*//! - `sha2`*//! - `sha3`*//! Linux only//! - `sm4`*//! ## `loongarch64`//! Linux only (LoongArch64 does not support OS-independent feature detection)//! - `lam`*//! - `ual`*//! - `fpu`*//! - `lsx`*//! - `lasx`*//! - `crc32`*//! - `complex`*//! - `crypto`*//! - `lvz`*//! - `lbt.x86`*//! - `lbt.arm`*//! - `lbt.mips`*//! - `ptw`*//! ## `x86`/`x86_64`//! OS independent and `no_std`-friendly//! - `adx`//! - `aes`//! - `avx`//! - `avx2`//! - `avx512bw`*//! - `avx512cd`*//! - `avx512dq`*//! - `avx512er`*//! - `avx512f`*//! - `avx512ifma`*//! - `avx512pf`*//! - `avx512vl`*//! - `bmi1`//! - `bmi2`//! - `fma`,//! - `mmx`//! - `pclmulqdq`//! - `popcnt`//! - `rdrand`//! - `rdseed`//! - `sgx`//! - `sha`//! - `sse`//! - `sse2`//! - `sse3`//! - `sse4.1`//! - `sse4.2`//! - `ssse3`//! If you would like detection support for a target feature which is not on//! this list, please [open a GitHub issue][gh].//! # #[cfg(any(target_arch = "x86", target_arch = "x86_64"))]//! // This macro creates `cpuid_aes_sha` module//! cpufeatures::new!(cpuid_aes_sha, "aes", "sha");//! // `token` is a Zero Sized Type (ZST) value, which guarantees//! // that underlying static storage got properly initialized,//! // which allows to omit initialization branch//! let token: cpuid_aes_sha::InitToken = cpuid_aes_sha::init();//! if token.get() {//!     println!("CPU supports both SHA and AES extensions");//!     println!("SHA and AES extensions are not supported");//! // If stored value needed only once you can get stored value//! // omitting the token//! let val = cpuid_aes_sha::get();//! assert_eq!(val, token.get());//! // Additionally you can get both token and value//! let (token, val) = cpuid_aes_sha::init_get();//! Note that if all tested target features are enabled via compiler options//! (e.g. by using `RUSTFLAGS`), the `get` method will always return `true`//! and `init` will not use CPUID instruction. Such behavior allows//! compiler to completely eliminate fallback code.//! After first call macro caches result and returns it in subsequent//! calls, thus runtime overhead for them is minimal.//! [RFC 2725]: https://github.com/rust-lang/rfcs/pull/2725//! [gh]: https://github.com/RustCrypto/utils/issues/new?title=cpufeatures:%20requesting%20support%20for%20CHANGEME%20target%20feature// Linux runtime detection of target CPU features using `getauxval`.getauxval_hwcap/// Linux helper function for calling `getauxval` to get `AT_HWCAP`.__expand_check_macro// Linux `expand_check_macro`CPUCFGLAMUALFPULSXLASXCRC32COMPLEXCRYPTOLVZLBT_X86LBT_ARMLBT_MIPSPTWhwcaps/// Linux hardware capabilities mapped to target features./// Note that LLVM target features are coarser grained than what Linux supports/// and imply more capabilities under each feature. This module attempts to/// provide that mapping accordingly.// On other targets, runtime CPU feature detection is unavailable//! LoongArch64 CPU feature detection support.//! This implementation relies on OS-specific APIs for feature detection.//! Minimal miri support.//! Miri is an interpreter, and though it tries to emulate the target CPU//! it does not support any target features./// Evaluate the given `$body` expression any of the supplied target features/// are not enabled. Otherwise returns true./// The `$body` expression is not evaluated on SGX targets, and returns false/// on these targets unless *all* supplied target features are enabled./// Use CPUID to detect the presence of all supplied target features.__xgetbv/// Check that OS supports required SIMD registers//! x86/x86-64 CPU feature detection support.//! Portable, `no_std`-friendly implementation that relies on the x86 `CPUID`//! instruction for feature detection.AtomicIsizeAtomicPtrepochAtomicBackoffCachePaddedMIN_CAP// Minimum buffer capacity.MAX_BATCH// Maximum number of tasks that can be stolen in `steal_batch()` and `steal_batch_and_pop()`.FLUSH_THRESHOLD_BYTES// If a buffer of at least this size is retired, thread-local garbage is flushed so that it gets// deallocated as soon as possible./// Pointer to the allocated memory./// Capacity of the buffer. Always a power of two./// A buffer that holds tasks in a worker queue./// This is just a pointer to the buffer and its length - dropping an instance of this struct will/// *not* deallocate the buffer./// Allocates a new buffer with the specified capacity./// Deallocates the buffer./// Returns a pointer to the task at the specified `index`./// Writes `task` into the specified `index`./// This method might be concurrently called with another `read` at the same index, which is/// technically speaking a data race and therefore UB. We should use an atomic store here, but/// that would be more expensive and difficult to implement generically for all types `T`./// Hence, as a hack, we use a volatile write instead./// Reads a task from the specified `index`./// This method might be concurrently called with another `write` at the same index, which is/// technically speaking a data race and therefore UB. We should use an atomic load here, but/// Hence, as a hack, we use a volatile load instead.front/// The front index.back/// The back index./// The underlying buffer./// Internal queue data shared between the worker and stealers./// The implementation is based on the following work:/// 1. [Chase and Lev. Dynamic circular work-stealing deque. SPAA 2005.][chase-lev]/// 2. [Le, Pop, Cohen, and Nardelli. Correct and efficient work-stealing for weak memory models.///    PPoPP 2013.][weak-mem]/// 3. [Norris and Demsky. CDSchecker: checking concurrent data structures written with C/C++///    atomics. OOPSLA 2013.][checker]/// [chase-lev]: https://dl.acm.org/citation.cfm?id=1073974/// [weak-mem]: https://dl.acm.org/citation.cfm?id=2442524/// [checker]: https://dl.acm.org/citation.cfm?id=2509514FlavorFifo/// The first-in first-out flavor.Lifo/// The last-in first-out flavor./// Worker queue flavor: FIFO or LIFO./// A reference to the inner representation of the queue./// A copy of `inner.buffer` for quick access.flavor/// The flavor of the queue./// Indicates that the worker cannot be shared among threads.// !Send + !SyncWorker/// A worker queue./// This is a FIFO or LIFO queue that is owned by a single thread, but other threads may steal/// tasks from it. Task schedulers typically create a single worker queue per thread./// A FIFO worker:/// use crossbeam_deque::{Steal, Worker};/// let w = Worker::new_fifo();/// let s = w.stealer();/// w.push(1);/// w.push(2);/// w.push(3);/// assert_eq!(s.steal(), Steal::Success(1));/// assert_eq!(w.pop(), Some(2));/// assert_eq!(w.pop(), Some(3));/// A LIFO worker:/// let w = Worker::new_lifo();new_fifo/// Creates a FIFO worker queue./// Tasks are pushed and popped from opposite ends./// use crossbeam_deque::Worker;/// let w = Worker::<i32>::new_fifo();new_lifo/// Creates a LIFO worker queue./// Tasks are pushed and popped from the same end./// let w = Worker::<i32>::new_lifo();stealerStealer/// Creates a stealer for this queue./// The returned stealer can be shared among threads and cloned./// Resizes the internal buffer to the new capacity of `new_cap`./// Reserves enough capacity so that `reserve_cap` tasks can be pushed without growing the/// Returns `true` if the queue is empty./// assert!(w.is_empty());/// assert!(!w.is_empty());/// Returns the number of tasks in the deque./// assert_eq!(w.len(), 0);/// assert_eq!(w.len(), 1);/// assert_eq!(w.len(), 2);/// Pushes a task into the queue./// Pops a task from the queue./// assert_eq!(w.pop(), Some(1));/// assert_eq!(w.pop(), None);/// A stealer handle of a worker queue./// Stealers can be shared among threads./// Task schedulers typically have a single worker queue per worker thread./// assert_eq!(s.steal(), Steal::Success(2));/// assert_eq!(s.steal(), Steal::Empty);/// assert!(!s.is_empty());/// assert_eq!(s.len(), 1);/// assert_eq!(s.len(), 2);stealSteal/// Steals a task from the queue.steal_batch/// Steals a batch of tasks and pushes them into another worker./// How many tasks exactly will be stolen is not specified. That said, this method will try to/// steal around half of the tasks in the queue, but also not more than some constant limit./// let w1 = Worker::new_fifo();/// w1.push(1);/// w1.push(2);/// w1.push(3);/// w1.push(4);/// let s = w1.stealer();/// let w2 = Worker::new_fifo();/// let _ = s.steal_batch(&w2);/// assert_eq!(w2.pop(), Some(1));/// assert_eq!(w2.pop(), Some(2));steal_batch_with_limit/// Steals no more than `limit` of tasks and pushes them into another worker./// steal around half of the tasks in the queue, but also not more than the given limit./// w1.push(5);/// w1.push(6);/// let _ = s.steal_batch_with_limit(&w2, 2);/// assert_eq!(w2.pop(), None);/// w1.push(7);/// w1.push(8);/// // Setting a large limit does not guarantee that all elements will be popped. In this case,/// // half of the elements are currently popped, but the number of popped elements is considered/// // an implementation detail that may be changed in the future./// let _ = s.steal_batch_with_limit(&w2, std::usize::MAX);/// assert_eq!(w2.len(), 3);steal_batch_and_pop/// Steals a batch of tasks, pushes them into another worker, and pops a task from that worker./// assert_eq!(s.steal_batch_and_pop(&w2), Steal::Success(1));steal_batch_with_limit_and_pop/// Steals no more than `limit` of tasks, pushes them into another worker, and pops a task from/// that worker./// assert_eq!(s.steal_batch_with_limit_and_pop(&w2, 2), Steal::Success(1));/// assert_eq!(s.steal_batch_with_limit_and_pop(&w2, std::usize::MAX), Steal::Success(3));/// assert_eq!(w2.pop(), Some(4));/// assert_eq!(w2.pop(), Some(5));WRITE// Bits indicating the state of a slot:// * If a task has been written into the slot, `WRITE` is set.// * If a task has been read from the slot, `READ` is set.// * If the block is being destroyed, `DESTROY` is set.READDESTROYLAP// Each block covers one "lap" of indices.BLOCK_CAP// The maximum number of values a block can hold.SHIFT// How many lower bits are reserved for metadata.HAS_NEXT// Indicates that the block is not the last one./// The task./// The state of the slot.Slot/// A slot in a block.wait_write/// Waits until a task is written into the slot./// The next block in the linked list.slots/// Slots for values./// A block in a linked list./// Each block in the list can hold up to `BLOCK_CAP` values.LAYOUT/// Creates an empty block.wait_next/// Waits until the next pointer is set.destroy/// Sets the `DESTROY` bit in slots starting from `start` and destroys the block./// The index in the queue./// The block in the linked list.Position/// A position in a queue.head/// The head of the queue.tail/// The tail of the queue./// Indicates that dropping a `Injector<T>` may drop values of type `T`.Injector/// An injector queue./// This is a FIFO queue that can be shared among multiple threads. Task schedulers typically have/// a single injector queue, which is the entry point for new tasks./// use crossbeam_deque::{Injector, Steal};/// let q = Injector::new();/// q.push(1);/// q.push(2);/// assert_eq!(q.steal(), Steal::Success(1));/// assert_eq!(q.steal(), Steal::Success(2));/// assert_eq!(q.steal(), Steal::Empty);/// Creates a new injector queue./// use crossbeam_deque::Injector;/// let q = Injector::<i32>::new();/// let w = Injector::new();/// Steals a batch of tasks and pushes them into a worker./// use crossbeam_deque::{Injector, Worker};/// q.push(3);/// q.push(4);/// let _ = q.steal_batch(&w);/// Steals no more than of tasks and pushes them into a worker./// q.push(5);/// q.push(6);/// let _ = q.steal_batch_with_limit(&w, 2);/// q.push(7);/// q.push(8);/// let _ = q.steal_batch_with_limit(&w, std::usize::MAX);/// assert_eq!(w.len(), 3);/// Steals a batch of tasks, pushes them into a worker, and pops a task from that worker./// use crossbeam_deque::{Injector, Steal, Worker};/// assert_eq!(q.steal_batch_and_pop(&w), Steal::Success(1));/// Steals no more than `limit` of tasks, pushes them into a worker, and pops a task from that worker./// assert_eq!(q.steal_batch_with_limit_and_pop(&w, 2), Steal::Success(1));/// assert_eq!(q.steal_batch_with_limit_and_pop(&w, std::usize::MAX), Steal::Success(3));/// assert_eq!(w.pop(), Some(4));/// assert_eq!(w.pop(), Some(5));/// assert!(q.is_empty());/// assert!(!q.is_empty());/// Returns the number of tasks in the queue./// assert_eq!(q.len(), 0);/// assert_eq!(q.len(), 1);/// assert_eq!(q.len(), 2);/// The queue was empty at the time of stealing.Success/// At least one task was successfully stolen.Retry/// The steal operation needs to be retried./// Possible outcomes of a steal operation./// There are lots of ways to chain results of steal operations together:/// use crossbeam_deque::Steal::{self, Empty, Retry, Success};/// let collect = |v: Vec<Steal<i32>>| v.into_iter().collect::<Steal<i32>>();/// assert_eq!(collect(vec![Empty, Empty, Empty]), Empty);/// assert_eq!(collect(vec![Empty, Retry, Empty]), Retry);/// assert_eq!(collect(vec![Retry, Success(1), Empty]), Success(1));/// assert_eq!(collect(vec![Empty, Empty]).or_else(|| Retry), Retry);/// assert_eq!(collect(vec![Retry, Empty]).or_else(|| Success(1)), Success(1));/// Returns `true` if the queue was empty at the time of stealing./// use crossbeam_deque::Steal::{Empty, Retry, Success};/// assert!(!Success(7).is_empty());/// assert!(!Retry::<i32>.is_empty());/// assert!(Empty::<i32>.is_empty());is_success/// Returns `true` if at least one task was stolen./// assert!(!Empty::<i32>.is_success());/// assert!(!Retry::<i32>.is_success());/// assert!(Success(7).is_success());is_retry/// Returns `true` if the steal operation needs to be retried./// assert!(!Empty::<i32>.is_retry());/// assert!(!Success(7).is_retry());/// assert!(Retry::<i32>.is_retry());success/// Returns the result of the operation, if successful./// assert_eq!(Empty::<i32>.success(), None);/// assert_eq!(Retry::<i32>.success(), None);/// assert_eq!(Success(7).success(), Some(7));or_else/// If no task was stolen, attempts another steal operation./// Returns this steal result if it is `Success`. Otherwise, closure `f` is invoked and then:/// * If the second steal resulted in `Success`, it is returned./// * If both steals were unsuccessful but any resulted in `Retry`, then `Retry` is returned./// * If both resulted in `None`, then `None` is returned./// assert_eq!(Success(1).or_else(|| Success(2)), Success(1));/// assert_eq!(Retry.or_else(|| Success(2)), Success(2));/// assert_eq!(Retry.or_else(|| Empty), Retry::<i32>);/// assert_eq!(Empty.or_else(|| Retry), Retry::<i32>);/// assert_eq!(Empty.or_else(|| Empty), Empty::<i32>);/// Consumes items until a `Success` is found and returns it./// If no `Success` was found, but there was at least one `Retry`, then returns `Retry`./// Otherwise, `Empty` is returned.deque//! Concurrent work-stealing deques.//! These data structures are most commonly used in work-stealing schedulers. The typical setup//! involves a number of threads, each having its own FIFO or LIFO queue (*worker*). There is also//! one global FIFO queue (*injector*) and a list of references to *worker* queues that are able to//! steal tasks (*stealers*).//! We spawn a new task onto the scheduler by pushing it into the *injector* queue. Each worker//! thread waits in a loop until it finds the next task to run and then runs it. To find a task, it//! first looks into its local *worker* queue, and then into the *injector* and *stealers*.//! # Queues//! [`Injector`] is a FIFO queue, where tasks are pushed and stolen from opposite ends. It is//! shared among threads and is usually the entry point for new tasks.//! [`Worker`] has two constructors://! * [`new_fifo()`] - Creates a FIFO queue, in which tasks are pushed and popped from opposite//!   ends.//! * [`new_lifo()`] - Creates a LIFO queue, in which tasks are pushed and popped from the same//!   end.//! Each [`Worker`] is owned by a single thread and supports only push and pop operations.//! Method [`stealer()`] creates a [`Stealer`] that may be shared among threads and can only steal//! tasks from its [`Worker`]. Tasks are stolen from the end opposite to where they get pushed.//! # Stealing//! Steal operations come in three flavors://! 1. [`steal()`] - Steals one task.//! 2. [`steal_batch()`] - Steals a batch of tasks and moves them into another worker.//! 3. [`steal_batch_and_pop()`] - Steals a batch of tasks, moves them into another queue, and pops//!    one task from that worker.//! In contrast to push and pop operations, stealing can spuriously fail with [`Steal::Retry`], in//! which case the steal operation needs to be retried.//! Suppose a thread in a work-stealing scheduler is idle and looking for the next task to run. To//! find an available task, it might do the following://! 1. Try popping one task from the local worker queue.//! 2. Try stealing a batch of tasks from the global injector queue.//! 3. Try stealing one task from another thread using the stealer list.//! An implementation of this work-stealing strategy://! use crossbeam_deque::{Injector, Stealer, Worker};//! use std::iter;//! fn find_task<T>(//!     local: &Worker<T>,//!     global: &Injector<T>,//!     stealers: &[Stealer<T>],//! ) -> Option<T> {//!     // Pop a task from the local queue, if not empty.//!     local.pop().or_else(|| {//!         // Otherwise, we need to look for a task elsewhere.//!         iter::repeat_with(|| {//!             // Try stealing a batch of tasks from the global queue.//!             global.steal_batch_and_pop(local)//!                 // Or try stealing a task from one of the other threads.//!                 .or_else(|| stealers.iter().map(|s| s.steal()).collect())//!         })//!         // Loop while no task was stolen and any steal operation needs to be retried.//!         .find(|s| !s.is_retry())//!         // Extract the stolen task, if there is one.//!         .and_then(|s| s.success())//!     })//! [`new_fifo()`]: Worker::new_fifo//! [`new_lifo()`]: Worker::new_lifo//! [`stealer()`]: Worker::stealer//! [`steal()`]: Stealer::steal//! [`steal_batch()`]: Stealer::steal_batch//! [`steal_batch_and_pop()`]: Stealer::steal_batch_and_popguardGuardprimitiveAtomicConsumestrongest_failure_ordering/// Given ordering for the success case in a compare-exchange operation, returns the strongest/// appropriate ordering for the failure case.'gCompareAndSetErrorCompareExchangeError/// The error returned on failed compare-and-set operation.// TODO: remove in the next major version.currentShared/// The value in the atomic pointer at the time of the failed operation./// The new value, which the operation failed to store.Pointable/// The error returned on failed compare-and-swap operation./// The ordering of the operation when it succeeds.failure/// The ordering of the operation when it fails./// The failure ordering can't be `Release` or `AcqRel` and must be equivalent or weaker than/// the success ordering.CompareAndSetOrdering/// Memory orderings for compare-and-set operations./// A compare-and-set operation can have different memory orderings depending on whether it/// succeeds or fails. This trait generalizes different ways of specifying memory orderings./// The two ways of specifying orderings for compare-and-set are:/// 1. Just one `Ordering` for the success case. In case of failure, the strongest appropriate///    ordering is chosen./// 2. A pair of `Ordering`s. The first one is for the success case, while the second one is///    for the failure case.low_bits/// Returns a bitmask containing the unused least significant bits of an aligned pointer to `T`.ensure_aligned/// Panics if the pointer is not properly unaligned.compose_tag/// Given a tagged pointer `data`, returns the same pointer, but tagged with `tag`./// `tag` is truncated to fit into the unused bits of the pointer to `T`.decompose_tag/// Decomposes a tagged pointer `data` into the pointer and the tag.ALIGN/// The alignment of pointer./// The type for initializers./// Initializes a with the given initializer./// The result should be a multiple of `ALIGN`./// Dereferences the given pointer./// - The given `ptr` should have been initialized with [`Pointable::init`]./// - `ptr` should not have yet been dropped by [`Pointable::drop`]./// - `ptr` should not be mutably dereferenced by [`Pointable::deref_mut`] concurrently./// Mutably dereferences the given pointer./// - `ptr` should not be dereferenced by [`Pointable::deref`] or [`Pointable::deref_mut`]///   concurrently./// Drops the object pointed to by the given pointer./// Types that are pointed to by a single word./// In concurrent programming, it is necessary to represent an object within a word because atomic/// operations (e.g., reads, writes, read-modify-writes) support only single words.  This trait/// qualifies such types that are pointed to by a single word./// The trait generalizes `Box<T>` for a sized type `T`.  In a box, an object of type `T` is/// allocated in heap and it is owned by a single-word pointer.  This trait is also implemented for/// `[MaybeUninit<T>]` by storing its size along with its elements and pointing to the pair of array/// size and elements./// Pointers to `Pointable` types can be stored in [`Atomic`], [`Owned`], and [`Shared`].  In/// particular, Crossbeam supports dynamically sized slices as follows./// use std::mem::MaybeUninit;/// use crossbeam_epoch::Owned;/// let o = Owned::<[MaybeUninit<i32>]>::init(10); // allocating [i32; 10]/// The number of elements (not the number of bytes)./// Array with size./// # Memory layout/// An array consisting of size and elements:///          elements///          |/// ------------------------------------/// | size | 0 | 1 | 2 | 3 | 4 | 5 | 6 |/// Its memory layout is different from that of `Box<[T]>` in that size is in the allocation (not/// along with pointer as in `Box<[T]>`)./// Elements are not present in the type, but they will be in the allocation./// An atomic pointer that can be safely shared between threads./// The pointer must be properly aligned. Since it is aligned, a tag can be stored into the unused/// least significant bits of the address. For example, the tag for a pointer to a sized type `T`/// should be less than `(1 << mem::align_of::<T>().trailing_zeros())`./// Any method that loads the pointer must be passed a reference to a [`Guard`]./// Crossbeam supports dynamically sized types.  See [`Pointable`] for details./// Allocates `value` on the heap and returns a new atomic pointer pointing to it./// use crossbeam_epoch::Atomic;/// let a = Atomic::new(1234);/// # unsafe { drop(a.into_owned()); } // avoid leak/// let a = Atomic::<i32>::init(1234);from_usize/// Returns a new atomic pointer pointing to the tagged pointer `data`./// Returns a new null atomic pointer./// let a = Atomic::<i32>::null();/// Loads a `Shared` from the atomic pointer./// This method takes an [`Ordering`] argument which describes the memory ordering of this/// operation./// use crossbeam_epoch::{self as epoch, Atomic};/// use std::sync::atomic::Ordering::SeqCst;/// let guard = &epoch::pin();/// let p = a.load(SeqCst, guard);load_consume/// Loads a `Shared` from the atomic pointer using a "consume" memory ordering./// This is similar to the "acquire" ordering, except that an ordering is/// only guaranteed with operations that "depend on" the result of the load./// However consume loads are usually much faster than acquire loads on/// architectures with a weak memory model since they don't require memory/// fence instructions./// The exact definition of "depend on" is a bit vague, but it works as you/// would expect in practice since a lot of software, especially the Linux/// kernel, rely on this behavior./// let p = a.load_consume(guard);store/// Stores a `Shared` or `Owned` pointer into the atomic pointer./// use crossbeam_epoch::{Atomic, Owned, Shared};/// # unsafe { drop(a.load(SeqCst, &crossbeam_epoch::pin()).into_owned()); } // avoid leak/// a.store(Shared::null(), SeqCst);/// a.store(Owned::new(1234), SeqCst);/// Stores a `Shared` or `Owned` pointer into the atomic pointer, returning the previous/// `Shared`./// use crossbeam_epoch::{self as epoch, Atomic, Shared};/// let p = a.swap(Shared::null(), SeqCst, guard);/// # unsafe { drop(p.into_owned()); } // avoid leakcompare_exchange/// Stores the pointer `new` (either `Shared` or `Owned`) into the atomic pointer if the current/// value is the same as `current`. The tag is also taken into account, so two pointers to the/// same object, but with different tags, will not be considered equal./// The return value is a result indicating whether the new pointer was written. On success the/// pointer that was written is returned. On failure the actual current value and `new` are/// This method takes two `Ordering` arguments to describe the memory/// ordering of this operation. `success` describes the required ordering for the/// read-modify-write operation that takes place if the comparison with `current` succeeds./// `failure` describes the required ordering for the load operation that takes place when/// the comparison fails. Using `Acquire` as success ordering makes the store part/// of this operation `Relaxed`, and using `Release` makes the successful load/// `Relaxed`. The failure ordering can only be `SeqCst`, `Acquire` or `Relaxed`/// and must be equivalent to or weaker than the success ordering./// use crossbeam_epoch::{self as epoch, Atomic, Owned, Shared};/// let curr = a.load(SeqCst, guard);/// let res1 = a.compare_exchange(curr, Shared::null(), SeqCst, SeqCst, guard);/// let res2 = a.compare_exchange(curr, Owned::new(5678), SeqCst, SeqCst, guard);/// # unsafe { drop(curr.into_owned()); } // avoid leakcompare_exchange_weak/// Unlike [`compare_exchange`], this method is allowed to spuriously fail even when comparison/// succeeds, which can result in more efficient code on some platforms.  The return value is a/// result indicating whether the new pointer was written. On success the pointer that was/// written is returned. On failure the actual current value and `new` are returned./// [`compare_exchange`]: Atomic::compare_exchange/// let mut new = Owned::new(5678);/// let mut ptr = a.load(SeqCst, guard);/// # unsafe { drop(a.load(SeqCst, guard).into_owned()); } // avoid leak///     match a.compare_exchange_weak(ptr, new, SeqCst, SeqCst, guard) {///         Ok(p) => {///             ptr = p;///             break;///         Err(err) => {///             ptr = err.current;///             new = err.new;/// let mut curr = a.load(SeqCst, guard);///     match a.compare_exchange_weak(curr, Shared::null(), SeqCst, SeqCst, guard) {///         Ok(_) => break,///         Err(err) => curr = err.current,fetch_update/// Fetches the pointer, and then applies a function to it that returns a new value./// Returns a `Result` of `Ok(previous_value)` if the function returned `Some`, else `Err(_)`./// Note that the given function may be called multiple times if the value has been changed by/// other threads in the meantime, as long as the function returns `Some(_)`, but the function/// will have been applied only once to the stored value./// `fetch_update` takes two [`Ordering`] arguments to describe the memory/// ordering of this operation. The first describes the required ordering for/// when the operation finally succeeds while the second describes the/// required ordering for loads. These correspond to the success and failure/// orderings of [`Atomic::compare_exchange`] respectively./// Using [`Acquire`] as success ordering makes the store part of this/// operation [`Relaxed`], and using [`Release`] makes the final successful/// load [`Relaxed`]. The (failed) load ordering can only be [`SeqCst`],/// [`Acquire`] or [`Relaxed`] and must be equivalent to or weaker than the/// success ordering./// [`Relaxed`]: Ordering::Relaxed/// [`Acquire`]: Ordering::Acquire/// [`Release`]: Ordering::Release/// [`SeqCst`]: Ordering::SeqCst/// let res1 = a.fetch_update(SeqCst, SeqCst, guard, |x| Some(x.with_tag(1)));/// assert!(res1.is_ok());/// let res2 = a.fetch_update(SeqCst, SeqCst, guard, |x| None);/// assert!(res2.is_err());compare_and_set/// This method takes a [`CompareAndSetOrdering`] argument which describes the memory/// ordering of this operation./// # Migrating to `compare_exchange`/// `compare_and_set` is equivalent to `compare_exchange` with the following mapping for/// memory orderings:/// Original | Success | Failure/// -------- | ------- | -------/// Relaxed  | Relaxed | Relaxed/// Acquire  | Acquire | Acquire/// Release  | Release | Relaxed/// AcqRel   | AcqRel  | Acquire/// SeqCst   | SeqCst  | SeqCst/// # #![allow(deprecated)]/// let res1 = a.compare_and_set(curr, Shared::null(), SeqCst, guard);/// let res2 = a.compare_and_set(curr, Owned::new(5678), SeqCst, guard);compare_and_set_weak/// Unlike [`compare_and_set`], this method is allowed to spuriously fail even when comparison/// [`compare_and_set`]: Atomic::compare_and_set/// # Migrating to `compare_exchange_weak`/// `compare_and_set_weak` is equivalent to `compare_exchange_weak` with the following mapping for///     match a.compare_and_set_weak(ptr, new, SeqCst, guard) {///     match a.compare_and_set_weak(curr, Shared::null(), SeqCst, guard) {fetch_and/// Bitwise "and" with the current tag./// Performs a bitwise "and" operation on the current tag and the argument `val`, and sets the/// new tag to the result. Returns the previous pointer./// let a = Atomic::<i32>::from(Shared::null().with_tag(3));/// assert_eq!(a.fetch_and(2, SeqCst, guard).tag(), 3);/// assert_eq!(a.load(SeqCst, guard).tag(), 2);fetch_or/// Bitwise "or" with the current tag./// Performs a bitwise "or" operation on the current tag and the argument `val`, and sets the/// let a = Atomic::<i32>::from(Shared::null().with_tag(1));/// assert_eq!(a.fetch_or(2, SeqCst, guard).tag(), 1);/// assert_eq!(a.load(SeqCst, guard).tag(), 3);fetch_xor/// Bitwise "xor" with the current tag./// Performs a bitwise "xor" operation on the current tag and the argument `val`, and sets the/// assert_eq!(a.fetch_xor(3, SeqCst, guard).tag(), 1);into_owned/// Takes ownership of the pointee./// This consumes the atomic and converts it into [`Owned`]. As [`Atomic`] doesn't have a/// destructor and doesn't drop the pointee while [`Owned`] does, this is suitable for/// destructors of data structures./// Panics if this pointer is null, but only in debug mode./// This method may be called only if the pointer is valid and nobody else is holding a/// reference to the same object./// # use std::mem;/// # use crossbeam_epoch::Atomic;/// struct DataStructure {///     ptr: Atomic<usize>,/// impl Drop for DataStructure {///     fn drop(&mut self) {///         // By now the DataStructure lives only in our thread and we are sure we don't hold///         // any Shared or & to it ourselves.///             drop(mem::replace(&mut self.ptr, Atomic::null()).into_owned());try_into_owned/// Takes ownership of the pointee if it is non-null./// reference to the same object, or the pointer is null.///         // any Shared or & to it ourselves, but it may be null, so we have to be careful.///         let old = mem::replace(&mut self.ptr, Atomic::null());///             if let Some(x) = old.try_into_owned() {///                 drop(x)/// Returns a copy of the atomic value./// Note that a `Relaxed` load is used here. If you need synchronization, use it with other/// atomics or fences./// Returns a new atomic pointer pointing to `owned`./// use crossbeam_epoch::{Atomic, Owned};/// let a = Atomic::<i32>::from(Owned::new(1234));/// Returns a new atomic pointer pointing to `ptr`./// use crossbeam_epoch::{Atomic, Shared};/// let a = Atomic::<i32>::from(Shared::<i32>::null());/// Returns a new atomic pointer pointing to `raw`./// let a = Atomic::<i32>::from(ptr::null::<i32>());into_usize/// Returns the machine representation of the pointer./// Returns a new pointer pointing to the tagged pointer `data`./// The given `data` should have been created by `Pointer::into_usize()`, and one `data` should/// not be converted back by `Pointer::from_usize()` multiple times./// A trait for either `Owned` or `Shared` pointers./// An owned heap-allocated object./// This type is very similar to `Box<T>`./// least significant bits of the address./// Panics if the data is zero in debug mode./// Returns a new owned pointer pointing to `raw`./// This function is unsafe because improper use may lead to memory problems. Argument `raw`/// must be a valid pointer. Also, a double-free may occur if the function is called twice on/// the same raw pointer./// Panics if `raw` is not properly aligned./// The given `raw` should have been derived from `Owned`, and one `raw` should not be converted/// back by `Owned::from_raw()` multiple times./// let o = unsafe { Owned::from_raw(Box::into_raw(Box::new(1234))) };/// Converts the owned pointer into a `Box`./// let o = Owned::new(1234);/// let b: Box<i32> = o.into_box();/// assert_eq!(*b, 1234);/// Allocates `value` on the heap and returns a new owned pointer pointing to it./// let o = Owned::<i32>::init(1234);into_shared/// Converts the owned pointer into a [`Shared`]./// use crossbeam_epoch::{self as epoch, Owned};/// let p = o.into_shared(guard);tag/// Returns the tag stored within the pointer./// assert_eq!(Owned::new(1234).tag(), 0);with_tag/// Returns the same pointer, but tagged with `tag`. `tag` is truncated to be fit into the/// unused bits of the pointer to `T`./// let o = Owned::new(0u64);/// assert_eq!(o.tag(), 0);/// let o = o.with_tag(2);/// assert_eq!(o.tag(), 2);/// Returns a new owned pointer pointing to `b`./// Panics if the pointer (the `Box`) is not properly aligned./// A pointer to an object protected by the epoch GC./// The pointer is valid for use only during the lifetime `'g`.as_raw/// Converts the pointer to a raw pointer (without the tag)./// use crossbeam_epoch::{self as epoch, Atomic, Owned};/// let raw = &*o as *const _;/// let a = Atomic::from(o);/// assert_eq!(p.as_raw(), raw);/// Returns a new null pointer./// use crossbeam_epoch::Shared;/// let p = Shared::<i32>::null();/// assert!(p.is_null());is_null/// Returns `true` if the pointer is null./// let a = Atomic::null();/// assert!(a.load(SeqCst, guard).is_null());/// assert!(!a.load(SeqCst, guard).is_null());/// Dereferences the pointer./// Returns a reference to the pointee that is valid during the lifetime `'g`./// Dereferencing a pointer is unsafe because it could be pointing to invalid memory./// Another concern is the possibility of data races due to lack of proper synchronization./// For example, consider the following scenario:/// 1. A thread creates a new object: `a.store(Owned::new(10), Relaxed)`/// 2. Another thread reads it: `*a.load(Relaxed, guard).as_ref().unwrap()`/// The problem is that relaxed orderings don't synchronize initialization of the object with/// the read from the second thread. This is a data race. A possible solution would be to use/// `Release` and `Acquire` orderings.///     assert_eq!(p.deref(), &1234);/// Returns a mutable reference to the pointee that is valid during the lifetime `'g`./// * There is no guarantee that there are no more threads attempting to read/write from/to the///   actual object at the same time.///   The user must know that there are no concurrent accesses towards the object itself./// * Other than the above, all safety concerns of `deref()` applies here./// let a = Atomic::new(vec![1, 2, 3, 4]);/// let mut p = a.load(SeqCst, guard);///     assert!(!p.is_null());///     let b = p.deref_mut();///     assert_eq!(b, &vec![1, 2, 3, 4]);///     b.push(5);///     assert_eq!(b, &vec![1, 2, 3, 4, 5]);///     assert_eq!(p.deref(), &vec![1, 2, 3, 4, 5]);/// Converts the pointer to a reference./// Returns `None` if the pointer is null, or else a reference to the object wrapped in `Some`.///     assert_eq!(p.as_ref(), Some(&1234));///     let guard = &epoch::unprotected();///     let p = a.load(SeqCst, guard);///     drop(p.into_owned());/// Takes ownership of the pointee if it is not null./// reference to the same object, or if the pointer is null.///     if let Some(x) = p.try_into_owned() {///         drop(x);/// let a = Atomic::<u64>::from(Owned::new(0u64).with_tag(2));/// assert_eq!(p.tag(), 2);/// let a = Atomic::new(0u64);/// let p1 = a.load(SeqCst, guard);/// let p2 = p1.with_tag(2);/// assert_eq!(p1.tag(), 0);/// assert_eq!(p2.tag(), 2);/// assert_eq!(p1.as_raw(), p2.as_raw());/// Returns a new pointer pointing to `raw`./// let p = Shared::from(Box::into_raw(Box::new(1234)) as *const _);/// assert!(!p.is_null());valid_tag_i8valid_tag_i64const_atomic_nullarray_init/// Epoch-based garbage collector./// use crossbeam_epoch::Collector;/// let collector = Collector::new();/// let handle = collector.register();/// drop(collector); // `handle` still works after dropping `collector`/// handle.pin().flush();GlobalglobalCollector/// An epoch-based garbage collector./// Creates a new collector.registerLocalHandle/// Registers a new handle for the collector./// Creates another reference to the same garbage collector./// Checks if both handles point to the same collector./// A handle to a garbage collector./// Pins the handle.is_pinned/// Returns `true` if the handle is pinned.collector/// Returns the `Collector` associated with this handle.NUM_THREADSpin_reentrantflush_local_baggarbage_bufferingpin_holds_advanceincremental// TODO: assertions failed due to `cfg(crossbeam_sanitize)` reduce `internal::MAX_OBJECTS`bufferingcount_dropscount_destroydrop_arraydestroy_arraystressonce_locklocal_implthread_local_innerr" The per-thread participant for the default garbage collector."LocalKey/// Pins the current thread./// Returns `true` if the current thread is pinned.default_collector/// Returns the default global collector.with_handlepin_while_exiting//! The default garbage collector.//! For each thread, a participant is lazily initialized on its first use, when the current thread//! is registered in the default collector.  If initialized, the thread's participant will get//! destructed on thread exit, which in turn unregisters the thread.DATA_WORDS/// Number of words a piece of `Data` can hold./// Three words should be enough for the majority of cases. For example, you can fit inside it the/// function pointer together with a fat pointer representing an object that needs to be destroyed./// Some space to keep a `FnOnce()` object on the stack.callDeferred/// A `FnOnce()` that is stored inline if small, or otherwise boxed on the heap./// This is a handy way of keeping an unsized `FnOnce()` within a sized structure.NO_OP/// Constructs a new `Deferred` from a `FnOnce()`./// Calls the function.on_stackon_heapboxed_slice_i32long_slice_usize/// The least significant bit is set if pinned. The rest of the bits hold the epoch./// An epoch that can be marked as pinned or unpinned./// Internally, the epoch is represented as an integer that wraps around at some unspecified point/// and a flag that represents whether it is pinned or unpinned.starting/// Returns the starting epoch in unpinned state./// Returns the number of epochs `self` is ahead of `rhs`./// Internally, epochs are represented as numbers in the range `(isize::MIN / 2) .. (isize::MAX/// / 2)`, so the returned distance will be in the same interval./// Returns `true` if the epoch is marked as pinned.pinned/// Returns the same epoch, but marked as pinned.unpinned/// Returns the same epoch, but marked as unpinned.successor/// Returns the successor epoch./// The returned epoch will be marked as pinned only if the previous one was as well./// Since `Epoch` is just a wrapper around `usize`, an `AtomicEpoch` is similarly represented/// using an `AtomicUsize`.AtomicEpoch/// An atomic value that holds an `Epoch`./// Creates a new atomic epoch./// Loads a value from the atomic epoch./// Stores a value into the atomic epoch./// Stores a value into the atomic epoch if the current value is the same as `current`./// The return value is a result indicating whether the new value was written and containing/// the previous value. On success this value is guaranteed to be equal to `current`.//! The global epoch//! The last bit in this number is unused and is always zero. Every so often the global epoch is//! incremented, i.e. we say it "advances". A pinned participant may advance the global epoch only//! if all currently pinned participants have been pinned in the current epoch.//! If an object became garbage in some epoch, then we can be sure that after two advancements no//! participant will hold a reference to it. That is the crux of safe memory reclamation.deferred/// A guard that keeps the current thread pinned./// # Pinning/// The current thread is pinned by calling [`pin`], which returns a new guard:/// use crossbeam_epoch as epoch;/// // It is often convenient to prefix a call to `pin` with a `&` in order to create a reference./// // This is not really necessary, but makes passing references to the guard a bit easier./// When a guard gets dropped, the current thread is automatically unpinned./// # Pointers on the stack/// Having a guard allows us to create pointers on the stack to heap-allocated objects./// // Create a heap-allocated number./// let a = Atomic::new(777);/// // Pin the current thread./// // Load the heap-allocated object and create pointer `p` on the stack./// // Dereference the pointer and print the value:/// if let Some(num) = unsafe { p.as_ref() } {///     println!("The number is {}.", num);/// # Multiple guards/// Pinning is reentrant and it is perfectly legal to create multiple guards. In that case, the/// thread will actually be pinned only when the first guard is created and unpinned when the last/// one is dropped:/// let guard1 = epoch::pin();/// let guard2 = epoch::pin();/// assert!(epoch::is_pinned());/// drop(guard1);/// drop(guard2);/// assert!(!epoch::is_pinned());/// [`pin`]: super::pindefer/// Stores a function so that it can be executed at some point after all currently pinned/// threads get unpinned./// This method first stores `f` into the thread-local (or handle-local) cache. If this cache/// becomes full, some functions are moved into the global cache. At the same time, some/// functions from both local and global caches may get executed in order to incrementally/// clean up the caches as they fill up./// There is no guarantee when exactly `f` will be executed. The only guarantee is that it/// won't be executed until all currently pinned threads get unpinned. In theory, `f` might/// never run, but the epoch-based garbage collection will make an effort to execute it/// reasonably soon./// If this method is called from an [`unprotected`] guard, the function will simply be/// executed immediately.defer_unchecked/// The given function must not hold reference onto the stack. It is highly recommended that/// the passed function is **always** marked with `move` in order to prevent accidental/// borrows./// let message = "Hello!";///     // ALWAYS use `move` when sending a closure into `defer_unchecked`.///     guard.defer_unchecked(move || {///         println!("{}", message);/// Apart from that, keep in mind that another thread may execute `f`, so anything accessed by/// the closure must be `Send`./// We intentionally didn't require `F: Send`, because Rust's type systems usually cannot prove/// `F: Send` for typical use cases. For example, consider the following code snippet, which/// exemplifies the typical use case of deferring the deallocation of a shared reference:/// let shared = Owned::new(7i32).into_shared(guard);/// guard.defer_unchecked(move || shared.into_owned()); // `Shared` is not `Send`!/// While `Shared` is not `Send`, it's safe for another thread to call the deferred function,/// because it's called only after the grace period and `shared` is no longer shared with other/// threads. But we don't expect type systems to prove this./// When a heap-allocated object in a data structure becomes unreachable, it has to be/// deallocated. However, the current thread and other threads may be still holding references/// on the stack to that same object. Therefore it cannot be deallocated before those references/// get dropped. This method can defer deallocation until all those threads get unpinned and/// consequently drop all their references on the stack./// let a = Atomic::new("foo");/// // Now suppose that `a` is shared among multiple threads and concurrently/// // accessed and modified.../// // Steal the object currently stored in `a` and swap it with another one./// let p = a.swap(Owned::new("bar").into_shared(guard), SeqCst, guard);/// if !p.is_null() {///     // The object `p` is pointing to is now unreachable.///     // Defer its deallocation until all currently pinned threads get unpinned.///         // ALWAYS use `move` when sending a closure into `defer_unchecked`.///         guard.defer_unchecked(move || {///             println!("{} is now being deallocated.", p.deref());///             // Now we have unique access to the object pointed to by `p` and can turn it///             // into an `Owned`. Dropping the `Owned` will deallocate the object.///             drop(p.into_owned());///         });defer_destroy/// Stores a destructor for an object so that it can be deallocated and dropped at some point/// after all currently pinned threads get unpinned./// This method first stores the destructor into the thread-local (or handle-local) cache. If/// this cache becomes full, some destructors are moved into the global cache. At the same/// time, some destructors from both local and global caches may get executed in order to/// incrementally clean up the caches as they fill up./// There is no guarantee when exactly the destructor will be executed. The only guarantee is/// that it won't be executed until all currently pinned threads get unpinned. In theory, the/// destructor might never run, but the epoch-based garbage collection will make an effort to/// execute it reasonably soon./// If this method is called from an [`unprotected`] guard, the destructor will simply be/// The object must not be reachable by other threads anymore, otherwise it might be still in/// use when the destructor runs./// Apart from that, keep in mind that another thread may execute the destructor, so the object/// must be sendable to other threads./// We intentionally didn't require `T: Send`, because Rust's type systems usually cannot prove/// `T: Send` for typical use cases. For example, consider the following code snippet, which/// guard.defer_destroy(shared); // `Shared` is not `Send`!/// While `Shared` is not `Send`, it's safe for another thread to call the destructor, because/// it's called only after the grace period and `shared` is no longer shared with other///         guard.defer_destroy(p);/// Clears up the thread-local cache of deferred functions by executing them or moving into the/// global cache./// Call this method after deferring execution of a function if you want to get it executed as/// soon as possible. Flushing will make sure it is residing in in the global cache, so that/// any thread has a chance of taking the function and executing it./// If this method is called from an [`unprotected`] guard, it is a no-op (nothing happens)./// guard.defer(move || {///     println!("This better be printed as soon as possible!");/// guard.flush();repin/// Unpins and then immediately re-pins the thread./// This method is useful when you don't want delay the advancement of the global epoch by/// holding an old epoch. For safety, you should not maintain any guard-based reference across/// the call (the latter is enforced by `&mut self`). The thread will only be repinned if this/// is the only active guard for the current thread./// If this method is called from an [`unprotected`] guard, then the call will be just no-op./// let mut guard = epoch::pin();///     let p = a.load(SeqCst, &guard);///     assert_eq!(unsafe { p.as_ref() }, Some(&777));/// guard.repin();repin_after/// Temporarily unpins the thread, executes the given function and then re-pins the thread./// This method is useful when you need to perform a long-running operation (e.g. sleeping)/// and don't need to maintain any guard-based reference across the call (the latter is enforced/// by `&mut self`). The thread will only be unpinned if this is the only active guard for the/// current thread./// If this method is called from an [`unprotected`] guard, then the passed function is called/// directly without unpinning the thread./// use std::thread;/// use std::time::Duration;/// guard.repin_after(|| thread::sleep(Duration::from_millis(50)));/// Returns the `Collector` associated with this guard./// This method is useful when you need to ensure that all guards used with/// a data structure come from the same collector./// If this method is called from an [`unprotected`] guard, then `None` is returned./// assert!(guard1.collector() == guard2.collector());unprotected/// Returns a reference to a dummy guard that allows unprotected access to [`Atomic`]s./// This guard should be used in special occasions only. Note that it doesn't actually keep any/// thread pinned - it's just a fake guard that allows loading from [`Atomic`]s unsafely./// Note that calling [`defer`] with a dummy guard will not defer the function - it will just/// execute the function immediately./// If necessary, it's possible to create more dummy guards by cloning: `unprotected().clone()`./// Loading and dereferencing data from an [`Atomic`] using this guard is safe only if the/// [`Atomic`] is not being concurrently modified by other threads./// use std::sync::atomic::Ordering::Relaxed;/// let a = Atomic::new(7);///     // Load `a` without pinning the current thread.///     a.load(Relaxed, epoch::unprotected());///     // It's possible to create more dummy guards.///     let dummy = epoch::unprotected();///     dummy.defer(move || {///         println!("This gets executed immediately.");///     // Dropping `dummy` doesn't affect the current thread - it's just a noop./// The most common use of this function is when constructing or destructing a data structure./// For example, we can use a dummy guard in the destructor of a Treiber stack because at that/// point no other thread could concurrently modify the [`Atomic`]s we are accessing./// If we were to actually pin the current thread during destruction, that would just unnecessarily/// delay garbage collection and incur some performance cost, so in cases like these `unprotected`/// is very helpful./// use std::mem::ManuallyDrop;/// struct Stack<T> {///     head: Atomic<Node<T>>,/// struct Node<T> {///     data: ManuallyDrop<T>,///     next: Atomic<Node<T>>,/// impl<T> Drop for Stack<T> {///             // Unprotected load.///             let mut node = self.head.load(Relaxed, epoch::unprotected());///             while let Some(n) = node.as_ref() {///                 // Unprotected load.///                 let next = n.next.load(Relaxed, epoch::unprotected());///                 // Take ownership of the node, then drop its data and deallocate it.///                 let mut o = node.into_owned();///                 ManuallyDrop::drop(&mut o.data);///                 drop(o);///                 node = next;/// [`Atomic`]: super::Atomic/// [`defer`]: Guard::deferlistIsElementIterErrorListQueueMAX_OBJECTS/// Maximum number of objects a bag can contain.deferreds/// Stashed objects.Bag/// A bag of deferred functions./// `Bag::try_push()` requires that it is safe for another thread to execute the given functions./// Returns a new, empty bag./// Returns `true` if the bag is empty./// Attempts to insert a deferred function into the bag./// Returns `Ok(())` if successful, and `Err(deferred)` for the given `deferred` if the bag is/// full./// It should be safe for another thread to execute the given function.sealSealedBag/// Seals the bag with the given epoch.// can't #[derive(Debug)] because Debug is not implemented for arrays 64 items long_bag/// A pair of an epoch and a bag./// It is safe to share `SealedBag` because `is_expired` only inspects the epoch.is_expired/// Checks if it is safe to drop the bag w.r.t. the given global epoch.locals/// The intrusive linked list of `Local`s./// The global queue of bags of deferred functions./// The global epoch./// The global data for a garbage collector.COLLECT_STEPS/// Number of bags to destroy./// Creates a new global data for garbage collection.push_bag/// Pushes the bag into the global queue and replaces the bag with a new empty bag./// Collects several bags from the global queue and executes deferred functions in them./// Note: This may itself produce garbage and in turn allocate new bags./// `pin()` rarely calls `collect()`, so we want the compiler to place that call on a cold/// path. In other words, we want the compiler to optimize branching for the case when/// `collect()` is not called.try_advance/// Attempts to advance the global epoch./// The global epoch can advance only if all currently pinned participants have been pinned in/// the current epoch./// Returns the current global epoch./// `try_advance()` is annotated `#[cold]` because it is rarely called./// A node in the intrusive linked list of `Local`s./// A reference to the global data./// When all guards and handles get dropped, this reference is destroyed.bag/// The local bag of deferred functions.guard_count/// The number of guards keeping this participant pinned.handle_count/// The number of active handles.pin_count/// Total number of pinnings performed./// This is just an auxiliary counter that sometimes kicks off collection./// The local epoch./// Participant for garbage collection.// Note: `entry` must be the first fieldlocal_size// Make sure `Local` is less than or equal to 2048 bytes.// https://github.com/crossbeam-rs/crossbeam/issues/551// `crossbeam_sanitize` and `miri` reduce the size of `Local`PINNINGS_BETWEEN_COLLECT/// Number of pinnings after which a participant will execute some deferred functions from the/// global queue./// Registers a new `Local` in the provided `Global`./// Returns a reference to the `Global` in which this `Local` resides./// Returns a reference to the `Collector` in which this `Local` resides./// Returns `true` if the current participant is pinned./// Adds `deferred` to the thread-local bag./// Pins the `Local`.unpin/// Unpins the `Local`./// Unpins and then pins the `Local`.acquire_handle/// Increments the handle count.release_handle/// Decrements the handle count./// Removes the `Local` from the global linked list.entry_ofelement_ofcheck_defercheck_bag//! The global data and participant for garbage collection.//! # Registration//! In order to track all participants in one place, we need some form of participant//! registration. When a participant is created, it is registered to a global lock-free//! singly-linked list of registries; and when a participant is leaving, it is unregistered from the//! list.//! # Pinning//! Every participant contains an integer that tells whether the participant is pinned and if so,//! what was the global epoch at the time it was pinned. Participants also hold a pin counter that//! aids in periodic global epoch advancement.//! When a participant is pinned, a `Guard` is returned as a witness that the participant is pinned.//! Guards are necessary for performing atomic operations, and for freeing/dropping locations.//! # Thread-local bag//! Objects that get unlinked from concurrent data structures must be stashed away until the global//! epoch sufficiently advances so that they become safe for destruction. Pointers to such objects//! are pushed into a thread-local bag, and when it becomes full, the bag is marked with the current//! global epoch and pushed into the global queue of bags. We store objects in thread-local storages//! for amortizing the synchronization cost of pushing the garbages to a global queue.//! # Global queue//! Whenever a bag is pushed into a queue, the objects in some bags in the queue are collected and//! destroyed along the way. This design reduces contention on data structures. The global queue//! cannot be explicitly accessed: the only way to interact with it is by calling functions//! `defer()` that adds an object to the thread-local bag, or `collect()` that manually triggers//! garbage collection.//! Ideally each instance of concurrent data structure may have its own queue that gets fully//! destroyed as soon as the data structure gets dropped.withwith_mut// loom's UnsafeCell has a slightly different API than the standard library UnsafeCell.// Since we want the rest of the code to be agnostic to whether it's running under loom or// not, we write this small wrapper that provides the loom-supported API for the standard// library UnsafeCell. This is also what the loom documentation recommends:// https://github.com/tokio-rs/loom#handling-loom-api-differencescompiler_fencefence//! Epoch-based memory reclamation.//! An interesting problem concurrent collections deal with comes from the remove operation.//! Suppose that a thread removes an element from a lock-free map, while another thread is reading//! that same element at the same time. The first thread must wait until the second thread stops//! reading the element. Only then it is safe to destruct it.//! Programming languages that come with garbage collectors solve this problem trivially. The//! garbage collector will destruct the removed element when no thread can hold a reference to it//! anymore.//! This crate implements a basic memory reclamation mechanism, which is based on epochs. When an//! element gets removed from a concurrent collection, it is inserted into a pile of garbage and//! marked with the current epoch. Every time a thread accesses a collection, it checks the current//! epoch, attempts to increment it, and destructs some garbage that became so old that no thread//! can be referencing it anymore.//! That is the general mechanism behind epoch-based memory reclamation, but the details are a bit//! more complicated. Anyhow, memory reclamation is designed to be fully automatic and something//! users of concurrent collections don't have to worry much about.//! # Pointers//! Concurrent collections are built using atomic pointers. This module provides [`Atomic`], which//! is just a shared atomic pointer to a heap-allocated object. Loading an [`Atomic`] yields a//! [`Shared`], which is an epoch-protected pointer through which the loaded object can be safely//! read.//! Before an [`Atomic`] can be loaded, a participant must be [`pin`]ned. By pinning a participant//! we declare that any object that gets removed from now on must not be destructed just//! yet. Garbage collection of newly removed objects is suspended until the participant gets//! unpinned.//! # Garbage//! Objects that get removed from concurrent collections must be stashed away until all currently//! pinned participants get unpinned. Such objects can be stored into a thread-local or global//! storage, where they are kept until the right time for their destruction comes.//! There is a global shared instance of garbage queue. You can [`defer`](Guard::defer) the execution of an//! arbitrary function until the global epoch is advanced enough. Most notably, concurrent data//! structures may defer the deallocation of an object.//! # APIs//! For majority of use cases, just use the default garbage collector by invoking [`pin`]. If you//! want to create your own garbage collector, use the [`Collector`] API./// The next entry in the linked list./// If the tag is 1, this entry is marked as deleted./// An entry in a linked list./// An Entry is accessed from multiple threads, so it would be beneficial to put it in a different/// cache-line than thread-local data in terms of performance./// Returns a reference to this element's `Entry`./// Given a reference to an element's entry, returns that element./// let elem = ListElement::new();/// assert_eq!(elem.entry_of(),///            unsafe { ListElement::element_of(elem.entry_of()) } );/// The caller has to guarantee that the `Entry` is called with was retrieved from an instance/// of the element type (`T`)./// The function that is called when an entry is unlinked from list./// Implementing this trait asserts that the type `T` can be used as an element in the intrusive/// linked list defined in this module. `T` has to contain (or otherwise be linked to) an instance/// of `Entry`.///     entry: Entry,///     data: usize,/// impl IsElement<A> for A {///     fn entry_of(a: &A) -> &Entry {///         let entry_ptr = ((a as usize) + offset_of!(A, entry)) as *const Entry;///         unsafe { &*entry_ptr }///     unsafe fn element_of(entry: &Entry) -> &T {///         let elem_ptr = ((entry as usize) - offset_of!(A, entry)) as *const T;///         &*elem_ptr///     unsafe fn finalize(entry: &Entry, guard: &Guard) {///         guard.defer_destroy(Shared::from(Self::element_of(entry) as *const _));/// This trait is implemented on a type separate from `T` (although it can be just `T`), because/// one type might be placeable into multiple lists, in which case it would require multiple/// implementations of `IsElement`. In such cases, each struct implementing `IsElement<T>`/// represents a distinct `Entry` in `T`./// For example, we can insert the following struct into two lists using `entry1` for one/// and `entry2` for the other:/// struct B {///     entry1: Entry,///     entry2: Entry,/// The head of the linked list./// The phantom data for using `T` and `C`./// A lock-free, intrusive linked list of type `T`./// The guard that protects the iteration./// Pointer from the predecessor to the current entry.curr/// The current entry./// The list head, needed for restarting iteration./// Logically, we store a borrow of an instance of `T` and/// use the type information from `C`./// An iterator used for retrieving values from the list.Stalled/// A concurrent thread modified the state of the list at the same place that this iterator/// was inspecting. Subsequent iteration will restart from the beginning of the list./// An error that occurs during iteration over the list./// Returns the empty entry.delete/// Marks this entry as deleted, deferring the actual deallocation to a later iteration./// The entry should be a member of a linked list, and it should not have been deleted./// It should be safe to call `C::finalize` on the entry after the `guard` is dropped, where `C`/// is the associated helper for the linked list./// Returns a new, empty linked list./// Inserts `entry` into the head of the list./// You should guarantee that:/// - `container` is not null/// - `container` is immovable, e.g. inside an `Owned`/// - the same `Entry` is not inserted more than once/// - the inserted object will be removed before the list is dropped/// Returns an iterator over all objects./// # Caveat/// Every object that is inserted at the moment this function is called and persists at least/// until the end of iteration will be returned. Since this iterator traverses a lock-free/// linked list that may be concurrently modified, some additional caveats apply:/// 1. If a new object is inserted during iteration, it may or may not be returned./// 2. If an object is deleted during iteration, it may or may not be returned./// 3. The iteration may be aborted when it lost in a race condition. In this case, the winning///    thread will continue to iterate over the same list.Barrier/// Checks whether the list retains inserted elements/// and returns them in the correct order./// Checks whether elements can be removed from the list and whether/// the correct elements are removed.THREADSITERSinsert_delete_multi/// Contends the list on insert and delete operations to make sure they can run concurrently.iter_multi/// Contends the list on iteration to make sure that it can be iterated over concurrently.//! Lock-free intrusive linked list.//! Ideas from Michael.  High Performance Dynamic Lock-Free Hash Tables and List-Based Sets.  SPAA//! 2002.  <http://dl.acm.org/citation.cfm?id=564870.564881>//! Synchronization primitives.// Unlike std::sync::OnceLock, we don't need PhantomData here because// we don't use #[may_dangle]./// Creates a new empty cell./// Gets the contents of the cell, initializing it with `f` if the cell/// was empty./// Many threads may call `get_or_init` concurrently with different/// initializing functions, but it is guaranteed that only one function/// will be executed./// If `f` panics, the panic is propagated to the caller, and the cell/// remains uninitialized./// It is an error to reentrantly initialize the cell from `f`. The/// exact outcome is unspecified. Current implementation deadlocks, but/// this may be changed to a panic in the future./// The value must be initialized// Based on unstable std::sync::OnceLock.// Source: https://github.com/rust-lang/rust/blob/8e9c93df464b7ada3fc7a1c8ccddd9dcb24ee0a0/library/std/src/sync/once_lock.rsNode// The representation here is a singly-linked list, with a sentinel node at the front. In general// the `tail` pointer may lag behind the actual tail. Non-sentinel nodes are either all `Data` or// all `Blocked` (requests for data from blocked threads)./// The slot in which a value of type `T` can be stored./// The type of `data` is `MaybeUninit<T>` because a `Node<T>` doesn't always contain a `T`./// For example, the sentinel node in a queue never contains a value: its slot is always empty./// Other nodes start their life with a push operation and contain a value until it gets popped/// out. After that such empty nodes get added to the collector for destruction.// Any particular `T` should never be accessed concurrently, so no need for `Sync`./// Create a new, empty queue.push_internal/// Attempts to atomically place `n` into the `next` pointer of `onto`, and returns `true` on/// success. The queue's `tail` pointer may be updated./// Adds `t` to the back of the queue, possibly waking up threads blocked on `pop`.pop_internal/// Attempts to pop a data node. `Ok(None)` if queue is empty; `Err(())` if lost race to pop.pop_if_internal/// Attempts to pop a data node, if the data satisfies the given condition. `Ok(None)` if queue/// is empty or the data does not satisfy the condition; `Err(())` if lost race to pop.try_pop/// Attempts to dequeue from the front./// Returns `None` if the queue is observed to be empty.try_pop_if/// Attempts to dequeue from the front, if the item satisfies the given condition./// Returns `None` if the queue is observed to be empty, or the head does not satisfy the given/// condition.CONC_COUNTpush_try_pop_1push_try_pop_2push_try_pop_many_seqpush_pop_1push_pop_2push_pop_many_seqpush_try_pop_many_spscpush_try_pop_many_spmcpush_try_pop_many_mpmcpush_pop_many_spscis_empty_dont_pop//! Michael-Scott lock-free queue.//! Usable with any number of producers and consumers.//! Michael and Scott.  Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue//! Algorithms.  PODC 1996.  <http://dl.acm.org/citation.cfm?id=248106>//! Simon Doherty, Lindsay Groves, Victor Luchangco, and Mark Moir. 2004b. Formal Verification of a//! Practical Lock-Free Queue Algorithm. <https://doi.org/10.1007/978-3-540-30232-2_7>convert_custom_linux_target// The target triplets have the form of 'arch-vendor-system'.// When building for Linux (e.g. the 'system' part is// 'linux-something'), replace the vendor with 'unknown'// so that mapping to rust standard targets happens correctly.// The rustc-cfg listed below are considered public API, but it is *unstable*// and outside of the normal semver guarantees:// - `crossbeam_no_atomic`//      Assume the target does *not* support any atomic operations.//      This is usually detected automatically by the build script, but you may//      need to enable it manually when building for custom targets or using//      non-cargo build systems that don't run the build script.// With the exceptions mentioned above, the rustc-cfg emitted by the build// script are *not* public API.NO_ATOMIC// This file is @generated by no_atomic.sh.// It is not intended for manual editing.seq_lockSeqLock/// The inner value./// If this value can be transmuted into a primitive atomic type, it will be treated as such./// Otherwise, all potentially concurrent operations on this data will be protected by a global/// lock./// Using MaybeUninit to prevent code outside the cell from observing partially initialized state:/// <https://github.com/crossbeam-rs/crossbeam/issues/833>/// (This rustc bug has been fixed in Rust 1.64.)/// Note:/// - we'll never store uninitialized `T` due to our API only using initialized `T`./// - this `MaybeUninit` does *not* fix <https://github.com/crossbeam-rs/crossbeam/issues/315>.AtomicCell/// A thread-safe mutable memory location./// This type is equivalent to [`Cell`], except it can also be shared among multiple threads./// Operations on `AtomicCell`s use atomic instructions whenever possible, and synchronize using/// global locks otherwise. You can call [`AtomicCell::<T>::is_lock_free()`] to check whether/// atomic instructions or locks will be used./// Atomic loads use the [`Acquire`] ordering and atomic stores use the [`Release`] ordering./// [`Cell`]: std::cell::Cell/// [`AtomicCell::<T>::is_lock_free()`]: AtomicCell::is_lock_free/// [`Acquire`]: std::sync::atomic::Ordering::Acquire/// [`Release`]: std::sync::atomic::Ordering::Release/// Creates a new atomic cell initialized with `val`./// use crossbeam_utils::atomic::AtomicCell;/// let a = AtomicCell::new(7);/// Consumes the atomic and returns the contained value./// This is safe because passing `self` by value guarantees that no other threads are/// concurrently accessing the atomic data./// let v = a.into_inner();/// assert_eq!(v, 7);is_lock_free/// Returns `true` if operations on values of this type are lock-free./// If the compiler or the platform doesn't support the necessary atomic instructions,/// `AtomicCell<T>` will use global locks for every potentially concurrent atomic operation./// // This type is internally represented as `AtomicUsize` so we can just use atomic/// // operations provided by it./// assert_eq!(AtomicCell::<usize>::is_lock_free(), true);/// // A wrapper struct around `isize`./// struct Foo {///     bar: isize,/// // `AtomicCell<Foo>` will be internally represented as `AtomicIsize`./// assert_eq!(AtomicCell::<Foo>::is_lock_free(), true);/// // Operations on zero-sized types are always lock-free./// assert_eq!(AtomicCell::<()>::is_lock_free(), true);/// // Very large types cannot be represented as any of the standard atomic types, so atomic/// // operations on them will have to use global locks for synchronization./// assert_eq!(AtomicCell::<[u8; 1000]>::is_lock_free(), false);/// Stores `val` into the atomic cell./// assert_eq!(a.load(), 7);/// a.store(8);/// assert_eq!(a.load(), 8);/// Stores `val` into the atomic cell and returns the previous value./// assert_eq!(a.swap(8), 7);/// Returns a raw pointer to the underlying data in this atomic cell./// let a = AtomicCell::new(5);/// let ptr = a.as_ptr();/// Takes the value of the atomic cell, leaving `Default::default()` in its place./// let five = a.take();/// assert_eq!(five, 5);/// assert_eq!(a.into_inner(), 0);/// Loads a value from the atomic cell.compare_and_swap/// If the current value equals `current`, stores `new` into the atomic cell./// The return value is always the previous value. If it is equal to `current`, then the value/// was updated./// let a = AtomicCell::new(1);/// assert_eq!(a.compare_and_swap(2, 3), 1);/// assert_eq!(a.load(), 1);/// assert_eq!(a.compare_and_swap(1, 2), 1);/// assert_eq!(a.load(), 2);/// assert_eq!(a.compare_exchange(2, 3), Err(1));/// assert_eq!(a.compare_exchange(1, 2), Ok(1));/// Fetches the value, and applies a function to it that returns an optional/// new value. Returns a `Result` of `Ok(previous_value)` if the function returned `Some(_)`, else/// `Err(previous_value)`./// Note: This may call the function multiple times if the value has been changed from other threads in/// the meantime, as long as the function returns `Some(_)`, but the function will have been applied/// only once to the stored value./// assert_eq!(a.fetch_update(|_| None), Err(7));/// assert_eq!(a.fetch_update(|a| Some(a + 1)), Ok(7));/// assert_eq!(a.fetch_update(|a| Some(a + 1)), Ok(8));/// assert_eq!(a.load(), 9);// `MaybeUninit` prevents `T` from being dropped, so we need to implement `Drop`// for `AtomicCell` to avoid leaks of non-`Copy` types.// If values of type `$t` can be transmuted into values of the primitive atomic type `$atomic`,// declares variable `$a` of type `$atomic` and executes `$atomic_op`, breaking out of the loop.// If values of type `$t` can be transmuted into values of a primitive atomic type, declares// variable `$a` of that type and executes `$atomic_op`. Otherwise, just executes// `$fallback_op`.impl_arithmeticr" Increments the current value by `val` and returns the previous value."r" The addition wraps on overflow."r" # Examples"r" use crossbeam_utils::atomic::AtomicCell;""let a = AtomicCell::new(7u8);"r" assert_eq!(a.fetch_add(3), 7);"r" assert_eq!(a.load(), 10);"fetch_addr" Decrements the current value by `val` and returns the previous value."r" The subtraction wraps on overflow."r" assert_eq!(a.fetch_sub(3), 7);"r" assert_eq!(a.load(), 4);"fetch_subr#" Applies bitwise "and" to the current value and returns the previous value."#r" assert_eq!(a.fetch_and(3), 7);"r" assert_eq!(a.load(), 3);"r#" Applies bitwise "nand" to the current value and returns the previous value."#r" assert_eq!(a.fetch_nand(3), 7);"r" assert_eq!(a.load(), !(7 & 3));"fetch_nandr#" Applies bitwise "or" to the current value and returns the previous value."#r" assert_eq!(a.fetch_or(16), 7);"r" assert_eq!(a.load(), 23);"r#" Applies bitwise "xor" to the current value and returns the previous value."#r" assert_eq!(a.fetch_xor(2), 7);"r" assert_eq!(a.load(), 5);"r" Compares and sets the maximum of the current value and `val`,"r" and returns the previous value."r" assert_eq!(a.fetch_max(9), 7);"r" assert_eq!(a.load(), 9);"fetch_maxr" Compares and sets the minimum of the current value and `val`,"r" assert_eq!(a.fetch_min(2), 7);"r" assert_eq!(a.load(), 2);"fetch_min"let a = AtomicCell::new(7i8);""let a = AtomicCell::new(7u16);""let a = AtomicCell::new(7i16);""let a = AtomicCell::new(7u32);""let a = AtomicCell::new(7i32);""let a = AtomicCell::new(7u64);""let a = AtomicCell::new(7i64);""let a = AtomicCell::new(7u128);"r" assert_eq!(a.fetch_max(2), 7);"r" assert_eq!(a.load(), 7);"// TODO: AtomicU128 is unstable// impl_arithmetic!(u128, AtomicU128, "let a = AtomicCell::new(7u128);");// impl_arithmetic!(i128, AtomicI128, "let a = AtomicCell::new(7i128);");"let a = AtomicCell::new(7i128);""let a = AtomicCell::new(7usize);""let a = AtomicCell::new(7isize);"/// Applies logical "and" to the current value and returns the previous value./// let a = AtomicCell::new(true);/// assert_eq!(a.fetch_and(true), true);/// assert_eq!(a.load(), true);/// assert_eq!(a.fetch_and(false), true);/// assert_eq!(a.load(), false);/// Applies logical "nand" to the current value and returns the previous value./// assert_eq!(a.fetch_nand(false), true);/// assert_eq!(a.fetch_nand(true), true);/// assert_eq!(a.fetch_nand(false), false);/// Applies logical "or" to the current value and returns the previous value./// let a = AtomicCell::new(false);/// assert_eq!(a.fetch_or(false), false);/// assert_eq!(a.fetch_or(true), false);/// Applies logical "xor" to the current value and returns the previous value./// assert_eq!(a.fetch_xor(false), true);/// assert_eq!(a.fetch_xor(true), true);can_transmute/// Returns `true` if values of type `A` can be transmuted into values of type `B`.lock/// Returns a reference to the global lock associated with the `AtomicCell` at address `addr`./// This function is used to protect atomic data which doesn't fit into any of the primitive atomic/// types in `std::sync::atomic`. Operations on such atomics must therefore use a global lock./// However, there is not only one global lock but an array of many locks, and one of them is/// picked based on the given address. Having many locks reduces contention and improves/// scalability.AtomicUnit/// An atomic `()`./// All operations are noops.atomic_is_lock_free/// Returns `true` if operations on `AtomicCell<T>` are lock-free.atomic_load/// Atomically reads data from `src`./// This operation uses the `Acquire` ordering. If possible, an atomic instructions is used, and a/// global lock otherwise.atomic_store/// Atomically writes `val` to `dst`./// This operation uses the `Release` ordering. If possible, an atomic instructions is used, and aatomic_swap/// Atomically swaps data at `dst` with `val`./// This operation uses the `AcqRel` ordering. If possible, an atomic instructions is used, and aatomic_compare_exchange_weak/// Atomically compares data at `dst` to `current` and, if equal byte-for-byte, exchanges data at/// `dst` with `new`./// Returns the old value on success, or the current value at `dst` on failure.// Necessary for implementing atomic methods for `AtomicUnit`Val/// Type returned by `load_consume`./// Loads a value from the atomic using a "consume" memory ordering./// This is currently only implemented on ARM and AArch64, where a fence/// can be avoided. On other architectures this will fall back to a simple/// `load(Ordering::Acquire)`./// Trait which allows reading from primitive atomic types with "consume" ordering.impl_consume// Miri and Loom don't support "consume" ordering and ThreadSanitizer doesn't treat// load(Relaxed) + compiler_fence(Acquire) as "consume" load.// LLVM generates machine code equivalent to fence(Acquire) in compiler_fence(Acquire)// on PowerPC, MIPS, etc. (https://godbolt.org/z/hffvjvW7h), so for now the fence// can be actually avoided here only on ARM and AArch64. See also// https://github.com/rust-lang/rust/issues/62256.impl_atomicAtomicI8AtomicU16AtomicI16AtomicI32AtomicU64AtomicI64// Use "wide" sequence lock if the pointer width <= 32 for preventing its counter against wrap// around.// In narrow architectures (pointer width <= 16), the counter is still <= 32-bit and may be// vulnerable to wrap around. But it's mostly okay, since in such a primitive hardware, the// counter will not be increased that fast.// Note that Rust (and C99) pointers must be at least 16-bit (i.e., 8-bit targets are impossible): https://github.com/rust-lang/rust/pull/49305atomic_cell// We cannot provide AtomicCell under cfg(crossbeam_loom) because loom's atomic// types have a different in-memory representation than the underlying type.// TODO: The latest loom supports fences, so fallback using seqlock may be available.//! Atomic types.//! * [`AtomicCell`], a thread-safe mutable memory location.//! * [`AtomicConsume`], for reading from primitive atomic types with "consume" ordering./// The current state of the lock./// All bits except the least significant one hold the current stamp. When locked, the state/// equals 1 and doesn't contain a valid stamp./// A simple stamped lock.optimistic_read/// If not locked, returns the current stamp./// This method should be called before optimistic reads.validate_read/// Returns `true` if the current stamp is equal to `stamp`./// This method should be called after optimistic reads to check whether they are valid. The/// argument `stamp` should correspond to the one returned by method `optimistic_read`.SeqLockWriteGuard/// Grabs the lock for writing./// The parent lock./// The stamp before locking./// An RAII guard that releases the lock and increments the stamp when dropped.abort/// Releases the lock without incrementing the stamp.test_abortstate_hi/// The high bits of the current state of the lock.state_lo/// The low bits of the current state of the lock./// All bits except the least significant one hold the current stamp. When locked, the state_lo/// The state is represented as two `AtomicUsize`: `state_hi` for high bits and `state_lo` for low/// bits.SPIN_LIMITYIELD_LIMITstep/// Performs exponential backoff in spin loops./// Backing off in spin loops reduces contention and improves overall performance./// This primitive can execute *YIELD* and *PAUSE* instructions, yield the current thread to the OS/// scheduler, and tell when is a good time to block the thread using a different synchronization/// mechanism. Each step of the back off procedure takes roughly twice as long as the previous/// step./// Backing off in a lock-free loop:/// use crossbeam_utils::Backoff;/// use std::sync::atomic::AtomicUsize;/// fn fetch_mul(a: &AtomicUsize, b: usize) -> usize {///     let backoff = Backoff::new();///     loop {///         let val = a.load(SeqCst);///         if a.compare_exchange(val, val.wrapping_mul(b), SeqCst, SeqCst).is_ok() {///             return val;///         backoff.spin();/// Waiting for an [`AtomicBool`] to become `true`:/// use std::sync::atomic::AtomicBool;/// fn spin_wait(ready: &AtomicBool) {///     while !ready.load(SeqCst) {///         backoff.snooze();/// Waiting for an [`AtomicBool`] to become `true` and parking the thread after a long wait./// Note that whoever sets the atomic variable to `true` must notify the parked thread by calling/// [`unpark()`]:/// fn blocking_wait(ready: &AtomicBool) {///         if backoff.is_completed() {///             thread::park();///             backoff.snooze();/// [`is_completed`]: Backoff::is_completed/// [`std::thread::park()`]: std::thread::park/// [`Condvar`]: std::sync::Condvar/// [`AtomicBool`]: std::sync::atomic::AtomicBool/// [`unpark()`]: std::thread::Thread::unpark/// Creates a new `Backoff`./// let backoff = Backoff::new();/// Resets the `Backoff`./// backoff.reset();spin/// Backs off in a lock-free loop./// This method should be used when we need to retry an operation because another thread made/// progress./// The processor may yield using the *YIELD* or *PAUSE* instruction./// let a = AtomicUsize::new(7);/// assert_eq!(fetch_mul(&a, 8), 7);/// assert_eq!(a.load(SeqCst), 56);snooze/// Backs off in a blocking loop./// This method should be used when we need to wait for another thread to make progress./// The processor may yield using the *YIELD* or *PAUSE* instruction and the current thread/// may yield by giving up a timeslice to the OS scheduler./// In `#[no_std]` environments, this method is equivalent to [`spin`]./// If possible, use [`is_completed`] to check when it is advised to stop using backoff and/// block the current thread using a different synchronization mechanism instead./// [`spin`]: Backoff::spin/// use std::sync::Arc;/// let ready = Arc::new(AtomicBool::new(false));/// let ready2 = ready.clone();/// thread::spawn(move || {///     thread::sleep(Duration::from_millis(100));///     ready2.store(true, SeqCst);/// assert_eq!(ready.load(SeqCst), false);/// spin_wait(&ready);/// assert_eq!(ready.load(SeqCst), true);/// # std::thread::sleep(std::time::Duration::from_millis(500)); // wait for background threads closed: https://github.com/rust-lang/miri/issues/1371is_completed/// Returns `true` if exponential backoff has completed and blocking the thread is advised./// Waiting for an [`AtomicBool`] to become `true` and parking the thread after a long wait:/// let waiter = thread::current();///     waiter.unpark();/// blocking_wait(&ready);/// Pads and aligns a value to the length of a cache line./// In concurrent programming, sometimes it is desirable to make sure commonly accessed pieces of/// data are not placed into the same cache line. Updating an atomic value invalidates the whole/// cache line it belongs to, which makes the next access to the same cache line slower for other/// CPU cores. Use `CachePadded` to ensure updating one piece of data doesn't invalidate other/// cached data./// # Size and alignment/// Cache lines are assumed to be N bytes long, depending on the architecture:/// * On x86-64, aarch64, and powerpc64, N = 128./// * On arm, mips, mips64, sparc, and hexagon, N = 32./// * On m68k, N = 16./// * On s390x, N = 256./// * On all others, N = 64./// Note that N is just a reasonable guess and is not guaranteed to match the actual cache line/// length of the machine the program is running on. On modern Intel architectures, spatial/// prefetcher is pulling pairs of 64-byte cache lines at a time, so we pessimistically assume that/// cache lines are 128 bytes long./// The size of `CachePadded<T>` is the smallest multiple of N bytes large enough to accommodate/// a value of type `T`./// The alignment of `CachePadded<T>` is the maximum of N bytes and the alignment of `T`./// Alignment and padding:/// use crossbeam_utils::CachePadded;/// let array = [CachePadded::new(1i8), CachePadded::new(2i8)];/// let addr1 = &*array[0] as *const i8 as usize;/// let addr2 = &*array[1] as *const i8 as usize;/// assert!(addr2 - addr1 >= 32);/// assert_eq!(addr1 % 32, 0);/// assert_eq!(addr2 % 32, 0);/// When building a concurrent queue with a head and a tail index, it is wise to place them in/// different cache lines so that concurrent threads pushing and popping elements don't invalidate/// each other's cache lines:/// struct Queue<T> {///     head: CachePadded<AtomicUsize>,///     tail: CachePadded<AtomicUsize>,///     buffer: *mut T,// Starting from Intel's Sandy Bridge, spatial prefetcher is now pulling pairs of 64-byte cache// lines at a time, so we have to align to 128 bytes rather than 64.// Sources:// - https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf// - https://github.com/facebook/folly/blob/1b5288e6eea6df074758f877c849b6e73bbb9fbb/folly/lang/Align.h#L107// aarch64/arm64ec's big.LITTLE architecture has asymmetric cores and "big" cores have 128-byte cache line size.// - https://www.mono-project.com/news/2016/09/12/arm64-icache/// powerpc64 has 128-byte cache line size.// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_ppc64x.go#L9// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/powerpc/include/asm/cache.h#L26// arm, mips, mips64, sparc, and hexagon have 32-byte cache line size.// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_arm.go#L7// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mips.go#L7// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mipsle.go#L7// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_mips64x.go#L9// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/sparc/include/asm/cache.h#L17// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/hexagon/include/asm/cache.h#L12// m68k has 16-byte cache line size.// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/m68k/include/asm/cache.h#L9// s390x has 256-byte cache line size.// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_s390x.go#L7// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/s390/include/asm/cache.h#L13// x86, wasm, riscv, and sparc64 have 64-byte cache line size.// - https://github.com/golang/go/blob/dda2991c2ea0c5914714469c4defc2562a907230/src/internal/cpu/cpu_x86.go#L9// - https://github.com/golang/go/blob/3dd58676054223962cd915bb0934d1f9f489d4d2/src/internal/cpu/cpu_wasm.go#L7// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/riscv/include/asm/cache.h#L10// - https://github.com/torvalds/linux/blob/3516bd729358a2a9b090c1905bd2a3fa926e24c6/arch/sparc/include/asm/cache.h#L19// All others are assumed to have 64-byte cache line size./// let padded_value = CachePadded::new(1);/// Returns the inner value./// let padded_value = CachePadded::new(7);/// let value = padded_value.into_inner();/// assert_eq!(value, 7);spin_loopCondvarcache_paddedbackoff//! Miscellaneous tools for concurrent programming.//! ## Atomics//! ## Thread synchronization//! * [`Parker`], a thread parking primitive.//! * [`ShardedLock`], a sharded reader-writer lock with fast concurrent reads.//! * [`WaitGroup`], for synchronizing the beginning or end of some computation.//! ## Utilities//! * [`Backoff`], for exponential backoff in spin loops.//! * [`CachePadded`], for padding and aligning a value to the length of a cache line.//! * [`scope`], for spawning threads that borrow local variables from the stack.//! [`AtomicCell`]: atomic::AtomicCell//! [`AtomicConsume`]: atomic::AtomicConsume//! [`Parker`]: sync::Parker//! [`ShardedLock`]: sync::ShardedLock//! [`WaitGroup`]: sync::WaitGroup//! [`scope`]: thread::scopeparkersharded_lockwait_groupParkerUnparkerShardedLockShardedLockReadGuardShardedLockWriteGuardWaitGroup//! Thread synchronization primitives.SeqCstInstantunparker/// A thread parking primitive./// Conceptually, each `Parker` has an associated token which is initially not present:/// * The [`park`] method blocks the current thread unless or until the token is available, at///   which point it automatically consumes the token./// * The [`park_timeout`] and [`park_deadline`] methods work the same as [`park`], but block for///   a specified maximum time./// * The [`unpark`] method atomically makes the token available if it wasn't already. Because the///   token is initially absent, [`unpark`] followed by [`park`] will result in the second call///   returning immediately./// In other words, each `Parker` acts a bit like a spinlock that can be locked and unlocked using/// [`park`] and [`unpark`]./// use crossbeam_utils::sync::Parker;/// let p = Parker::new();/// let u = p.unparker().clone();/// // Make the token available./// u.unpark();/// // Wakes up immediately and consumes the token./// p.park();///     thread::sleep(Duration::from_millis(500));///     u.unpark();/// // Wakes up when `u.unpark()` provides the token./// [`park`]: Parker::park/// [`park_timeout`]: Parker::park_timeout/// [`park_deadline`]: Parker::park_deadline/// [`unpark`]: Unparker::unpark/// Creates a new `Parker`.park/// Blocks the current thread until the token is made available.park_timeout/// Blocks the current thread until the token is made available, but only for a limited time./// // Waits for the token to become available, but will not wait longer than 500 ms./// p.park_timeout(Duration::from_millis(500));park_deadline/// Blocks the current thread until the token is made available, or until a certain deadline./// use std::time::{Duration, Instant};/// let deadline = Instant::now() + Duration::from_millis(500);/// p.park_deadline(deadline);/// Returns a reference to an associated [`Unparker`]./// The returned [`Unparker`] doesn't have to be used by reference - it can also be cloned./// Converts a `Parker` into a raw pointer./// let raw = Parker::into_raw(p);/// # let _ = unsafe { Parker::from_raw(raw) };/// Converts a raw pointer into a `Parker`./// This method is safe to use only with pointers returned by [`Parker::into_raw`]./// let p = unsafe { Parker::from_raw(raw) };/// Unparks a thread parked by the associated [`Parker`].unpark/// Atomically makes the token available if it is not already./// This method will wake up the thread blocked on [`park`] or [`park_timeout`], if there is/// any./// Converts an `Unparker` into a raw pointer./// use crossbeam_utils::sync::{Parker, Unparker};/// let raw = Unparker::into_raw(u);/// # let _ = unsafe { Unparker::from_raw(raw) };/// Converts a raw pointer into an `Unparker`./// This method is safe to use only with pointers returned by [`Unparker::into_raw`]./// let u = unsafe { Unparker::from_raw(raw) };PARKEDNOTIFIEDcvarLockResultTryLockErrorTryLockResultRwLockReadGuardRwLockWriteGuardThreadIdNUM_SHARDS/// The number of shards per sharded lock. Must be a power of two./// The inner reader-writer lock.write_guard/// The write-guard keeping this shard locked./// Write operations will lock each shard and store the guard here. These guards get dropped at/// the same time the big guard is dropped.Shard/// A shard containing a single reader-writer lock.shards/// A list of locks protecting the internal data./// The internal data./// A sharded reader-writer lock./// This lock is equivalent to [`RwLock`], except read operations are faster and write operations/// are slower./// A `ShardedLock` is internally made of a list of *shards*, each being a [`RwLock`] occupying a/// single cache line. Read operations will pick one of the shards depending on the current thread/// and lock it. Write operations need to lock all shards in succession./// By splitting the lock into shards, concurrent read operations will in most cases choose/// different shards and thus update different cache lines, which is good for scalability. However,/// write operations need to do more work and are therefore slower than usual./// The priority policy of the lock is dependent on the underlying operating system's/// implementation, and this type does not guarantee that any particular policy will be used./// # Poisoning/// A `ShardedLock`, like [`RwLock`], will become poisoned on a panic. Note that it may only be/// poisoned if a panic occurs while a write operation is in progress. If a panic occurs in any/// read operation, the lock will not be poisoned./// use crossbeam_utils::sync::ShardedLock;/// let lock = ShardedLock::new(5);/// // Any number of read locks can be held at once.///     let r1 = lock.read().unwrap();///     let r2 = lock.read().unwrap();///     assert_eq!(*r1, 5);///     assert_eq!(*r2, 5);/// } // Read locks are dropped at this point./// // However, only one write lock may be held.///     let mut w = lock.write().unwrap();///     *w += 1;///     assert_eq!(*w, 6);/// } // Write lock is dropped here./// [`RwLock`]: std::sync::RwLock/// Creates a new sharded reader-writer lock./// Consumes this lock, returning the underlying data./// This method will return an error if the lock is poisoned. A lock gets poisoned when a write/// operation panics./// let lock = ShardedLock::new(String::new());///     let mut s = lock.write().unwrap();///     *s = "modified".to_owned();/// assert_eq!(lock.into_inner().unwrap(), "modified");is_poisoned/// Returns `true` if the lock is poisoned./// If another thread can still access the lock, it may become poisoned at any time. A `false`/// result should not be trusted without additional synchronization./// let lock = Arc::new(ShardedLock::new(0));/// let c_lock = lock.clone();/// let _ = thread::spawn(move || {///     let _lock = c_lock.write().unwrap();///     panic!(); // the lock gets poisoned/// }).join();/// assert_eq!(lock.is_poisoned(), true);/// Returns a mutable reference to the underlying data./// Since this call borrows the lock mutably, no actual locking needs to take place./// let mut lock = ShardedLock::new(0);/// *lock.get_mut().unwrap() = 10;/// assert_eq!(*lock.read().unwrap(), 10);try_read/// Attempts to acquire this lock with shared read access./// If the access could not be granted at this time, an error is returned. Otherwise, a guard/// is returned which will release the shared access when it is dropped. This method does not/// provide any guarantees with respect to the ordering of whether contentious readers or/// writers will acquire the lock first./// let lock = ShardedLock::new(1);/// match lock.try_read() {///     Ok(n) => assert_eq!(*n, 1),///     Err(_) => unreachable!(),/// Locks with shared read access, blocking the current thread until it can be acquired./// The calling thread will be blocked until there are no more writers which hold the lock./// There may be other readers currently inside the lock when this method returns. This method/// does not provide any guarantees with respect to the ordering of whether contentious readers/// or writers will acquire the lock first./// Returns a guard which will release the shared access when dropped./// This method might panic when called if the lock is already held by the current thread./// let lock = Arc::new(ShardedLock::new(1));/// let n = lock.read().unwrap();/// assert_eq!(*n, 1);///     let r = c_lock.read();///     assert!(r.is_ok());/// }).join().unwrap();try_write/// Attempts to acquire this lock with exclusive write access./// is returned which will release the exclusive access when it is dropped. This method does/// not provide any guarantees with respect to the ordering of whether contentious readers or/// assert!(lock.try_write().is_err());/// Locks with exclusive write access, blocking the current thread until it can be acquired./// Returns a guard which will release the exclusive access when dropped./// let mut n = lock.write().unwrap();/// *n = 2;/// assert!(lock.try_read().is_err());clippyhas_significant_drop_guard/// A guard used to release the shared read access of a [`ShardedLock`] when dropped./// A guard used to release the exclusive write access of a [`ShardedLock`] when dropped.current_index/// Returns a `usize` that identifies the current thread./// Each thread is associated with an 'index'. While there are no particular guarantees, indices/// usually tend to be consecutive numbers between 0 and the number of running threads./// Since this function accesses TLS, `None` might be returned if the current thread's TLS is/// tearing down.mapping/// Mapping from `ThreadId` to thread index.free_list/// A list of free indices.next_index/// The next index to allocate if the free list is empty.ThreadIndices/// The global registry keeping track of registered threads and indices.thread_indicesthread_idRegistration/// A registration of a thread with an index./// When dropped, unregisters the thread and frees the reserved index.REGISTRATION/// Enables threads to synchronize the beginning or end of some computation./// # Wait groups vs barriers/// `WaitGroup` is very similar to [`Barrier`], but there are a few differences:/// * [`Barrier`] needs to know the number of threads at construction, while `WaitGroup` is cloned to///   register more threads./// * A [`Barrier`] can be reused even after all threads have synchronized, while a `WaitGroup`///   synchronizes threads only once./// * All threads wait for others to reach the [`Barrier`]. With `WaitGroup`, each thread can choose///   to either wait for other threads or to continue without blocking./// use crossbeam_utils::sync::WaitGroup;/// // Create a new wait group./// let wg = WaitGroup::new();/// for _ in 0..4 {///     // Create another reference to the wait group.///     let wg = wg.clone();///     thread::spawn(move || {///         // Do some work.///         // Drop the reference to the wait group.///         drop(wg);/// // Block until all threads have finished their work./// wg.wait();/// [`Barrier`]: std::sync::Barrier/// Inner state of a `WaitGroup`./// Creates a new wait group and returns the single reference to it.wait/// Drops this reference and waits until all other references are dropped./// thread::spawn({///     move || {///         // Block until both threads have reached `wait()`.///         wg.wait();/// // Block until both threads have reached `wait()`.SharedVecSharedOption'envscopeScope/// Creates a new scope for spawning threads./// All child threads that haven't been manually joined will be automatically joined just before/// this function invocation ends. If all joined threads have successfully completed, `Ok` is/// returned with the return value of `f`. If any of the joined threads has panicked, an `Err` is/// returned containing errors from panicked threads. Note that if panics are implemented by/// aborting the process, no error is returned; see the notes of [std::panic::catch_unwind]./// **Note:** Since Rust 1.63, this function is soft-deprecated in favor of the more efficient [`std::thread::scope`]./// use crossbeam_utils::thread;/// let var = vec![1, 2, 3];/// thread::scope(|s| {///     s.spawn(|_| {///         println!("A child thread borrowing `var`: {:?}", var);/// }).unwrap();handlesJoinHandle/// The list of the thread join handles./// Used to wait until all subscopes all dropped./// Borrows data with invariant lifetime `'env`./// A scope for spawning threads.'scopeScopedJoinHandle/// Spawns a scoped thread./// This method is similar to the [`spawn`] function in Rust's standard library. The difference/// is that this thread is scoped, meaning it's guaranteed to terminate before the scope exits,/// allowing it to reference variables outside the scope./// The scoped thread is passed a reference to this scope as an argument, which can be used for/// spawning nested threads./// The returned [handle](ScopedJoinHandle) can be used to manually/// [join](ScopedJoinHandle::join) the thread before the scope exits./// This will create a thread using default parameters of [`ScopedThreadBuilder`], if you want to specify the/// stack size or the name of the thread, use this API instead./// [`spawn`]: std::thread::spawn/// Panics if the OS fails to create a thread; use [`ScopedThreadBuilder::spawn`]/// to recover from such errors.///     let handle = s.spawn(|_| {///         println!("A child thread is running");///         42///     // Join the thread and retrieve its result.///     let res = handle.join().unwrap();///     assert_eq!(res, 42);ScopedThreadBuilder/// Creates a builder that can configure a thread before spawning.///     s.builder()///         .spawn(|_| println!("A child thread is running"))///         .unwrap();/// Configures the properties of a new thread./// The two configurable properties are:/// - [`name`]: Specifies an [associated name for the thread][naming-threads]./// - [`stack_size`]: Specifies the [desired stack size for the thread][stack-size]./// The [`spawn`] method will take ownership of the builder and return an [`io::Result`] of the/// thread handle with the given configuration./// The [`Scope::spawn`] method uses a builder with default configuration and unwraps its return/// value. You may want to use this builder when you want to recover from a failure to launch a/// thread.///         .spawn(|_| println!("Running a child thread"))/// [`name`]: ScopedThreadBuilder::name/// [`stack_size`]: ScopedThreadBuilder::stack_size/// [`spawn`]: ScopedThreadBuilder::spawn/// [`io::Result`]: std::io::Result/// [naming-threads]: std::thread#naming-threads/// [stack-size]: std::thread#stack-size/// Sets the name for the new thread./// The name must not contain null bytes (`\0`)./// For more information about named threads, see [here][naming-threads]./// use std::thread::current;///         .name("my thread".to_string())///         .spawn(|_| assert_eq!(current().name(), Some("my thread")))stack_size/// Sets the size of the stack for the new thread./// The stack size is measured in bytes./// For more information about the stack size for threads, see [here][stack-size].///         .stack_size(32 * 1024)/// Spawns a scoped thread with this configuration./// The returned handle can be used to manually join the thread before the scope exits./// Unlike the [`Scope::spawn`] method, this method yields an/// [`io::Result`] to capture any failure to create the thread at/// the OS level./// Panics if a thread name was set and it contained null bytes.///     let handle = s.builder()///         .spawn(|_| {///             println!("A child thread is running");///             42///         })handle/// A join handle to the spawned thread./// Holds the result of the inner closure.Thread/// A handle to the spawned thread./// Borrows the parent scope with lifetime `'scope`./// A handle that can be used to join its scoped thread./// This struct is created by the [`Scope::spawn`] method and the/// [`ScopedThreadBuilder::spawn`] method./// Waits for the thread to finish and returns its result./// If the child thread panics, an error is returned. Note that if panics are implemented by/// This function may panic on some platforms if a thread attempts to join itself or otherwise/// may create a deadlock with joining threads.///     let handle1 = s.spawn(|_| println!("I'm a happy thread :)"));///     let handle2 = s.spawn(|_| panic!("I'm a sad thread :("));///     // Join the first thread and verify that it succeeded.///     let res = handle1.join();///     assert!(res.is_ok());///     // Join the second thread and verify that it panicked.///     let res = handle2.join();///     assert!(res.is_err());/// Returns a handle to the underlying thread.///     let handle = s.spawn(|_| println!("A child thread is running"));///     println!("The child thread ID: {:?}", handle.thread().id());JoinHandleExtRawPthreadas_pthread_tinto_pthread_t/// Unix-specific extensions.//! Threads that can borrow variables from the stack.//! Create a scope when spawned threads need to access variables on the stack://! use crossbeam_utils::thread;//! let people = vec![//!     "Alice".to_string(),//!     "Bob".to_string(),//!     "Carol".to_string(),//! ];//! thread::scope(|s| {//!     for person in &people {//!         s.spawn(move |_| {//!             println!("Hello, {}!", person);//!         });//! }).unwrap();//! # Why scoped threads?//! Suppose we wanted to re-write the previous example using plain threads://! ```compile_fail,E0597//! use std::thread;//! let mut threads = Vec::new();//! for person in &people {//!     threads.push(thread::spawn(move || {//!         println!("Hello, {}!", person);//!     }));//! for thread in threads {//!     thread.join().unwrap();//! This doesn't work because the borrow checker complains about `people` not living long enough://! error[E0597]: `people` does not live long enough//!   --> src/main.rs:12:20//!    |//! 12 |     for person in &people {//!    |                    ^^^^^^ borrowed value does not live long enough//! ...//! 21 | }//!    | - borrowed value only lives until here//!    = note: borrowed value must be valid for the static lifetime...//! The problem here is that spawned threads are not allowed to borrow variables on stack because//! the compiler cannot prove they will be joined before `people` is destroyed.//! Scoped threads are a mechanism to guarantee to the compiler that spawned threads will be joined//! before the scope ends.//! # How scoped threads work//! If a variable is borrowed by a thread, the thread must complete before the variable is//! destroyed. Threads spawned using [`std::thread::spawn`] can only borrow variables with the//! `'static` lifetime because the borrow checker cannot be sure when the thread will complete.//! A scope creates a clear boundary between variables outside the scope and threads inside the//! scope. Whenever a scope spawns a thread, it promises to join the thread before the scope ends.//! This way we guarantee to the borrow checker that scoped threads only live within the scope and//! can safely access variables outside it.//! # Nesting scoped threads//! Sometimes scoped threads need to spawn more threads within the same scope. This is a little//! tricky because argument `s` lives *inside* the invocation of `thread::scope()` and as such//! cannot be borrowed by scoped threads://! ```compile_fail,E0521//!     s.spawn(|_| {//!         // Not going to compile because we're trying to borrow `s`,//!         // which lives *inside* the scope! :(//!         s.spawn(|_| println!("nested thread"));//!     });//! });//! Fortunately, there is a solution. Every scoped thread is passed a reference to its scope as an//! argument, which can be used for spawning nested threads://!     // Note the `|s|` here.//!     s.spawn(|s| {//!         // Yay, this works because we're using a fresh argument `s`! :)LOWER_LIMIT" Unroll the given for loop"" Example:"" ```ignore"" unroll! {""   for i in 0..5 {""     println!(\"Iteration {}\", i);""   }"" }"" ```"" will expand into:"" { println!(\"Iteration {}\", 0); }"" { println!(\"Iteration {}\", 1); }"" { println!(\"Iteration {}\", 2); }"" { println!(\"Iteration {}\", 3); }"" { println!(\"Iteration {}\", 4); }"//! The crunchy unroller - deterministically unroll constant loops. For number "crunching".//! The Rust optimizer will unroll constant loops that don't use the loop variable, like this://! for _ in 0..100 {//!     println!("Hello!");//! However, using the loop variable will cause it to never unroll the loop. This is unfortunate because it means that you can't//! constant-fold the loop variable, and if you end up stomping on the registers it will have to do a load for each iteration.//! This crate ensures that your code is unrolled and const-folded. It only works on literals,//! unfortunately, but there's a work-around://! debug_assert_eq!(MY_CONSTANT, 100);//! unroll! {//!     for i in 0..100 {//!         println!("Iteration {}", i);//! This means that your tests will catch if you redefine the constant.//! To default maximum number of loops to unroll is `64`, but that can be easily increased using the cargo features://! * `limit_128`//! * `limit_256`//! * `limit_512`//! * `limit_1024`//! * `limit_2048`/// Block on which [`BlockSizeUser`] implementors operate.ParBlocksSizeUserParBlocksSize/// Parallel blocks on which [`ParBlocksSizeUser`] implementors operate./// Output array of [`OutputSizeUser`] implementors./// Key used by [`KeySizeUser`] implementors.IvIvSizeUserIvSize/// Initialization vector (nonce) used by [`IvSizeUser`] implementors./// Size of the block in bytes./// Return block size in bytes./// Types which process data in blocks./// Number of blocks which can be processed in parallel./// Types which can process blocks in parallel./// Size of the output in bytes.output_size/// Return output size in bytes./// Types which return data with the given size./// Key size in bytes.key_size/// Return key size in bytes./// Types which use key for initialization./// Generally it's used indirectly via [`KeyInit`] or [`KeyIvInit`]./// Initialization vector size in bytes.iv_size/// Return IV size in bytes./// Types which use initialization vector (nonce) for initialization./// Generally it's used indirectly via [`KeyIvInit`] or [`InnerIvInit`]./// Inner type.InnerUser/// Types which use another type for initialization./// Generally it's used indirectly via [`InnerInit`] or [`InnerIvInit`]./// Reset state to its initial value./// Resettable types.write_alg_name/// Write algorithm name into `f`.AlgorithmName/// Trait which stores algorithm name constant, used in `Debug` implementations./// Create new value from fixed size key./// Create new value from variable size key./// Types which can be initialized from key./// Create new value from fixed length key and nonce./// Create new value from variable length key and nonce.KeyIvInit/// Types which can be initialized from key and initialization vector (nonce).inner_init/// Initialize value from the `inner`.InnerInit/// Types which can be initialized from another type (usually block ciphers)./// Usually used for initializing types from block ciphers.inner_iv_init/// Initialize value using `inner` and `iv` array.inner_iv_slice_init/// Initialize value using `inner` and `iv` slice.InnerIvInit/// Types which can be initialized from another type and additional initialization/// vector/nonce./// The error type returned when key and/or IV used in the [`KeyInit`],/// [`KeyIvInit`], and [`InnerIvInit`] slice-based methods had/// an invalid length.//! Common cryptographic traits.// Unfortunately this blanket impl is impossible without mutually// exclusive traits, see: https://github.com/rust-lang/rfcs/issues/1053// or at the very least without: https://github.com/rust-lang/rust/issues/20400/*
impl<T> KeyIvInit for T
where
    T: InnerInit,
    T::Inner: KeyIvInit,
{
    #[inline]
    fn new(key: &Key<Self>, iv: &Iv<Self>) -> Self {
        Self::inner_init(T::Inner::new(key, iv))
    }

    #[inline]
    fn new_from_slices(key: &[u8], iv: &[u8]) -> Result<Self, InvalidLength> {
        T::Inner::new_from_slice(key)
            .map_err(|_| InvalidLength)
            .map(Self::inner_init)
    }
}
*//// Define testbench/// Define benchmarkMacError/// Error type for signaling failed MAC verificationInvalidKeyLength/// Error type for signaling invalid key length for MAC initializationChoiceConstantTimeEqNewMac/// Key for an algorithm that implements [`NewMac`]./// Initialize new MAC instance from key with fixed size.new_varkey/// Initialize new MAC instance from key with variable size./// `KeySize`, but some MACs can accept range of key lengths./// Instantiate a [`Mac`] algorithm./// Output size of the [[`Mac`]]/// Update MAC state with the given data./// Reset [`Mac`] instance./// Obtain the result of a [`Mac`] computation as a [`Output`] and consume/// [`Mac`] instance.finalize_reset/// Obtain the result of a [`Mac`] computation as a [`Output`] and reset/// Check if tag/code value is correct for the processed input.Mac/// The [`Mac`] trait defines methods for a Message Authentication algorithm./// [`Output`] is a thin wrapper around bytes array which provides a safe `Eq`/// implementation that runs in a fixed time./// Create a new MAC [`Output`]./// Get the MAC tag/code value as a byte array./// Be very careful using this method, since incorrect use of the tag value/// may permit timing attacks which defeat the security provided by the/// [`Mac`] trait.ct_eqimpl_write/// Implements `std::io::Write` trait for implementer of [`Mac`]//! This crate provides trait for Message Authentication Code (MAC) algorithms.CtrFlavoroperator_aliasesPartialQuottype_operatorsPartialDivChunkSizeChunksCSCtr128BE/// 128-bit big endian counter flavor.Backendgenerate_blockincrementto_backendfrom_backendCtr128LE/// 128-bit little endian counter flavor.//! 128-bit counter falvors.Ctr32BE/// 32-bit big endian counter flavor./// 32-bit little endian counter flavor.//! 32-bit counter falvors./// 64-bit big endian counter flavor.Ctr64LE/// 64-bit little endian counter flavor.//! 64-bit counter falvors.ctr128ctr32ctr64/// Inner representation of nonce./// Backend numeric type/// Generate block for given `nonce` value./// Load nonce value from bytes./// Checked addition./// Wrapped increment./// Convert from a backend value/// Convert to a backend value/// Trait implemented by different counter types used in the CTR mode.//! CTR mode flavorsflavorsCtr/// CTR mode with 128-bit big endian counter./// CTR mode with 128-bit little endian counter./// CTR mode with 64-bit big endian counter./// CTR mode with 64-bit little endian counter./// CTR mode with 32-bit big endian counter./// CTR mode with 32-bit little endian counter.buf_pos/// Generic CTR block mode isntance.check_data_lenseek_block/// Seek to the given block// TODO: replace with a trait-based methodcurrent_block/// Return number of the current blockto_slice//! Generic implementations of CTR mode for block ciphers.//! Mode functionality is accessed using traits from re-exported//! # ⚠️ Security Warning: [Hazmat!]//! This crate does not ensure ciphertexts are authentic! Thus ciphertext integrity//! is not verified, which can lead to serious vulnerabilities!//! # `Ctr128` Usage Example//! use ctr::cipher::{NewCipher, StreamCipher, StreamCipherSeek};//! // `aes` crate provides AES block cipher implementation//! type Aes128Ctr = ctr::Ctr128BE<aes::Aes128>;//! let mut data = [1, 2, 3, 4, 5, 6, 7];//! let key = b"very secret key.";//! let nonce = b"and secret nonce";//! // create cipher instance//! let mut cipher = Aes128Ctr::new(key.into(), nonce.into());//! // apply keystream (encrypt)//! cipher.apply_keystream(&mut data);//! assert_eq!(data, [6, 245, 126, 124, 180, 146, 37]);//! // seek to the keystream beginning and apply it again to the `data` (decrypt)//! cipher.seek(0);//! assert_eq!(data, [1, 2, 3, 4, 5, 6, 7]);//! [Hazmat!]: https://github.com/RustCrypto/meta/blob/master/HAZMAT.mdserial// -*- mode: rust; -*-// This file is part of curve25519-dalek.// Copyright (c) 2016-2021 isis lovecruft// Copyright (c) 2016-2019 Henry de Valence// See LICENSE for licensing information.// Authors:// - isis agora lovecruft <isis@patternsinthevoid.net>// - Henry de Valence <hdevalence@hdevalence.ca>//! Pluggable implementations for different architectures.//! The backend code is split into two parts: a serial backend,//! and a vector backend.//! The [`serial`] backend contains 32- and 64-bit implementations of//! field arithmetic and scalar arithmetic, as well as implementations//! of point operations using the mixed-model strategy (passing//! between different curve models depending on the operation).//! The [`vector`] backend contains implementations of vectorized//! field arithmetic, used to implement point operations using a novel//! implementation strategy derived from parallel formulas of Hisil,//! Wong, Carter, and Dawson.//! Because the two strategies give rise to different curve models,//! it's not possible to reuse exactly the same scalar multiplication//! code (or to write it generically), so both serial and vector//! backends contain matching implementations of scalar multiplication//! algorithms.  These are intended to be selected by a `#[cfg]`-based//! type alias.//! The [`vector`] backend is selected by the `simd_backend` cargo//! feature; it uses the [`serial`] backend for non-vectorized operations.ConditionallySelectableedwardsEdwardsPointFieldElementValidityCheckYZProjectivePoint/// A `ProjectivePoint` is a point \\((X:Y:Z)\\) on the \\(\mathbb/// P\^2\\) model of the curve./// A point \\((x,y)\\) in the affine model corresponds to/// \\((x:y:1)\\)./// More details on the relationships between the different curve models/// can be found in the module-level documentation.CompletedPoint/// A `CompletedPoint` is a point \\(((X:Z), (Y:T))\\) on the \\(\mathbb/// P\^1 \times \mathbb P\^1 \\) model of the curve./// A point (x,y) in the affine model corresponds to \\( ((x:1),(y:1))/// \\).y_plus_xy_minus_xxy2dAffineNielsPoint/// A pre-computed point in the affine model for the curve, represented as/// \\((y+x, y-x, 2dxy)\\) in "Niels coordinates".// Safe to derive Eq because affine coordinates.Y_plus_XY_minus_XT2dProjectiveNielsPoint/// A pre-computed point on the \\( \mathbb P\^3 \\) model for the/// curve, represented as \\((Y+X, Y-X, Z, 2dXY)\\) in "Niels coordinates".Identityis_validconditional_selectconditional_assignto_extended/// Convert this point from the \\( \mathbb P\^2 \\) model to the/// \\( \mathbb P\^3 \\) model./// This costs \\(3 \mathrm M + 1 \mathrm S\\).to_projective/// Convert this point from the \\( \mathbb P\^1 \times \mathbb P\^1/// \\) model to the \\( \mathbb P\^2 \\) model./// This costs \\(3 \mathrm M \\)./// \\) model to the \\( \mathbb P\^3 \\) model./// This costs \\(4 \mathrm M \\)./// Double this point: return self + self// XXX(hdevalence) These were doc(hidden) so they don't appear in the// public API docs.// However, that prevents them being used with --document-private-items,// so comment out the doc(hidden) for now until this is resolved// upstream rust issue: https://github.com/rust-lang/rust/issues/46380//#[doc(hidden)]//! Internal curve representations which are not part of the public API.//! # Curve representations//! Internally, we use several different models for the curve.  Here//! is a sketch of the relationship between the models, following [a//! post][smith-moderncrypto]//! by Ben Smith on the `moderncrypto` mailing list.  This is also briefly//! discussed in section 2.5 of [_Montgomery curves and their//! arithmetic_][costello-smith-2017] by Costello and Smith.//! Begin with the affine equation for the curve,//! $$//!     -x\^2 + y\^2 = 1 + dx\^2y\^2.//! Next, pass to the projective closure \\(\mathbb P\^1 \times \mathbb//! P\^1 \\) by setting \\(x=X/Z\\), \\(y=Y/T.\\)  Clearing denominators//! gives the model//!     -X\^2T\^2 + Y\^2Z\^2 = Z\^2T\^2 + dX\^2Y\^2.//! In `curve25519-dalek`, this is represented as the `CompletedPoint`//! struct.//! To map from \\(\mathbb P\^1 \times \mathbb P\^1 \\), a product of//! two lines, to \\(\mathbb P\^3\\), we use the [Segre//! embedding](https://en.wikipedia.org/wiki/Segre_embedding)//!     \sigma : ((X:Z),(Y:T)) \mapsto (XY:XT:ZY:ZT).//! Using coordinates \\( (W_0:W_1:W_2:W_3) \\) for \\(\mathbb P\^3\\),//! the image \\(\sigma (\mathbb P\^1 \times \mathbb P\^1) \\) is the//! surface defined by \\( W_0 W_3 = W_1 W_2 \\), and under \\(//! \sigma\\), the equation above becomes//!     -W\_1\^2 + W\_2\^2 = W\_3\^2 + dW\_0\^2,//! so that the curve is given by the pair of equations//! \begin{aligned}//!     -W\_1\^2 + W\_2\^2 &= W\_3\^2 + dW\_0\^2, \\\\  W_0 W_3 &= W_1 W_2.//! \end{aligned}//! Up to variable naming, this is exactly the "extended" curve model//! introduced in [_Twisted Edwards Curves//! Revisited_][hisil-wong-carter-dawson-2008] by Hisil, Wong, Carter,//! and Dawson.  In `curve25519-dalek`, it is represented as the//! `EdwardsPoint` struct.  We can map from \\(\mathbb P\^3 \\) to//! \\(\mathbb P\^2 \\) by sending \\( (W\_0:W\_1:W\_2:W\_3) \\) to \\(//! (W\_1:W\_2:W\_3) \\).  Notice that//!     \frac {W\_1} {W\_3} = \frac {XT} {ZT} = \frac X Z = x,//!     \frac {W\_2} {W\_3} = \frac {YZ} {ZT} = \frac Y T = y,//! so this is the same as if we had started with the affine model//! and passed to \\( \mathbb P\^2 \\) by setting \\( x = W\_1 / W\_3//! \\), \\(y = W\_2 / W\_3 \\).//! Up to variable naming, this is the projective representation//! introduced in in [_Twisted Edwards//! Curves_][bernstein-birkner-joye-lange-peters-2008] by Bernstein,//! Birkner, Joye, Lange, and Peters.  In `curve25519-dalek`, it is//! represented by the `ProjectivePoint` struct.//! # Passing between curve models//! Although the \\( \mathbb P\^3 \\) model provides faster addition//! formulas, the \\( \mathbb P\^2 \\) model provides faster doubling//! formulas.  Hisil, Wong, Carter, and Dawson therefore suggest mixing//! coordinate systems for scalar multiplication, attributing the idea//! to [a 1998 paper][cohen-miyaji-ono-1998] of Cohen, Miyagi, and Ono.//! Their suggestion is to vary the formulas used by context, using a//! \\( \mathbb P\^2 \rightarrow \mathbb P\^2 \\) doubling formula when//! a doubling is followed//! by another doubling, a \\( \mathbb P\^2 \rightarrow \mathbb P\^3 \\)//! doubling formula when a doubling is followed by an addition, and//! computing point additions using a \\( \mathbb P\^3 \times \mathbb P\^3//! \rightarrow \mathbb P\^2 \\) formula.//! The `ref10` reference implementation of [Ed25519][ed25519], by//! Bernstein, Duif, Lange, Schwabe, and Yang, tweaks//! this strategy, factoring the addition formulas through the//! completion \\( \mathbb P\^1 \times \mathbb P\^1 \\), so that the//! output of an addition or doubling always lies in \\( \mathbb P\^1 \times//! \mathbb P\^1\\), and the choice of which formula to use is replaced//! by a choice of whether to convert the result to \\( \mathbb P\^2 \\)//! or \\(\mathbb P\^3 \\).  However, this tweak is not described in//! their paper, only in their software.//! Our naming for the `CompletedPoint` (\\(\mathbb P\^1 \times \mathbb//! P\^1 \\)), `ProjectivePoint` (\\(\mathbb P\^2 \\)), and//! `EdwardsPoint` (\\(\mathbb P\^3 \\)) structs follows the naming in//! Adam Langley's [Golang ed25519][agl-ed25519] implementation, which//! `curve25519-dalek` was originally derived from.//! Finally, to accelerate readditions, we use two cached point formats//! in "Niels coordinates", named for Niels Duif,//! one for the affine model and one for the \\( \mathbb P\^3 \\) model://! * `AffineNielsPoint`: \\( (y+x, y-x, 2dxy) \\)//! * `ProjectiveNielsPoint`: \\( (Y+X, Y-X, Z, 2dXY) \\)//! [smith-moderncrypto]: https://moderncrypto.org/mail-archive/curves/2016/000807.html//! [costello-smith-2017]: https://eprint.iacr.org/2017/212//! [hisil-wong-carter-dawson-2008]: https://www.iacr.org/archive/asiacrypt2008/53500329/53500329.pdf//! [bernstein-birkner-joye-lange-peters-2008]: https://eprint.iacr.org/2008/013//! [cohen-miyaji-ono-1998]: https://link.springer.com/content/pdf/10.1007%2F3-540-49649-1_6.pdf//! [ed25519]: https://eprint.iacr.org/2011/368//! [agl-ed25519]: https://github.com/agl/ed25519// ------------------------------------------------------------------------// Internal point representations// Constructors// Validity checks (for debugging, not CT)// Constant-time assignment// Point conversions// Doubling// Addition and Subtraction// Negation// Debug traitsfiat_cryptocurve25519_32FieldElement2625/// A `FieldElement2625` represents an element of the field/// \\( \mathbb Z / (2\^{255} - 19)\\)./// In the 32-bit implementation, a `FieldElement` is represented in/// radix \\(2\^{25.5}\\) as ten `u32`s.  This means that a field/// element \\(x\\) is represented as/// $$/// x = \sum\_{i=0}\^9 x\_i 2\^{\lceil i \frac {51} 2 \rceil}///   = x\_0 + x\_1 2\^{26} + x\_2 2\^{51} + x\_3 2\^{77} + \cdots + x\_9 2\^{230};/// the coefficients are alternately bounded by \\(2\^{25}\\) and/// \\(2\^{26}\\).  The limbs are allowed to grow between reductions up/// to \\(2\^{25+b}\\) or \\(2\^{26+b}\\), where \\(b = 1.75\\)./// The `curve25519_dalek::field` module provides a type alias/// `curve25519_dalek::field::FieldElement` to either `FieldElement51`/// or `FieldElement2625`./// The backend-specific type `FieldElement2625` should not be used/// outside of the `curve25519_dalek::field` module.conditional_swapnegate/// Invert the sign of this field element/// Construct zero./// Construct one.minus_one/// Construct -1.pow2k/// Given `k > 0`, return `self^(2^k)`./// Load a `FieldElement2625` from the low 255 bits of a 256-bit/// input./// This function does not check that the input used the canonical/// representative.  It masks the high bit, but it will happily/// decode 2^255 - 18 to 1.  Applications that require a canonical/// encoding of every field element should decode, re-encode to/// the canonical encoding, and check that the input was/// canonical./// Serialize this `FieldElement51` to a 32-byte array.  The/// encoding is canonical./// Compute `self^2`.square2/// Compute `2*self^2`.// -*- mode: rust; coding: utf-8; -*-// Copyright (c) 2016-2018 Isis Lovecruft, Henry de Valence// - Isis Agora Lovecruft <isis@patternsinthevoid.net>//! Field arithmetic modulo \\(p = 2\^{255} - 19\\), using \\(32\\)-bit//! limbs with \\(64\\)-bit products.//! This code was originally derived from Adam Langley's Golang ed25519//! implementation, and was then rewritten to use unsigned limbs instead//! of signed limbs.//! This uses the formally-verified field arithmetic generated by the//! [fiat-crypto project](https://github.com/mit-plv/fiat-crypto)"../u32/scalar.rs"scalar"../u32/constants.rs"//! The `u32` backend uses `u32`s and a `(u32, u32) -> u64` multiplier.//! This code is intended to be portable, but it requires that//! multiplication of two \\(32\\)-bit values to a \\(64\\)-bit result//! is constant-time on the target platform.curve25519_64FieldElement51/// A `FieldElement51` represents an element of the field/// In the 64-bit implementation, a `FieldElement` is represented in/// radix \\(2\^{51}\\) as five `u64`s; the coefficients are allowed to/// grow up to \\(2\^{54}\\) between reductions modulo \\(p\\)./// The backend-specific type `FieldElement51` should not be usedreduce/// Given 64-bit input limbs, reduce to enforce the bound 2^(51 + epsilon).// Need this to not complain about reduce not being used/// Load a `FieldElement51` from the low 255 bits of a 256-bit/// Returns the square of this field element./// Returns 2 times the square of this field element.//! Field arithmetic modulo \\(p = 2\^{255} - 19\\), using \\(64\\)-bit//! limbs with \\(128\\)-bit products."../u64/scalar.rs""../u64/constants.rs"//! The `u64` backend uses `u64`s and a `(u64, u64) -> u128` multiplier.//! On x86_64, the idiom `(x as u128) * (y as u128)` lowers to `MUL`//! instructions taking 64-bit inputs and producing 128-bit outputs.  On//! other platforms, this implementation is not recommended.//! On Haswell and newer, the BMI2 extension provides `MULX`, and on//! Broadwell and newer, the ADX extension provides `ADCX` and `ADOX`//! (allowing the CPU to compute two carry chains in parallel).  These//! will be used if available.curve_models//! Serial implementations of field, scalar, point arithmetic.//! When the vector backend is disabled, the crate uses the//! mixed-model strategy for implementing point operations and scalar//! multiplication; see the [`curve_models`](self::curve_models) and//! [`scalar_mul`](self::scalar_mul) documentation for more//! information.//! When the vector backend is enabled, the field and scalar//! implementations are still used for non-vectorized operations.//! Note: at this time the `u32` and `u64` backends cannot be built//! together.vartime_double_basestrausprecomputed_strauspippenger//! Implementations of various scalar multiplication algorithms.//! Note that all of these implementations use serial code for field//! arithmetic with the multi-model strategy described in the//! `curve_models` module.  The vectorized AVX2 backend has its own//! scalar multiplication implementations, since it only uses one//! curve model.ScalarVartimeMultiscalarMulPippenger/// Implements a version of Pippenger's algorithm./// The algorithm works as follows:/// Let `n` be a number of point-scalar pairs./// Let `w` be a window of bits (6..8, chosen based on `n`, see cost factor)./// 1. Prepare `2^(w-1) - 1` buckets with indices `[1..2^(w-1))` initialized with identity points.///    Bucket 0 is not needed as it would contain points multiplied by 0./// 2. Convert scalars to a radix-`2^w` representation with signed digits in `[-2^w/2, 2^w/2]`.///    Note: only the last digit may equal `2^w/2`./// 3. Starting with the last window, for each point `i=[0..n)` add it to a a bucket indexed by///    the point's scalar's value in the window./// 4. Once all points in a window are sorted into buckets, add buckets by multiplying each///    by their index. Efficient way of doing it is to start with the last bucket and compute two sums:///    intermediate sum from the last to the first, and the full sum made of all intermediate sums./// 5. Shift the resulting sum of buckets by `w` bits by using `w` doublings./// 6. Add to the return value./// 7. Repeat the loop./// Approximate cost w/o wNAF optimizations (A = addition, D = doubling):/// ```ascii/// cost = (n*A + 2*(2^w/2)*A + w*D + A)*256/w///          |          |       |     |   |///          |          |       |     |   looping over 256/w windows///          |          |       |     adding to the result///    sorting points   |       shifting the sum by w bits (to the next window, starting from last window)///    one by one       |///    into buckets     adding/subtracting all buckets///                     multiplied by their indexes///                     using a sum of intermediate sums/// For large `n`, dominant factor is (n*256/w) additions./// However, if `w` is too big and `n` is not too big, then `(2^w/2)*A` could dominate./// Therefore, the optimal choice of `w` grows slowly as `n` grows./// This algorithm is adapted from section 4 of <https://eprint.iacr.org/2012/549.pdf>.optional_multiscalar_multest_vartime_pippenger// Copyright (c) 2019 Oleg Andreev// - Oleg Andreev <oleganza@gmail.com>//! Implementation of a variant of Pippenger's algorithm.backendVartimePrecomputedMultiscalarMulwindowNafLookupTable5NafLookupTable8static_lookup_tablesVartimePrecomputedStrausoptional_mixed_multiscalar_mul// Copyright (c) 2019 Henry de Valence.//! Precomputation for Straus's method.MultiscalarMulStraus/// Perform multiscalar multiplication by the interleaved window/// method, also known as Straus' method (since it was apparently/// [first published][solution] by Straus in 1964, as a solution to [a/// problem][problem] posted in the American Mathematical Monthly in/// 1963)./// It is easy enough to reinvent, and has been repeatedly.  The basic/// idea is that when computing/// \\[/// Q = s_1 P_1 + \cdots + s_n P_n/// \\]/// by means of additions and doublings, the doublings can be shared/// across the \\( P_i \\\)./// We implement two versions, a constant-time algorithm using fixed/// windows and a variable-time algorithm using sliding windows.  They/// are slight variations on the same idea, and are described in more/// detail in the respective implementations./// [solution]: https://www.jstor.org/stable/2310929/// [problem]: https://www.jstor.org/stable/2312273multiscalar_mul/// Constant-time Straus using a fixed window of size \\(4\\)./// Our goal is to compute/// Q = s_1 P_1 + \cdots + s_n P_n./// For each point \\( P_i \\), precompute a lookup table of/// P_i, 2P_i, 3P_i, 4P_i, 5P_i, 6P_i, 7P_i, 8P_i./// For each scalar \\( s_i \\), compute its radix-\\(2^4\\)/// signed digits \\( s_{i,j} \\), i.e.,///    s_i = s_{i,0} + s_{i,1} 16^1 + ... + s_{i,63} 16^{63},/// with \\( -8 \leq s_{i,j} < 8 \\).  Since \\( 0 \leq |s_{i,j}|/// \leq 8 \\), we can retrieve \\( s_{i,j} P_i \\) from the/// lookup table with a conditional negation: using signed/// digits halves the required table size./// Then as in the single-base fixed window case, we have/// \begin{aligned}/// s_i P_i &= P_i (s_{i,0} +     s_{i,1} 16^1 + \cdots +     s_{i,63} 16^{63})   \\\\/// s_i P_i &= P_i s_{i,0} + P_i s_{i,1} 16^1 + \cdots + P_i s_{i,63} 16^{63}     \\\\/// s_i P_i &= P_i s_{i,0} + 16(P_i s_{i,1} + 16( \cdots +16P_i s_{i,63})\cdots )/// \end{aligned}/// so each \\( s_i P_i \\) can be computed by alternately adding/// a precomputed multiple \\( P_i s_{i,j} \\) of \\( P_i \\) and/// repeatedly doubling./// Now consider the two-dimensional sum/// s\_1 P\_1 &=& P\_1 s\_{1,0} &+& 16 (P\_1 s\_{1,1} &+& 16 ( \cdots &+& 16 P\_1 s\_{1,63}&) \cdots ) \\\\///     +     & &      +        & &      +            & &             & &     +            &           \\\\/// s\_2 P\_2 &=& P\_2 s\_{2,0} &+& 16 (P\_2 s\_{2,1} &+& 16 ( \cdots &+& 16 P\_2 s\_{2,63}&) \cdots ) \\\\/// \vdots    & &  \vdots       & &   \vdots          & &             & &  \vdots          &           \\\\/// s\_n P\_n &=& P\_n s\_{n,0} &+& 16 (P\_n s\_{n,1} &+& 16 ( \cdots &+& 16 P\_n s\_{n,63}&) \cdots )/// The sum of the left-hand column is the result \\( Q \\); by/// computing the two-dimensional sum on the right column-wise,/// top-to-bottom, then right-to-left, we need to multiply by \\(/// 16\\) only once per column, sharing the doublings across all/// of the input points./// Variable-time Straus using a non-adjacent form of width \\(5\\)./// This is completely similar to the constant-time code, but we/// use a non-adjacent form for the scalar, and do not do table/// lookups in constant time./// The non-adjacent form has signed, odd digits.  Using only odd/// digits halves the table size (since we only need odd/// multiples), or gives fewer additions for the same table size.//! Implementation of the interleaved window method, also known as Straus' method.LookupTable/// Perform constant-time, variable-base scalar multiplication./// Compute \\(aA + bB\\) in variable time, where \\(B\\) is the Ed25519 basepoint.Scalar29EdwardsBasepointTableMINUS_ONE/// The value of minus one, equal to `-&FieldElement::one()`EDWARDS_D/// Edwards `d` value, equal to `-121665/121666 mod p`.EDWARDS_D2/// Edwards `2*d` value, equal to `2*(-121665/121666) mod p`.ONE_MINUS_EDWARDS_D_SQUARED/// One minus edwards `d` value squared, equal to `(1 - (-121665/121666) mod p) pow 2`EDWARDS_D_MINUS_ONE_SQUARED/// Edwards `d` value minus one squared, equal to `(((-121665/121666) mod p) - 1) pow 2`SQRT_AD_MINUS_ONE/// `= sqrt(a*d - 1)`, where `a = -1 (mod p)`, `d` are the Edwards curve parameters.INVSQRT_A_MINUS_D/// `= 1/sqrt(a-d)`, where `a = -1 (mod p)`, `d` are the Edwards curve parameters.SQRT_M1/// Precomputed value of one of the square roots of -1 (mod p)APLUS2_OVER_FOUR/// `APLUS2_OVER_FOUR` is (A+2)/4. (This is used internally within the Montgomery ladder.)MONTGOMERY_A/// `MONTGOMERY_A` is equal to 486662, which is a constant of the curve equation/// for Curve25519 in its Montgomery form. (This is used internally within the/// Elligator map.)MONTGOMERY_A_NEG/// `MONTGOMERY_A_NEG` is equal to -486662. (This is used internally within the/// `L` is the order of base point, i.e. 2^252 +/// 27742317777372353535851937790883648493LFACTOR/// `L` * `LFACTOR` = -1 (mod 2^29)/// `R` = R % L where R = 2^261RR/// `RR` = (R^2) % L where R = 2^261ED25519_BASEPOINT_POINT/// The Ed25519 basepoint, as an `EdwardsPoint`./// This is called `_POINT` to distinguish it from/// `ED25519_BASEPOINT_TABLE`, which should be used for scalar/// multiplication (it's much faster).EIGHT_TORSION/// The 8-torsion subgroup \\(\mathcal E [8]\\)./// In the case of Curve25519, it is cyclic; the \\(i\\)-th element of/// the array is \\([i]P\\), where \\(P\\) is a point of order \\(8\\)/// generating \\(\mathcal E[8]\\)./// Thus \\(\mathcal E[4]\\) is the points indexed by `0,2,4,6`, and/// \\(\mathcal E[2]\\) is the points indexed by `0,4`./// The Ed25519 basepoint has y = 4/5.  This is called `_POINT` to/// distinguish it from `_TABLE`, which should be used for scalarEIGHT_TORSION_INNER_DOC_HIDDEN/// Inner item used to hide limb constants from cargo doc output.ED25519_BASEPOINT_TABLE/// Table containing precomputed multiples of the Ed25519 basepoint \\(B = (x, 4/5)\\).ED25519_BASEPOINT_TABLE_INNER_DOC_HIDDEN/// Inner constant, used to avoid filling the docs with precomputed points.AFFINE_ODD_MULTIPLES_OF_BASEPOINT/// Odd multiples of the basepoint `[B, 3B, 5B, 7B, 9B, 11B, 13B, 15B, ..., 127B]`.//! This module contains various constants (such as curve parameters//! and useful field elements like `sqrt(-1)`), as well as//! lookup tables of pre-computed points./// Given unreduced coefficients `z[0], ..., z[9]` of any size,/// carry and reduce them mod p to obtain a `FieldElement2625`/// whose coefficients have excess `b < 0.007`./// In other words, each coefficient of the result is bounded by/// either `2^(25 + 0.007)` or `2^(26 + 0.007)`, as appropriate.square_inner/// The `Scalar29` struct represents an element in ℤ/lℤ as 9 29-bit limbsm/// u32 * u32 = u64 multiply helper/// Return the zero scalar./// Unpack a 32 byte / 256 bit scalar into 9 29-bit limbs.from_bytes_wide/// Reduce a 64 byte / 512 bit scalar mod l./// Pack the limbs of this `Scalar29` into 32 bytes./// Compute `a + b` (mod l)./// Compute `a - b` (mod l).mul_internal/// Compute `a * b`./// This is implemented with a one-level refined Karatsuba decompositionsquare_internal/// Compute `a^2`.montgomery_reduce/// Compute `limbs/R` (mod l), where R is the Montgomery modulus 2^261/// Compute `a * b` (mod l)./// Compute `a^2` (mod l).// XXX we don't expose square() via the Scalar APImontgomery_mul/// Compute `(a * b) / R` (mod l), where R is the Montgomery modulus 2^261montgomery_square/// Compute `(a^2) / R` (mod l) in Montgomery form, where R is the Montgomery modulus 2^261to_montgomery/// Puts a Scalar29 in to Montgomery form, i.e. computes `a*R (mod l)`from_montgomery/// Takes a Scalar29 out of Montgomery form, i.e. computes `a/R (mod l)`/// Note: x is 2^253-1 which is slightly larger than the largest scalar produced by/// this implementation (l-1), and should verify there are no overflows for valid scalars/// x = 2^253-1 = 14474011154664524427946373126085988481658748083205070504932198000989141204991/// x = 7237005577332262213973186563042994240801631723825162898930247062703686954002 mod l/// x = 5147078182513738803124273553712992179887200054963030844803268920753008712037*R mod l in Montgomery form/// x^2 = 3078544782642840487852506753550082162405942681916160040940637093560259278169 mod lXX_MONT/// x^2 = 2912514428060642753613814151688322857484807845836623976981729207238463947987*R mod l in Montgomery form/// y = 6145104759870991071742105800796537629880401874866217824609283457819451087098XY/// x*y = 36752150652102274958925982391442301741XY_MONT/// x*y = 3783114862749659543382438697751927473898937741870308063443170013240655651591*R mod l in Montgomery form/// a = 2351415481556538453565687241199399922945659411799870114962672658845158063753/// b = 4885590095775723760407499321843594317911456947580037491039278279440296187236/// a+b = 0/// a-b = 4702830963113076907131374482398799845891318823599740229925345317690316127506// c = (2^512 - 1) % l = 1627715501170711445284395025044413883736156588369414752970002579683115011840mul_maxsquare_maxmontgomery_mul_maxmontgomery_square_max//! Arithmetic mod 2^252 + 27742317777372353535851937790883648493//! with 9 29-bit unsigned limbs//! To see that this is safe for intermediate results, note that//! the largest limb in a 9 by 9 product of 29-bit limbs will be//! (0x1fffffff^2) * 9 = 0x23fffffdc0000009 (62 bits).//! For a one level Karatsuba decomposition, the specific ranges//! depend on how the limbs are combined, but will stay within//! -0x1ffffffe00000008 (62 bits with sign bit) to//! 0x43fffffbc0000011 (63 bits), which is still safe.Scalar52/// `L` is the order of base point, i.e. 2^252 + 27742317777372353535851937790883648493/// `L` * `LFACTOR` = -1 (mod 2^52)/// `R` = R % L where R = 2^260/// `RR` = (R^2) % L where R = 2^260//! This module contains backend-specific constant values, such as the 64-bit limbs of curve constants.// Copyright (c) 2016-2018 Henry de Valence/// The `Scalar52` struct represents an element in/// \\(\mathbb Z / \ell \mathbb Z\\) as 5 \\(52\\)-bit limbs./// u64 * u64 = u128 multiply helper/// Return the zero scalar/// Unpack a 32 byte / 256 bit scalar into 5 52-bit limbs./// Reduce a 64 byte / 512 bit scalar mod l/// Pack the limbs of this `Scalar52` into 32 bytes/// Compute `a + b` (mod l)/// Compute `a - b` (mod l)/// Compute `a * b`/// Compute `a^2`/// Compute `limbs/R` (mod l), where R is the Montgomery modulus 2^260/// Compute `a * b` (mod l)/// Compute `a^2` (mod l)/// Compute `(a * b) / R` (mod l), where R is the Montgomery modulus 2^260/// Compute `(a^2) / R` (mod l) in Montgomery form, where R is the Montgomery modulus 2^260/// Puts a Scalar52 in to Montgomery form, i.e. computes `a*R (mod l)`/// Takes a Scalar52 out of Montgomery form, i.e. computes `a/R (mod l)`/// this implementation (l-1), and should show there are no overflows for valid scalars/// x = 14474011154664524427946373126085988481658748083205070504932198000989141204991/// x = 3057150787695215392275360544382990118917283750546154083604586903220563173085*R mod l in Montgomery form/// x^2 = 4413052134910308800482070043710297189082115023966588301924965890668401540959*R mod l in Montgomery form/// x*y = 36752150652102274958925982391442301741 mod l/// x*y = 658448296334113745583381664921721413881518248721417041768778176391714104386*R mod l in Montgomery form//! Arithmetic mod \\(2\^{252} + 27742317777372353535851937790883648493\\)//! with five \\(52\\)-bit unsigned limbs.//! \\(51\\)-bit limbs would cover the desired bit range (\\(253\\)//! bits), but isn't large enough to reduce a \\(512\\)-bit number with//! Montgomery multiplication, so \\(52\\) bits is used instead.  To see//! that this is safe for intermediate results, note that the largest//! limb in a \\(5\times 5\\) product of \\(52\\)-bit limbs will be//! (0xfffffffffffff^2) * 5 = 0x4ffffffffffff60000000000005 (107 bits).packed_simdu32x8avx2CachedPointExtendedPointFieldElement2625x4EXTENDEDPOINT_IDENTITY/// The identity element as an `ExtendedPoint`.CACHEDPOINT_IDENTITY/// The identity element as a `CachedPoint`.P_TIMES_2_LO/// The low limbs of (2p, 2p, 2p, 2p), so that/// ```ascii,no_run/// (2p, 2p, 2p, 2p) = [P_TIMES_2_LO, P_TIMES_2_HI, P_TIMES_2_HI, P_TIMES_2_HI, P_TIMES_2_HI]P_TIMES_2_HI/// The high limbs of (2p, 2p, 2p, 2p), so thatP_TIMES_16_LO/// The low limbs of (16p, 16p, 16p, 16p), so that/// (16p, 16p, 16p, 16p) = [P_TIMES_16_LO, P_TIMES_16_HI, P_TIMES_16_HI, P_TIMES_16_HI, P_TIMES_16_HI]P_TIMES_16_HI/// The high limbs of (16p, 16p, 16p, 16p), so thatBASEPOINT_ODD_LOOKUP_TABLE/// Odd multiples of the Ed25519 basepoint://! This module contains constants used by the AVX2 backend.LanesShuffle/// A point on Curve25519, using parallel Edwards formulas for curve/// # Invariant/// The coefficients of an `ExtendedPoint` are bounded with/// \\( b < 0.007 \\)./// Compute the double of this point.mul_by_pow_2/// A cached point with some precomputed variables used for readdition./// It is not safe to negate this point more than once./// As long as the `CachedPoint` is not repeatedly negated, its/// coefficients will be bounded with \\( b < 1.0 \\)./// Lazily negate the point./// Because this method does not perform a reduction, it is not/// safe to repeatedly negate a point./// Add an `ExtendedPoint` and a `CachedPoint`./// Implement subtraction by negating the point and adding./// Empirically, this seems about the same cost as a custom/// subtraction impl (maybe because the benefit is cancelled by/// increased code size?)serial_addaddition_test_helpervector_addition_vs_serial_addition_vs_edwards_extendedpointserial_doubledoubling_test_helpervector_doubling_vs_serial_doubling_vs_edwards_extendedpointbasepoint_odd_lookup_table_verify//! Parallel Edwards Arithmetic for Curve25519.//! This module currently has two point types://! * `ExtendedPoint`: a point stored in vector-friendly format, with//! vectorized doubling and addition;//! * `CachedPoint`: used for readdition.//! Details on the formulas can be found in the documentation for the//! parent `avx2` module.//! This API is designed to be safe: vectorized points can only be//! created from serial points (which do validation on decompression),//! and operations on valid points return valid points, so invalid//! point states should be unrepresentable.//! This design goal is met, with one exception: the `Neg`//! implementation for the `CachedPoint` performs a lazy negation, so//! that subtraction can be efficiently implemented as a negation and//! an addition.  Repeatedly negating a `CachedPoint` will cause its//! coefficients to grow and eventually overflow.  Repeatedly negating//! a point should not be necessary anyways.A_LANESB_LANESC_LANESD_LANESA_LANES64B_LANES64C_LANES64D_LANES64i32x8u64x4IntoBitsunpack_pair/// Unpack 32-bit lanes into 64-bit lanes:/// (a0, b0, a1, b1, c0, d0, c1, d1)/// into/// (a0, 0, b0, 0, c0, 0, d0, 0)/// (a1, 0, b1, 0, c1, 0, d1, 0)repack_pair/// Repack 64-bit lanes into 32-bit lanes:ACCDADABCD/// The `Lanes` enum represents a subset of the lanes `A,B,C,D` of a/// `FieldElement2625x4`./// It's used to specify blend operations without/// having to know details about the data layout of theAAAABBBBCACADBBDADDACBCBABABBADCBACDABDC/// The `Shuffle` enum represents a shuffle of a `FieldElement2625x4`./// The enum variants are named by what they do to a vector \\(/// (A,B,C,D) \\); for instance, `Shuffle::BADC` turns \\( (A, B, C,/// D) \\) into \\( (B, A, D, C) \\)./// A vector of four field elements./// Each operation on a `FieldElement2625x4` has documented effects on/// the bounds of the coefficients.  This API is designed for speed/// and not safety; it is the caller's responsibility to ensure that/// the post-conditions of one operation are compatible with the/// pre-conditions of the next.split/// Split this vector into an array of four (serial) field/// Rearrange the elements of this vector according to `control`./// The `control` parameter should be a compile-time constant, so/// that when this function is inlined, LLVM is able to lower the/// shuffle using an immediate.blend/// Blend `self` with `other`, taking lanes specified in `control` from `other`./// that this function can be inlined and LLVM can lower it to a/// blend instruction using an immediate./// Construct a vector of zeros./// Convenience wrapper around `new(x,x,x,x)`./// Create a `FieldElement2625x4` from four `FieldElement51`s./// The resulting `FieldElement2625x4` is bounded with \\( b < 0.0002 \\).negate_lazy/// Given \\((A,B,C,D)\\), compute \\((-A,-B,-C,-D)\\), without/// performing a reduction./// The coefficients of `self` must be bounded with \\( b < 0.999 \\)./// The coefficients of the result are bounded with \\( b < 1 \\).diff_sum/// Given `self = (A,B,C,D)`, compute `(B - A, B + A, D - C, D + C)`./// The coefficients of `self` must be bounded with \\( b < 0.01 \\)./// The coefficients of the result are bounded with \\( b < 1.6 \\)./// Reduce this vector of field elements \\(\mathrm{mod} p\\)./// The coefficients of the result are bounded with \\( b < 0.0002 \\).reduce64/// Given an array of wide coefficients, reduce them to a `FieldElement2625x4`./// The coefficients of the result are bounded with \\( b < 0.007 \\).square_and_negate_D/// Square this field element, and negate the result's \\(D\\) value./// The coefficients of `self` must be bounded with \\( b < 1.5 \\)./// Negate this field element, performing a reduction./// If the coefficients are known to be small, use `negate_lazy`/// to avoid performing a reduction./// The coefficients of `self` must be bounded with \\( b < 4.0 \\)./// Add two `FieldElement2625x4`s, without performing a reduction./// Perform a multiplication by a vector of small constants./// Multiply `self` by `rhs`./// The coefficients of `self` must be bounded with \\( b < 2.5 \\)./// The coefficients of `rhs` must be bounded with \\( b < 1.75 \\).scale_by_curve_constantsdiff_sum_vs_serialsquare_vs_serialmultiply_vs_serialtest_unpack_repack_pairnew_split_roundtrips//! An implementation of 4-way vectorized 32bit field arithmetic using//! AVX2.//! The `FieldElement2625x4` struct provides a vector of four field//! elements, implemented using AVX2 operations.  Its API is designed//! to abstract away the platform-dependent details, so that point//! arithmetic can be implemented only in terms of a vector of field//! elements.//! At this level, the API is optimized for speed and not safety.  The//! `FieldElement2625x4` does not always perform reductions.  The pre-//! and post-conditions on the bounds of the coefficients are//! documented for each method, but it is the caller's responsibility//! to ensure that there are no overflows.F51x4ReducedF51x4Unreduced// Copyright (c) 2018-2019 Henry de Valence//! This module contains constants used by the IFMA backend.madd52lo/// A wrapper around `vpmadd52luq` that works on `u64x4`.madd52hi/// A wrapper around `vpmadd52huq` that works on `u64x4`./// A vector of four field elements in radix 2^51, with unreduced coefficients./// A vector of four field elements in radix 2^51, with reduced coefficients.shuffle_lanesBCDblend_lanesvpmadd52luqnew_split_round_trip_on_reduced_inputnew_split_round_trip_on_unreduced_inputtest_reductionmul_matches_serialiterated_mul_matches_serialsquare_matches_muliterated_square_matches_serialiterated_u32_mul_matches_serialshuffle_AAAAblend_ABifma// Conditionally include the notes if we're on nightly (so we can include docs at all)./// See the documentation in the serial `scalar_mul::pippenger` module for details.Zeroizing/// Multiscalar multiplication using interleaved window / Straus'/// method.  See the `Straus` struct in the serial backend for more/// This exists as a seperate implementation from that one because the/// AVX2 code uses different curve models (it does not pass between/// multiple models during scalar mul), and it has to convert the/// point representation on the fly.CompressedEdwardsYristrettoRistrettoPointCompressedRistrettoMontgomeryPointED25519_BASEPOINT_COMPRESSED/// The Ed25519 basepoint, in `CompressedEdwardsY` format./// This is the little-endian byte encoding of \\( 4/5 \pmod p \\),/// which is the \\(y\\)-coordinate of the Ed25519 basepoint./// The sign bit is 0 since the basepoint has \\(x\\) chosen to be positive.X25519_BASEPOINT/// The X25519 basepoint, in `MontgomeryPoint` format.RISTRETTO_BASEPOINT_COMPRESSED/// The Ristretto basepoint, in `CompressedRistretto` format.RISTRETTO_BASEPOINT_POINT/// The Ristretto basepoint, as a `RistrettoPoint`./// This is called `_POINT` to distinguish it from `_TABLE`, which/// provides fast scalar multiplication.BASEPOINT_ORDER/// `BASEPOINT_ORDER` is the order of the Ristretto group and of the Ed25519 basepoint, i.e.,/// \ell = 2^\{252\} + 27742317777372353535851937790883648493.RistrettoBasepointTableRISTRETTO_BASEPOINT_TABLE/// The Ristretto basepoint, as a `RistrettoBasepointTable` for scalar multiplication.IsIdentitytest_eight_torsiontest_four_torsiontest_two_torsiontest_sqrt_minus_one/// Test that SQRT_M1 is the positive square root of -1test_sqrt_constants_signtest_d_vs_ratio/// Test that d = -121665/121666test_sqrt_ad_minus_one//! Various constants, such as the Ristretto and Ed25519 basepoints.//! Most of the constants are given with//! `LONG_DESCRIPTIVE_UPPER_CASE_NAMES`, but they can be brought into//! scope using a `let` binding://! use curve25519_dalek::constants;//! use curve25519_dalek::traits::IsIdentity;//! let B = &constants::RISTRETTO_BASEPOINT_TABLE;//! let l = &constants::BASEPOINT_ORDER;//! let A = l * B;//! assert!(A.is_identity());ConditionallyNegatableLookupTableRadix16LookupTableRadix32LookupTableRadix64LookupTableRadix128LookupTableRadix256BasepointTable/// In "Edwards y" / "Ed25519" format, the curve point \\((x,y)\\) is/// determined by the \\(y\\)-coordinate and the sign of \\(x\\)./// The first 255 bits of a `CompressedEdwardsY` represent the/// \\(y\\)-coordinate.  The high bit of the 32nd byte gives the sign of \\(x\\)./// View this `CompressedEdwardsY` as an array of bytes./// Copy this `CompressedEdwardsY` to an array of bytes.decompress/// Attempt to decompress to an `EdwardsPoint`./// Returns `None` if the input is not the \\(y\\)-coordinate of a/// curve point./// An `EdwardsPoint` represents a point on the Edwards form of Curve25519./// Construct a `CompressedEdwardsY` from a slice of bytes./// If the input `bytes` slice does not have a length of 32./// Reset this `CompressedEdwardsY` to the compressed form of the identity element./// Reset this `CompressedEdwardsPoint` to the identity element.to_projective_niels/// Convert to a ProjectiveNielsPoint/// Convert the representation of this point from extended/// coordinates to projective coordinates./// Free.to_affine_niels/// Dehomogenize to a AffineNielsPoint./// Mainly for testing./// Convert this `EdwardsPoint` on the Edwards model to the/// corresponding `MontgomeryPoint` on the Montgomery model./// This function has one exceptional case; the identity point of/// the Edwards curve is sent to the 2-torsion point \\((0,0)\\)/// on the Montgomery curve./// Note that this is a one-way conversion, since the Montgomery/// model does not retain sign information.compress/// Compress this point to `CompressedEdwardsY` format.hash_from_bytes/// Perform hashing to the group using the Elligator2 map/// See https://tools.ietf.org/html/draft-irtf-cfrg-hash-to-curve-10#section-6.7.1/// Add this point to itself.define_add_variantsdefine_add_assign_variantsdefine_sub_variantsdefine_sub_assign_variantsdefine_mul_assign_variantsdefine_mul_variants/// Scalar multiplication: compute `scalar * self`./// For scalar multiplication of a basepoint,/// `EdwardsBasepointTable` is approximately 4x faster.VartimeEdwardsPrecomputation/// Precomputation for variable-time multiscalar multiplication with `EdwardsPoint`s.// This wraps the inner implementation in a facade type so that we can// decouple stability of the inner type from the stability of the// outer type.vartime_double_scalar_mul_basepointimpl_basepoint_tabler" A precomputed table of multiples of a basepoint, for accelerating"r" fixed-base scalar multiplication.  One table, for the Ed25519"r" basepoint, is provided in the `constants` module."r" The basepoint tables are reasonably large, so they should probably be boxed."r" The sizes for the tables and the number of additions required for one scalar"r" multiplication are as follows:"r" * [`EdwardsBasepointTableRadix16`]: 30KB, 64A"r"   (this is the default size, and is used for [`ED25519_BASEPOINT_TABLE`])"r" * [`EdwardsBasepointTableRadix64`]: 120KB, 43A"r" * [`EdwardsBasepointTableRadix128`]: 240KB, 37A"r" * [`EdwardsBasepointTableRadix256`]: 480KB, 33A"r" # Why 33 additions for radix-256?"r" Normally, the radix-256 tables would allow for only 32 additions per scalar"r" multiplication.  However, due to the fact that standardised definitions of"r" legacy protocols—such as x25519—require allowing unreduced 255-bit scalar"r" invariants, when converting such an unreduced scalar's representation to"r" radix-\\(2^{8}\\), we cannot guarantee the carry bit will fit in the last"r" coefficient (the coefficients are `i8`s).  When, \\(w\\), the power-of-2 of"r" the radix, is \\(w < 8\\), we can fold the final carry onto the last"r" coefficient, \\(d\\), because \\(d < 2^{w/2}\\), so"r" $$"r"     d + carry \cdot 2^{w} = d + 1 \cdot 2^{w} < 2^{w+1} < 2^{8}"r" When \\(w = 8\\), we can't fit \\(carry \cdot 2^{w}\\) into an `i8`, so we"r" add the carry bit onto an additional coefficient."EdwardsBasepointTableRadix16r" Create a table of precomputed multiples of `basepoint`."r" Get the basepoint for this table as an `EdwardsPoint`."basepointr" The computation uses Pippeneger's algorithm, as described for the"r" specific case of radix-16 on page 13 of the Ed25519 paper."r" # Piggenger's Algorithm Generalised"r" Write the scalar \\(a\\) in radix-\\(w\\), where \\(w\\) is a power of"r" 2, with coefficients in \\([\frac{-w}{2},\frac{w}{2})\\), i.e.,"r"     a = a\_0 + a\_1 w\^1 + \cdots + a\_{x} w\^{x},"r" with"r"     \frac{-w}{2} \leq a_i < \frac{w}{2}, \cdots, \frac{-w}{2} \leq a\_{x} \leq \frac{w}{2}"r" and the number of additions, \\(x\\), is given by \\(x = \lceil \frac{256}{w} \rceil\\)."r" Then"r"     a B = a\_0 B + a\_1 w\^1 B + \cdots + a\_{x-1} w\^{x-1} B."r" Grouping even and odd coefficients gives"r" \begin{aligned}"r"     a B = \quad a\_0 w\^0 B +& a\_2 w\^2 B + \cdots + a\_{x-2} w\^{x-2} B    \\\\"r"               + a\_1 w\^1 B +& a\_3 w\^3 B + \cdots + a\_{x-1} w\^{x-1} B    \\\\"r"         = \quad(a\_0 w\^0 B +& a\_2 w\^2 B + \cdots + a\_{x-2} w\^{x-2} B)   \\\\"r"             + w(a\_1 w\^0 B +& a\_3 w\^2 B + \cdots + a\_{x-1} w\^{x-2} B).  \\\\"r" \end{aligned}"r" For each \\(i = 0 \ldots 31\\), we create a lookup table of"r" [w\^{2i} B, \ldots, \frac{w}{2}\cdotw\^{2i} B],"r" and use it to select \\( y \cdot w\^{2i} \cdot B \\) in constant time."r" The radix-\\(w\\) representation requires that the scalar is bounded"r" by \\(2\^{255}\\), which is always the case."r" The above algorithm is trivially generalised to other powers-of-2 radices."basepoint_mulr" Construct an `EdwardsPoint` from a `Scalar` \\(a\\) by"r" computing the multiple \\(aB\\) of this basepoint \\(B\\)."// The number of additions required is ceil(256/w) where w is the radix representation.EdwardsBasepointTableRadix32EdwardsBasepointTableRadix64EdwardsBasepointTableRadix128EdwardsBasepointTableRadix256/// A precomputed table of multiples of a basepoint, for accelerating/// fixed-base scalar multiplication.  One table, for the Ed25519/// basepoint, is provided in the `constants` module./// The basepoint tables are reasonably large, so they should probably be boxed./// The sizes for the tables and the number of additions required for one scalar/// multiplication are as follows:/// * [`EdwardsBasepointTableRadix16`]: 30KB, 64A///   (this is the default size, and is used for [`ED25519_BASEPOINT_TABLE`])/// * [`EdwardsBasepointTableRadix64`]: 120KB, 43A/// * [`EdwardsBasepointTableRadix128`]: 240KB, 37A/// * [`EdwardsBasepointTableRadix256`]: 480KB, 33A/// # Why 33 additions for radix-256?/// Normally, the radix-256 tables would allow for only 32 additions per scalar/// multiplication.  However, due to the fact that standardised definitions of/// legacy protocols—such as x25519—require allowing unreduced 255-bit scalar/// invariants, when converting such an unreduced scalar's representation to/// radix-\\(2^{8}\\), we cannot guarantee the carry bit will fit in the last/// coefficient (the coefficients are `i8`s).  When, \\(w\\), the power-of-2 of/// the radix, is \\(w < 8\\), we can fold the final carry onto the last/// coefficient, \\(d\\), because \\(d < 2^{w/2}\\), so///     d + carry \cdot 2^{w} = d + 1 \cdot 2^{w} < 2^{w+1} < 2^{8}/// When \\(w = 8\\), we can't fit \\(carry \cdot 2^{w}\\) into an `i8`, so we/// add the carry bit onto an additional coefficient./// Create a table of precomputed multiples of `basepoint`./// The computation uses Pippenger's algorithm, as described on/// page 13 of the Ed25519 paper.  Write the scalar \\(a\\) in radix \\(16\\) with/// coefficients in \\([-8,8)\\), i.e.,///     a = a\_0 + a\_1 16\^1 + \cdots + a\_{63} 16\^{63},/// with \\(-8 \leq a_i < 8\\), \\(-8 \leq a\_{63} \leq 8\\).  Then///     a B = a\_0 B + a\_1 16\^1 B + \cdots + a\_{63} 16\^{63} B./// Grouping even and odd coefficients gives///     a B = \quad a\_0 16\^0 B +& a\_2 16\^2 B + \cdots + a\_{62} 16\^{62} B    \\\\///               + a\_1 16\^1 B +& a\_3 16\^3 B + \cdots + a\_{63} 16\^{63} B    \\\\///         = \quad(a\_0 16\^0 B +& a\_2 16\^2 B + \cdots + a\_{62} 16\^{62} B)   \\\\///            + 16(a\_1 16\^0 B +& a\_3 16\^2 B + \cdots + a\_{63} 16\^{62} B).  \\\\/// For each \\(i = 0 \ldots 31\\), we create a lookup table of/// [16\^{2i} B, \ldots, 8\cdot16\^{2i} B],/// and use it to select \\( x \cdot 16\^{2i} \cdot B \\) in constant time./// The radix-\\(16\\) representation requires that the scalar is bounded/// by \\(2\^{255}\\), which is always the case./// Get the basepoint for this table as an `EdwardsPoint`./// Construct an `EdwardsPoint` from a `Scalar` \\(a\\) by/// computing the multiple \\(aB\\) of this basepoint \\(B\\).impl_basepoint_table_conversions/// Multiply by the cofactor: return \\([8]P\\)./// Compute \\([2\^k] P \\) by successive doublings. Requires \\( k > 0 \\).is_small_order/// Determine if this point is of small order./// # Return/// * `true` if `self` is in the torsion subgroup \\( \mathcal E[8] \\);/// * `false` if `self` is not in the torsion subgroup \\( \mathcal E[8] \\)./// use curve25519_dalek::constants;/// // Generator of the prime-order subgroup/// let P = constants::ED25519_BASEPOINT_POINT;/// // Generator of the torsion subgroup/// let Q = constants::EIGHT_TORSION[1];/// // P has large order/// assert_eq!(P.is_small_order(), false);/// // Q has small order/// assert_eq!(Q.is_small_order(), true);is_torsion_free/// Determine if this point is “torsion-free”, i.e., is contained in/// * `true` if `self` has zero torsion component and is in the/// prime-order subgroup;/// * `false` if `self` has a nonzero torsion component and is not/// in the prime-order subgroup./// // P is torsion-free/// assert_eq!(P.is_torsion_free(), true);/// // P + Q is not torsion-free/// assert_eq!((P+Q).is_torsion_free(), false);BASE_X_COORD_BYTES/// X coordinate of the basepoint./// = 15112221349535400772501151409588531511454012693041857206046113283949847762202BASE2_CMPRSSD/// Compressed Edwards Y form of 2*basepoint.BASE16_CMPRSSD/// Compressed Edwards Y form of 16*basepoint.A_SCALAR/// 4493907448824000747700850167940867464579944529806937181821189941592931634714B_SCALAR/// 2506056684125797857694181776241676200180934651973138769173342316833279714961A_TIMES_BASEPOINT/// A_SCALAR * basepoint, computed with ed25519.pyDOUBLE_SCALAR_MULT_RESULT/// A_SCALAR * (A_TIMES_BASEPOINT) + B_SCALAR * BASEPOINT/// computed with ed25519.pybasepoint_decompression_compression/// Test round-trip decompression for the basepoint.decompression_sign_handling/// Test sign handling in decompressionbasepoint_mult_one_vs_basepoint/// Test that computing 1*basepoint gives the correct basepoint.basepoint_table_basepoint_function_correct/// Test that `EdwardsBasepointTable::basepoint()` gives the correct basepoint.basepoint_plus_basepoint_vs_basepoint2/// Test `impl Add<EdwardsPoint> for EdwardsPoint`/// using basepoint + basepoint versus the 2*basepoint constant.basepoint_plus_basepoint_projective_niels_vs_basepoint2/// Test `impl Add<ProjectiveNielsPoint> for EdwardsPoint`/// using the basepoint, basepoint2 constantsbasepoint_plus_basepoint_affine_niels_vs_basepoint2/// Test `impl Add<AffineNielsPoint> for EdwardsPoint`extended_point_equality_handles_scaling/// Check that equality of `EdwardsPoints` handles projective/// coordinates correctly.to_affine_niels_clears_denominators/// Sanity check for conversion to precomputed pointsbasepoint_mult_vs_ed25519py/// Test basepoint_mult versus a known scalar multiple from ed25519.pybasepoint_mult_by_basepoint_order/// Test that multiplication by the basepoint order kills the basepointtest_precomputed_basepoint_mult/// Test precomputed basepoint multscalar_mul_vs_ed25519py/// Test scalar_mul versus a known scalar multiple from ed25519.pybasepoint_double_vs_basepoint2/// Test basepoint.double() versus the 2*basepoint constant.basepoint_mult_two_vs_basepoint2/// Test that computing 2*basepoint is the same as basepoint.double()basepoint_tables/// Test that all the basepoint table types compute the same results.basepoint_tables_unreduced_scalar// Check a unreduced scalar multiplication by the basepoint tables.basepoint_projective_extended_round_trip/// Check that converting to projective and then back to extended round-trips.basepoint16_vs_mul_by_pow_2_4/// Test computing 16*basepoint vs mul_by_pow_2(4)impl_sumconditional_assign_for_affine_niels_point/// Test that the conditional assignment trait works for AffineNielsPoints.compressed_identityis_identitymonte_carlo_overflow_underflow_debug_assert_test/// Rust's debug builds have overflow and underflow trapping,/// and enable `debug_assert!()`.  This performs many scalar/// multiplications to attempt to trigger possible overflows etc./// For instance, the `u64` `Mul` implementation for/// `FieldElements` requires the input `Limb`s to be bounded by/// 2^54, but we cannot enforce this dynamically at runtime, or/// statically at compile time (until Rust gets type-level/// integers, at which point we can encode "bits of headroom" into/// the type system and prove correctness).scalarmult_extended_point_works_both_waysmultiscalar_consistency_iter// A single iteration of a consistency check for MSM.multiscalar_consistency_n_100multiscalar_consistency_n_250multiscalar_consistency_n_500multiscalar_consistency_n_1000vartime_precomputed_vs_nonprecomputed_multiscalardouble_scalar_mul_basepoint_vs_ed25519py/// Test double_scalar_mul_vartime vs ed25519.pymultiscalar_mul_vs_ed25519pymultiscalar_mul_vartime_vs_consttimevartimeserde_bincode_basepoint_roundtriptest_vectorselligator_signal_test_vectors// Use different multiscalar sizes to hit different internal// parameters.////////////////////////////////////////////////////////////// Signal tests from                                      ////     https://github.com/signalapp/libsignal-protocol-c/ //// Copyright (c) 2016-2020 Henry de Valence//! Group operations for Curve25519, in Edwards form.//! ## Encoding and Decoding//! Encoding is done by converting to and from a `CompressedEdwardsY`//! struct, which is a typed wrapper around `[u8; 32]`.//! ## Equality Testing//! The `EdwardsPoint` struct implements the `subtle::ConstantTimeEq`//! trait for constant-time equality checking, and the Rust `Eq` trait//! for variable-time equality checking.//! ## Cofactor-related functions//! The order of the group of points on the curve \\(\mathcal E\\)//! is \\(|\mathcal E| = 8\ell \\), so its structure is \\( \mathcal//! E = \mathcal E[8] \times \mathcal E[\ell]\\).  The torsion//! subgroup \\( \mathcal E[8] \\) consists of eight points of small//! order.  Technically, all of \\(\mathcal E\\) is torsion, but we//! use the word only to refer to the small \\(\mathcal E[8]\\) part, not//! the large prime-order \\(\mathcal E[\ell]\\) part.//! To test if a point is in \\( \mathcal E[8] \\), use//! `EdwardsPoint::is_small_order()`.//! To test if a point is in \\( \mathcal E[\ell] \\), use//! `EdwardsPoint::is_torsion_free()`.//! To multiply by the cofactor, use `EdwardsPoint::mul_by_cofactor()`.//! To avoid dealing with cofactors entirely, consider using Ristretto.//! ## Scalars//! Scalars are represented by the `Scalar` struct.  To construct a scalar with a specific bit//! pattern, see `Scalar::from_bits()`.//! ## Scalar Multiplication//! Scalar multiplication on Edwards points is provided by://! * the `*` operator between a `Scalar` and a `EdwardsPoint`, which//! performs constant-time variable-base scalar multiplication;//! * the `*` operator between a `Scalar` and a//! `EdwardsBasepointTable`, which performs constant-time fixed-base//! scalar multiplication;//! * an implementation of the//! [`MultiscalarMul`](../traits/trait.MultiscalarMul.html) trait for//! constant-time variable-base multiscalar multiplication;//! [`VartimeMultiscalarMul`](../traits/trait.VartimeMultiscalarMul.html)//! trait for variable-time variable-base multiscalar multiplication;//! ## Implementation//! The Edwards arithmetic is implemented using the “extended twisted//! coordinates” of Hisil, Wong, Carter, and Dawson, and the//! corresponding complete formulas.  For more details,//! see the [`curve_models` submodule][curve_models]//! of the internal documentation.//! ## Validity Checking//! There is no function for checking whether a point is valid.//! Instead, the `EdwardsPoint` struct is guaranteed to hold a valid//! point on the curve.//! We use the Rust type system to make invalid points//! unrepresentable: `EdwardsPoint` objects can only be created via//! successful decompression of a compressed point, or else by//! operations on other (valid) `EdwardsPoint`s.//! [curve_models]: https://doc-internal.dalek.rs/curve25519_dalek/backend/serial/curve_models/index.html// We allow non snake_case names because coordinates in projective space are// traditionally denoted by the capitalisation of their respective// counterparts in affine space.  Yeah, you heard me, rustc, I'm gonna have my// affine and projective cakes and eat both of them too.// Compressed points// Serde support// Serializes to and from `EdwardsPoint` directly, doing compression// and decompression internally.  This means that users can create// structs containing `EdwardsPoint`s and use Serde's derived// serializers to serialize those structures.// Zeroize implementations for wiping points from memory// Equality// Scalar multiplication// Multiscalar Multiplication impls// These use the iterator's size hint and the target settings to// forward to a specific backend implementation.// End macro_rules! impl_basepoint_table// -------------------------------------------------------------------------------------// BEGIN legacy 3.x series code for backwards compatibility with BasepointTable trait// END legacy 3.x series code for backwards compatibility with BasepointTable trait// Tests/// A `FieldElement` represents an element of the field/// The `FieldElement` type is an alias for one of the platform-specific/// Test equality between two `FieldElement`s.  Since the/// internal representation is not canonical, the field elements/// are normalized to wire format before comparison./// Determine if this `FieldElement` is negative, in the sense/// used in the ed25519 paper: `x` is negative if the low bit is/// set./// If negative, return `Choice(1)`.  Otherwise, return `Choice(0)`./// Determine if this `FieldElement` is zero./// If zero, return `Choice(1)`.  Otherwise, return `Choice(0)`.pow22501/// Compute (self^(2^250-1), self^11), used as a helper function/// within invert() and pow22523().batch_invert/// Given a slice of public `FieldElements`, replace each with its inverse./// All input `FieldElements` **MUST** be nonzero./// Given a nonzero field element, compute its inverse./// The inverse is computed as self^(p-2), since/// x^(p-2)x = x^(p-1) = 1 (mod p)./// This function returns zero on input zero.pow_p58/// Raise this field element to the power (p-5)/8 = 2^252 -3.sqrt_ratio_i/// Given `FieldElements` `u` and `v`, compute either `sqrt(u/v)`/// or `sqrt(i*u/v)` in constant time./// This function always returns the nonnegative square root./// - `(Choice(1), +sqrt(u/v))  ` if `v` is nonzero and `u/v` is square;/// - `(Choice(1), zero)        ` if `u` is zero;/// - `(Choice(0), zero)        ` if `v` is zero and `u` is nonzero;/// - `(Choice(0), +sqrt(i*u/v))` if `u/v` is nonsquare (so `i*u/v` is square).invsqrt/// Attempt to compute `sqrt(1/self)` in constant time./// Convenience wrapper around `sqrt_ratio_i`./// - `(Choice(1), +sqrt(1/self))  ` if `self` is a nonzero square;/// - `(Choice(0), zero)           ` if `self` is zero;/// - `(Choice(0), +sqrt(i/self))  ` if `self` is a nonzero nonsquare;A_BYTES/// Random element a of GF(2^255-19), from Sage/// a = 1070314506888354081329385823235218444233221\///     2228051251926706380353716438957572ASQ_BYTES/// Byte representation of a**2AINV_BYTES/// Byte representation of 1/aAP58_BYTES/// Byte representation of a^((p-5)/8)a_mul_a_vs_a_squared_constanta_square_vs_a_squared_constanta_square2_vs_a_squared_constanta_invert_vs_inverse_of_a_constantbatch_invert_a_matches_nonbatchedsqrt_ratio_behaviora_p58_vs_ap58_constantequalityB_BYTES/// Notice that the last element has the high bit set, which/// should be ignoredfrom_bytes_highbit_is_ignoredconditional_negateencoding_is_canonicalbatch_invert_empty// Copyright (c) 2016-2021 isis agora lovecruft//! Field arithmetic modulo \\(p = 2\^{255} - 19\\).//! The `curve25519_dalek::field` module provides a type alias//! `curve25519_dalek::field::FieldElement` to a field element type//! defined in the `backend` module; either `FieldElement51` or//! `FieldElement2625`.//! Field operations defined in terms of machine//! operations, such as field multiplication or squaring, are defined in//! the backend implementation.//! Field operations defined in terms of other field operations, such as//! field inversion or square roots, are defined here.// Used for traits related to constant-time code.// Internal macros. Must come first!// Scalar arithmetic mod l = 2^252 + ..., the order of the Ristretto group// Point operations on the Montgomery form of Curve25519// Point operations on the Edwards form of Curve25519// Group operations on the Ristretto group// Useful constants, like the Ed25519 basepoint// External (and internal) traits.// Finite field arithmetic mod p = 2^255 - 19// Arithmetic backends (using u32, u64, etc) live here// Crate-local prelude (for alloc-dependent features like `Vec`)// Generic code for window lookups// Refuse to compile if documentation is missing.//! # curve25519-dalek [![](https://img.shields.io/crates/v/curve25519-dalek.svg)](https://crates.io/crates/curve25519-dalek) [![](https://img.shields.io/badge/dynamic/json.svg?label=docs&uri=https%3A%2F%2Fcrates.io%2Fapi%2Fv1%2Fcrates%2Fcurve25519-dalek%2Fversions&query=%24.versions%5B0%5D.num&colorB=4F74A6)](https://doc.dalek.rs) [![](https://travis-ci.org/dalek-cryptography/curve25519-dalek.svg?branch=master)](https://travis-ci.org/dalek-cryptography/curve25519-dalek)//! <img//!  width="33%"//!  align="right"//!  src="https://doc.dalek.rs/assets/dalek-logo-clear.png"/>//! **A pure-Rust implementation of group operations on Ristretto and Curve25519.**//! `curve25519-dalek` is a library providing group operations on the Edwards and//! Montgomery forms of Curve25519, and on the prime-order Ristretto group.//! `curve25519-dalek` is not intended to provide implementations of any particular//! crypto protocol.  Rather, implementations of those protocols (such as//! [`x25519-dalek`][x25519-dalek] and [`ed25519-dalek`][ed25519-dalek]) should use//! `curve25519-dalek` as a library.//! `curve25519-dalek` is intended to provide a clean and safe _mid-level_ API for use//! implementing a wide range of ECC-based crypto protocols, such as key agreement,//! signatures, anonymous credentials, rangeproofs, and zero-knowledge proof//! systems.//! In particular, `curve25519-dalek` implements Ristretto, which constructs a//! prime-order group from a non-prime-order Edwards curve.  This provides the//! speed and safety benefits of Edwards curve arithmetic, without the pitfalls of//! cofactor-related abstraction mismatches.//! # Documentation//! The semver-stable, public-facing `curve25519-dalek` API is documented//! [here][docs-external].  In addition, the unstable internal implementation//! details are documented [here][docs-internal].//! The `curve25519-dalek` documentation requires a custom HTML header to include//! KaTeX for math support. Unfortunately `cargo doc` does not currently support//! this, but docs can be built using//! ```sh//! make doc//! make doc-internal//! # Use//! To import `curve25519-dalek`, add the following to the dependencies section of//! your project's `Cargo.toml`://! curve25519-dalek = "3"//! The sole breaking change in the `3.x` series was an update to the `digest`//! version, and in terms of non-breaking changes it includes://! * support for using `alloc` instead of `std` on stable Rust,//! * the Elligator2 encoding for Edwards points,//! * a fix to use `packed_simd2`,//! * various documentation fixes and improvements,//! * support for configurably-sized, precomputed lookup tables for basepoint scalar//!   multiplication,//! * two new formally-verified field arithmetic backends which use the Fiat Crypto//!   Rust code, which is generated from proofs of functional correctness checked by//!   the Coq theorem proving system, and//! * support for explicitly calling the `zeroize` traits for all point types.//! The `2.x` series has API almost entirely unchanged from the `1.x` series,//! except that://! * an error in the data modeling for the (optional) `serde` feature was//!   corrected, so that when the `2.x`-series `serde` implementation is used//!   with `serde-bincode`, the derived serialization matches the usual X/Ed25519//!   formats;//! * the `rand` version was updated.//! See `CHANGELOG.md` for more details.//! # Backends and Features//! The `nightly` feature enables features available only when using a Rust nightly//! compiler.  In particular, it is required for rendering documentation and for//! the SIMD backends.//! Curve arithmetic is implemented using one of the following backends://! * a `u32` backend using serial formulas and `u64` products;//! * a `u64` backend using serial formulas and `u128` products;//! * an `avx2` backend using [parallel formulas][parallel_doc] and `avx2` instructions (sets speed records);//! * an `ifma` backend using [parallel formulas][parallel_doc] and `ifma` instructions (sets speed records);//! By default the `u64` backend is selected.  To select a specific backend, use://! cargo build --no-default-features --features "std u32_backend"//! cargo build --no-default-features --features "std u64_backend"//! # Requires nightly, RUSTFLAGS="-C target_feature=+avx2" to use avx2//! cargo build --no-default-features --features "std simd_backend"//! # Requires nightly, RUSTFLAGS="-C target_feature=+avx512ifma" to use ifma//! Crates using `curve25519-dalek` can either select a backend on behalf of their//! users, or expose feature flags that control the `curve25519-dalek` backend.//! The `std` feature is enabled by default, but it can be disabled for no-`std`//! builds using `--no-default-features`.  Note that this requires explicitly//! selecting an arithmetic backend using one of the `_backend` features.//! If no backend is selected, compilation will fail.//! # Safety//! The `curve25519-dalek` types are designed to make illegal states//! unrepresentable.  For example, any instance of an `EdwardsPoint` is//! guaranteed to hold a point on the Edwards curve, and any instance of a//! `RistrettoPoint` is guaranteed to hold a valid point in the Ristretto//! group.//! All operations are implemented using constant-time logic (no//! secret-dependent branches, no secret-dependent memory accesses),//! unless specifically marked as being variable-time code.//! We believe that our constant-time logic is lowered to constant-time//! assembly, at least on `x86_64` targets.//! As an additional guard against possible future compiler optimizations,//! the `subtle` crate places an optimization barrier before every//! conditional move or assignment.  More details can be found in [the//! documentation for the `subtle` crate][subtle_doc].//! Some functionality (e.g., multiscalar multiplication or batch//! inversion) requires heap allocation for temporary buffers.  All//! heap-allocated buffers of potentially secret data are explicitly//! zeroed before release.//! However, we do not attempt to zero stack data, for two reasons.//! First, it's not possible to do so correctly: we don't have control//! over stack allocations, so there's no way to know how much data to//! wipe.  Second, because `curve25519-dalek` provides a mid-level API,//! the correct place to start zeroing stack data is likely not at the//! entrypoints of `curve25519-dalek` functions, but at the entrypoints of//! functions in other crates.//! The implementation is memory-safe, and contains no significant//! `unsafe` code.  The SIMD backend uses `unsafe` internally to call SIMD//! intrinsics.  These are marked `unsafe` only because invoking them on an//! inappropriate CPU would cause `SIGILL`, but the entire backend is only//! compiled with appropriate `target_feature`s, so this cannot occur.//! # Performance//! Benchmarks are run using [`criterion.rs`][criterion]://! cargo bench --no-default-features --features "std u32_backend"//! cargo bench --no-default-features --features "std u64_backend"//! # Uses avx2 or ifma only if compiled for an appropriate target.//! export RUSTFLAGS="-C target_cpu=native"//! cargo bench --no-default-features --features "std simd_backend"//! Performance is a secondary goal behind correctness, safety, and//! clarity, but we aim to be competitive with other implementations.//! # FFI//! Unfortunately, we have no plans to add FFI to `curve25519-dalek` directly.  The//! reason is that we use Rust features to provide an API that maintains safety//! invariants, which are not possible to maintain across an FFI boundary.  For//! instance, as described in the _Safety_ section above, invalid points are//! impossible to construct, and this would not be the case if we exposed point//! operations over FFI.//! However, `curve25519-dalek` is designed as a *mid-level* API, aimed at//! implementing other, higher-level primitives.  Instead of providing FFI at the//! mid-level, our suggestion is to implement the higher-level primitive (a//! signature, PAKE, ZKP, etc) in Rust, using `curve25519-dalek` as a dependency,//! and have that crate provide a minimal, byte-buffer-oriented FFI specific to//! that primitive.//! # Contributing//! Please see [CONTRIBUTING.md][contributing].//! Patches and pull requests should be make against the `develop`//! branch, **not** `main`.//! # About//! **SPOILER ALERT:** *The Twelfth Doctor's first encounter with the Daleks is in//! his second full episode, "Into the Dalek". A beleaguered ship of the "Combined//! Galactic Resistance" has discovered a broken Dalek that has turned "good",//! desiring to kill all other Daleks. The Doctor, Clara and a team of soldiers//! are miniaturized and enter the Dalek, which the Doctor names Rusty. They//! repair the damage, but accidentally restore it to its original nature, causing//! it to go on the rampage and alert the Dalek fleet to the whereabouts of the//! rebel ship. However, the Doctor manages to return Rusty to its previous state//! by linking his mind with the Dalek's: Rusty shares the Doctor's view of the//! universe's beauty, but also his deep hatred of the Daleks. Rusty destroys the//! other Daleks and departs the ship, determined to track down and bring an end//! to the Dalek race.*//! `curve25519-dalek` is authored by Isis Agora Lovecruft and Henry de Valence.//! Portions of this library were originally a port of [Adam Langley's//! Golang ed25519 library](https://!github.com/agl/ed25519), which was in//! turn a port of the reference `ref10` implementation.  Most of this code,//! including the 32-bit field arithmetic, has since been rewritten.//! The fast `u32` and `u64` scalar arithmetic was implemented by Andrew Moon, and//! the addition chain for scalar inversion was provided by Brian Smith.  The//! optimised batch inversion was contributed by Sean Bowe and Daira Hopwood.//! The `no_std` and `zeroize` support was contributed by Tony Arcieri.//! The formally verified backends, `fiat_u32_backend` and `fiat_u64_backend`, which//! integrate with the Rust generated by the//! [Fiat Crypto project](https://github.com/mit-plv/fiat-crypto) were contributed//! by François Garillot.//! Thanks also to Ashley Hauck, Lucas Salibian, Manish Goregaokar, Jack Grigg,//! Pratyush Mishra, Michael Rosenberg, and countless others for their//! contributions.//! [ed25519-dalek]: https://github.com/dalek-cryptography/ed25519-dalek//! [x25519-dalek]: https://github.com/dalek-cryptography/x25519-dalek//! [contributing]: https://github.com/dalek-cryptography/curve25519-dalek/blob/master/CONTRIBUTING.md//! [docs-external]: https://doc.dalek.rs/curve25519_dalek///! [docs-internal]: https://doc-internal.dalek.rs/curve25519_dalek///! [criterion]: https://github.com/japaric/criterion.rs//! [parallel_doc]: https://doc-internal.dalek.rs/curve25519_dalek/backend/vector/avx2/index.html//! [subtle_doc]: https://doc.dalek.rs/subtle///------------------------------------------------------------------------// External dependencies:// curve25519-dalek public modules// curve25519-dalek internal modules/// Define borrow and non-borrow variants of `Add`./// Define non-borrow variants of `AddAssign`./// Define borrow and non-borrow variants of `Sub`./// Define non-borrow variants of `SubAssign`./// Define borrow and non-borrow variants of `Mul`./// Define non-borrow variants of `MulAssign`.//! Internal macros./// Holds the \\(u\\)-coordinate of a point on the Montgomery form of/// Curve25519 or its twist./// Equality of `MontgomeryPoint`s is defined mod p./// Return the group identity element, which has order 4./// View this `MontgomeryPoint` as an array of bytes./// Convert this `MontgomeryPoint` to an array of bytes.to_edwards/// Attempt to convert to an `EdwardsPoint`, using the supplied/// choice of sign for the `EdwardsPoint`./// # Inputs/// * `sign`: a `u8` donating the desired sign of the resulting///   `EdwardsPoint`.  `0` denotes positive and `1` negative./// * `Some(EdwardsPoint)` if `self` is the \\(u\\)-coordinate of a/// point on (the Montgomery form of) Curve25519;/// * `None` if `self` is the \\(u\\)-coordinate of a point on the/// twist of (the Montgomery form of) Curve25519;elligator_encode/// Perform the Elligator2 mapping to a Montgomery point./// See <https://tools.ietf.org/html/draft-irtf-cfrg-hash-to-curve-10#section-6.7.1>// TODO Determine how much of the hash-to-group API should be exposed after the CFRG//      draft gets into a more polished/accepted state./// A `ProjectivePoint` holds a point on the projective line/// \\( \mathbb P(\mathbb F\_p) \\), which we identify with the Kummer/// line of the Montgomery curve.to_affine/// Dehomogenize this point to affine coordinates./// * \\( u = U / W \\) if \\( W \neq 0 \\);/// * \\( 0 \\) if \\( W \eq 0 \\);differential_add_and_double/// Perform the double-and-add step of the Montgomery ladder./// Given projective points/// \\( (U\_P : W\_P) = u(P) \\),/// \\( (U\_Q : W\_Q) = u(Q) \\),/// and the affine difference/// \\(      u\_{P-Q} = u(P-Q) \\), set///     (U\_P : W\_P) \gets u([2]P)/// and///     (U\_Q : W\_Q) \gets u(P + Q)./// Given `self` \\( = u\_0(P) \\), and a `Scalar` \\(n\\), return \\( u\_0([n]P) \\)./// Multiply this `MontgomeryPoint` by a `Scalar`.OsRngidentity_in_different_coordinatesidentity_in_different_modelsbasepoint_montgomery_to_edwards/// Test Montgomery -> Edwards on the X/Ed25519 basepointbasepoint_edwards_to_montgomery/// Test Edwards -> Montgomery on the X/Ed25519 basepointmontgomery_to_edwards_rejects_twist/// Check that Montgomery -> Edwards fails for points on the twist.eq_defined_mod_pmontgomery_ladder_matches_edwards_scalarmultELLIGATOR_CORRECT_OUTPUTmontgomery_elligator_correct// Vecmontgomery_elligator_zero_zero//! Scalar multiplication on the Montgomery form of Curve25519.//! To avoid notational confusion with the Edwards code, we use//! variables \\( u, v \\) for the Montgomery curve, so that “Montgomery//! \\(u\\)” here corresponds to “Montgomery \\(x\\)” elsewhere.//! Montgomery arithmetic works not on the curve itself, but on the//! \\(u\\)-line, which discards sign information and unifies the curve//! and its quadratic twist.  See [_Montgomery curves and their//! arithmetic_][costello-smith] by Costello and Smith for more details.//! The `MontgomeryPoint` struct contains the affine \\(u\\)-coordinate//! \\(u\_0(P)\\) of a point \\(P\\) on either the curve or the twist.//! Here the map \\(u\_0 : \mathcal M \rightarrow \mathbb F\_p \\) is//! defined by \\(u\_0((u,v)) = u\\); \\(u\_0(\mathcal O) = 0\\).  See//! section 5.4 of Costello-Smith for more details.//! # Scalar Multiplication//! Scalar multiplication on `MontgomeryPoint`s is provided by the `*`//! operator, which implements the Montgomery ladder.//! # Edwards Conversion//! The \\(2\\)-to-\\(1\\) map from the Edwards model to the Montgomery//! \\(u\\)-line is provided by `EdwardsPoint::to_montgomery()`.//! To lift a `MontgomeryPoint` to an `EdwardsPoint`, use//! `MontgomeryPoint::to_edwards()`, which takes a sign parameter.//! This function rejects `MontgomeryPoints` which correspond to points//! on the twist.//! [costello-smith]: https://eprint.iacr.org/2017/212.pdf//! Crate-local prelude (for alloc-dependent features like `Vec`)CryptoRng/// A Ristretto point, in compressed wire format./// The Ristretto encoding is canonical, so two points are equal if and/// only if their encodings are equal./// Copy the bytes of this `CompressedRistretto`./// View this `CompressedRistretto` as an array of bytes./// Construct a `CompressedRistretto` from a slice of bytes./// Attempt to decompress to an `RistrettoPoint`./// - `Some(RistrettoPoint)` if `self` was the canonical encoding of a point;/// - `None` if `self` was not the canonical encoding of a point./// A `RistrettoPoint` represents a point in the Ristretto group for/// Curve25519.  Ristretto, a variant of Decaf, constructs a/// prime-order group as a quotient group of a subgroup of (the/// Edwards form of) Curve25519./// Internally, a `RistrettoPoint` is implemented as a wrapper type/// around `EdwardsPoint`, with custom equality, compression, and/// decompression routines to account for the quotient.  This means that/// operations on `RistrettoPoint`s are exactly as fast as operations on/// `EdwardsPoint`s./// Compress this point using the Ristretto encoding.double_and_compress_batch/// Double-and-compress a batch of points.  The Ristretto encoding/// is not batchable, since it requires an inverse square root./// However, given input points \\( P\_1, \ldots, P\_n, \\)/// it is possible to compute the encodings of their doubles \\(/// \mathrm{enc}( [2]P\_1), \ldots, \mathrm{enc}( [2]P\_n ) \\)/// in a batch./// # extern crate curve25519_dalek;/// # use curve25519_dalek::ristretto::RistrettoPoint;/// extern crate rand_core;/// use rand_core::OsRng;/// # // Need fn main() here in comment so the doctest compiles/// # // See https://doc.rust-lang.org/book/documentation.html#documentation-as-tests/// let mut rng = OsRng;/// let points: Vec<RistrettoPoint> =///     (0..32).map(|_| RistrettoPoint::random(&mut rng)).collect();/// let compressed = RistrettoPoint::double_and_compress_batch(&points);/// for (P, P2_compressed) in points.iter().zip(compressed.iter()) {///     assert_eq!(*P2_compressed, (P + P).compress());coset4/// Return the coset self + E[4], for debugging.elligator_ristretto_flavor/// Computes the Ristretto Elligator map./// This method is not public because it's just used for hashing/// to a point -- proper elligator support is deferred for now./// Return a `RistrettoPoint` chosen uniformly at random using a user-provided RNG./// * `rng`: any RNG which implements the `RngCore + CryptoRng` interface./// # Returns/// A random element of the Ristretto group./// # Implementation/// Uses the Ristretto-flavoured Elligator 2 map, so that the/// discrete log of the output point with respect to any other/// point should be unknown.  The map is applied twice and the/// results are added, to ensure a uniform distribution./// Hash a slice of bytes into a `RistrettoPoint`./// Takes a type parameter `D`, which is any `Digest` producing 64/// bytes of output./// Convenience wrapper around `from_hash`./// extern crate sha2;/// use sha2::Sha512;/// let msg = "To really appreciate architecture, you may even need to commit a murder";/// let P = RistrettoPoint::hash_from_bytes::<Sha512>(msg.as_bytes());from_hash/// Construct a `RistrettoPoint` from an existing `Digest` instance./// Use this instead of `hash_from_bytes` if it is more convenient/// to stream data into the `Digest` than to pass a single bytefrom_uniform_bytes/// Construct a `RistrettoPoint` from 64 bytes of data./// If the input bytes are uniformly distributed, the resulting/// point will be uniformly distributed over the group, and its/// discrete log with respect to other points should be unknown./// This function splits the input array into two 32-byte halves,/// takes the low 255 bits of each half mod p, applies the/// Ristretto-flavored Elligator map to each, and adds the results./// Test equality between two `RistrettoPoint`s./// * `Choice(1)` if the two `RistrettoPoint`s are equal;/// * `Choice(0)` otherwise./// Scalar multiplication: compute `self * scalar`.VartimeRistrettoPrecomputation/// Precomputation for variable-time multiscalar multiplication with `RistrettoPoint`s./// Compute \\(aA + bB\\) in variable time, where \\(B\\) is the/// Ristretto basepoint./// A precomputed table of multiples of a basepoint, used to accelerate/// scalar multiplication./// A precomputed table of multiples of the Ristretto basepoint is/// available in the `constants` module:/// use curve25519_dalek::scalar::Scalar;/// let a = Scalar::from(87329482u64);/// let P = &a * &constants::RISTRETTO_BASEPOINT_TABLE;/// Create a precomputed table of multiples of the given `basepoint`./// Get the basepoint for this table as a `RistrettoPoint`./// Conditionally select between `self` and `other`./// # extern crate subtle;/// use subtle::ConditionallySelectable;/// use subtle::Choice;/// # use curve25519_dalek::traits::Identity;/// # use curve25519_dalek::constants;/// let A = RistrettoPoint::identity();/// let B = constants::RISTRETTO_BASEPOINT_POINT;/// let mut P = A;/// P = RistrettoPoint::conditional_select(&A, &B, Choice::from(0));/// assert_eq!(P, A);/// P = RistrettoPoint::conditional_select(&A, &B, Choice::from(1));/// assert_eq!(P, B);scalarmult_ristrettopoint_works_both_waysdecompress_negative_s_failsdecompress_idcompress_idbasepoint_roundtripencodings_of_small_multiples_of_basepointfour_torsion_basepointfour_torsion_randomelligator_vs_ristretto_sagerandom_roundtripdouble_and_compress_1024_random_points//! An implementation of [Ristretto][ristretto_main], which provides a//! prime-order group.//! # The Ristretto Group//! Ristretto is a modification of Mike Hamburg's Decaf scheme to work//! with cofactor-\\(8\\) curves, such as Curve25519.//! The introduction of the Decaf paper, [_Decaf://! Eliminating cofactors through point//! compression_](https://eprint.iacr.org/2015/673.pdf), notes that while//! most cryptographic systems require a group of prime order, most//! concrete implementations using elliptic curve groups fall short –//! they either provide a group of prime order, but with incomplete or//! variable-time addition formulae (for instance, most Weierstrass//! models), or else they provide a fast and safe implementation of a//! group whose order is not quite a prime \\(q\\), but \\(hq\\) for a//! small cofactor \\(h\\) (for instance, Edwards curves, which have//! cofactor at least \\(4\\)).//! This abstraction mismatch is commonly “handled” by pushing the//! complexity upwards, adding ad-hoc protocol modifications.  But//! these modifications require careful analysis and are a recurring//! source of [vulnerabilities][cryptonote] and [design//! complications][ed25519_hkd].//! Instead, Decaf (and Ristretto) use a quotient group to implement a//! prime-order group using a non-prime-order curve.  This provides//! the correct abstraction for cryptographic systems, while retaining//! the speed and safety benefits of an Edwards curve.//! Decaf is named “after the procedure which divides the effect of//! coffee by \\(4\\)”.  However, Curve25519 has a cofactor of//! \\(8\\).  To eliminate its cofactor, Ristretto restricts further;//! this [additional restriction][ristretto_coffee] gives the//! _Ristretto_ encoding.//! More details on why Ristretto is necessary can be found in the//! [Why Ristretto?][why_ristretto] section of the Ristretto website.//! Ristretto//! points are provided in `curve25519-dalek` by the `RistrettoPoint`//! Encoding is done by converting to and from a `CompressedRistretto`//! The encoding is not batchable, but it is possible to//! double-and-encode in a batch using//! `RistrettoPoint::double_and_compress_batch`.//! Testing equality of points on an Edwards curve in projective//! coordinates requires an expensive inversion.  By contrast, equality//! checking in the Ristretto group can be done in projective//! coordinates without requiring an inversion, so it is much faster.//! The `RistrettoPoint` struct implements the//! `subtle::ConstantTimeEq` trait for constant-time equality//! checking, and the Rust `Eq` trait for variable-time equality//! checking.//! Scalars are represented by the `Scalar` struct.  Each scalar has a//! canonical representative mod the group order.  To attempt to load//! a supposedly-canonical scalar, use//! `Scalar::from_canonical_bytes()`. To check whether a//! representative is canonical, use `Scalar::is_canonical()`.//! Scalar multiplication on Ristretto points is provided by://! * the `*` operator between a `Scalar` and a `RistrettoPoint`, which//! `RistrettoBasepointTable`, which performs constant-time fixed-base//! ## Random Points and Hashing to Ristretto//! The Ristretto group comes equipped with an Elligator map.  This is//! used to implement//! * `RistrettoPoint::random()`, which generates random points from an//! RNG;//! * `RistrettoPoint::from_hash()` and//! `RistrettoPoint::hash_from_bytes()`, which perform hashing to the//! The Elligator map itself is not currently exposed.//! The Decaf suggestion is to use a quotient group, such as \\(\mathcal//! E / \mathcal E[4]\\) or \\(2 \mathcal E / \mathcal E[2] \\), to//! implement a prime-order group using a non-prime-order curve.//! This requires only changing//! 1. the function for equality checking (so that two representatives//!    of the same coset are considered equal);//! 2. the function for encoding (so that two representatives of the//!    same coset are encoded as identical bitstrings);//! 3. the function for decoding (so that only the canonical encoding of//!    a coset is accepted).//! Internally, each coset is represented by a curve point; two points//! \\( P, Q \\) may represent the same coset in the same way that two//! points with different \\(X,Y,Z\\) coordinates may represent the//! same point.  The group operations are carried out with no overhead//! using Edwards formulas.//! Notes on the details of the encoding can be found in the//! [Details][ristretto_notes] section of the Ristretto website.//! [cryptonote]://! https://moderncrypto.org/mail-archive/curves/2017/000898.html//! [ed25519_hkd]://! https://moderncrypto.org/mail-archive/curves/2017/000858.html//! [ristretto_coffee]://! https://en.wikipedia.org/wiki/Ristretto//! [ristretto_notes]://! https://ristretto.group/details/index.html//! [why_ristretto]://! https://ristretto.group/why_ristretto.html//! [ristretto_main]://! https://ristretto.group/// Serializes to and from `RistrettoPoint` directly, doing compression// structs containing `RistrettoPoint`s and use Serde's derived// Arithmetic// These use iterator combinators to unwrap the underlying points and// forward to the EdwardsPoint implementations.// Constant-time conditional selection// Zeroize traitsUnpackedScalar/// An `UnpackedScalar` represents an element of the field GF(l), optimized for speed./// This is a type alias for one of the scalar types in the `backend`/// `bytes` is a little-endian byte encoding of an integer representing a scalar modulo the/// group order./// The integer representing this scalar must be bounded above by \\(2\^{255}\\), or/// equivalently the high bit of `bytes[31]` must be zero./// This ensures that there is room for a carry bit when computing a NAF representation.// XXX This is pub(crate) so we can write literal constants.  If const fns were stable, we could//     make the Scalar constructors const fns and use those instead./// The `Scalar` struct holds an integer \\(s < 2\^{255} \\) which/// represents an element of \\(\mathbb Z / \ell\\).from_bytes_mod_order/// Construct a `Scalar` by reducing a 256-bit little-endian integer/// modulo the group order \\( \ell \\).from_bytes_mod_order_wide/// Construct a `Scalar` by reducing a 512-bit little-endian integerfrom_canonical_bytes/// Attempt to construct a `Scalar` from a canonical byte representation./// - `Some(s)`, where `s` is the `Scalar` corresponding to `bytes`,///   if `bytes` is a canonical byte representation;/// - `None` if `bytes` is not a canonical byte representation./// Construct a `Scalar` from the low 255 bits of a 256-bit integer./// This function is intended for applications like X25519 which/// require specific bit-patterns when performing scalar/// multiplication./// Index the bytes of the representative for this `Scalar`.  Mutation is not permitted./// Construct a scalar from the given `u64`./// An `u64` to convert to a `Scalar`./// A `Scalar` corresponding to the input `u64`./// let fourtytwo = Scalar::from(42u64);/// let six = Scalar::from(6u64);/// let seven = Scalar::from(7u64);/// assert!(fourtytwo == six * seven);/// Return a `Scalar` chosen uniformly at random using a user-provided RNG./// A random scalar within ℤ/lℤ./// let mut csprng = OsRng;/// let a: Scalar = Scalar::random(&mut csprng);/// Hash a slice of bytes into a scalar./// bytes (512 bits) of output./// # use curve25519_dalek::scalar::Scalar;/// let s = Scalar::hash_from_bytes::<Sha512>(msg.as_bytes());/// Construct a scalar from an existing `Digest` instance./// use sha2::Digest;/// let mut h = Sha512::new()///     .chain("To really appreciate architecture, you may even need to commit a murder.")///     .chain("While the programs used for The Manhattan Transcripts are of the most extreme")///     .chain("nature, they also parallel the most common formula plot: the archetype of")///     .chain("murder. Other phantasms were occasionally used to underline the fact that")///     .chain("perhaps all architecture, rather than being about functional standards, is")///     .chain("about love and death.");/// let s = Scalar::from_hash(h);/// println!("{:?}", s.to_bytes());/// assert!(s == Scalar::from_bits([ 21,  88, 208, 252,  63, 122, 210, 152,///                                 154,  38,  15,  23,  16, 167,  80, 150,///                                 192, 221,  77, 226,  62,  25, 224, 148,///                                 239,  48, 176,  10, 185,  69, 168,  11, ]));/// Convert this `Scalar` to its underlying sequence of bytes./// let s: Scalar = Scalar::zero();/// assert!(s.to_bytes() == [0u8; 32]);/// View the little-endian byte encoding of the integer representing this Scalar./// assert!(s.as_bytes() == &[0u8; 32]);/// Construct the scalar \\( 0 \\)./// Construct the scalar \\( 1 \\)./// Given a nonzero `Scalar`, compute its multiplicative inverse./// `self` **MUST** be nonzero.  If you cannot/// *prove* that this is the case, you **SHOULD NOT USE THIS/// FUNCTION**./// The multiplicative inverse of the this `Scalar`./// // x = 2238329342913194256032495932344128051776374960164957527413114840482143558222/// let X: Scalar = Scalar::from_bytes_mod_order([///         0x4e, 0x5a, 0xb4, 0x34, 0x5d, 0x47, 0x08, 0x84,///         0x59, 0x13, 0xb4, 0x64, 0x1b, 0xc2, 0x7d, 0x52,///         0x52, 0xa5, 0x85, 0x10, 0x1b, 0xcc, 0x42, 0x44,///         0xd4, 0x49, 0xf4, 0xa8, 0x79, 0xd9, 0xf2, 0x04,///     ]);/// // 1/x = 6859937278830797291664592131120606308688036382723378951768035303146619657244/// let XINV: Scalar = Scalar::from_bytes_mod_order([///         0x1c, 0xdc, 0x17, 0xfc, 0xe0, 0xe9, 0xa5, 0xbb,///         0xd9, 0x24, 0x7e, 0x56, 0xbb, 0x01, 0x63, 0x47,///         0xbb, 0xba, 0x31, 0xed, 0xd5, 0xa9, 0xbb, 0x96,///         0xd5, 0x0b, 0xcd, 0x7a, 0x3f, 0x96, 0x2a, 0x0f,/// let inv_X: Scalar = X.invert();/// assert!(XINV == inv_X);/// let should_be_one: Scalar = &inv_X * &X;/// assert!(should_be_one == Scalar::one());/// Given a slice of nonzero (possibly secret) `Scalar`s,/// compute their inverses in a batch./// Each element of `inputs` is replaced by its inverse./// The product of all inverses is returned./// All input `Scalars` **MUST** be nonzero.  If you cannot/// let mut scalars = [///     Scalar::from(3u64),///     Scalar::from(5u64),///     Scalar::from(7u64),///     Scalar::from(11u64),/// let allinv = Scalar::batch_invert(&mut scalars);/// assert_eq!(allinv, Scalar::from(3*5*7*11u64).invert());/// assert_eq!(scalars[0], Scalar::from(3u64).invert());/// assert_eq!(scalars[1], Scalar::from(5u64).invert());/// assert_eq!(scalars[2], Scalar::from(7u64).invert());/// assert_eq!(scalars[3], Scalar::from(11u64).invert());/// Get the bits of the scalar.non_adjacent_form/// Compute a width-\\(w\\) "Non-Adjacent Form" of this scalar./// A width-\\(w\\) NAF of a positive integer \\(k\\) is an expression/// k = \sum_{i=0}\^m n\_i 2\^i,/// where each nonzero/// coefficient \\(n\_i\\) is odd and bounded by \\(|n\_i| < 2\^{w-1}\\),/// \\(n\_{m-1}\\) is nonzero, and at most one of any \\(w\\) consecutive/// coefficients is nonzero.  (Hankerson, Menezes, Vanstone; def 3.32)./// The length of the NAF is at most one more than the length of/// the binary representation of \\(k\\).  This is why the/// `Scalar` type maintains an invariant that the top bit is/// \\(0\\), so that the NAF of a scalar has at most 256 digits./// Intuitively, this is like a binary expansion, except that we/// allow some coefficients to grow in magnitude up to/// \\(2\^{w-1}\\) so that the nonzero coefficients are as sparse/// as possible./// When doing scalar multiplication, we can then use a lookup/// table of precomputed multiples of a point to add the nonzero/// terms \\( k_i P \\).  Using signed digits cuts the table size/// in half, and using odd digits cuts the table size in half/// again./// To compute a \\(w\\)-NAF, we use a modification of Algorithm 3.35 of HMV:/// 1. \\( i \gets 0 \\)/// 2. While \\( k \ge 1 \\):///     1. If \\(k\\) is odd, \\( n_i \gets k \operatorname{mods} 2^w \\), \\( k \gets k - n_i \\).///     2. If \\(k\\) is even, \\( n_i \gets 0 \\).///     3. \\( k \gets k / 2 \\), \\( i \gets i + 1 \\)./// 3. Return \\( n_0, n_1, ... , \\)/// Here \\( \bar x = x \operatorname{mods} 2^w \\) means the/// \\( \bar x \\) with \\( \bar x \equiv x \pmod{2^w} \\) and/// \\( -2^{w-1} \leq \bar x < 2^w \\)./// We implement this by scanning across the bits of \\(k\\) from/// least-significant bit to most-significant-bit./// Write the bits of \\(k\\) as/// k = \sum\_{i=0}\^m k\_i 2^i,/// and split the sum as/// k = \sum\_{i=0}^{w-1} k\_i 2^i + 2^w \sum\_{i=0} k\_{i+w} 2^i/// where the first part is \\( k \mod 2^w \\)./// If \\( k \mod 2^w\\) is odd, and \\( k \mod 2^w < 2^{w-1} \\), then we emit/// \\( n_0 = k \mod 2^w \\).  Instead of computing/// \\( k - n_0 \\), we just advance \\(w\\) bits and reindex./// If \\( k \mod 2^w\\) is odd, and \\( k \mod 2^w \ge 2^{w-1} \\), then/// \\( n_0 = k \operatorname{mods} 2^w = k \mod 2^w - 2^w \\)./// The quantity \\( k - n_0 \\) is/// k - n_0 &= \sum\_{i=0}^{w-1} k\_i 2^i + 2^w \sum\_{i=0} k\_{i+w} 2^i///          - \sum\_{i=0}^{w-1} k\_i 2^i + 2^w \\\\/// &= 2^w + 2^w \sum\_{i=0} k\_{i+w} 2^i/// so instead of computing the subtraction, we can set a carry/// bit, advance \\(w\\) bits, and reindex./// If \\( k \mod 2^w\\) is even, we emit \\(0\\), advance 1 bit/// and reindex.  In fact, by setting all digits to \\(0\\)/// initially, we don't need to emit anything.to_radix_16/// Write this scalar in radix 16, with coefficients in \\([-8,8)\\),/// i.e., compute \\(a\_i\\) such that///    a = a\_0 + a\_1 16\^1 + \cdots + a_{63} 16\^{63},/// with \\(-8 \leq a_i < 8\\) for \\(0 \leq i < 63\\) and \\(-8 \leq a_{63} \leq 8\\).to_radix_2w_size_hint/// Returns a size hint indicating how many entries of the return/// value of `to_radix_2w` are nonzero.to_radix_2w/// Creates a representation of a Scalar in radix 32, 64, 128 or 256 for use with the Pippenger algorithm./// For lower radix, use `to_radix_16`, which is used by the Straus multi-scalar multiplication./// Higher radixes are not supported to save cache space. Radix 256 is near-optimal even for very/// large inputs./// Radix below 32 or above 256 is prohibited./// This method returns digits in a fixed-sized array, excess digits are zeroes./// ## Scalar representation/// Radix \\(2\^w\\), with \\(n = ceil(256/w)\\) coefficients in \\([-(2\^w)/2,(2\^w)/2)\\),/// i.e., scalar is represented using digits \\(a\_i\\) such that///    a = a\_0 + a\_1 2\^1w + \cdots + a_{n-1} 2\^{w*(n-1)},/// with \\(-2\^w/2 \leq a_i < 2\^w/2\\) for \\(0 \leq i < (n-1)\\) and \\(-2\^w/2 \leq a_{n-1} \leq 2\^w/2\\).unpack/// Unpack this `Scalar` to an `UnpackedScalar` for faster arithmetic./// Reduce this `Scalar` modulo \\(\ell\\).is_canonical/// Check whether this `Scalar` is the canonical representative mod \\(\ell\\)./// This is intended for uses like input validation, where variable-time code is acceptable./// # use subtle::ConditionallySelectable;/// // 2^255 - 1, since `from_bits` clears the high bit/// let _2_255_minus_1 = Scalar::from_bits([0xff;32]);/// assert!(!_2_255_minus_1.is_canonical());/// let reduced = _2_255_minus_1.reduce();/// assert!(reduced.is_canonical());pack/// Pack the limbs of this `UnpackedScalar` into a `Scalar`.montgomery_invert/// Inverts an UnpackedScalar in Montgomery form./// Inverts an UnpackedScalar not in Montgomery form./// x = 2238329342913194256032495932344128051776374960164957527413114840482143558222XINV/// 1/x = 6859937278830797291664592131120606308688036382723378951768035303146619657244/// y = 2592331292931086675770238855846338635550719849568364935475441891787804997264X_TIMES_Y/// x*y = 5690045403673944803228348699031245560686958845067437804563560795922180092780CANONICAL_2_256_MINUS_1/// sage: l = 2^252 + 27742317777372353535851937790883648493/// sage: big = 2^256 - 1/// sage: repr((big % l).digits(256))A_NAFLARGEST_ED25519_SCANONICAL_LARGEST_ED25519_S_PLUS_ONECANONICAL_LARGEST_ED25519_S_MINUS_ONEfuzzer_testcase_reductionnon_adjacent_form_test_vectornon_adjacent_form_iternon_adjacent_form_randomscalar_mul_by_oneadd_reducessub_reducesquarkslab_scalar_overflow_does_not_occurimpl_addimpl_mulimpl_productneg_twice_is_identity// Negating a scalar twice should result in the original scalar.to_bytes_from_bytes_roundtripsmontgomery_reduce_matches_from_bytes_mod_order_widecanonical_decodingserde_bincode_scalar_roundtripbatch_invert_consistencytest_pippenger_radix_itertest_pippenger_radix// Portions Copyright 2017 Brian Smith// - Brian Smith <brian@briansmith.org>//! Arithmetic on scalars (integers mod the group order).//! Both the Ristretto group and the Ed25519 basepoint have prime order//! \\( \ell = 2\^{252} + 27742317777372353535851937790883648493 \\).//! This code is intended to be useful with both the Ristretto group//! (where everything is done modulo \\( \ell \\)), and the X/Ed25519//! setting, which mandates specific bit-twiddles that are not//! well-defined modulo \\( \ell \\).//! All arithmetic on `Scalars` is done modulo \\( \ell \\).//! # Constructing a scalar//! To create a [`Scalar`](struct.Scalar.html) from a supposedly canonical encoding, use//! [`Scalar::from_canonical_bytes`](struct.Scalar.html#method.from_canonical_bytes).//! This function does input validation, ensuring that the input bytes//! are the canonical encoding of a `Scalar`.//! If they are, we'll get//! `Some(Scalar)` in return://! use curve25519_dalek::scalar::Scalar;//! let one_as_bytes: [u8; 32] = Scalar::one().to_bytes();//! let a: Option<Scalar> = Scalar::from_canonical_bytes(one_as_bytes);//! assert!(a.is_some());//! However, if we give it bytes representing a scalar larger than \\( \ell \\)//! (in this case, \\( \ell + 2 \\)), we'll get `None` back://! let l_plus_two_bytes: [u8; 32] = [//!    0xef, 0xd3, 0xf5, 0x5c, 0x1a, 0x63, 0x12, 0x58,//!    0xd6, 0x9c, 0xf7, 0xa2, 0xde, 0xf9, 0xde, 0x14,//!    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,//!    0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x10,//! let a: Option<Scalar> = Scalar::from_canonical_bytes(l_plus_two_bytes);//! assert!(a.is_none());//! Another way to create a `Scalar` is by reducing a \\(256\\)-bit integer mod//! \\( \ell \\), for which one may use the//! [`Scalar::from_bytes_mod_order`](struct.Scalar.html#method.from_bytes_mod_order)//! method.  In the case of the second example above, this would reduce the//! resultant scalar \\( \mod \ell \\), producing \\( 2 \\)://! let a: Scalar = Scalar::from_bytes_mod_order(l_plus_two_bytes);//! let two: Scalar = Scalar::one() + Scalar::one();//! assert!(a == two);//! There is also a constructor that reduces a \\(512\\)-bit integer,//! [`Scalar::from_bytes_mod_order_wide`](struct.Scalar.html#method.from_bytes_mod_order_wide).//! To construct a `Scalar` as the hash of some input data, use//! [`Scalar::hash_from_bytes`](struct.Scalar.html#method.hash_from_bytes),//! which takes a buffer, or//! [`Scalar::from_hash`](struct.Scalar.html#method.from_hash),//! which allows an IUF API.//! # extern crate curve25519_dalek;//! # extern crate sha2;//! #//! use sha2::{Digest, Sha512};//! // Hashing a single byte slice//! let a = Scalar::hash_from_bytes::<Sha512>(b"Abolish ICE");//! // Streaming data into a hash object//! let mut hasher = Sha512::default();//! hasher.update(b"Abolish ");//! hasher.update(b"ICE");//! let a2 = Scalar::from_hash(hasher);//! assert_eq!(a, a2);//! Finally, to create a `Scalar` with a specific bit-pattern//! (e.g., for compatibility with X/Ed25519//! ["clamping"](https://github.com/isislovecruft/ed25519-dalek/blob/f790bd2ce/src/ed25519.rs#L349)),//! use [`Scalar::from_bits`](struct.Scalar.html#method.from_bits). This//! constructs a scalar with exactly the bit pattern given, without any//! assurances as to reduction modulo the group order://! let a: Scalar = Scalar::from_bits(l_plus_two_bytes);//! assert!(a != two);              // the scalar is not reduced (mod l)…//! assert!(! a.is_canonical());    // …and therefore is not canonical.//! assert!(a.reduce() == two);     // if we were to reduce it manually, it would be.//! The resulting `Scalar` has exactly the specified bit pattern,//! **except for the highest bit, which will be set to 0**./// Returns the identity element of the curve./// Can be used as a constructor./// Trait for getting the identity element of a point type./// Return true if this element is the identity element of the curve./// Trait for testing if a curve point is equivalent to the identity point./// Implement generic identity equality testing for a point representations/// which have constant-time equality testing and a defined identity/// constructor./// The type of point contained within this table./// Generate a new precomputed basepoint table from the given basepoint./// Retrieve the original basepoint from this table./// Multiply a `scalar` by this precomputed basepoint table, in constant time./// A precomputed table of basepoints, for optimising scalar multiplications./// The type of point being multiplied, e.g., `RistrettoPoint`./// Given an iterator of (possibly secret) scalars and an iterator of/// public points, compute/// Q = c\_1 P\_1 + \cdots + c\_n P\_n./// It is an error to call this function with two iterators of different lengths./// The trait bound aims for maximum flexibility: the inputs must be/// convertable to iterators (`I: IntoIter`), and the iterator's items/// must be `Borrow<Scalar>` (or `Borrow<Point>`), to allow/// iterators returning either `Scalar`s or `&Scalar`s./// use curve25519_dalek::traits::MultiscalarMul;/// use curve25519_dalek::ristretto::RistrettoPoint;/// // Some scalars/// let b = Scalar::from(37264829u64);/// let c = Scalar::from(98098098u64);/// // Some points/// let P = constants::RISTRETTO_BASEPOINT_POINT;/// let Q = P + P;/// let R = P + Q;/// // A1 = a*P + b*Q + c*R/// let abc = [a,b,c];/// let A1 = RistrettoPoint::multiscalar_mul(&abc, &[P,Q,R]);/// // Note: (&abc).into_iter(): Iterator<Item=&Scalar>/// // A2 = (-a)*P + (-b)*Q + (-c)*R/// let minus_abc = abc.iter().map(|x| -x);/// let A2 = RistrettoPoint::multiscalar_mul(minus_abc, &[P,Q,R]);/// // Note: minus_abc.into_iter(): Iterator<Item=Scalar>/// assert_eq!(A1.compress(), (-A2).compress());/// A trait for constant-time multiscalar multiplication without precomputation./// Given an iterator of public scalars and an iterator of/// `Option`s of points, compute either `Some(Q)`, where/// Q = c\_1 P\_1 + \cdots + c\_n P\_n,/// if all points were `Some(P_i)`, or else return `None`./// This function is particularly useful when verifying statements/// involving compressed points.  Accepting `Option<Point>` allows/// inlining point decompression into the multiscalar call,/// avoiding the need for temporary buffers./// use curve25519_dalek::traits::VartimeMultiscalarMul;/// let PQR = [P, Q, R];/// let compressed = [P.compress(), Q.compress(), R.compress()];/// // Now we can compute A1 = a*P + b*Q + c*R using P, Q, R:/// let A1 = RistrettoPoint::vartime_multiscalar_mul(&abc, &PQR);/// // Or using the compressed points:/// let A2 = RistrettoPoint::optional_multiscalar_mul(///     &abc,///     compressed.iter().map(|pt| pt.decompress()),/// assert_eq!(A2, Some(A1));/// // It's also possible to mix compressed and uncompressed points:/// let A3 = RistrettoPoint::optional_multiscalar_mul(///     abc.iter()///         .chain(abc.iter()),///     compressed.iter().map(|pt| pt.decompress())///         .chain(PQR.iter().map(|&pt| Some(pt))),/// assert_eq!(A3, Some(A1+A1));vartime_multiscalar_mul/// using variable-time operations./// let A1 = RistrettoPoint::vartime_multiscalar_mul(&abc, &[P,Q,R]);/// let A2 = RistrettoPoint::vartime_multiscalar_mul(minus_abc, &[P,Q,R]);/// A trait for variable-time multiscalar multiplication without precomputation./// The type of point to be multiplied, e.g., `RistrettoPoint`./// Given the static points \\( B_i \\), perform precomputation/// and return the precomputation data./// Given `static_scalars`, an iterator of public scalars/// \\(b_i\\), compute/// Q = b_1 B_1 + \cdots + b_m B_m,/// where the \\(B_j\\) are the points that were supplied to `new`./// It is an error to call this function with iterators of/// inconsistent lengths./// The trait bound aims for maximum flexibility: the input must/// be convertable to iterators (`I: IntoIter`), and the/// iterator's items must be `Borrow<Scalar>`, to allow iterators/// returning either `Scalar`s or `&Scalar`s.vartime_mixed_multiscalar_mul/// \\(b_i\\), `dynamic_scalars`, an iterator of public scalars/// \\(a_i\\), and `dynamic_points`, an iterator of points/// \\(A_i\\), compute/// Q = a_1 A_1 + \cdots + a_n A_n + b_1 B_1 + \cdots + b_m B_m,/// If any of the dynamic points were `None`, return `None`./// A trait for variable-time multiscalar multiplication with precomputation./// A general multiscalar multiplication with precomputation can be written as/// where the \\(B_i\\) are *static* points, for which precomputation/// is possible, and the \\(A_j\\) are *dynamic* points, for which/// precomputation is not possible./// This trait has three methods for performing this computation:/// * [`vartime_multiscalar_mul`], which handles the special case/// where \\(n = 0\\) and there are no dynamic points;/// * [`vartime_mixed_multiscalar_mul`], which takes the dynamic/// points as already-validated `Point`s and is infallible;/// * [`optional_mixed_multiscalar_mul`], which takes the dynamic/// points as `Option<Point>`s and returns an `Option<Point>`,/// allowing decompression to be composed into the input iterators./// All methods require that the lengths of the input iterators be/// known and matching, as if they were `ExactSizeIterator`s.  (It/// does not require `ExactSizeIterator` only because that trait is/// broken)./// Checks whether the point is on the curve. Not CT./// Trait for checking whether a point is on the curve./// This trait is only for debugging/testing, since it should be/// impossible for a `curve25519-dalek` user to construct an invalid/// point.//! Module for common traits.// Public Traits// Private Traitsimpl_lookup_tabler" A lookup table of precomputed multiples of a point \\(P\\), used to"r" compute \\( xP \\) for \\( -8 \leq x \leq 8 \\)."r" The computation of \\( xP \\) is done in constant time by the `select` function."r" Since `LookupTable` does not implement `Index`, it's more difficult"r" to accidentally use the table directly.  Unfortunately the table is"r" only `pub(crate)` so that we can write hardcoded constants, so it's"r" still technically possible.  It would be nice to prevent direct"r" access to the table."r" Given \\(-8 \leq x \leq 8\\), return \\(xP\\) in constant time."select// The first one has to be named "LookupTable" because it's used as a constructor for consts.// radix-16// radix-32// radix-64// radix-128// For homogeneity we then alias it to "LookupTableRadix16"./// Holds odd multiples 1A, 3A, ..., 15A of a point A./// Given public, odd \\( x \\) with \\( 0 < x < 2^4 \\), return \\(xA\\)./// Holds stuff up to 8.//! Code for fixed- and sliding-window functionality// End macro_rules! impl_lookup_table// radix-256FromAttributesFromDeriveInputFromFieldFromGenericParamFromGenericsFromMetaFromTypeParamFromVariantastusage// XXX exported so that `ExtractAttribute::extractor` can convert a path into tokens.// This is likely to change in the future, so only generated code should depend on this export.Someexport/// Core/std trait re-exports. This should help produce generated code which doesn't/// depend on `std` unnecessarily, and avoids problems caused by aliasing `std` or any/// of the referenced types.macros_public//! # Darling//! Darling is a tool for declarative attribute parsing in proc macro implementations.//! ## Design//! Darling takes considerable design inspiration from [`serde`](https://serde.rs). A data structure that can be//! read from any attribute implements `FromMeta` (or has an implementation automatically//! generated using `derive`). Any crate can provide `FromMeta` implementations, even one not//! specifically geared towards proc-macro authors.//! Proc-macro crates should provide their own structs which implement or derive `FromDeriveInput`,//! `FromField`, `FromVariant`, `FromGenerics`, _et alia_ to gather settings relevant to their operation.//! ## Attributes//! There are a number of attributes that `darling` exposes to enable finer-grained control over the code//! it generates.//! * **Field renaming**: You can use `#[darling(rename="new_name")]` on a field to change the name Darling looks for.//!   You can also use `#[darling(rename_all="...")]` at the struct or enum level to apply a casing rule to all fields or variants.//! * **Map function**: You can use `#[darling(map="path::to::function")]` to run code on a field before its stored in the struct.//! * **Default values**: You can use `#[darling(default)]` at the type or field level to use that type's default value to fill//!   in values not specified by the caller.//! * **Skipped fields**: You can skip a variant or field using `#[darling(skip)]`. Fields marked with this will fall back to//!   `Default::default()` for their value, but you can override that with an explicit default or a value from the type-level default.//! * **Custom shorthand**: Use `#[darling(from_word = ...)]` on a struct or enum to override how a simple word is interpreted.//!   By default, it is an error for your macro's user to fail to specify the fields of your struct, but with this you can choose to//!   instead produce a set of default values. This takes either a path or a closure whose signature matches `FromMeta::from_word`.//! * **Custom handling for missing fields**: When a field is not present and `#[darling(default)]` is not used, derived impls will//!   call `FromMeta::from_none` on that field's type to try and get the fallback value for the field. Usually, there is not a fallback//!   value, so a missing field error is generated. `Option<T: FromMeta>` uses this to make options optional without requiring//!   `#[darling(default)]` declarations, and structs and enums can use this themselves with `#[darling(from_none = ...)]`.//!   This takes either a path or a closure whose signature matches `FromMeta::from_none`.//! ## Forwarded Fields//! All derivable traits except `FromMeta` support forwarding some fields from the input AST to the derived struct.//! These fields are matched up by identifier **before** `rename` attribute values are considered,//! allowing you to use their names for your own properties.//! The deriving struct is responsible for making sure the types of fields it chooses to declare are compatible with this table.//! A deriving struct is free to include or exclude any of the fields below.//! ### `FromDeriveInput`//! |Field name|Type|Meaning|//! |---|---|---|//! |`ident`|`syn::Ident`|The identifier of the passed-in type|//! |`vis`|`syn::Visibility`|The visibility of the passed-in type|//! |`generics`|`T: darling::FromGenerics`|The generics of the passed-in type. This can be `syn::Generics`, `darling::ast::Generics`, or any compatible type.|//! |`data` (or anything, using `#[darling(with = ...)]`)|`darling::ast::Data`|The body of the passed-in type|//! |`attrs`|`Vec<syn::Attribute>` (or anything, using `#[darling(with = ...)]`)|The forwarded attributes from the passed in type. These are controlled using the `forward_attrs` attribute.|//! ### `FromField`//! |`ident`|`Option<syn::Ident>`|The identifier of the passed-in field, or `None` for tuple fields|//! |`vis`|`syn::Visibility`|The visibility of the passed-in field|//! |`ty`|`syn::Type`|The type of the passed-in field|//! |`attrs`|`Vec<syn::Attribute>` (or anything, using `#[darling(with = ...)]`)|The forwarded attributes from the passed in field. These are controlled using the `forward_attrs` attribute.|//! ### `FromTypeParam`//! |`ident`|`syn::Ident`|The identifier of the passed-in type param|//! |`bounds`|`Vec<syn::TypeParamBound>`|The bounds applied to the type param|//! |`default`|`Option<syn::Type>`|The default type of the parameter, if one exists|//! |`attrs`|`Vec<syn::Attribute>` (or anything, using `#[darling(with = ...)]`)|The forwarded attributes from the passed in type param. These are controlled using the `forward_attrs` attribute.|//! ### `FromVariant`//! |`ident`|`syn::Ident`|The identifier of the passed-in variant|//! |`discriminant`|`Option<syn::Expr>`|For a variant such as `Example = 2`, the `2`|//! |`fields`|`darling::ast::Fields<T> where T: FromField`|The fields associated with the variant|//! |`attrs`|`Vec<syn::Attribute>` (or anything, using `#[darling(with = ...)]`)|The forwarded attributes from the passed in variant. These are controlled using the `forward_attrs` attribute.|uses_type_params/// Generator for `UsesTypeParam` impls that unions the used type parameters of the selected fields./// The macro takes the type implementing the trait as the first argument, then a comma-separated list of/// fields for the rest of its arguments./// The type of each passed-in field must implement `UsesTypeParams`, or the resulting code won't compile./// # extern crate syn;/// # use darling_core::uses_type_params;/// struct MyField {///     ty: syn::Type,/// uses_type_params!(MyField, ty);///     // no test run/// `darling` cannot derive this trait automatically, as it doesn't know which information extracted from/// proc-macro input is meant to constitute "using" the type parameter, but crate consumers should/// implement it by hand or using the macro.uses_lifetimes/// Generator for `UsesLifetimes` impls that unions the used lifetimes of the selected fields./// The type of each passed-in field must implement `UsesLifetimes`, or the resulting code won't compile.//! Macros that should be exported from both `darling_core` and `darling`.//! Note that these are **sym-linked** into the main code, and so cannot declare on items that are exported differently//! in `darling_core` vs. `darling`.IdentRefSetIdentSetLifetimeRefSetLifetimeSetUsesLifetimesUsesTypeParams/// A struct or enum body./// `V` is the type which receives any encountered variants, and `F` receives struct fields.empty_from/// Creates an empty body of the same shape as the passed-in body./// This function will panic if passed `syn::Data::Union`.try_empty_from/// `darling` does not support unions; calling this function with a union body will return an error./// Creates a new `Data<&'a V, &'a F>` instance from `Data<V, F>`.map_enum_variants/// Applies a function `V -> U` on enum variants, if this is an enum.map_struct_fields/// Applies a function `F -> U` on struct fields, if this is a struct.map_struct/// Applies a function to the `Fields` if this is a struct.take_struct/// Consumes the `Data`, returning `Fields<F>` if it was a struct.take_enum/// Consumes the `Data`, returning `Vec<V>` if it was an enum.is_enum/// Returns `true` if this instance is `Data::Enum`.is_struct/// Returns `true` if this instance is `Data::Struct`./// Attempt to convert from a `syn::Data` instance.styleStyle__nonexhaustive/// Equivalent to `syn::Fields`, but replaces the AST element with a generic./// Creates a new [`Fields`] struct.with_span/// Adds a [`Span`] to [`Fields`]./// Splits the `Fields` into its style and fields for further processing./// Returns an empty `Vec` for `Unit` data.is_newtype/// Returns true if this variant's data makes it a newtype.is_unitis_tuple/// Returns the number of fields in the structure./// Returns `true` if the `Fields` contains no fields.with_fields/// Creates a new `Fields` of the specified style with the passed-in fields.parse_meta_listtoken_stream_to_fields// it is not possible to directly convert a TokenStream into syn::Fields, so you have// to convert the TokenStream into DeriveInput first and then pass the syn::Fields to// Fields::try_from.test_style_eqtest_fields_to_tokens_structtest_fields_to_tokens_tuple/// The type this GenericParam uses to represent type params and their boundsLifetimeParamas_type_param/// If this GenericParam is a type param, get the underlying value.as_lifetime_param/// If this GenericParam is a lifetime, get the underlying value.as_const_param/// If this GenericParam is a const param, get the underlying value.GenericParamExt/// Extension trait for `GenericParam` to support getting values by variant./// `darling::ast::Generics` needs a way to test its params array in order to iterate over type params./// Rather than require callers to use `darling::ast::GenericParam` in all cases, this trait makes that/// polymorphic.Lifetime/// A mirror of `syn::GenericParam` which is generic over all its contents.from_type_paramfrom_generic_param/// A mirror of the `syn::Generics` type which can contain arbitrary representations/// of params and where clauses.type_paramsTypeParamsfrom_generics//! Types for working with generics//! Utility types for working with the AST.PathListForwardAttrslocal_declarations/// A set of mutable declarations for all members of the implementing type.attr_names/// Gets the list of attribute names that should be parsed by the extractor.forward_attrsparam_name/// Gets the name used by the generated impl to return to the `syn` item passed as input.attrs_accessor/// Get the tokens to access a borrowed list of attributes where extraction will take place./// By default, this will be `&#input.attrs` where `#input` is `self.param_name()`.core_loop/// Gets the core from-meta-item loop that should be used on matching attributes.extractor/// Generates the main extraction loop.ExtractAttribute/// Infrastructure for generating an attribute extractor.TokenStreamExtForwardAttrsFilterForwardedFieldfilterwill_forward_any/// Check if this will forward any attributes; this requires both that/// there be a filter which can match some attributes and a field to receive them.as_declaration/// Get the field declarations to support attribute forwardingas_match_armsMatchArms/// Get the match arms for attribute matchingas_value_populatorValuePopulator/// Get the statement that will try to transform forwarded attributes into/// the result expected by the receiver field.as_initializerInitializer/// Get the field initializer for use when building the deriving struct.DEFAULT_STRUCT_NAME/// This will be in scope during struct initialization after option parsing.DefaultExpressionInherit/// Only valid on fields, `Inherit` indicates that the value should be taken from a pre-constructed/// fallback object. The value in the variant is the ident of the field.Explicit/// The fallback value for a field or container.DefaultDeclaration/// Used only by containers, this wrapper type generates code to declare the fallback instance.__hiddenErrorDeclaration/// Declares the local variable into which errors will be accumulated.locationErrorCheck/// Returns early if attribute or body parsing has caused any errors.with_locationPostfixTransformname_in_attr/// The name presented to the user of the library. This will appear/// in error messages and will be looked when parsing names./// The name presented to the author of the library. This will appear/// in the setters or temporary variables which contain the values./// The type of the field in the input.default_expressionwith_callable/// An expression that will be wrapped in a call to [`core::convert::identity`] and/// then used for converting a provided value into the field value _before_ postfix/// transforms are called.post_transformmultipleflatten/// If set, this field will be given all unclaimed meta items and will/// not be exposed as a standard named field./// Properties needed to generate code for a field in all the contexts/// where one may appear.as_name/// Get the name of the meta item that should be matched against input and should be used in diagnostics./// This will be `None` if the field is `skip` or `flatten`, as neither kind of field is addressable/// by name from the input meta.as_flatten_initializerFlattenInitializeras_matchMatchArmas_presence_checkCheckMissing/// An individual field during variable declaration in the generated parsing method.parent_field_names/// Represents an individual field in the match./// Wrapper to generate initialization code for a field./// Creates an error if a field has no value and no default.OuterFromImplTraitImplFromAttributesImpltrait_pathtrait_boundDeriveInputShapeSetvisfrom_identsupportsFromDeriveInputImplFromFieldImpl/// `impl FromField` generator. This is used for parsing an individual/// field and its attributes.Callablefrom_wordfrom_noneFromMetaImplFromTypeParamImplDataShape/// If set, the ident of the field into which the variant ident should be placed./// This is one of `darling`'s "magic fields", which allow a type deriving a `darling`/// trait to get fields from the input `syn` element added to the deriving struct/// automatically./// If set, the ident of the field into which the transformed output of the input/// variant's fields should be placed./// This is one of `darling`'s "magic fields".discriminant/// If set, the ident of the field into which the discriminant of the input variant/// should be placed. The receiving field must be an `Option` as not all enums have/// discriminants.FromVariantImplattr_extractorattrs_fielddefault_exprfrom_attributes_implfrom_derive_implfrom_fieldfrom_meta_implfrom_variant_implouter_from_implpostfix_transformvariantvariant_dataFieldsGenTraitBoundTraitBoundModifier/// Gets the path of the trait being implemented./// Wrapper for "outer From" traits, such as `FromDeriveInput`, `FromVariant`, and `FromField`.compute_impl_boundstransformerfunction/// A method invocation applied to a value./// This is used for `map` and `and_then` transforms in derivations.CollectTypeParamsPurposeallow_unknown_fieldsdeclared_type_params/// Get all declared type parameters.used_type_params/// Get the type parameters which are used by non-skipped, non-magic fields./// These type parameters will have a `FromMeta` bound applied to them in emitted/// code.type_params_matchingtype_params_in_fields/// Get the type parameters of all fields in a set matching some filterdeclare_errors/// Gets the `let` declaration for errors accumulated during parsing.check_errors/// Gets the check which performs an early return if errors occurred during parsing./// Generate local variable declarations for all fields.post_transform_callfallback_decl/// Generate local variable declaration and initialization for instance from which missing fields will be taken.require_fieldsinitializers/// Generate the loop which walks meta items looking for property matches.make_field_ctx/// The name which will appear in code passed to the `FromMeta` input.variant_ident/// The name of the variant which will be returned for a given `name_in_attr`.ty_ident/// The name of the parent enum type./// Whether or not the variant should be skipped in the generated code./// A variant of the enum which is deriving `FromMeta`.as_unit_match_armUnitMatchArmas_data_match_armDataMatchArm/// Code generator for an enum variant in a unit match position./// This is placed in generated `from_string` calls for the parent enum./// Value-carrying variants wrapped in this type will emit code to produce an "unsupported format" error./// Code generator for an enum variant in a data-carrying match position./// This is placed in generated `from_list` calls for the parent enum./// Unit variants wrapped in this type will emit code to produce an "unsupported format" error./// Create declarations for all the fields in the struct.emit_impl_or_error/// Run an expression which returns a `darling::Result`, then either return the tokenized/// representation of the `Ok` value, or the tokens of the compiler errors in the `Err` case.from_meta/// Create tokens for a `darling::FromMeta` impl from a `DeriveInput`. If/// the input cannot produce a valid impl, the returned tokens will contain/// compile errors instead.from_attributes/// Create tokens for a `darling::FromAttributes` impl from a `DeriveInput`. Iffrom_derive_input/// Create tokens for a `darling::FromDeriveInput` impl from a `DeriveInput`. If/// Create tokens for a `darling::FromField` impl from a `DeriveInput`. If/// Create tokens for a `darling::FromTypeParam` impl from a `DeriveInput`. Iffrom_variant/// Create tokens for a `darling::FromVariant` impl from a `DeriveInput`. If//! Functions to derive `darling`'s traits from well-formed input, without directly depending//! on `proc_macro`.LevelWarningNoteHelp/// Exhaustive mirror of [`proc_macro::Level`].levelChildDiagnostic/// Supplemental message for an [`Error`](super::Error) when it's emitted as a `Diagnostic`./// # Example Output/// The `note` and `help` lines below come from child diagnostics./// error: My custom error///   --> my_project/my_file.rs:3:5/// 13 |     FooBar { value: String },///    |     ^^^^^^///    = note: My note on the macro usage///    = help: Try doing this insteadappend_toDiagnostic/// Append this child diagnostic to a `Diagnostic`./// This method panics if `self` has a span and is being invoked outside of/// a proc-macro due to the behavior of [`Span::unwrap()`](Span).DeriveInputShapeMetaFormat/// An arbitrary error message.DuplicateFieldMissingFieldobservedexpectedUnsupportedShapeErrorUnknownFieldUnknownFieldUnexpectedFormatUnexpectedTypeUnknownValueTooFewItemsTooManyItemsMultiple/// A set of errors.// TODO make this variant take `!` so it can't exist// Don't want to publicly commit to ErrorKind supporting equality yet, but// not having it makes testing very difficult./// Deeply counts the number of errors this item represents.did_you_mean/// An error for an unknown field, with a possible "did-you-mean" suggestion to get/// the user back on the right track.with_altsadd_alts/// Add more alternate field names to the error, updating the `did_you_mean` suggestion/// if a closer match to the unknown field's name is found.path_to_string/// An alias of `Result` specific to attribute parsing.locations/// The span to highlight in the emitted diagnostic./// An error encountered during attribute parsing./// Given that most errors darling encounters represent code bugs in dependent crates,/// the internal structure of the error is deliberately opaque./// Proc-macro expansion happens very infrequently compared to runtime tasks such as/// deserialization, and it happens in the context of an expensive compilation taks./// For that reason, darling prefers not to fail on the first error it encounters, instead/// doing as much work as it can, accumulating errors into a single report./// As a result, `darling::Error` is more of guaranteed-non-empty error collection/// than a single problem. These errors also have some notion of hierarchy, stemming from/// the hierarchical nature of darling's input./// These characteristics make for great experiences when using darling-powered crates,/// provided crates using darling adhere to some best practices:/// 1. Do not attempt to simplify a `darling::Error` into some other error type, such as///    `syn::Error`. To surface compile errors, instead use `darling::Error::write_errors`.///    This preserves all span information, suggestions, etc. Wrapping a `darling::Error` in///    a custom error enum works as-expected and does not force any loss of fidelity./// 2. Do not use early return (e.g. the `?` operator) for custom validations. Instead,///    create an [`error::Accumulator`](Accumulator) to collect errors as they are encountered.  Then use///    [`Accumulator::finish`] to return your validated result; it will give `Ok` if and only if///    no errors were encountered.  This can create very complex custom validation functions;///    in those cases, split independent "validation chains" out into their own functions to///    keep the main validator manageable./// 3. Use `darling::Error::custom` to create additional errors as-needed, then call `with_span`///    to ensure those errors appear in the right place. Use `darling::util::SpannedValue` to keep///    span information around on parsed fields so that custom diagnostics can point to the correct///    parts of the input AST./// Creates a new error with a custom message.duplicate_field/// Creates a new error for a field that appears twice in the input.duplicate_field_path/// Creates a new error for a field that appears twice in the input. Helper to avoid repeating/// the syn::Path to String conversion.missing_field/// Creates a new error for a non-optional field that does not appear in the input.unknown_field/// Creates a new error for a field name that appears in the input but does not correspond/// to a known field.unknown_field_path/// to a known field. Helper to avoid repeating the syn::Path to String conversion.unknown_field_with_alts/// Creates a new error for a field name that appears in the input but does not correspond to/// a known attribute. The second argument is the list of known attributes; if a similar name/// is found that will be shown in the emitted error message.unknown_field_path_with_altsunsupported_shape/// Creates a new error for a struct or variant that does not adhere to the supported shape.unsupported_shape_with_expectedunsupported_formatunexpected_type/// Creates a new error for a field which has an unexpected literal type.unexpected_expr_typeunexpected_lit_type/// Creates a new error for a field which has an unexpected literal type. This will automatically/// extract the literal type name from the passed-in `Lit` and set the span to encompass only the/// literal value./// This is most frequently used in overrides of the `FromMeta::from_value` method./// # // pretend darling_core is darling so the doc example looks correct./// # extern crate darling_core as darling;/// use darling::{FromMeta, Error, Result};/// use syn::{Lit, LitStr};/// pub struct Foo(String);/// impl FromMeta for Foo {///     fn from_value(value: &Lit) -> Result<Self> {///         if let Lit::Str(ref lit_str) = *value {///             Ok(Foo(lit_str.value()))///             Err(Error::unexpected_lit_type(value))/// # fn main() {}unknown_value/// Creates a new error for a value which doesn't match a set of expected literals.too_few_items/// Creates a new error for a list which did not get enough items to proceed.too_many_items/// Creates a new error when a list got more items than it supports. The `max` argument/// is the largest number of items the receiver could accept./// Bundle a set of multiple errors into a single `Error` instance./// Usually it will be more convenient to use an [`error::Accumulator`](Accumulator)./// This function will panic if `errors.is_empty() == true`.accumulatorAccumulator/// Creates an error collector, for aggregating multiple errors/// See [`Accumulator`] for details./// Error creation functionsunknown_lit_str_value/// Create a new error about a literal string that doesn't match a set of known/// or permissible values. This function can be made public if the API proves useful/// beyond impls for `syn` types.has_span/// Check if this error is associated with a span in the token stream./// Tie a span to the error if none is already present. This is used in `darling::FromMeta`/// and other traits to attach errors to the most specific possible location in the input/// source code./// All `darling`-built impls, either from the crate or from the proc macro, will call this/// when appropriate during parsing, so it should not be necessary to call this unless you have/// overridden:/// * `FromMeta::from_meta`/// * `FromMeta::from_nested_meta`/// * `FromMeta::from_value`/// Get a span for the error./// # Return Value/// This function will return [`Span::call_site()`](proc_macro2::Span) if [`Self::has_span`] is `false`./// To get the span only if one has been explicitly set for `self`, instead use [`Error::explicit_span`].explicit_span/// Get the span for `self`, if one has been set./// Recursively converts a tree of errors to a flattened list./// # Child Diagnostics/// If the `diagnostics` feature is enabled, any child diagnostics on `self`/// will be cloned down to all the errors within `self`./// Adds a location to the error, such as a field or variant./// Locations must be added in reverse order of specificity.at_path/// Locations must be added in reverse order of specificity. This is a helper function to avoid/// repeating path to string logic./// Gets the number of individual errors in this error./// This function never returns `0`, as it's impossible to construct/// a multi-error from an empty `Vec`.add_sibling_alts_for_unknown_field/// Consider additional field names as "did you mean" suggestions for/// unknown field errors **if and only if** the caller appears to be operating/// at error's origin (meaning no calls to [`Self::at`] have yet taken place)./// `flatten` fields in derived trait implementations rely on this method to offer correct/// "did you mean" suggestions in errors./// Because the `flatten` field receives _all_ unknown fields, if a user mistypes a field name/// that is present on the outer struct but not the flattened struct, they would get an incomplete/// or inferior suggestion unless this method was invoked.prepend_at/// Adds a location chain to the head of the error's existing locations./// Gets the location slice.write_errors/// Write this error and any children as compile errors into a `TokenStream` to/// be returned by the proc-macro./// The behavior of this method will be slightly different if the `diagnostics` feature/// is enabled: In that case, the diagnostics will be emitted immediately by this call,/// and an empty `TokenStream` will be returned./// Return these tokens unmodified to avoid disturbing the attached span information./// // in your proc-macro function/// let opts = match MyOptions::from_derive_input(&ast) {///     Ok(val) => val,///     Err(err) => {///         return err.write_errors();/// Error instance methods// Error can never be empty// Don't want to publicly commit to Error supporting equality yet, but// not having it makes testing very difficult. Note that spans are not// considered for equality since that would break testing in most cases.IntoIterEnum/// An iterator that moves out of an `Error`."Accumulator will panic on drop if not defused."/// Accumulator for errors, for helping call [`Error::multiple`]./// See the docs for [`darling::Error`](Error) for more discussion of error handling with darling./// `Accumulator` panics on drop unless [`finish`](Self::finish), [`finish_with`](Self::finish_with),/// or [`into_inner`](Self::into_inner) has been called, **even if it contains no errors**./// If you want to discard an `Accumulator` that you know to be empty, use `accumulator.finish().unwrap()`./// # struct Thing;/// # struct Output;/// # impl Thing { fn validate(self) -> darling::Result<Output> { Ok(Output) } }/// fn validate_things(inputs: Vec<Thing>) -> darling::Result<Vec<Output>> {///     let mut errors = darling::Error::accumulator();///     let outputs = inputs///         .into_iter()///         .filter_map(|thing| errors.handle_in(|| thing.validate()))///         .collect::<Vec<_>>();///     errors.finish()?;///     Ok(outputs)handle_in/// Runs a closure, returning the successful value as `Some`, or collecting the error/// The closure's return type is `darling::Result`, so inside it one can use `?`./// Handles a possible error./// Returns a successful value as `Some`, or collects the error and returns `None`./// Stop accumulating errors, producing `Ok` if there are no errors or producing/// an error with all those encountered by the accumulator.finish_with/// Bundles the collected errors if there were any, or returns the success value/// Call this at the end of your input processing./// If there were no errors recorded, returns `Ok(success)`./// Otherwise calls [`Error::multiple`] and returns the result as an `Err`."Accumulated errors should be handled or propagated to the caller"/// Returns the accumulated errors as a `Vec`./// This function defuses the drop bomb./// Add one error to the collection.checkpoint/// Finish the current accumulation, and if there are no errors create a new `Self` so processing may continue./// This is shorthand for:/// errors.finish()?;/// errors = Error::accumulator();/// # Drop Behavior/// This function returns a new [`Accumulator`] in the success case./// This new accumulator is "armed" and will detonate if dropped without being finished./// # impl Thing { fn validate(&self) -> darling::Result<Output> { Ok(Output) } }/// fn validate(lorem_inputs: &[Thing], ipsum_inputs: &[Thing])///             -> darling::Result<(Vec<Output>, Vec<Output>)> {///     let lorems = lorem_inputs.iter().filter_map(|l| {///         errors.handle(l.validate())///     }).collect();///     errors = errors.checkpoint()?;///     let ipsums = ipsum_inputs.iter().filter_map(|l| {///     errors.finish_with((lorems, ipsums))/// # validate(&[], &[]).unwrap();flatten_noopflatten_simplelen_singlelen_multiplelen_nestedaccum_okaccum_errraccum_into_inneraccum_drop_panicaccum_drop_panic_with_error_countaccum_checkpoint_erroraccum_checkpoint_drop_panic//! The `darling::Error` type, the multiple error `Accumulator`, and their internals.//! Error handling is one of the core values of `darling`; creating great errors is hard and//! never the reason that a proc-macro author started writing their crate. As a result, the//! `Error` type in `darling` tries to make adding span information, suggestions, and other//! help content easy when manually implementing `darling` traits, and automatic when deriving//! them./// Create an instance by parsing a list of attributes./// By convention, `FromAttributes` implementations should merge item/// declarations across attributes, so that the following forms are/// equivalent:/// #[serde(rename_all = "camel_case")]/// #[serde(borrow)]/// pub struct SplitExample {}/// #[serde(borrow, rename_all = "camel_case")]/// pub struct JoinedExample {}/// This trait is useful when dealing with items such as traits on traits and impl blocks,/// for which `darling` does not provide dedicated traits./// Create an instance from `syn::DeriveInput`, or return an error./// Creates an instance by parsing an entire proc-macro `derive` input,/// including the, identity, generics, and visibility of the type./// This trait should either be derived or manually implemented by a type/// in the proc macro crate which is directly using `darling`. It is unlikely/// that these implementations will be reusable across crates./// Creates an instance by parsing an individual field and its attributes./// Creates an instance by parsing a specific `syn::GenericParam`./// This can be a type param, a lifetime, or a const param./// Creates an instance by parsing an entire generics declaration, including the/// `where` clause.from_nested_meta/// Create an instance from a `syn::Meta` by dispatching to the format-appropriate/// trait function. This generally should not be overridden by implementers./// # Error Spans/// If this method is overridden and can introduce errors that weren't passed up from/// other `from_meta` calls, the override must call `with_span` on the error using the/// `item` to make sure that the emitted diagnostic points to the correct location in/// When a field is omitted from a parent meta-item, `from_none` is used to attempt/// recovery before a missing field error is generated./// **Most types should not override this method.** `darling` already allows field-level/// missing-field recovery using `#[darling(default)]` and `#[darling(default = "...")]`,/// and users who add a `String` field to their `FromMeta`-deriving struct would be surprised/// if they get back `""` instead of a missing field error when that field is omitted./// The primary use-case for this is `Option<T>` fields gracefully handlling absence without/// needing `#[darling(default)]`./// Create an instance from the presence of the word in the attribute with no/// additional options specified.from_list/// Create an instance from a list of nested meta items./// Create an instance from a literal value of either `foo = "bar"` or `foo("bar")`./// This dispatches to the appropriate method based on the type of literal encountered,/// and generally should not be overridden by implementers./// If this method is overridden, the override must make sure to add `value`'s span/// information to the returned error by calling `with_span(value)` on the `Error` instance.from_exprfrom_char/// Create an instance from a char literal in a value position.from_string/// Create an instance from a string literal in a value position.from_bool/// Create an instance from a bool literal in a value position./// Create an instance from an item in an attribute declaration./// # Implementing `FromMeta`/// * Do not take a dependency on the `ident` of the passed-in meta item. The ident will be set by the field name of the containing struct./// * Implement only the `from_*` methods that you intend to support. The default implementations will return useful errors./// # Provided Implementations/// ## bool/// * Word with no value specified - becomes `true`./// * As a boolean literal, e.g. `foo = true`./// * As a string literal, e.g. `foo = "true"`./// ## char/// * As a char literal, e.g. `foo = '#'`./// * As a string literal consisting of a single character, e.g. `foo = "#"`./// ## String/// * As a string literal, e.g. `foo = "hello"`./// * As a raw string literal, e.g. `foo = r#"hello "world""#`./// ## Number/// * As a string literal, e.g. `foo = "-25"`./// * As an unquoted positive value, e.g. `foo = 404`. Negative numbers must be in quotation marks./// ## ()/// * Word with no value specified, e.g. `foo`. This is best used with `Option`.///   See `darling::util::Flag` for a more strongly-typed alternative./// ## Option/// * Any format produces `Some`./// ## `Result<T, darling::Error>`/// * Allows for fallible parsing; will populate the target field with the result of the///   parse attempt.// false positivefrom_meta_num/// Generate an impl of `FromMeta` that will accept strings which parse to numbers or/// integer literals.from_meta_float/// Generate an impl of `FromMeta` that will accept strings which parse to floats or/// float literals./// Parsing support for punctuated. This attempts to preserve span information/// when available, but also supports parsing strings with the call site as the/// emitted span./// Support for arbitrary expressions as values in a meta item./// For backwards-compatibility to versions of `darling` based on `syn` 1,/// string literals will be "unwrapped" and their contents will be parsed/// as an expression./// See [`util::parse_expr`](crate::util::parse_expr) for functions to provide/// alternate parsing modes for this type./// Parser for paths that supports both quote-wrapped and bare values.from_syn_expr_type/// Adapter for various expression types./// Prior to syn 2.0, darling supported arbitrary expressions as long as they/// were wrapped in quotation marks. This was helpful for people writing/// libraries that needed expressions, but it now creates an ambiguity when/// parsing a meta item./// To address this, the macro supports both formats; if it cannot parse the/// item as an expression of the right type and the passed-in expression is/// a string literal, it will fall back to parsing the string contents.ExprArrayfrom_syn_parse/// Adapter from `syn::parse::Parse` to `FromMeta` for items that cannot/// be expressed in a [`syn::MetaNameValue`]./// This cannot be a blanket impl, due to the `syn::Lit` family's need to handle non-string values./// Therefore, we use a macro and a lot of impls.TypeBareFnTypeGroupTypeImplTraitTypeInferTypeMacroTypeNeverTypeParenTypePtrTypeReferenceTypeSliceTypeTraitObjectTypeTuplefrom_numeric_arrayr#" Parsing an unsigned integer array, i.e. `example = "[1, 2, 3, 4]"`."#from_meta_litLitFloatLitByteStrLitCharLitBoolRenameRule// `#[darling(flatten)]` forwards directly to this method, so it's// necessary to declare it to avoid getting an unsupported format// error if it's invoked directly.smart_pointer_t/// Create an impl that forwards to an inner type `T` for parsing./// Parses the meta-item, and in case of error preserves a copy of the input for/// later analysis.to_displayKeyFromPath/// Trait to convert from a path into an owned key for a map.// This is done as a macro rather than a blanket impl to avoid breaking backwards compatibility// with 0.12.x, while still sharing the same impl.pm/// parse a string as a syn::Meta instance.fmunit_succeedsbool_succeedschar_succeedsstring_succeedspathbuf_succeedsnumber_succeeds// we want exact equalitynonzero_number_failsnonzero_number_succeedsint_without_quotesnegative_int_without_quotesfloat_without_quotestoo_large_int_produces_errormeta_succeedshash_map_succeedshash_map_duplicate/// Check that a `HashMap` cannot have duplicate keys, and that the generated error/// is assigned a span to correctly target the diagnostic message.hash_map_multiple_errorshash_map_ident_succeedshash_map_ident_rejects_non_identshash_map_path_succeedsbtree_map_succeedsbtree_map_duplicatebtree_map_multiple_errorsbtree_map_ident_succeedsbtree_map_ident_rejects_non_identsbtree_map_expr_values_succeeddarling_result_succeeds/// Tests that fallible parsing will always produce an outer `Ok` (from `fm`),/// and will accurately preserve the inner contents.test_punctuated/// Test punctuatedtest_expr_arraytest_exprtest_expr_without_quotestest_expr_pathtest_expr_path_without_quotestest_path_without_quotestest_number_arraytest_lit_arrayexpr_range_without_quotes/// Tests for `FromMeta` implementations. Wherever the word `ignore` appears in test input,/// it should not be considered by the parsing.// FromMeta impls for std and syn types./// Creates an instance by parsing an individual type_param and its attributes./// Create an instance from `syn::Variant`, or return an error./// Creates an instance from a specified `syn::Variant`."256"macros_private// Re-exportsInputFieldInputVariantParseAttributeParseData/// The type identifier./// The type's generics. If the type does not use any generics, this will/// be an empty instance./// Controls whether missing properties should cause errors or should be filled by/// the result of a function call. This can be overridden at the field level.rename_rule/// The rule that should be used to rename all fields/variants in the container./// A transform which will be called on `darling::Result<Self>`. It must either be/// an `FnOnce(T) -> T` when `map` is used, or `FnOnce(T) -> darling::Result<T>` when/// `and_then` is used./// `map` and `and_then` are mutually-exclusive to avoid confusion about the order in/// which the two are applied./// The body of the _deriving_ type.bound/// The custom bound to apply to the generated impl/// Whether or not unknown fields should produce an error at compilation time.Core/// A struct or enum which should have `FromMeta` or `FromDeriveInput` implementations/// generated./// Partially initializes `Core` by reading the identity, generics, and body shape.as_codegen_defaultparse_nestedparse_variantparse_fieldvalidate_bodyAllOnly/// A rule about which attributes to forward to the generated struct./// Returns `true` if this will not forward any attributes./// The ident of the field that will receive the forwarded value./// Path of the function that will be called to convert the forwarded value/// into the type expected by the field in `ident`./// A forwarded field and attributes that influence its behavior.OuterFrom// Note: FromAttributes has no behaviors beyond those common// to all the `OuterFrom` traits.FromAttributesOptions/// Receiver for derived `FromAttributes` impls.forwarded_field/// The field on the target struct which should receive the type visibility, if any./// The field on the target struct which should receive the type generics, if any./// The field on the target struct which should receive the derive input body, if any.FdiOptionsFromFieldOptions/// Override for the default [`FromMeta::from_word`] method./// Override for the default [`FromMeta::from_none`] method.FromMetaOptions// The reason is commented out due to MSRV issues.// reason = "This matches the name of the input option and output method"/// Get the `from_word` method body, if one exists. This can come from direct use of/// `#[darling(from_word = ...)]` on the container or from use of `#[darling(word)]` on/// a unit variant.FromTypeParamOptions/// The field on the deriving struct into which the discriminant expression/// should be placed by the derived `FromVariant` impl.FromVariantOptionsparse_quote_spannedSpannedValueattr_name/// If `true`, generated code will not look for this field in the input meta item,/// instead always falling back to either `InputField::default` or `Default::default`.as_codegen_field/// Generate a view into this field that can be used for code generation./// Generate a codegen::DefaultExpression for this field. This requires the field name/// in the `Inherit` case.with_inherited/// Apply inherited settings from the container. This is done _after_ parsing/// to ensure deference to explicit field-level settings.word/// Whether or not the variant should be used to create an instance for/// `FromMeta::from_word`./// Whether or not unknown fields are acceptable in thisas_codegen_variantfrom_deriveinput_fieldinput_variantouter_fromshape/// The value should be taken from the `default` instance of the containing struct./// This is not valid in container options./// The input span that is responsible for the use of `Default::default`./// A default/fallback expression encountered in attributes during parsing.// Note: This cannot use `from_word` as it needs to capture the span// in the `Meta::Path` case.parse_attributes/// Read a meta-item, and apply its values to the current instance./// Middleware for extracting attribute values. Implementers are expected to override/// `parse_nested` so they can apply individual items to themselves, while `parse_attributes`/// is responsible for looping through distinct outer attributes and collecting errors.parse_attrparse_body/// Apply the next found variant to the object, returning an error/// if parsing goes wrong./// Apply the next found struct field to the object, returning an error/// Perform validation checks that require data from more than one field or variant./// The default implementation does no validations./// Implementors can override this method as appropriate for their use-case./// Middleware for extracting values from the body of the derive input. Implementers are/// expected to override `parse_field` or `parse_variant` as appropriate for their use-case,/// while `parse_body` dispatches to the appropriate methods and handles error collection./// The field on the target struct which should receive the type identifier, if any.attrs/// The field on the target struct which should receive the type attributes, if any.container/// The attribute names that should be searched./// The attribute names that should be forwarded. The presence of the word with no additional/// filtering will cause _all_ attributes to be cloned and exposed to the struct after parsing./// Whether or not the container can be made through conversion from the type `Ident`./// Reusable base for `FromDeriveInput`, `FromVariant`, `FromField`, and other top-level/// `From*` traits.as_forward_attrsenum_valuesstruct_values/// Receiver struct for shape validation. Shape validation allows a deriving type/// to declare that it only accepts - for example - named structs, or newtype enum/// variants./// #[ignore(any, struct_named, enum_newtype)]/// The kind of shape being described. This can be `struct_` or `enum_`.newtypenamedtupleunit/// Receiver for shape information within a struct or enum context. See `Shape` for more information/// on valid uses of shape validation.set_wordsupports_anysupports_structsupports_mixed//! Types for "shape" validation. This allows types deriving `FromDeriveInput` etc. to declare//! that they only work on - for example - structs with named fields, or newtype enum variants.declared_lifetimes/// Get the set of all lifetimes declared by the syntax element./// This does not look for usage of the lifetime; see `UsesLifetimes` for that./// Get the set of all type parameters declared by the syntax element./// This does not look for usage of the type parameter; see `UsesTypeParams` for that.GenericsExt/// Extension trait for pulling specific generics data from a generics AST representation.FnvHashSet/// A set of idents./// A set of references to idents./// A set of lifetimes./// A set of references to lifetimes./// Returns the subset of the queried lifetimes that are used by the implementing syntax element./// This method only accounts for direct usage by the element; indirect usage via bounds or `where`/// predicates are not detected.uses_lifetimes_cloned/// Find all used lifetimes, then clone them and return that set./// Searcher for finding lifetimes in a syntax tree./// This can be used to determine which lifetimes must be emitted in generated code.collect_lifetimes/// Consume an iterator, accumulating all lifetimes in the elements which occur in `lifetimes`.collect_lifetimes_cloned/// Consume an iterator using `collect_lifetimes`, then clone all found lifetimes and return that set.CollectLifetimes/// Searcher for finding lifetimes in an iterator./// This trait extends iterators, providing a way to turn a filtered list of fields or variants into a set/// of lifetimes.'genAngleBracketedGenericArgumentsAssocTypeBareFnArgBoundLifetimesDataStructDataUnionFieldsNamedParenthesizedGenericArgumentsPredicateTypeQSelfstruct_namedqselfgenerics_extident_setlifetimes//! Traits and types used for tracking the usage of generic parameters through a proc-macro input.//! When generating trait impls, libraries often want to automatically figure out which type parameters//! are used in which fields, and then emit bounds that will produce the most permissive compilable//! code.//! ## Example 1: Filtering//! This example accepts a proc-macro input, then finds all lifetimes and type parameters used//! by private fields.//! # extern crate darling_core;//! # extern crate syn;//! # // in real-world usage, import from `darling`//! # use darling_core::usage::{self, CollectLifetimes, CollectTypeParams, GenericsExt, Purpose};//! # use syn::{Data, DeriveInput, GenericParam, Generics, Visibility};//! # #[allow(dead_code)]//! fn process(input: &DeriveInput) -> Generics {//!     let type_params = input.generics.declared_type_params();//!     let lifetimes = input.generics.declared_lifetimes();//!     let mut ret_generics = input.generics.clone();//!     if let Data::Struct(ref body) = input.data {//!         let internal_fields = body//!             .fields//!             .iter()//!             .filter(|field| field.vis == Visibility::Inherited)//!             .collect::<Vec<_>>();//!         let int_type_params = internal_fields//!             .collect_type_params(&Purpose::BoundImpl.into(), &type_params);//!         // We could reuse the vec from above, but here we'll instead//!         // directly consume the chained iterator.//!         let int_lifetimes = body//!             .collect_lifetimes(&Purpose::BoundImpl.into(), &lifetimes);//!         ret_generics.params = ret_generics//!             .params//!             .into_iter()//!             .filter(|gp| {//!                 match *gp {//!                     GenericParam::Type(ref ty) => int_type_params.contains(&ty.ident),//!                     GenericParam::Lifetime(ref lt) => int_lifetimes.contains(&lt.lifetime),//!                     _ => true,//!                 }//!             })//!             .collect();//!     ret_generics//! ## Example 2: Integrating with `FromDeriveInput`//! It is possible to use `darling`'s magic fields feature in tandem with the `usage` feature set.//! While there is no custom derive for `UsesTypeParams` or `UsesLifetimes`, there are macros to//! generate impls.//! #![allow(dead_code)]//! #[derive(FromField)]//! #[darling(attributes(speak))]//! struct SpeakerField {//!     ident: Option<syn::Ident>,//!     ty: syn::Type,//!     #[darling(default)]//!     volume: Option<u32>,//! uses_type_params!(SpeakerField, ty);//! uses_lifetimes!(SpeakerField, ty);//! #[derive(FromDeriveInput)]//! struct SpeakerOptions {//!     generics: syn::Generics,//!     data: darling::ast::Data<darling::util::Ignored, SpeakerField>,//! At this point, you are able to call `uses_type_params` on `SpeakerOptions.data`, or any filtered//! view of it. `darling` internally uses this in conjunction with the `skip` meta-item to determine//! which type parameters don't require the `FromMeta` bound in generated impls.//! **Note:** If you are performing operations referencing generic params in meta-items parsed by `darling`,//! you should determine if those impact the emitted code and wire up `UsesTypeParams` accordingly for//! your field/variant.BoundImpl/// The tracing is being used to generate an `impl` block./// Uses such as `syn::TypePath.qself` will _not_ be returned.Declare/// The tracing is being used to generate a new struct or enum./// All uses will be returned./// The goal of tracing generic parameter usage./// Not all uses of type parameters imply a need to add bounds to a generated trait impl./// For example, a field of type `<Vec<T> as a::b::Trait>::Associated` does not need a/// `where T: Serialize` bound in `serde`./// However, a proc macro that is attempting to generate a helper struct _would_ need to/// know about this usage, or else the generated code would reference an unknown type `T`/// and fail to compile.purpose/// Control struct for searching type parameters./// This acts as the search context, preserving information that might have been/// kept on a visitor in a different implementation./// Trait implementers are required to pass this through on any invocations they make./// For extensibility, `Options` hides all of its fields from consumers./// To create an instance, use the `From<Purpose>` trait implementation:/// # use darling_core::usage::{Options, Purpose};/// let opts: Options = Purpose::BoundImpl.into();/// assert!(!opts.include_type_path_qself());include_type_path_qself/// Returns `true` if the implementer of `UseTypeParams` should search/// `<___ as ...>::...` when looking for type parameter uses./// Returns the subset of the queried type parameters that are used by the implementing syntax element.uses_type_params_cloned/// Find all type params using `uses_type_params`, then clone the found values and return the set./// Searcher for finding type params in a syntax tree./// This can be used to determine if a given type parameter needs to be bounded in a generated impl.collect_type_params/// Consume an iterator, accumulating all type parameters in the elements which occur in `type_set`.collect_type_params_cloned/// Consume an iterator using `collect_type_params`, then clone all found type params and return that set./// Searcher for finding type params in an iterator./// of type parameter idents.union_in_place/// Insert the contents of `right` into `left`./// Check if an Ident exactly matches one of the sought-after type parameters.finds_simplefinds_namedfinds_as_type_argassociated_typebox_fn_outputbox_fn_inputqself_vec/// Test that `syn::TypePath` is correctly honoring the different modes a/// search can execute in./// The callable/// Either a path or a closure./// This type is useful for options that historically took a path,/// e.g. `#[darling(with = ...)]` or `#[serde(skip_serializing_if = ...)]`/// and now want to also allow using a closure to avoid needing a separate/// function declaration./// In `darling`, this value is wrapped in [`core::convert::identity`] before usage;/// this allows treatment of the closure and path cases as equivalent, and prevents/// a closure from accessing locals in the generated code.ExprClosure/// A meta-item that can be present as a word - with no value - or absent./// # Defaulting/// Like `Option`, `Flag` does not require `#[darling(default)]` to be optional./// If the caller does not include the property, then an absent `Flag` will be included/// in the receiver struct./// # Spans/// `Flag` keeps the span where its word was seen./// This enables attaching custom error messages to the word, such as in the case of two/// conflicting flags being present./// #[derive(FromMeta)]/// #[darling(and_then = Self::not_both)]/// struct Demo {///     flag_a: Flag,///     flag_b: Flag,/// impl Demo {///     fn not_both(self) -> Result<Self> {///         if self.flag_a.is_present() && self.flag_b.is_present() {///             Err(Error::custom("Cannot set flag_a and flag_b").with_span(&self.flag_b.span()))///             Ok(self)/// The above struct would then produce the following error./// #[example(flag_a, flag_b)]/// //                ^^^^^^ Cannot set flag_a and flag_bpresent/// Creates a new `Flag` which corresponds to the presence of a value.is_present/// Check if the flag is present.is_some/// Get the span of the flag, or [`Span::call_site`] if the flag was not present.IdentString/// A wrapper for an `Ident` which also keeps the value as a string./// This struct can be used to perform string comparisons and operations./// Create a new `IdentString`.as_ident/// Get the ident as a `proc_macro2::Ident`./// Get the ident as a string./// Get the location of this `Ident` in source./// Apply some transform to the ident's string representation./// This will panic if the transform produces an invalid ident.map_transformIgnored/// An efficient way of discarding data from a syntax element./// All syntax elements will be successfully read into/// the `Ignored` struct, with all properties discarded.ignoredcallableover_rideparse_attributeparse_exprpath_listspanned_valuewith_originalOverrideparse_attribute_to_meta_listAsShapeShapeShapeSetWithOriginal//! Utility types for attribute parsing./// Inherit the eventual value from an external source./// Explicitly set the value./// A value which can inherit a default value or have an explicit value specified./// This type is meant for attributes like `default` in `darling`, which can take the following forms:/// * `#[darling(default)]`/// * `#[darling(default="path::to::fn")]`/// In a struct collecting input for this attribute, that would be written as:/// use darling::{util::Override, FromField};/// #[derive(FromField)]/// #[darling(attributes(darling))]/// pub struct Options {///    default: Option<Override<syn::Path>>,/// impl Options {///     fn hydrate(self) -> Option<syn::Path> {///         self.default.map(|ov| ov.unwrap_or(syn::parse_path("::Default::default").unwrap()))/// The `word` format (with no associated value), would produce `Override::Inherit`, while a list/// or value format would produce `Override::Explicit`./// Converts from `Override<T>` to `Override<&T>`./// Produces a new `Override`, containing a reference into the original, leaving the original in place./// Converts from `Override<T>` to `Override<&mut T>`./// Produces a new `Override`, containing a mutable reference into the original.is_explicit/// Returns `true` if the override is an `Explicit` value.explicit/// Converts from `Override<T>` to `Option<T>`.unwrap_or/// Unwraps an override, yielding the content of an `Explicit`. Otherwise, it returns `optb`.unwrap_or_else/// Unwraps an override, yielding the content of an `Explicit`. Otherwise, it calls `op`.unwrap_or_default/// Returns the contained value or the default value of `T`./// Parses a `Meta`. A bare word will produce `Override::Inherit`, while/// any value will be forwarded to `T::from_meta`.MetaList/// Try to parse an attribute into a meta list. Path-type meta values are accepted and returned/// as empty lists with their passed-in path. Name-value meta values and non-meta attributes/// will cause errors to be returned.DisplayPathparse_listparse_path_returns_empty_listparse_name_value_returns_errorparse_name_value_error_includes_examplepreserve_str_literal/// Parse a [`Meta`] to an [`Expr`]; if the value is a string literal, the emitted/// expression will be a string literal.parse_str_literal/// Parse a [`Meta`] to an [`Expr`]; if the value is a string literal, the string's/// contents will be parsed as an expression and emitted.preserve_strpreserve_binary_expparse_ident//! Functions to use with `#[darling(with = "...")]` that control how quoted values//! in [`Meta`] instances are parsed into [`Expr`] fields.//! Version 1 of syn did not permit expressions on the right-hand side of the `=` in a//! [`MetaNameValue`](syn::MetaNameValue), so darling accepted string literals and then//! parsed their contents as expressions.//! Passing a string literal in this version would have required the use of a raw string//! to add quotation marks inside the literal.//! Version 2 of syn removes the requirement that the right-hand side be a literal.//! For most types, such as [`Path`](syn::Path), the [`FromMeta`] impl can accept the//! version without quotation marks without causing ambiguity; a path cannot start and//! end with quotation marks, so removal is automatic.//! [`Expr`] is the one type where this ambiguity is new and unavoidable. To address this,//! this module provides different functions for different expected behaviors./// A list of `syn::Path` instances. This type is used to extract a list of paths from an/// attribute./// An `PathList` field on a struct implementing `FromMeta` will turn `#[builder(derive(serde::Debug, Clone))]` into:/// StructOptions {///     derive: PathList(vec![syn::Path::new("serde::Debug"), syn::Path::new("Clone")])/// Create a new list.to_strings/// Create a new `Vec` containing the string representation of each path.succeedsfails_non_word/// Check that the parser rejects non-word members of the list, and that the error/// has an associated span./// Transform Rust paths to a readable and comparable string./// * Leading colons are ignored./// * Angle brackets and `as` elements are ignored./// # use darling_core::util::path_to_string;/// # use syn::parse_quote;/// assert_eq!(path_to_string(&parse_quote!(a::b)), "a::b");simple_identsimple_pathas_shape/// Get the "shape" of a fields container./// Get the "shape" of a fields container, such as a struct or variant./// A set of named fields, e.g. `{ field: String }`./// A list of unnamed fields, e.g. `(String, u64)`./// No fields, e.g. `struct Example;`Newtype/// A special case of [`Tuple`](Shape#variant.Tuple) with exactly one field, e.g. `(String)`./// Description of how fields in a struct or variant are syntactically laid out./// A set of [`Shape`] values, which correctly handles the relationship between/// [newtype](Shape#variant.Newtype) and [tuple](Shape#variant.Tuple) shapes./// # use darling_core::util::{Shape, ShapeSet};/// let shape_set = ShapeSet::new(vec![Shape::Tuple]);/// // This is correct, because all newtypes are single-field tuples./// assert!(shape_set.contains(&Shape::Newtype));/// Create a new `ShapeSet` which includes the specified items./// # Exampe/// let shape_set = ShapeSet::new(vec![Shape::Named, Shape::Newtype]);insert_all/// Insert all possible shapes into the set./// This is equivalent to calling [`insert`](ShapeSet#method.insert) with every value of [`Shape`]./// let mut shape_set = ShapeSet::default();/// shape_set.insert_all();/// assert!(shape_set.contains(&Shape::Named));/// Insert a shape into the set, so that the set will match that shape/// Whether this set is empty.contains_shape/// Check if a fields container's shape is in this set./// Check if a field container's shape is in this set of shapes, and produce/// an [`Error`](crate::Error) if it does not.any_accepts_anythingtuple_accepts_newtypenewtype_rejects_tuple/// A value and an associated position in source code. The main use case for this is/// to preserve position information to emit warnings from proc macros. You can use/// a `SpannedValue<T>` as a field in any struct that implements or derives any of/// `darling`'s core traits./// To access the underlying value, use the struct's `Deref` implementation./// This type is meant to be used in conjunction with attribute-extracted options,/// but the user may not always explicitly set those options in their source code./// In this case, using `Default::default()` will create an instance which points/// to `Span::call_site()`./// Get the source code location referenced by this struct.map_ref/// Apply a mapping function to a reference to the spanned value./// Make sure that `SpannedValue` can be seamlessly used as its underlying type.original/// A container to parse some syntax and retain access to the original.derive_from_metaderive_from_meta_itemderive_from_attributesderive_from_inputderive_fieldderive_type_paramderive_variantDerivationPathErrorPathTooLongChildIndexErrorInvalidChildIndex/// Errors when building a [DerivationPath]DerivationPathParseErrorInvalidPrefixChildIndexParseError/// Errors when parsing a [DerivationPath] from a [str]ChildIndexDerivationPath/// A list of [ChildIndex] itemsDerivationPathTypeBIP32BIP44BIP49/// [DerivationPath] specifications as defined by BIP's/// Build a [DerivationPath] from a list of [ChildIndex] itemsbip32/// Build a BIP32 style [DerivationPath]. This will fail if the length of the path is greater/// than 255 itemsbip44/// Build a BIP44 style [DerivationPath]: `m/44'/coin'/account'/change/address`bip49/// Build a BIP49 style [DerivationPath]: `m/49'/coin'/account'/change/address`bip4x/// Get a reference to the list of [ChildIndex] itemspath_type/// Get the [DerivationPathType]. This will check the "purpose" index in BIP44/49 style/// derivation paths or otherwise return BIP32 if the length is less than 255NormalHardened/// An index in a [DerivationPath]/// Errors when parsing a [ChildIndex] from a [str]NumberTooLarge/// Errors when building a [ChildIndex]hardened/// Create a [ChildIndex::Hardened] instance from a [u32]. This will fail if `num` is not/// in `[0, 2^31 - 1]`normal/// Create a [ChildIndex::Normal] instance from a [u32]. This will fail if `num` is notcheck_sizeto_u32/// Convert [ChildIndex] to its inner [u32]/// Convert [ChildIndex] to a [u32] representing the type and a 31 bit number. The highest bit/// is set for a hard derivation and clear for a normal derivation, and the remaining 31 bits are/// the index/// Build a [ChildIndex] from a [u32] representing the type and a 31 bit number./// See [ChildIndex::to_bits] for more informationis_hardened/// Check if the [ChildIndex] is "hardened"is_normal/// Check if the [ChildIndex] is "normal"child_index_is_normalchild_index_is_hardenedchild_index_rangechild_index_to_u32child_index_to_bitschild_index_from_bitschild_index_to_stringchild_index_from_strderivation_path_newderivation_bip32derivation_bip44derivation_bip49derivation_path_typederivation_path_to_stringderivation_path_parsing//! A simple struct for dealing with derivation paths as defined by BIP32, BIP44 and BIP49 of the//! Bitcoin protocol. This crate provides interfaces for dealing with hardened vs normal child//! indexes, as well as display and parsing derivation paths from strings//! # use derivation_path::{ChildIndex, DerivationPath, DerivationPathType};//! let path = DerivationPath::bip44(0, 1, 0, 1).unwrap();//! assert_eq!(&path.to_string(), "m/44'/0'/1'/0/1");//! assert_eq!(path.path()[2], ChildIndex::Hardened(1));//! let path: DerivationPath = "m/49'/0'/0'/1/0".parse().unwrap();//! assert_eq!(path.path()[4], ChildIndex::Normal(0));//! assert_eq!(path.path_type(), DerivationPathType::BIP49);Derivative/// No value/// Some value `T`/// Returns None.patssize_limitdfa_size_limitcase_insensitivemulti_linedot_matches_new_lineswap_greedignore_whitespaceunicodeRegexOptionsIdentifier/// The major version./// The minor version./// The patch version.pre/// The pre-release version identifier./// The build metadata, ignored when/// determining version precedence.// We should ignore build metadata// here, otherwise versions v1 and// v2 can exist such that !(v1 < v2)// && !(v1 > v2) && v1 != v2, which// violate strict total ordering rules.attrSynSpannedBodyfrom_astis_trivial_enum/// Checks whether this type is an enum with only unit variants.all_fields/// Checks whether this variant is a unit variant.enum_from_aststruct_from_astfields_from_astInputClone/// Whether `Clone` is present and its specific attributes.copyInputCopy/// Whether `Copy` is present and its specific attributes.InputDebug/// Whether `Debug` is present and its specific attributes.InputDefault/// Whether `Default` is present and its specific attributes.InputEq/// Whether `Eq` is present and its specific attributes.InputHash/// Whether `Hash` is present and its specific attributes.partial_eqInputPartialEq/// Whether `PartialEq` is present and its specific attributes.partial_ordInputPartialOrd/// Whether `PartialOrd` is present and its specific attributes.ordInputOrd/// Whether `Ord` is present and its specific attributes.is_packed/// Represent the `derivative` attributes on the input type (`struct`/`enum`).FieldClone/// The parameters for `Clone`.copy_bound/// The parameters for `Copy`.FieldDebug/// The parameters for `Debug`.FieldDefault/// The parameters for `Default`.eq_bound/// The parameters for `Eq`.FieldHash/// The parameters for `Hash`.FieldPartialEq/// The parameters for `PartialEq`.FieldPartialOrd/// The parameters for `PartialOrd`.FieldOrd/// The parameters for `Ord`./// Represent the `derivative` attributes on a field./// The `bound` attribute if present and the corresponding bounds./// Whether the implementation should have an explicit `clone_from`./// Represent the `derivative(Clone(…))` attributes on an input./// Whether the type is marked `transparent`./// Represent the `derivative(Debug(…))` attributes on an input./// Whether the type is marked with `new`./// Represent the `derivative(Default(…))` attributes on an input./// Represent the `derivative(Eq(…))` attributes on an input./// Represent the `derivative(Hash(…))` attributes on an input./// Represent the `derivative(PartialEq(…))` attributes on an input.on_enum/// Allow `derivative(PartialOrd)` on enums:/// Represent the `derivative(PartialOrd(…))` attributes on an input./// Allow `derivative(Ord)` on enums:/// Represent the `derivative(Ord(…))` attributes on an input.clone_with/// The `clone_with` attribute if present and the path to the cloning function./// Represents the `derivative(Clone(…))` attributes on a field.format_with/// The `format_with` attribute if present and the path to the formatting function./// Whether the field is to be ignored from output./// Represents the `derivative(Debug(…))` attributes on a field./// The default value for the field if present./// Represent the `derivative(Default(…))` attributes on a field./// The `hash_with` attribute if present and the path to the hashing function./// Whether the field is to be ignored when hashing./// Represents the `derivative(Hash(…))` attributes on a field.compare_with/// The `compare_with` attribute if present and the path to the comparison function./// Whether the field is to be ignored when comparing./// Represent the `derivative(PartialEq(…))` attributes on a field./// Represent the `derivative(PartialOrd(…))` attributes on a field./// Represent the `derivative(Ord(…))` attributes on a field.for_all_attrmatch_attributes/// Parse the `derivative` attributes on a type.// mostly macrosclone_bounddebug_bounddebug_transparentdefault_boundhash_boundpartial_eq_boundpartial_ord_boundord_boundpartial_ord_on_enumord_on_enumdebug_format_withignore_debugignore_hashdefault_valuepartial_eq_compare_withpartial_ord_compare_withord_compare_withignore_partial_eqignore_partial_ordignore_ordMetaItem/// Represent an attribute./// We only have a limited set of possible attributes:/// * `#[derivative(Debug)]` is represented as `(Debug, [])`;/// * `#[derivative(Debug="foo")]` is represented as `(Debug, [(None, Some("foo"))])`;/// * `#[derivative(Debug(foo="bar")]` is represented as `(Debug, [(Some(foo), Some("bar"))])`.read_items/// Parse an arbitrary item for our limited `MetaItem` subset.derivative_attribute/// Filter the `derivative` items from an attribute.parse_boolean_meta_item/// Parse an item value as a boolean. Accepted values are the string literal `"true"` and/// `"false"`. The `default` parameter specifies what the value of the boolean is when only its/// name is specified (eg. `Debug="ignore"` is equivalent to `Debug(ignore="true")`). The `name`/// parameter is used for error reporting.parse_bound/// Parse a `bound` item.parse_str_litensure_str_lithas_repr_packed_attrvisit/// Remove the default from every type parameter because in the generated `impl`s/// they look like associated types: "error: associated type bindings are not/// allowed here".with_where_predicateswith_where_predicates_from_fieldswith_bound/// Puts the given bound on any generic type parameters that are used in fields/// for which filter returns true./// For example, the following structure needs the bound `A: Debug, B: Debug`./// struct S<'b, A, B: 'b, C> {///     a: A,///     b: Option<&'b B>///     #[derivative(Debug="ignore")]///     c: C,is_phantom_data// needs rustc 1.42/* This file incorporates work covered by the following copyright and
 * permission notice:
 *   Copyright 2016 The serde Developers. See
 *   https://github.com/serde-rs/serde/blob/3f28a9324042950afa80354722aeeee1a55cbfa3/README.md#license.
 *
 *   Licensed under the Apache License, Version 2.0 <LICENSE-APACHE or
 *   http://www.apache.org/licenses/LICENSE-2.0> or the MIT license
 *   <LICENSE-MIT or http://opensource.org/licenses/MIT>, at your
 *   option. This file may not be copied, modified, or distributed
 *   except according to those terms.
 */// use internals::ast::Item;// use internals::attr;matcherderive_copy/// Derive `Copy` for `input`.derive_clone/// Derive `Clone` for `input`.needs_clone_boundclone_trait_path/// Return the path of the `Clone` trait, that is `::std::clone::Clone`.copy_trait_path/// Return the path of the `Copy` trait, that is `::std::marker::Copy`.pathsderive_eq/// Derive `Eq` for `input`.derive_partial_eq/// Derive `PartialEq` for `input`.derive_partial_ord/// Derive `PartialOrd` for `input`.derive_ord/// Derive `Ord` for `input`.needs_partial_eq_boundneeds_partial_ord_boundneeds_ord_boundneeds_eq_boundeq_trait_path/// Return the path of the `Eq` trait, that is `::std::cmp::Eq`.partial_eq_trait_path/// Return the path of the `PartialEq` trait, that is `::std::cmp::PartialEq`.partial_ord_trait_path/// Return the path of the `PartialOrd` trait, that is `::std::cmp::PartialOrd`.ord_trait_path/// Return the path of the `Ord` trait, that is `::std::cmp::Ord`.option_path/// Return the path of the `Option` trait, that is `::std::option::Option`.ordering_path/// Return the path of the `Ordering` trait, that is `::std::cmp::Ordering`.maybe_add_copy// https://github.com/rust-lang/rust/issues/13101needs_debug_bounddebug_trait_path/// Return the path of the `Debug` trait, that is `::std::fmt::Debug`.fmt_path/// Return the path of the `fmt` module, that is `::std::fmt`.phantom_path/// Return the path of the `PhantomData` type, that is `::std::marker::PhantomData`./// Derive `Default` for `input`.default_trait_path/// Return the path of the `Default` trait, that is `::std::default::Default`.needs_hash_boundhash_trait_path/// Return the path of the `Hash` trait, that is `::std::hash::Hash`.hasher_trait_path/// Return the path of the `Hasher` trait, that is `::std::hash::Hasher`.derive_impls// We need to support Rust 1.34 to stable// support for multiple Clippy versions// because of other #![allow]s// needs rustc 1.40// old name of cognitive_complexity// in code generated by macrosBindingStyleMove/// `x`MoveMut/// `mut x`/// `ref x`/// `ref mut x`/// The type of binding to use when generating a pattern.with_packedBindingInfoCommonVariantbinding_namebinding_stylefield_filterMatcherwith_namewith_field_filterbuild_armsbuild_2_armsbuild_match_pattern/// Generate patterns for matching against all of the variantsbuild_match_pattern_implbuild_inner_pattern// TODO: remove// This is inspired from `synstructure`, but `synstructure` is not adapted in severals ways// including://     * `&mut` everywhere//     * not generic, we use our own `ast`, `synstructure` only knows about `syn`//     * missing information (what arm are we in?, what attributes? etc.)discriminant_path/// Return the path of the `discriminant` function, that is `::std::mem::discriminant`.//! Contains some standard paths.build_impl_generics/// Make generic with all the generics in the input, plus a bound `T: <trait_path>` for each/// generic field type that will be shown.hygienic_type_parameter/// Construct a name for the inner type parameter that can't collide with any/// type parameters of the item. This is achieved by starting with a base and/// then concatenating the names of all other type parameters.BufferKindUserFixedOutputCoreTruncSideUpdateCoreVariableOutputCoreIsLessOrEqualLeEqNoOid/// Dummy type used with [`CtVariableCoreWrapper`] in cases when/// resulting hash does not have a known OID._outOutSizeCtVariableCoreWrapper/// Wrapper around [`VariableOutputCore`] which selects output size/// at compile time.update_blocksfinalize_fixed_coreimpl_oid_carrier/// Implement dummy type with hidden docs which is used to "carry" hasher/// OID for [`CtVariableCoreWrapper`].InvalidBufferSizeInvalidOutputSizeVariableOutputVariableOutputResetRtVariableCoreWrapper/// at run time.finalize_dirtyMAX_OUTPUT_SIZEfinalize_variablefinalize_variable_resetExtendableOutputCoreXofReaderCoreWrapperCoreWrapper/// Wrapper around [`BufferKindUser`]./// It handles data buffering and implements the slice-based traits.// this blanket impl is needed for HMACfrom_core/// Create new wrapper from `core`.decompose/// Decompose wrapper into inner parts.ReaderCore/// Type wrapped by [`CoreWrapper`].CoreProxy/// A proxy trait to a core type implemented by [`CoreWrapper`]// TODO: replace with an inherent associated type on stabilization:// https://github.com/rust-lang/rust/issues/8995XofReaderCore/// Wrapper around [`XofReaderCore`] implementations./// It handles data buffering and implements the mid-level traits.ct_variablert_variablexof_reader/// Buffer type used by type which implements [`BufferKindUser`]./// Update state using the provided data blocks./// Types which consume data in blocks./// Block buffer kind over which type operates./// Types which use [`BlockBuffer`] functionality./// Finalize state using remaining data stored in the provided block buffer,/// write result into provided array and leave `self` in a dirty state./// Core trait for hash functions with fixed output size./// XOF reader core state.finalize_xof_core/// Retrieve XOF reader using remaining data stored in the block buffer/// and leave hasher in a dirty state./// Core trait for hash functions with extendable (XOF) output size.read_block/// Read next XOF block./// Core reader trait for extendable-output function (XOF) result.TRUNC_SIDE/// Side which should be used in a truncated result./// Initialize hasher state for given output size./// Returns [`InvalidOutputSize`] if `output_size` is not valid for/// the algorithm, e.g. if it's bigger than the [`OutputSize`]/// associated type./// [`OutputSize`]: OutputSizeUser::OutputSizefinalize_variable_core/// Finalize hasher and write full hashing result into the `out` buffer./// The result must be truncated to `output_size` used during hasher/// construction. Truncation side is defined by the [`TRUNC_SIDE`]/// associated constant./// [`TRUNC_SIDE`]: VariableOutputCore::TRUNC_SIDE/// Core trait for hash functions with variable output size./// Maximum output size is equal to [`OutputSizeUser::OutputSize`]./// Users are expected to truncate result returned by the/// [`finalize_variable_core`] to `output_size` passed to the [`new`] method/// during construction. Truncation side is defined by the [`TRUNC_SIDE`]/// [`finalize_variable_core`]: VariableOutputCore::finalize_variable_core/// [`new`]: VariableOutputCore::newLeft/// Truncate left side, i.e. `&out[..n]`.Right/// Truncate right side, i.e. `&out[m..]`./// Type which used for defining truncation side in the [`VariableOutputCore`]//! Low-level traits operating on blocks and wrappers around them.//! Usage of traits in this module in user code is discouraged. Instead use//! core algorithm wrapped by the wrapper types, which implement the//! higher-level traits.fixed_reset_test/// Fixed-output resettable digest test via the `Digest` traitfixed_test/// Variable-output resettable digest testnew_mac_test/// Define MAC testnew_resettable_mac_test/// Define resettable MAC testRNGXorShiftRng/// Initial RNG state used in tests.// chosen by fair dice roll. guaranteed to be random./// Xorshift RNG instance/next_u32//! Xorshift RNG used for tests. Based on the `rand_xorshift` crate.variable_reset_testvariable_testxof_reset_test/// Resettable XOF testvariablexof/// Define hash function testbench_update/// Define [`Update`][crate::Update] impl benchmarkfeed_rand_16mib/// Feed ~1 MiB of pseudorandom data to an updatable state./// Marker trait for cryptographic hash functions./// Create new hasher instance.new_with_prefix/// Create new hasher instance which has processed the provided data./// Process data, updating the internal state.chain_update/// Process input data in a chained manner./// Retrieve result and consume hasher instance./// Write result into provided array and consume the hasher instance./// Retrieve result and reset hasher instance./// Write result into provided array and reset the hasher instance./// Reset hasher instance to its initial state./// Get output size of the hasher/// Compute hash of `data`./// Convenience wrapper trait covering functionality of cryptographic hash/// functions with fixed output size./// This trait wraps [`Update`], [`FixedOutput`], [`Default`], and/// [`HashMarker`] traits and provides additional convenience methods./// Digest input data./// This method can be called repeatedly for use with streaming messages./// Retrieve result and reset hasher instance/// Retrieve result and consume boxed hasher instance/// Returns error if buffer length is not equal to `output_size`.box_clone/// Clone hasher state into a boxed trait object/// Modification of the [`Digest`] trait suitable for trait objects.core_apiCtOutput/// Update state using the provided data./// Digest input data in a chained manner./// Types which consume data with byte granularity./// Consume value and write result into provided array.finalize_fixed/// Retrieve result and consume the hasher instance./// Trait for hash functions with fixed-size output./// Write result into provided array and reset the hasher state.finalize_fixed_reset/// Retrieve result and reset the hasher state./// Trait for hash functions with fixed-size output able to reset themselves./// Read output into the `buffer`. Can be called an unlimited number of times.read_boxed/// Read output into a boxed slice of the specified size./// Can be called an unlimited number of times in combination with `read`./// `Box<[u8]>` is used instead of `Vec<u8>` to save stack space, since/// they have size of 2 and 3 words respectively./// Trait for reader types which are used to extract extendable output/// from a XOF (extendable-output function) result./// Reader/// Retrieve XOF reader and consume hasher instance.finalize_xof_into/// Finalize XOF and write result into `out`.digest_xof/// Compute hash of `data` and write it into `output`.finalize_boxed/// Retrieve result into a boxed slice of the specified size and consume/// the hasher./// Trait for hash functions with extendable-output (XOF)./// Retrieve XOF reader and reset hasher instance state.finalize_xof_reset_into/// Finalize XOF, write result into `out`, and reset the hasher state.finalize_boxed_reset/// Retrieve result into a boxed slice of the specified size and reset/// the hasher state./// Trait for hash functions with extendable-output (XOF) able to reset themselves./// Maximum size of output hash./// Create new hasher instance with the given output size./// It will return `Err(InvalidOutputSize)` in case if hasher can not return/// hash of the specified output size./// Get output size of the hasher instance provided to the `new` method/// Write result into the output buffer./// Returns `Err(InvalidOutputSize)` if `out` size is not equal to/// `self.output_size()`.digest_variable/// Compute hash of `data` and write it to `output`./// Length of the output hash is determined by `output`. If `output` is/// bigger than `Self::MAX_OUTPUT_SIZE`, this method returns/// `InvalidOutputSize`./// Retrieve result into a boxed slice and consume hasher./// Trait for hash functions with variable-size output./// Write result into the output buffer and reset the hasher state./// Retrieve result into a boxed slice and reset the hasher state./// Trait for hash functions with variable-size output able to reset themselves./// The error type used in variable hash traits./// Buffer length is not equal to hash output size.//! This crate provides traits which describe functionality of cryptographic hash//! functions and Message Authentication algorithms.//! Traits in this repository are organized into the following levels://! - **High-level convenience traits**: [`Digest`], [`DynDigest`], [`Mac`].//!   Wrappers around lower-level traits for most common use-cases. Users should//!   usually prefer using these traits.//! - **Mid-level traits**: [`Update`], [`FixedOutput`], [`FixedOutputReset`],//!   [`ExtendableOutput`], [`ExtendableOutputReset`], [`XofReader`],//!   [`VariableOutput`], [`Reset`], [`KeyInit`], and [`InnerInit`]. These//!   traits atomically describe available functionality of an algorithm.//! - **Marker traits**: [`HashMarker`], [`MacMarker`]. Used to distinguish//!   different algorithm classes.//! - **Low-level traits** defined in the [`core_api`] module. These traits//!   operate at a block-level and do not contain any built-in buffering.//!   They are intended to be implemented by low-level algorithm providers only.//!   Usually they should not be used in application-level code.//! Additionally hash functions implement traits from the standard library://! [`Default`], [`Clone`], [`Write`][std::io::Write]. The latter is//! feature-gated behind `std` feature, which is usually enabled by default//! by hash implementation crates./// Marker trait for Message Authentication algorithms./// Obtain the result of a [`Mac`] computation as a [`CtOutput`] and consume/// Obtain the result of a [`Mac`] computation as a [`CtOutput`] and reset/// Reset MAC instance to its initial state.verify_reset/// Check if tag/code value is correct for the processed input and resetverify_slice/// Check truncated tag correctness using all bytes/// of calculated tag./// Returns `Error` if `tag` is not valid or not equal in length/// to MAC's output.verify_slice_reset/// of calculated tag and reset [`Mac`] instance.verify_truncated_left/// Check truncated tag correctness using left side bytes/// (i.e. `tag[..n]`) of calculated tag./// Returns `Error` if `tag` is not valid or empty.verify_truncated_right/// Check truncated tag correctness using right side bytes/// (i.e. `tag[n..]`) of calculated tag./// Convenience wrapper trait covering functionality of Message Authentication algorithms./// This trait wraps [`KeyInit`], [`Update`], [`FixedOutput`], and [`MacMarker`]/// traits and provides additional convenience methods./// Fixed size output value which provides a safe [`Eq`] implementation that/// runs in constant time./// It is useful for implementing Message Authentication Codes (MACs)./// Create a new [`CtOutput`] value./// Get the inner [`Output`] array this type wraps./// Error type for when the [`Output`] of a [`Mac`]/// is not equal to the expected value.digest_test/// Digest testone_million_a/// Compute digest of one million `a` bytesfoo/// Module to separate Digest from other traitsxof_test/// XOF test/// Variable-output digest test/// Output size for `Digest`/// Create new hasher instance/// Digest data, updating the internal state./// This method sometimes can be more efficient compared to hasher/// re-creation./// Convenience function to compute hash of the `data`. It will handle/// hasher creation, data feeding and finalization./// Example:/// println!("{:x}", sha2::Sha256::digest(b"Hello world"));/// The `Digest` trait specifies an interface common for digest functions./// It's a convenience wrapper around [`Update`], [`FixedOutput`], [`Reset`],/// [`Clone`], and [`Default`] traits. It also provides additional convenience methods./// Output of a [`Digest`] function/// The `DynDigest` trait is a modification of `Digest` trait suitable/// for trait objects./// The error type for variable hasher initialization/// Output size for fixed output digest/// Retrieve result and reset the hasher instance./// Trait for returning digest result with the fixed sizefinalize_into_dirty/// Retrieve result into provided buffer and leave hasher in a dirty state./// This method is expected to only be called once unless/// [`Reset::reset`] is called, after which point it can be/// called again and reset again (and so on).FixedOutputDirty/// Trait for fixed-output digest implementations to use to retrieve the/// hash output./// Usage of this trait in user code is discouraged. Instead use the/// [`FixedOutput::finalize_fixed`] or [`FixedOutput::finalize_fixed_reset`]/// methods./// Types which impl this trait along with [`Reset`] will receive a blanket/// impl of [`FixedOutput`].//! Fixed-size output digest supportdyn_digestVariableOutputDirtyExtendableOutputDirty/// This method can be called repeatedly, e.g. for processing streaming/// messages./// Trait for updating digest state with input data./// Block sizeBlockInput/// Trait to indicate that digest function processes data in blocks of size/// `BlockSize`./// The main usage of this trait is for implementing HMAC generically./// Reset hasher instance to its initial state and return current state./// Trait for resetting hash instances/// Implements `std::io::Write` trait for implementer of [`Update`]//! functions.//! Traits in this repository are organized into high-level convenience traits,//! mid-level traits which expose more fine-grained functionality, and//! low-level traits intended to only be used by algorithm implementations://! - **High-level convenience traits**: [`Digest`], [`DynDigest`]. They are wrappers//!   around lower-level traits for most common hash-function use-cases.//! - **Mid-level traits**: [`Update`], [`BlockInput`], [`Reset`], [`FixedOutput`],//!   [`VariableOutput`], [`ExtendableOutput`]. These traits atomically describe//!   available functionality of hash function implementations.//! - **Low-level traits**: [`FixedOutputDirty`], [`VariableOutputDirty`],//!   [`ExtendableOutputDirty`]. These traits are intended to be implemented by//!   low-level algorithm providers only and simplify the amount of work//!   implementers need to do and therefore shouldn't be used in//!   application-level code.//! `Default`, `Clone`, `Write`. The latter is feature-gated behind `std` feature,//! which is usually enabled by default by hash implementation crates.//! The [`Digest`] trait is the most commonly used trait./// specified output size. It will always return an error if output size/// equals to zero./// Retrieve result via closure and consume hasher./// Closure is guaranteed to be called, length of the buffer passed to it/// will be equal to `output_size`./// Retrieve result via closure and reset the hasher state./// Retrieve result into a boxed slice and reset hasher state./// Trait for returning digest result with the variable sizefinalize_variable_dirty/// Trait for variable-sized output digest implementations to use to retrieve/// the hash output./// [`VariableOutput::finalize_variable`] or/// [`VariableOutput::finalize_variable_reset`] methods./// impl of [`VariableOutput`].//! Variable-sized output digest support/// Trait for describing readers which are used to extract extendable output/// from XOF (extendable-output function) result./// the hasher's state./// Trait which describes extendable-output functions (XOF).finalize_xof_dirty/// Retrieve XOF reader./// Trait for extendable-output function (XOF) implementations to use to/// retrieve the hash output./// [`ExtendableOutput::finalize_xof`] or/// [`ExtendableOutput::finalize_xof_reset`] methods./// impl of [`ExtendableOutput`].//! Extendable-Output Function (XOF) supportSIGNATURE_LENGTH/// Length of an Ed25519 signature in bytes.SignatureBYTE_SIZE/// Ed25519 signature./// Size of an encoded Ed25519 signature in bytes./// Parse an Ed25519 signature from a byte slice./// Return the inner byte array./// DEPRECATED: Create a new signature from a byte array./// This method will panic if an invalid signature is encountered./// Use [`Signature::from_bytes`] or [`Signature::try_from`] instead for/// a fallible conversion./// DEPRECATED: use `TryFrom<&[u8]>` instead./// This conversion will panic if a signature is invalid.// TODO(tarcieri): remove this in the next breaking release/// Decode a signature from hexadecimal./// Upper and lower case hexadecimal are both accepted, however mixed case is/// rejected.// TODO(tarcieri): use `base16ct`?//! # Using Ed25519 generically over algorithm implementations/providers//! By using the `ed25519` crate, you can write code which signs and verifies//! messages using the Ed25519 signature algorithm generically over any//! supported Ed25519 implementation (see the next section for available//! providers).//! This allows consumers of your code to plug in whatever implementation they//! want to use without having to add all potential Ed25519 libraries you'd//! like to support as optional dependencies.//! use ed25519::signature::{Signer, Verifier};//! pub struct HelloSigner<S>//! where//!     S: Signer<ed25519::Signature>//!     pub signing_key: S//! impl<S> HelloSigner<S>//!     pub fn sign(&self, person: &str) -> ed25519::Signature {//!         // NOTE: use `try_sign` if you'd like to be able to handle//!         // errors from external signing services/devices (e.g. HSM/KMS)//!         // <https://docs.rs/signature/latest/signature/trait.Signer.html#tymethod.try_sign>//!         self.signing_key.sign(format_message(person).as_bytes())//! pub struct HelloVerifier<V> {//!     pub verify_key: V//! impl<V> HelloVerifier<V>//!     V: Verifier<ed25519::Signature>//!     pub fn verify(//!         &self,//!         person: &str,//!         signature: &ed25519::Signature//!     ) -> Result<(), ed25519::Error> {//!         self.verify_key.verify(format_message(person).as_bytes(), signature)//! fn format_message(person: &str) -> String {//!     format!("Hello, {}!", person)//! ## Using above example with `ed25519-dalek`//! The [`ed25519-dalek`] crate natively supports the [`ed25519::Signature`][`Signature`]//! type defined in this crate along with the [`signature::Signer`] and//! [`signature::Verifier`] traits.//! Below is an example of how a hypothetical consumer of the code above can//! instantiate and use the previously defined `HelloSigner` and `HelloVerifier`//! types with [`ed25519-dalek`] as the signing/verification provider://! use ed25519_dalek::{Signer, Verifier, Signature};//! # pub struct HelloSigner<S>//! # where//! #     S: Signer<Signature>//! #     pub signing_key: S//! # impl<S> HelloSigner<S>//! #     pub fn sign(&self, person: &str) -> Signature {//! #         // NOTE: use `try_sign` if you'd like to be able to handle//! #         // errors from external signing services/devices (e.g. HSM/KMS)//! #         // <https://docs.rs/signature/latest/signature/trait.Signer.html#tymethod.try_sign>//! #         self.signing_key.sign(format_message(person).as_bytes())//! #     }//! # pub struct HelloVerifier<V> {//! #     pub verify_key: V//! # impl<V> HelloVerifier<V>//! #     V: Verifier<Signature>//! #     pub fn verify(//! #         &self,//! #         person: &str,//! #         signature: &Signature//! #     ) -> Result<(), ed25519::Error> {//! #         self.verify_key.verify(format_message(person).as_bytes(), signature)//! # fn format_message(person: &str) -> String {//! #     format!("Hello, {}!", person)//! use rand_core::OsRng; // Requires the `std` feature of `rand_core`//! /// `HelloSigner` defined above instantiated with `ed25519-dalek` as//! /// the signing provider.//! pub type DalekHelloSigner = HelloSigner<ed25519_dalek::Keypair>;//! let signing_key = ed25519_dalek::Keypair::generate(&mut OsRng);//! let signer = DalekHelloSigner { signing_key };//! let person = "Joe"; // Message to sign//! let signature = signer.sign(person);//! /// `HelloVerifier` defined above instantiated with `ed25519-dalek`//! /// as the signature verification provider.//! pub type DalekHelloVerifier = HelloVerifier<ed25519_dalek::PublicKey>;//! let verify_key: ed25519_dalek::PublicKey = signer.signing_key.public;//! let verifier = DalekHelloVerifier { verify_key };//! assert!(verifier.verify(person, &signature).is_ok());//! ## Using above example with `ring-compat`//! The [`ring-compat`] crate provides wrappers for [*ring*] which implement//! the [`signature::Signer`] and [`signature::Verifier`] traits for//! [`ed25519::Signature`][`Signature`].//! types with [`ring-compat`] as the signing/verification provider://! use ring_compat::signature::{//!     ed25519::{Signature, SigningKey, VerifyingKey},//!     Signer, Verifier//! use rand_core::{OsRng, RngCore}; // Requires the `std` feature of `rand_core`//! /// `HelloSigner` defined above instantiated with *ring* as//! pub type RingHelloSigner = HelloSigner<SigningKey>;//! let mut ed25519_seed = [0u8; 32];//! OsRng.fill_bytes(&mut ed25519_seed);//! let signing_key = SigningKey::from_seed(&ed25519_seed).unwrap();//! let verify_key = signing_key.verify_key();//! let signer = RingHelloSigner { signing_key };//! /// `HelloVerifier` defined above instantiated with *ring*//! pub type RingHelloVerifier = HelloVerifier<VerifyingKey>;//! let verifier = RingHelloVerifier { verify_key };//! # Available Ed25519 providers//! The following libraries support the types/traits from the `ed25519` crate://! - [`ed25519-dalek`] - mature pure Rust implementation of Ed25519//! - [`ring-compat`] - compatibility wrapper for [*ring*]//! - [`yubihsm`] - host-side client library for YubiHSM2 devices from Yubico//! [`ed25519-dalek`]: https://docs.rs/ed25519-dalek//! [`ring-compat`]: https://docs.rs/ring-compat//! [*ring*]: https://github.com/briansmith/ring//! [`yubihsm`]: https://github.com/iqlusioninc/yubihsm.rs/blob/develop/README.md//! The following features are presently supported://! - `pkcs8`: support for decoding/encoding PKCS#8-formatted private keys using the//!   [`KeypairBytes`] type.//! - `std` *(default)*: Enable `std` support in [`signature`], which currently only affects whether//!   [`signature::Error`] implements `std::error::Error`.//! - `serde`: Implement `serde::Deserialize` and `serde::Serialize` for [`Signature`]. Signatures//!   are serialized as their bytes.//! - `serde_bytes`: Implement `serde_bytes::Deserialize` and `serde_bytes::Serialize` for//!   [`Signature`]. This enables more compact representations for formats with an efficient byte//!   array representation. As per the `serde_bytes` documentation, this can most easily be realised//!   using the `#[serde(with = "serde_bytes")]` annotation, e.g.://!   ```ignore//!   # use ed25519::Signature;//!   # use serde::{Deserialize, Serialize};//!   #[derive(Deserialize, Serialize)]//!   #[serde(transparent)]//!   struct SignatureAsBytes(#[serde(with = "serde_bytes")] Signature);pkcs8DecodePrivateKeyDecodePublicKeyspkiEncodePublicKeyEncodePrivateKeyObjectIdentifierderDocumentSecretDocumentALGORITHM_OID/// Algorithm [`ObjectIdentifier`] for the Ed25519 digital signature algorithm/// (`id-Ed25519`)./// <http://oid-info.com/get/1.3.101.112>ALGORITHM_IDAlgorithmIdentifier/// Ed25519 Algorithm Identifier.secret_key/// Ed25519 secret key./// Little endian serialization of an element of the Curve25519 scalar/// field, prior to "clamping" (i.e. setting/clearing bits to ensure the/// scalar is actually a valid field element)public_key/// Ed25519 public key (if available)./// Compressed Edwards-y encoded curve point.KeypairBytes/// Ed25519 keypair serialized as bytes./// This type is primarily useful for decoding/encoding PKCS#8 private key/// files (either DER or PEM) encoded using the following traits:/// - [`DecodePrivateKey`]: decode DER or PEM encoded PKCS#8 private key./// - [`EncodePrivateKey`]: encode DER or PEM encoded PKCS#8 private key./// PKCS#8 private key files encoded with PEM begin with:/// -----BEGIN PRIVATE KEY-----/// Note that this type operates on raw bytes and performs no validation that/// keys represent valid Ed25519 field elements./// Size of an Ed25519 keypair when serialized as bytes./// Parse raw keypair from a 64-byte input./// Serialize as a 64-byte keypair./// - `Some(bytes)` if the `public_key` is present./// - `None` if the `public_key` is absent (i.e. `None`).to_pkcs8_derPrivateKeyInfoPublicKeyBytes/// Ed25519 public key serialized as bytes./// This type is primarily useful for decoding/encoding SPKI public key/// - [`DecodePublicKey`]: decode DER or PEM encoded PKCS#8 private key./// - [`EncodePublicKey`]: encode DER or PEM encoded PKCS#8 private key./// SPKI public key files encoded with PEM begin with:/// -----BEGIN PUBLIC KEY-----/// public keys represent valid compressed Ed25519 y-coordinates./// Size of an Ed25519 public key when serialized as bytes./// Returns the raw bytes of the public key.to_public_key_derSubjectPublicKeyInfoto_stringSECRET_KEY_BYTESPUBLIC_KEY_BYTES//! PKCS#8 private key support.//! Implements Ed25519 PKCS#8 private keys as described in RFC8410 Section 7://! <https://datatracker.ietf.org/doc/html/rfc8410#section-7>//! ## SemVer Notes//! The `pkcs8` module of this crate is exempted from SemVer as it uses a//! pre-1.0 dependency (the `pkcs8` crate).//! However, breaking changes to this module will be accompanied by a minor//! version bump.//! Please lock to a specific minor version of the `ed25519` crate to avoid//! breaking changes when using this module.serde_bytes_crate// serde lacks support for deserializing arrays larger than 32-bytes// see: <https://github.com/serde-rs/serde/issues/631>SIGNATURE_BYTESround_tripoverflow//! `serde` support.TranscriptInternalErrorSignatureErrorInternalSignatureappend_scalarsappend_message_lengthsBatchTranscript/// Append some `scalars` to this batch verification sigma protocol transcript./// For ed25519 batch verification, we include the following as scalars:/// * All of the computed `H(R||A||M)`s to the protocol transcript, and/// * All of the `s` components of each signature./// Each is also prefixed with their index in the vector./// Append the lengths of the messages into the transcript./// This is done out of an (potential over-)abundance of caution, to guard/// against the unlikely event of collisions.  However, a nicer way to do/// this would be to append the message length before the message, but this/// is messy w.r.t. the calculations of the `H(R||A||M)`s above.ZeroRng/// An implementation of `rand_core::RngCore` which does nothing, to provide/// purely deterministic transcript-based nonces, rather than synthetically/// random nonces.next_u64fill_bytes/// A no-op function which leaves the destination bytes for randomness unchanged./// In this case, the internal merlin code is initialising the destination/// by doing `[0u8; …]`, which means that when we call/// `merlin::TranscriptRngBuilder.finalize()`, rather than rekeying the/// STROBE state based on external randomness, we're doing an/// `ENC_{state}(00000000000000000000000000000000)` operation, which is/// identical to the STROBE `MAC` operation.try_fill_byteszero_rngverify_batch/// Verify a batch of `signatures` on `messages` with their respective `public_keys`./// * `messages` is a slice of byte slices, one per signed message./// * `signatures` is a slice of `Signature`s./// * `public_keys` is a slice of `PublicKey`s./// * A `Result` whose `Ok` value is an emtpy tuple and whose `Err` value is a///   `SignatureError` containing a description of the internal error which///   occured./// # Notes on Nonce Generation & Malleability/// ## On Synthetic Nonces/// This library defaults to using what is called "synthetic" nonces, which/// means that a mixture of deterministic (per any unique set of inputs to this/// function) data and system randomness is used to seed the CSPRNG for nonce/// generation.  For more of the background theory on why many cryptographers/// currently believe this to be superior to either purely deterministic/// generation or purely relying on the system's randomness, see [this section/// of the Merlin design](https://merlin.cool/transcript/rng.html) by Henry de/// Valence, isis lovecruft, and Oleg Andreev, as well as Trevor Perrin's/// [designs for generalised/// EdDSA](https://moderncrypto.org/mail-archive/curves/2017/000925.html)./// ## On Deterministic Nonces/// In order to be ammenable to protocols which require stricter third-party/// auditability trails, such as in some financial cryptographic settings, this/// library also supports a `--features=batch_deterministic` setting, where the/// nonces for batch signature verification are derived purely from the inputs/// to this function themselves./// **This is not recommended for use unless you have several cryptographers on///   staff who can advise you in its usage and all the horrible, terrible,///   awful ways it can go horribly, terribly, awfully wrong.**/// In any sigma protocol it is wise to include as much context pertaining/// to the public state in the protocol as possible, to avoid malleability/// attacks where an adversary alters publics in an algebraic manner that/// manages to satisfy the equations for the protocol in question./// For ed25519 batch verification (both with synthetic and deterministic nonce/// generation), we include the following as scalars in the protocol transcript:/// The former, while not quite as elegant as adding the `R`s, `A`s, and/// `M`s separately, saves us a bit of context hashing since the/// `H(R||A||M)`s need to be computed for the verification equation anyway./// The latter prevents a malleability attack only found in deterministic batch/// signature verification (i.e. only when compiling `ed25519-dalek` with/// `--features batch_deterministic`) wherein an adversary, without access/// to the signing key(s), can take any valid signature, `(s,R)`, and swap/// `s` with `s' = -z1`.  This doesn't contitute a signature forgery, merely/// a vulnerability, as the resulting signature will not pass single/// signature verification.  (Thanks to Github users @real_or_random and/// @jonasnick for pointing out this malleability issue.)/// For an additional way in which signatures can be made to probablistically/// falsely "pass" the synthethic batch verification equation *for the same/// inputs*, but *only some crafted inputs* will pass the deterministic batch/// single, and neither of these will ever pass single signature verification,/// see the documentation for [`PublicKey.validate()`]./// extern crate ed25519_dalek;/// extern crate rand;/// use ed25519_dalek::verify_batch;/// use ed25519_dalek::Keypair;/// use ed25519_dalek::PublicKey;/// use ed25519_dalek::Signer;/// use ed25519_dalek::Signature;/// use rand::rngs::OsRng;/// let mut csprng = OsRng{};/// let keypairs: Vec<Keypair> = (0..64).map(|_| Keypair::generate(&mut csprng)).collect();/// let msg: &[u8] = b"They're good dogs Brant";/// let messages: Vec<&[u8]> = (0..64).map(|_| msg).collect();/// let signatures:  Vec<Signature> = keypairs.iter().map(|key| key.sign(&msg)).collect();/// let public_keys: Vec<PublicKey> = keypairs.iter().map(|key| key.public).collect();/// let result = verify_batch(&messages[..], &signatures[..], &public_keys[..]);/// assert!(result.is_ok());// This file is part of ed25519-dalek.// Copyright (c) 2017-2019 isis lovecruft//! Batch signature verification./// The length of a ed25519 `Signature`, in bytes.SECRET_KEY_LENGTH/// The length of a ed25519 `SecretKey`, in bytes.PUBLIC_KEY_LENGTH/// The length of an ed25519 `PublicKey`, in bytes.KEYPAIR_LENGTH/// The length of an ed25519 `Keypair`, in bytes.EXPANDED_SECRET_KEY_KEY_LENGTH/// The length of the "key" portion of an "expanded" ed25519 secret key, in bytes.EXPANDED_SECRET_KEY_NONCE_LENGTH/// The length of the "nonce" portion of an "expanded" ed25519 secret key, in bytes.EXPANDED_SECRET_KEY_LENGTH/// The length of an "expanded" ed25519 key, `ExpandedSecretKey`, in bytes.//! Common constants such as buffer sizes for keypairs and signatures.PointDecompressionErrorScalarFormatErrorBytesLengthError/// An error in the length of bytes handed to a constructor./// To use this, pass a string specifying the `name` of the type which is/// returning the error, and the `length` in bytes which its constructor/// expects.VerifyError/// The verification equation wasn't satisfiedname_alength_aname_blength_bname_clength_cArrayLengthError/// Two arrays did not match in size, making the called signature/// verification method impossible.PrehashedContextLengthError/// An ed25519ph signature can only take up to 255 octets of context./// Internal errors.  Most application-level developers will likely not/// need to pay any attention to these./// Errors which may occur while processing signatures and keypairs./// This error may arise due to:/// * Being given bytes with a length different to what was expected./// * A problem decompressing `r`, a curve point, in the `Signature`, or the///   curve point for a `PublicKey`./// * A problem with the format of `s`, a scalar, in the `Signature`.  This///   is only raised if the high-bit of the scalar was set.  (Scalars must///   only be constructed from 255-bit integers.)/// * Failure of a signature to satisfy the verification equation.//! Errors which may occur when parsing keys and/or signatures to or from wire formats.// rustc seems to think the typenames in match statements (e.g. in// Display) should be snake cased, for some reason.SerdeErrorSerdeBytesByteBufSerdeByteBufVerifiersecretSecretKey/// The secret half of this keypair./// The public half of this keypair.Keypair/// An ed25519 keypair./// Convert this keypair to bytes./// An array of bytes, `[u8; KEYPAIR_LENGTH]`.  The first/// `SECRET_KEY_LENGTH` of bytes is the `SecretKey`, and the next/// `PUBLIC_KEY_LENGTH` bytes is the `PublicKey` (the same as other/// libraries, such as [Adam Langley's ed25519 Golang/// implementation](https://github.com/agl/ed25519/))./// Construct a `Keypair` from the bytes of a `PublicKey` and `SecretKey`./// * `bytes`: an `&[u8]` representing the scalar for the secret key, and a///   compressed Edwards-Y coordinate of a point on curve25519, both as bytes.///   (As obtained from `Keypair::to_bytes()`.)/// Absolutely no validation is done on the key.  If you give this function/// bytes which do not represent a valid point, or which do not represent/// corresponding parts of the key, then your `Keypair` will be broken and/// it will be your fault./// A `Result` whose okay value is an EdDSA `Keypair` or whose error value/// is an `SignatureError` describing the error that occurred./// Generate an ed25519 keypair./// let keypair: Keypair = Keypair::generate(&mut csprng);/// # #[cfg(not(feature = "std"))]/// # fn main() { }/// # Input/// A CSPRNG with a `fill_bytes()` method, e.g. `rand_os::OsRng`./// The caller must also supply a hash function which implements the/// `Digest` and `Default` traits, and which returns 512 bits of output./// The standard hash function used for most ed25519 libraries is SHA-512,/// which is available with `use sha2::Sha512` as in the example above./// Other suitable hash functions include Keccak-512 and Blake2b-512.sign_prehashed/// Sign a `prehashed_message` with this `Keypair` using the/// Ed25519ph algorithm defined in [RFC8032 §5.1][rfc8032]./// * `prehashed_message` is an instantiated hash digest with 512-bits of///   output which has had the message to be signed previously fed into its///   state./// * `context` is an optional context string, up to 255 bytes inclusive,///   which may be used to provide additional domain separation.  If not///   set, this will default to an empty string./// An Ed25519ph [`Signature`] on the `prehashed_message`./// use ed25519_dalek::Digest;/// use ed25519_dalek::Sha512;/// let message: &[u8] = b"All I want is to pet all of the dogs.";/// // Create a hash digest object which we'll feed the message into:/// let mut prehashed: Sha512 = Sha512::new();/// prehashed.update(message);/// If you want, you can optionally pass a "context".  It is generally a/// good idea to choose a context and try to make it unique to your project/// and this specific usage of signatures./// For example, without this, if you were to [convert your OpenPGP key/// to a Bitcoin key][terrible_idea] (just as an example, and also Don't/// Ever Do That) and someone tricked you into signing an "email" which was/// actually a Bitcoin transaction moving all your magic internet money to/// their address, it'd be a valid transaction./// By adding a context, this trick becomes impossible, because the context/// is concatenated into the hash, which is then signed.  So, going with the/// previous example, if your bitcoin wallet used a context of/// "BitcoinWalletAppTxnSigning" and OpenPGP used a context (this is likely/// the least of their safety problems) of "GPGsCryptoIsntConstantTimeLol",/// then the signatures produced by both could never match the other, even/// if they signed the exact same message with the same key./// Let's add a context for good measure (remember, you'll want to choose/// your own!):/// # extern crate ed25519_dalek;/// # extern crate rand;/// # use ed25519_dalek::Digest;/// # use ed25519_dalek::Keypair;/// # use ed25519_dalek::Signature;/// # use ed25519_dalek::SignatureError;/// # use ed25519_dalek::Sha512;/// # use rand::rngs::OsRng;/// # fn do_test() -> Result<Signature, SignatureError> {/// # let mut csprng = OsRng{};/// # let keypair: Keypair = Keypair::generate(&mut csprng);/// # let message: &[u8] = b"All I want is to pet all of the dogs.";/// # let mut prehashed: Sha512 = Sha512::new();/// # prehashed.update(message);/// let context: &[u8] = b"Ed25519DalekSignPrehashedDoctest";/// let sig: Signature = keypair.sign_prehashed(prehashed, Some(context))?;/// # Ok(sig)/// #     do_test();/// [rfc8032]: https://tools.ietf.org/html/rfc8032#section-5.1/// [terrible_idea]: https://github.com/isislovecruft/scripts/blob/master/gpgkey2bc.py/// Verify a signature on a message with this keypair's public key.verify_prehashed/// Verify a `signature` on a `prehashed_message` using the Ed25519ph algorithm./// * `signature` is a purported Ed25519ph [`Signature`] on the `prehashed_message`./// Returns `true` if the `signature` was a valid signature created by this/// `Keypair` on the `prehashed_message`./// use ed25519_dalek::SignatureError;/// # fn do_test() -> Result<(), SignatureError> {/// // The sha2::Sha512 struct doesn't implement Copy, so we'll have to create a new one:/// let mut prehashed_again: Sha512 = Sha512::default();/// prehashed_again.update(message);/// let verified = keypair.public.verify_prehashed(prehashed_again, Some(context), &sig);/// assert!(verified.is_ok());/// # verifiedverify_strict/// Strictly verify a signature on a message with this keypair's public key./// # On The (Multiple) Sources of Malleability in Ed25519 Signatures/// This version of verification is technically non-RFC8032 compliant.  The/// following explains why./// 1. Scalar Malleability/// The authors of the RFC explicitly stated that verification of an ed25519/// signature must fail if the scalar `s` is not properly reduced mod \ell:/// > To verify a signature on a message M using public key A, with F/// > being 0 for Ed25519ctx, 1 for Ed25519ph, and if Ed25519ctx or/// > Ed25519ph is being used, C being the context, first split the/// > signature into two 32-octet halves.  Decode the first half as a/// > point R, and the second half as an integer S, in the range/// > 0 <= s < L.  Decode the public key A as point A'.  If any of the/// > decodings fail (including S being out of range), the signature is/// > invalid.)/// All `verify_*()` functions within ed25519-dalek perform this check./// 2. Point malleability/// The authors of the RFC added in a malleability check to step #3 in/// §5.1.7, for small torsion components in the `R` value of the signature,/// *which is not strictly required*, as they state:/// > Check the group equation \[8\]\[S\]B = \[8\]R + \[8\]\[k\]A'.  It's/// > sufficient, but not required, to instead check \[S\]B = R + \[k\]A'./// # History of Malleability Checks/// As originally defined (cf. the "Malleability" section in the README of/// this repo), ed25519 signatures didn't consider *any* form of/// malleability to be an issue.  Later the scalar malleability was/// considered important.  Still later, particularly with interests in/// cryptocurrency design and in unique identities (e.g. for Signal users,/// Tor onion services, etc.), the group element malleability became a/// concern./// However, libraries had already been created to conform to the original/// definition.  One well-used library in particular even implemented the/// group element malleability check, *but only for batch verification*!/// Which meant that even using the same library, a single signature could/// verify fine individually, but suddenly, when verifying it with a bunch/// of other signatures, the whole batch would fail!/// # "Strict" Verification/// This method performs *both* of the above signature malleability checks./// It must be done as a separate method because one doesn't simply get to/// change the definition of a cryptographic primitive ten years/// after-the-fact with zero consideration for backwards compatibility in/// hardware and protocols which have it already have the older definition/// baked in./// Returns `Ok(())` if the signature is valid, and `Err` otherwise.try_sign/// Sign a message with this keypair's secret key.'d//! ed25519 keypairs./// An ed25519 public key./// Derive this public key from its corresponding `SecretKey`.ExpandedSecretKey/// Derive this public key from its corresponding `ExpandedSecretKey`./// Convert this public key to a byte array./// View this public key as a byte array./// Construct a `PublicKey` from a slice of bytes./// The caller is responsible for ensuring that the bytes passed into this/// method actually represent a `curve25519_dalek::curve::CompressedEdwardsY`/// and that said compressed point is actually a point on the curve./// use ed25519_dalek::PUBLIC_KEY_LENGTH;/// # fn doctest() -> Result<PublicKey, SignatureError> {/// let public_key_bytes: [u8; PUBLIC_KEY_LENGTH] = [///    215,  90, 152,   1, 130, 177,  10, 183, 213,  75, 254, 211, 201, 100,   7,  58,///     14, 225, 114, 243, 218, 166,  35,  37, 175,   2,  26, 104, 247,   7,   81, 26];/// let public_key = PublicKey::from_bytes(&public_key_bytes)?;/// # Ok(public_key)/// #     doctest();/// A `Result` whose okay value is an EdDSA `PublicKey` or whose error valuemangle_scalar_bits_and_multiply_by_basepoint_to_produce_public_key/// Internal utility function for mangling the bits of a (formerly/// mathematically well-defined) "scalar" and multiplying it to produce a/// public key.//! ed25519 public keys./// An EdDSA secret key./// Instances of this secret are automatically overwritten with zeroes when they/// fall out of scope.// Overwrite secret key material with null bytes when it goes out of scope./// Convert this secret key to a byte array./// View this secret key as a byte array./// Construct a `SecretKey` from a slice of bytes./// use ed25519_dalek::SecretKey;/// use ed25519_dalek::SECRET_KEY_LENGTH;/// # fn doctest() -> Result<SecretKey, SignatureError> {/// let secret_key_bytes: [u8; SECRET_KEY_LENGTH] = [///    157, 097, 177, 157, 239, 253, 090, 096,///    186, 132, 074, 244, 146, 236, 044, 196,///    068, 073, 197, 105, 123, 050, 105, 025,///    112, 059, 172, 003, 028, 174, 127, 096, ];/// let secret_key: SecretKey = SecretKey::from_bytes(&secret_key_bytes)?;/// # Ok(secret_key)/// #     let result = doctest();/// #     assert!(result.is_ok());/// A `Result` whose okay value is an EdDSA `SecretKey` or whose error value/// is an `SignatureError` wrapping the internal error that occurred./// Generate a `SecretKey` from a `csprng`./// let secret_key: SecretKey = SecretKey::generate(&mut csprng);/// Afterwards, you can generate the corresponding public:/// # use ed25519_dalek::PublicKey;/// # use ed25519_dalek::SecretKey;/// # let secret_key: SecretKey = SecretKey::generate(&mut csprng);/// let public_key: PublicKey = (&secret_key).into();/// A CSPRNG with a `fill_bytes()` method, e.g. `rand::OsRng`/// An "expanded" secret key./// This is produced by using an hash function with 512-bits output to digest a/// `SecretKey`.  The output digest is then split in half, the lower half being/// the actual `key` used to sign messages, after twiddling with some bits.¹ The/// upper half is used a sort of half-baked, ill-designed² pseudo-domain-separation/// "nonce"-like thing, which is used during signature production by/// concatenating it with the message to be signed before the message is hashed.// ¹ This results in a slight bias towards non-uniformity at one spectrum of// the range of valid keys.  Oh well: not my idea; not my problem.// ² It is the author's view (specifically, isis agora lovecruft, in the event// you'd like to complain about me, again) that this is "ill-designed" because// this doesn't actually provide true hash domain separation, in that in many// real-world applications a user wishes to have one key which is used in// several contexts (such as within tor, which does domain separation// manually by pre-concatenating static strings to messages to achieve more// robust domain separation).  In other real-world applications, such as// bitcoind, a user might wish to have one master keypair from which others are// derived (à la BIP32) and different domain separators between keys derived at// different levels (and similarly for tree-based key derivation constructions,// such as hash-based signatures).  Leaving the domain separation to// application designers, who thus far have produced incompatible,// slightly-differing, ad hoc domain separation (at least those application// designers who knew enough cryptographic theory to do so!), is therefore a// bad design choice on the part of the cryptographer designing primitives// which should be simple and as foolproof as possible to use for// non-cryptographers.  Further, later in the ed25519 signature scheme, as// specified in RFC8032, the public key is added into *another* hash digest// (along with the message, again); it is unclear to this author why there's// not only one but two poorly-thought-out attempts at domain separation in the// same signature scheme, and which both fail in exactly the same way.  For a// better-designed, Schnorr-based signature scheme, see Trevor Perrin's work on// "generalised EdDSA" and "VXEdDSA"./// Construct an `ExpandedSecretKey` from a `SecretKey`./// # extern crate sha2;/// use ed25519_dalek::{SecretKey, ExpandedSecretKey};/// let expanded_secret_key: ExpandedSecretKey = ExpandedSecretKey::from(&secret_key);/// Convert this `ExpandedSecretKey` into an array of 64 bytes./// An array of 64 bytes.  The first 32 bytes represent the "expanded"/// secret key, and the last 32 bytes represent the "domain-separation"/// "nonce"./// let expanded_secret_key_bytes: [u8; 64] = expanded_secret_key.to_bytes();/// assert!(&expanded_secret_key_bytes[..] != &[0u8; 64][..]);/// Construct an `ExpandedSecretKey` from a slice of bytes./// A `Result` whose okay value is an EdDSA `ExpandedSecretKey` or whose/// error value is an `SignatureError` describing the error that occurred./// # use ed25519_dalek::{ExpandedSecretKey, SignatureError};/// # fn do_test() -> Result<ExpandedSecretKey, SignatureError> {/// let bytes: [u8; 64] = expanded_secret_key.to_bytes();/// let expanded_secret_key_again = ExpandedSecretKey::from_bytes(&bytes)?;/// # Ok(expanded_secret_key_again)/// #     let result = do_test();sign/// Sign a message with this `ExpandedSecretKey`./// Sign a `prehashed_message` with this `ExpandedSecretKey` using the/// * `public_key` is a [`PublicKey`] which corresponds to this secret key./// A `Result` whose `Ok` value is an Ed25519ph [`Signature`] on the/// `prehashed_message` if the context was 255 bytes or less, otherwise/// a `SignatureError`.secret_key_zeroize_on_drop//! ed25519 secret key types./// `R` is an `EdwardsPoint`, formed by using an hash function with/// 512-bits output to produce the digest of:/// - the nonce half of the `ExpandedSecretKey`, and/// - the message to be signed./// This digest is then interpreted as a `Scalar` and reduced into an/// element in ℤ/lℤ.  The scalar is then multiplied by the distinguished/// basepoint to produce `R`, and `EdwardsPoint`./// `s` is a `Scalar`, formed by using an hash function with 512-bits output/// to produce the digest of:/// - the `r` portion of this `Signature`,/// - the `PublicKey` which should be used to verify this `Signature`, and/// element in ℤ/lℤ./// An ed25519 signature./// These signatures, unlike the ed25519 signature reference implementation, are/// "detached"—that is, they do **not** include a copy of the message which has/// been signed.check_scalar/// Convert this `Signature` to a byte array./// Construct a `Signature` from a slice of bytes./// # Scalar Malleability Checking/// As originally specified in the ed25519 paper (cf. the "Malleability"/// section of the README in this repo), no checks whatsoever were performed/// for signature malleability./// Later, a semi-functional, hacky check was added to most libraries to/// "ensure" that the scalar portion, `s`, of the signature was reduced `mod/// \ell`, the order of the basepoint:/// if signature.s[31] & 224 != 0 {///     return Err();/// This bit-twiddling ensures that the most significant three bits of the/// scalar are not set:/// ```python,ignore/// >>> 0b00010000 & 224/// >>> 0b00100000 & 224/// 32/// >>> 0b01000000 & 224/// 64/// >>> 0b10000000 & 224/// 128/// However, this check is hacky and insufficient to check that the scalar is/// fully reduced `mod \ell = 2^252 + 27742317777372353535851937790883648493` as/// it leaves us with a guanteed bound of 253 bits.  This means that there are/// `2^253 - 2^252 + 2774231777737235353585193779088364849311` remaining scalars/// which could cause malleabilllity./// RFC8032 [states](https://tools.ietf.org/html/rfc8032#section-5.1.7):/// > To verify a signature on a message M using public key A, [...]/// > first split the signature into two 32-octet halves.  Decode the first/// > half as a point R, and the second half as an integer S, in the range/// > invalid./// However, by the time this was standardised, most libraries in use were/// only checking the most significant three bits.  (See also the/// documentation for `PublicKey.verify_strict`.)//! An ed25519 signature.HmacED25519_BIP32_NAMEEd25519ExpectedHardenedIndex/// Errors thrown while deriving secret keys/// How many derivations this key is from the root (0 for root)child_index/// Child index of the key used to derive from parent (`Normal(0)` for root)/// Secret Keychain_code/// Chain codeExtendedSecretKey/// An expanded secret key with chain code and meta dataHmacSha512/// A convenience wrapper for a [`core::result::Result`] with an [`Error`]from_seed/// Create a new extended secret key from a seed/// Derive an extended secret key fom the current using a derivation pathderive_child/// Derive a child extended secret key with an index/// Get the associated public keyhex_strrootnormal_errsvector1vector2//! A simple BIP32 implementation for ed25519 public keys. Although there exists [another very good//! library that does this](https://docs.rs/ed25519-bip32), this library preserves 32 byte secret//! keys and doesn't allow for extended public keys or "normal" child indexes, so that it can be as//! close to the BIP32 specifications as possible, allowing for compatibility with libraries like//! `trezor-crypto`Eitherinto_either/// Converts `self` into a [`Left`] variant of [`Either<Self, Self>`](Either)/// if `into_left` is `true`./// Converts `self` into a [`Right`] variant of [`Either<Self, Self>`](Either)/// use either::{IntoEither, Left, Right};/// let x = 0;/// assert_eq!(x.into_either(true), Left(x));/// assert_eq!(x.into_either(false), Right(x));into_either_with/// if `into_left(&self)` returns `true`./// fn is_even(x: &u8) -> bool {///     x % 2 == 0/// assert_eq!(x.into_either_with(is_even), Left(x));/// assert_eq!(x.into_either_with(|x| !is_even(x)), Right(x));IntoEither/// Provides methods for converting a type `Self` into either a [`Left`] or [`Right`]/// variant of [`Either<Self, Self>`](Either)./// The [`into_either`](IntoEither::into_either) method takes a [`bool`] to determine/// whether to convert to [`Left`] or [`Right`]./// The [`into_either_with`](IntoEither::into_either_with) method takes a/// [predicate function](FnOnce) to determine whether to convert to [`Left`] or [`Right`].//! The trait [`IntoEither`] provides methods for converting a type `Self`, whose//! size is constant and known at compile-time, into an [`Either`] variant.for_bothwrap_eitherIterEither/// Iterator that maps left or right iterators to corresponding `Either`-wrapped items./// This struct is created by the [`Either::factor_into_iter`],/// [`factor_iter`][Either::factor_iter],/// and [`factor_iter_mut`][Either::factor_iter_mut] methods.Accfoldfor_eachpartitionfind_map/// `Either<L, R>` is an iterator if both `L` and `R` are iterators.rfoldrfind/// A value of type `L`./// A value of type `R`./// The enum `Either` with variants `Left` and `Right` is a general purpose/// sum type with two cases./// The `Either` type is symmetric and treats its variants the same way, without/// preference./// (For representing success or error, use the regular `Result` enum instead.)/// Evaluate the provided expression for both [`Either::Left`] and [`Either::Right`]./// This macro is useful in cases where both sides of [`Either`] can be interacted with/// in the same way even though the don't share the same type./// Syntax: `either::for_both!(` *expression* `,` *pattern* `=>` *expression* `)`/// use either::Either;/// fn length(owned_or_borrowed: Either<String, &'static str>) -> usize {///     either::for_both!(owned_or_borrowed, s => s.len())///     let borrowed = Either::Right("Hello world!");///     let owned = Either::Left("Hello world!".to_owned());///     assert_eq!(length(borrowed), 12);///     assert_eq!(length(owned), 12);try_left/// Macro for unwrapping the left side of an [`Either`], which fails early/// with the opposite side. Can only be used in functions that return/// `Either` because of the early return of `Right` that it provides./// See also [`try_right!`] for its dual, which applies the same just to the/// right side./// use either::{Either, Left, Right};/// fn twice(wrapper: Either<u32, &str>) -> Either<u32, &str> {///     let value = either::try_left!(wrapper);///     Left(value * 2)///     assert_eq!(twice(Left(2)), Left(4));///     assert_eq!(twice(Right("ups")), Right("ups"));try_right/// Dual to [`try_left!`], see its documentation for more information.map_eitheriteratoris_left/// Return true if the value is the `Left` variant./// use either::*;/// let values = [Left(1), Right("the right value")];/// assert_eq!(values[0].is_left(), true);/// assert_eq!(values[1].is_left(), false);is_right/// Return true if the value is the `Right` variant./// assert_eq!(values[0].is_right(), false);/// assert_eq!(values[1].is_right(), true);left/// Convert the left side of `Either<L, R>` to an `Option<L>`./// let left: Either<_, ()> = Left("some value");/// assert_eq!(left.left(),  Some("some value"));/// let right: Either<(), _> = Right(321);/// assert_eq!(right.left(), None);right/// Convert the right side of `Either<L, R>` to an `Option<R>`./// assert_eq!(left.right(),  None);/// assert_eq!(right.right(), Some(321));/// Convert `&Either<L, R>` to `Either<&L, &R>`./// assert_eq!(left.as_ref(), Left(&"some value"));/// let right: Either<(), _> = Right("some value");/// assert_eq!(right.as_ref(), Right(&"some value"));/// Convert `&mut Either<L, R>` to `Either<&mut L, &mut R>`./// fn mutate_left(value: &mut Either<u32, u32>) {///     if let Some(l) = value.as_mut().left() {///         *l = 999;/// let mut left = Left(123);/// let mut right = Right(123);/// mutate_left(&mut left);/// mutate_left(&mut right);/// assert_eq!(left, Left(999));/// assert_eq!(right, Right(123));as_pin_ref/// Convert `Pin<&Either<L, R>>` to `Either<Pin<&L>, Pin<&R>>`,/// pinned projections of the inner variants.as_pin_mut/// Convert `Pin<&mut Either<L, R>>` to `Either<Pin<&mut L>, Pin<&mut R>>`,flip/// Convert `Either<L, R>` to `Either<R, L>`./// let left: Either<_, ()> = Left(123);/// assert_eq!(left.flip(), Right(123));/// assert_eq!(right.flip(), Left("some value"));map_left/// Apply the function `f` on the value in the `Left` variant if it is present rewrapping the/// result in `Left`./// let left: Either<_, u32> = Left(123);/// assert_eq!(left.map_left(|x| x * 2), Left(246));/// let right: Either<u32, _> = Right(123);/// assert_eq!(right.map_left(|x| x * 2), Right(123));map_right/// Apply the function `f` on the value in the `Right` variant if it is present rewrapping the/// result in `Right`./// assert_eq!(left.map_right(|x| x * 2), Left(123));/// assert_eq!(right.map_right(|x| x * 2), Right(246));/// Apply the functions `f` and `g` to the `Left` and `Right` variants/// respectively. This is equivalent to/// [bimap](https://hackage.haskell.org/package/bifunctors-5/docs/Data-Bifunctor.html)/// in functional programming./// let f = |s: String| s.len();/// let g = |u: u8| u.to_string();/// let left: Either<String, u8> = Left("loopy".into());/// assert_eq!(left.map_either(f, g), Left(5));/// let right: Either<String, u8> = Right(42);/// assert_eq!(right.map_either(f, g), Right("42".into()));Ctxmap_either_with/// Similar to [`map_either`][Self::map_either], with an added context `ctx` accessible to/// both functions./// let mut sum = 0;/// // Both closures want to update the same value, so pass it as context./// let mut f = |sum: &mut usize, s: String| { *sum += s.len(); s.to_uppercase() };/// let mut g = |sum: &mut usize, u: usize| { *sum += u; u.to_string() };/// let left: Either<String, usize> = Left("loopy".into());/// assert_eq!(left.map_either_with(&mut sum, &mut f, &mut g), Left("LOOPY".into()));/// let right: Either<String, usize> = Right(42);/// assert_eq!(right.map_either_with(&mut sum, &mut f, &mut g), Right("42".into()));/// assert_eq!(sum, 47);/// Apply one of two functions depending on contents, unifying their result. If the value is/// `Left(L)` then the first function `f` is applied; if it is `Right(R)` then the second/// function `g` is applied./// fn square(n: u32) -> i32 { (n * n) as i32 }/// fn negate(n: i32) -> i32 { -n }/// let left: Either<u32, i32> = Left(4);/// assert_eq!(left.either(square, negate), 16);/// let right: Either<u32, i32> = Right(-4);/// assert_eq!(right.either(square, negate), 4);either_with/// Like [`either`][Self::either], but provide some context to whichever of the/// functions ends up being called./// // In this example, the context is a mutable reference/// let values = vec![Left(2), Right(2.7)];/// for value in values {///     value.either_with(&mut result,///                       |ctx, integer| ctx.push(integer),///                       |ctx, real| ctx.push(f64::round(real) as i32));/// assert_eq!(result, vec![2, 3]);left_and_then/// Apply the function `f` on the value in the `Left` variant if it is present./// assert_eq!(left.left_and_then::<_,()>(|x| Right(x * 2)), Right(246));/// assert_eq!(right.left_and_then(|x| Right::<(), _>(x * 2)), Right(123));right_and_then/// Apply the function `f` on the value in the `Right` variant if it is present./// assert_eq!(left.right_and_then(|x| Right(x * 2)), Left(123));/// assert_eq!(right.right_and_then(|x| Right(x * 2)), Right(246));/// Convert the inner value to an iterator./// This requires the `Left` and `Right` iterators to have the same item type./// See [`factor_into_iter`][Either::factor_into_iter] to iterate different types./// let left: Either<_, Vec<u32>> = Left(vec![1, 2, 3, 4, 5]);/// let mut right: Either<Vec<u32>, _> = Right(vec![]);/// right.extend(left.into_iter());/// assert_eq!(right, Right(vec![1, 2, 3, 4, 5]));/// Borrow the inner value as an iterator./// See [`factor_iter`][Either::factor_iter] to iterate different types./// let left: Either<_, &[u32]> = Left(vec![2, 3]);/// let mut right: Either<Vec<u32>, _> = Right(&[4, 5][..]);/// let mut all = vec![1];/// all.extend(left.iter());/// all.extend(right.iter());/// assert_eq!(all, vec![1, 2, 3, 4, 5]);/// Mutably borrow the inner value as an iterator./// See [`factor_iter_mut`][Either::factor_iter_mut] to iterate different types./// let mut left: Either<_, &mut [u32]> = Left(vec![2, 3]);/// for l in left.iter_mut() {///     *l *= *l/// assert_eq!(left, Left(vec![4, 9]));/// let mut inner = [4, 5];/// let mut right: Either<Vec<u32>, _> = Right(&mut inner[..]);/// for r in right.iter_mut() {///     *r *= *r/// assert_eq!(inner, [16, 25]);factor_into_iter/// Converts an `Either` of `Iterator`s to be an `Iterator` of `Either`s/// Unlike [`into_iter`][Either::into_iter], this does not require the/// `Left` and `Right` iterators to have the same item type./// let left: Either<_, Vec<u8>> = Left(&["hello"]);/// assert_eq!(left.factor_into_iter().next(), Some(Left(&"hello")));/// let right: Either<&[&str], _> = Right(vec![0, 1]);/// assert_eq!(right.factor_into_iter().collect::<Vec<_>>(), vec![Right(0), Right(1)]);// TODO(MSRV): doc(alias) was stabilized in Rust 1.48// #[doc(alias = "transpose")]factor_iter/// Borrows an `Either` of `Iterator`s to be an `Iterator` of `Either`s/// Unlike [`iter`][Either::iter], this does not require the/// let left: Either<_, Vec<u8>> = Left(["hello"]);/// assert_eq!(left.factor_iter().next(), Some(Left(&"hello")));/// let right: Either<[&str; 2], _> = Right(vec![0, 1]);/// assert_eq!(right.factor_iter().collect::<Vec<_>>(), vec![Right(&0), Right(&1)]);factor_iter_mut/// Mutably borrows an `Either` of `Iterator`s to be an `Iterator` of `Either`s/// Unlike [`iter_mut`][Either::iter_mut], this does not require the/// let mut left: Either<_, Vec<u8>> = Left(["hello"]);/// left.factor_iter_mut().for_each(|x| *x.unwrap_left() = "goodbye");/// assert_eq!(left, Left(["goodbye"]));/// let mut right: Either<[&str; 2], _> = Right(vec![0, 1, 2]);/// right.factor_iter_mut().for_each(|x| if let Right(r) = x { *r = -*r; });/// assert_eq!(right, Right(vec![0, -1, -2]));left_or/// Return left value or given value/// Arguments passed to `left_or` are eagerly evaluated; if you are passing/// the result of a function call, it is recommended to use/// [`left_or_else`][Self::left_or_else], which is lazily evaluated./// # use either::*;/// let left: Either<&str, &str> = Left("left");/// assert_eq!(left.left_or("foo"), "left");/// let right: Either<&str, &str> = Right("right");/// assert_eq!(right.left_or("left"), "left");left_or_default/// Return left or a default/// let left: Either<String, u32> = Left("left".to_string());/// assert_eq!(left.left_or_default(), "left");/// let right: Either<String, u32> = Right(42);/// assert_eq!(right.left_or_default(), String::default());left_or_else/// Returns left value or computes it from a closure/// let left: Either<String, u32> = Left("3".to_string());/// assert_eq!(left.left_or_else(|_| unreachable!()), "3");/// let right: Either<String, u32> = Right(3);/// assert_eq!(right.left_or_else(|x| x.to_string()), "3");right_or/// Return right value or given value/// Arguments passed to `right_or` are eagerly evaluated; if you are passing/// [`right_or_else`][Self::right_or_else], which is lazily evaluated./// assert_eq!(right.right_or("foo"), "right");/// assert_eq!(left.right_or("right"), "right");right_or_default/// Return right or a default/// assert_eq!(left.right_or_default(), u32::default());/// assert_eq!(right.right_or_default(), 42);right_or_else/// Returns right value or computes it from a closure/// assert_eq!(left.right_or_else(|x| x.parse().unwrap()), 3);/// assert_eq!(right.right_or_else(|_| unreachable!()), 3);unwrap_left/// Returns the left value/// let left: Either<_, ()> = Left(3);/// assert_eq!(left.unwrap_left(), 3);/// When `Either` is a `Right` value/// let right: Either<(), _> = Right(3);/// right.unwrap_left();unwrap_right/// Returns the right value/// assert_eq!(right.unwrap_right(), 3);/// When `Either` is a `Left` value/// left.unwrap_right();expect_left/// assert_eq!(left.expect_left("value was Right"), 3);/// right.expect_left("value was Right");expect_right/// assert_eq!(right.expect_right("value was Left"), 3);/// left.expect_right("value was Right");either_into/// Convert the contained value into `T`/// // Both u16 and u32 can be converted to u64./// let left: Either<u16, u32> = Left(3u16);/// assert_eq!(left.either_into::<u64>(), 3u64);/// let right: Either<u16, u32> = Right(7u32);/// assert_eq!(right.either_into::<u64>(), 7u64);factor_none/// Factors out `None` from an `Either` of [`Option`]./// let left: Either<_, Option<String>> = Left(Some(vec![0]));/// assert_eq!(left.factor_none(), Some(Left(vec![0])));/// let right: Either<Option<Vec<u8>>, _> = Right(Some(String::new()));/// assert_eq!(right.factor_none(), Some(Right(String::new())));factor_err/// Factors out a homogenous type from an `Either` of [`Result`]./// Here, the homogeneous type is the `Err` type of the [`Result`]./// let left: Either<_, Result<String, u32>> = Left(Ok(vec![0]));/// assert_eq!(left.factor_err(), Ok(Left(vec![0])));/// let right: Either<Result<Vec<u8>, u32>, _> = Right(Ok(String::new()));/// assert_eq!(right.factor_err(), Ok(Right(String::new())));factor_ok/// Here, the homogeneous type is the `Ok` type of the [`Result`]./// let left: Either<_, Result<u32, String>> = Left(Err(vec![0]));/// assert_eq!(left.factor_ok(), Err(Left(vec![0])));/// let right: Either<Result<u32, Vec<u8>>, _> = Right(Err(String::new()));/// assert_eq!(right.factor_ok(), Err(Right(String::new())));factor_first/// Factor out a homogeneous type from an either of pairs./// Here, the homogeneous type is the first element of the pairs./// let left: Either<_, (u32, String)> = Left((123, vec![0]));/// assert_eq!(left.factor_first().0, 123);/// let right: Either<(u32, Vec<u8>), _> = Right((123, String::new()));/// assert_eq!(right.factor_first().0, 123);factor_second/// Here, the homogeneous type is the second element of the pairs./// let left: Either<_, (String, u32)> = Left((vec![0], 123));/// assert_eq!(left.factor_second().1, 123);/// let right: Either<(Vec<u8>, u32), _> = Right((String::new(), 123));/// assert_eq!(right.factor_second().1, 123);/// Extract the value of an either over two equivalent types./// assert_eq!(left.into_inner(), 123);/// assert_eq!(right.into_inner(), 123);/// Map `f` over the contained value and return the result in the/// corresponding variant./// let value: Either<_, i32> = Right(42);/// let other = value.map(|x| x * 2);/// assert_eq!(other, Right(84));cloned/// Maps an `Either<&L, &R>` to an `Either<L, R>` by cloning the contents of/// either branch.copied/// Maps an `Either<&L, &R>` to an `Either<L, R>` by copying the contents of/// Maps an `Either<&mut L, &mut R>` to an `Either<L, R>` by cloning the contents of/// Maps an `Either<&mut L, &mut R>` to an `Either<L, R>` by copying the contents of/// Convert from `Result` to `Either` with `Ok => Right` and `Err => Left`./// Convert from `Either` to `Result` with `Right => Ok` and `Left => Err`./// `Either<L, R>` is a future if both `L` and `R` are futures.read_to_endread_to_string/// `Either<L, R>` implements `Read` if both `L` and `R` do./// Requires crate feature `"std"`/// `Either<L, R>` implements `Seek` if both `L` and `R` do.read_line/// `Either<L, R>` implements `Write` if both `L` and `R` do.impl_specific_ref_and_mut"Requires crate feature `std`."CStr/// `Either` implements `Error` if *both* `L` and `R` implement it.basicread_writecheck_t/// A helper macro to check if AsRef and AsMut are implemented for a given type._unsized_ref_propagation// This "unused" method is here to ensure that compilation doesn't fail on given types._unsized_std_propagation//! The enum [`Either`] with variants `Left` and `Right` is a general purpose//! sum type with two cases.//! [`Either`]: enum.Either.html//! **Crate features:**//! * `"std"`//!   Enabled by default. Disable to make the library `#![no_std]`.//! * `"serde"`//!   Disabled by default. Enable to `#[derive(Serialize, Deserialize)]` for `Either`//! Untagged serialization/deserialization support for Either<L, R>.//! `Either` uses default, externally-tagged representation.//! However, sometimes it is useful to support several alternative types.//! For example, we may have a field which is generally Map<String, i32>//! but in typical cases Vec<String> would suffice, too.//! use either::Either;//! #[derive(serde::Serialize, serde::Deserialize, Debug)]//! #[serde(transparent)]//! struct IntOrString {//!     #[serde(with = "either::serde_untagged")]//!     inner: Either<Vec<String>, HashMap<String, i32>>//! // serialization//! let data = IntOrString {//!     inner: Either::Left(vec!["Hello".to_string()])//! // notice: no tags are emitted.//! assert_eq!(serde_json::to_string(&data)?, r#"["Hello"]"#);//! // deserialization//! let data: IntOrString = serde_json::from_str(//!     r#"{"a": 0, "b": 14}"#//! )?;//! println!("found {:?}", data);//! Untagged serialization/deserialization support for Option<Either<L, R>>.//!     #[serde(with = "either::serde_untagged_optional")]//!     inner: Option<Either<Vec<String>, HashMap<String, i32>>>//!     inner: Some(Either::Left(vec!["Hello".to_string()]))LevelFilterRecord"regex.rs"directivesDirectiveFilter/// A log filter./// This struct can be used to determine whether or not a log record/// should be written to the output./// Use the [`Builder`] type to parse and construct a `Filter`./// [`Builder`]: struct.Builder.htmlbuilt/// A builder for a log filter./// It can be used to parse a set of directives from a string before building/// a [`Filter`] instance./// # #[macro_use] extern crate log;/// # use std::env;/// use env_logger::filter::Builder;/// let mut builder = Builder::new();/// // Parse a logging filter from an environment variable./// if let Ok(rust_log) = env::var("RUST_LOG") {///     builder.parse(&rust_log);/// let filter = builder.build();/// [`Filter`]: struct.Filter.html/// Returns the maximum `LevelFilter` that this filter instance is/// configured to output./// use log::LevelFilter;/// builder.filter(Some("module1"), LevelFilter::Info);/// builder.filter(Some("module2"), LevelFilter::Error);/// assert_eq!(filter.filter(), LevelFilter::Info);/// Checks if this record matches the configured filter./// Determines if a log message with the specified metadata would be logged./// Initializes the filter builder with defaults./// Initializes the filter builder from an environment.filter_module/// Adds a directive to the filter for a specific module.filter_level/// Adds a directive to the filter for all modules./// Adds a directive to the filter./// The given module (if any) will log at most the specified level provided./// If no module is provided then the filter will apply to all log messages./// Parses the directives string./// See the [Enabling Logging] section for more details./// [Enabling Logging]: ../index.html#enabling-logging/// Build a log filter.parse_spec/// Parse a logging specification string (e.g: "crate1,crate2::mod3,crate3::x=error/foo")/// and return a vector with log directives.// Check whether a level and target are enabled by the set of directives.make_logger_filterfilter_infofilter_beginning_longest_matchensure_tests_cover_level_universe// Some of our tests are only correct or complete when they cover the full// universe of variants for log::Level. In the unlikely event that a new// variant is added in the future, this test will detect the scenario and// alert us to the need to review and update the tests. In such a// situation, this test will fail to compile, and the error message will// look something like this://     error[E0004]: non-exhaustive patterns: `NewVariant` not covered//        --> src/filter/mod.rs:413:15//         |//     413 |         match level_universe {//         |               ^^^^^^^^^^^^^^ pattern `NewVariant` not coveredparse_defaultparse_default_bare_level_off_lcparse_default_bare_level_off_ucparse_default_bare_level_error_lcparse_default_bare_level_error_ucparse_default_bare_level_warn_lcparse_default_bare_level_warn_ucparse_default_bare_level_info_lcparse_default_bare_level_info_ucparse_default_bare_level_debug_lcparse_default_bare_level_debug_ucparse_default_bare_level_trace_lcparse_default_bare_level_trace_ucparse_default_bare_level_debug_mixed// In practice, the desired log level is typically specified by a token// that is either all lowercase (e.g., 'trace') or all uppercase (.e.g,// 'TRACE'), but this tests serves as a reminder that// log::Level::from_str() ignores all case variants.match_full_pathno_matchmatch_beginningmatch_beginning_longest_matchmatch_defaultzero_levelparse_spec_validparse_spec_invalid_crateparse_spec_invalid_levelparse_spec_string_levelparse_spec_empty_levelparse_spec_empty_level_isolatedparse_spec_blank_level_isolatedparse_spec_blank_level_isolated_comma_onlyparse_spec_blank_level_isolated_comma_blankparse_spec_blank_level_isolated_blank_commaparse_spec_globalparse_spec_global_bare_warn_lcparse_spec_global_bare_warn_ucparse_spec_global_bare_warn_mixedparse_spec_valid_filterparse_spec_invalid_crate_filterparse_spec_empty_with_filter//! Filtering for log records.//! This module contains the log filtering used by `env_logger` to match records.//! You can use the `Filter` type in your own logger implementation to use the same//! filter parsing and matching as `env_logger`. For more details about the format//! for directive strings see [Enabling Logging].//! ## Using `env_logger` in your own logger//! You can use `env_logger`'s filtering functionality with your own logger.//! Call [`Builder::parse`] to parse directives from a string when constructing//! your logger. Call [`Filter::matches`] to check whether a record should be//! logged based on the parsed filters when log records are received.//! extern crate log;//! extern crate env_logger;//! use env_logger::filter::Filter;//! use log::{Log, Metadata, Record};//! struct MyLogger {//!     filter: Filter//! impl MyLogger {//!     fn new() -> MyLogger {//!         use env_logger::filter::Builder;//!         let mut builder = Builder::new();//!         // Parse a directives string from an environment variable//!         if let Ok(ref filter) = std::env::var("MY_LOG_LEVEL") {//!            builder.parse(filter);//!         MyLogger {//!             filter: builder.build()//! impl Log for MyLogger {//!     fn enabled(&self, metadata: &Metadata) -> bool {//!         self.filter.enabled(metadata)//!     fn log(&self, record: &Record) {//!         // Check if the record is matched by the filter//!         if self.filter.matches(record) {//!             println!("{:?}", record);//!     fn flush(&self) {}//! [Enabling Logging]: ../index.html#enabling-logging//! [`Builder::parse`]: struct.Builder.html#method.parse//! [`Filter::matches`]: struct.Filter.html#method.matchesformat_rfc3339_microsformat_rfc3339_millisformat_rfc3339_nanosformat_rfc3339_secondsTimestampPrecisionglob/// Get a [`Timestamp`] for the current date and time in UTC./// Include the current timestamp with the log record:/// let mut builder = env_logger::Builder::new();/// builder.format(|buf, record| {///     let ts = buf.timestamp();///     writeln!(buf, "{}: {}: {}", ts, record.level(), record.args())/// [`Timestamp`]: struct.Timestamp.htmltimestamp_seconds/// Get a [`Timestamp`] for the current date and time in UTC with full/// second precision./// Get a [`Timestamp`] for the current date and time in UTC with/// millisecond precision./// microsecond precision./// nanosecond precision./// An [RFC3339] formatted timestamp./// The timestamp implements [`Display`] and can be written to a [`Formatter`]./// [RFC3339]: https://www.ietf.org/rfc/rfc3339.txt/// [`Display`]: https://doc.rust-lang.org/stable/std/fmt/trait.Display.html/// [`Formatter`]: struct.Formatter.html/*
This internal module contains the timestamp implementation.

Its public API is available when the `humantime` crate is available.
*//*
Timestamps aren't available when we don't have a `humantime` dependency.
*/WriterWriteStyle/// Full second precision (0 decimal digits)/// Millisecond precision (3 decimal digits)/// Microsecond precision (6 decimal digits)/// Nanosecond precision (9 decimal digits)/// Formatting precision of timestamps./// Seconds give precision of full seconds, milliseconds give thousands of a/// second (3 decimal digits), microseconds are millionth of a second (6 decimal/// digits) and nanoseconds are billionth of a second (9 decimal digits)./// The default timestamp precision is seconds.write_style/// A formatter to write logs into./// `Formatter` implements the standard [`Write`] trait for writing log records./// It also supports terminal colors, through the [`style`] method./// Use the [`writeln`] macro to format a log record./// An instance of a `Formatter` is passed to an `env_logger` format as `buf`:/// builder.format(|buf, record| writeln!(buf, "{}: {}", record.level(), record.args()));/// [`Write`]: https://doc.rust-lang.org/stable/std/io/trait.Write.html/// [`writeln`]: https://doc.rust-lang.org/stable/std/macro.writeln.html/// [`style`]: #method.styleprintFormatFnformat_timestampformat_module_pathformat_targetformat_levelformat_indentcustom_formatformat_suffix/// Convert the format into a callable function./// If the `custom_format` is `Some`, then any `default_format` switches are ignored./// If the `custom_format` is `None`, then a default format is returned./// Any `default_format` switches set to `false` won't be written by the format.SubtleStyleStyledValuemodule_pathwritten_header_valueindentsuffixDefaultFormat/// The default format./// This format needs to work with any combination of crate features.subtle_stylewrite_header_valuewrite_levelwrite_timestampwrite_module_pathwrite_targetfinish_headerwrite_argswrite_recordformat_with_headerformat_no_headerformat_indent_spacesformat_indent_zero_spacesformat_indent_spaces_no_headerformat_suffix_with_indentformat_empty_targetformat_no_target//! Formatting for log records.//! This module contains a [`Formatter`] that can be used to format log records//! into without needing temporary allocations. Usually you won't need to worry//! about the contents of this module and can use the `Formatter` like an ordinary//! [`Write`].//! # Formatting log records//! The format used to print log records can be customised using the [`Builder::format`]//! method.//! Custom formats can apply different color and weight to printed values using//! [`Style`] builders.//! use std::io::Write;//! let mut builder = env_logger::Builder::new();//! builder.format(|buf, record| {//!     writeln!(buf, "{}: {}",//!         record.level(),//!         record.args())//! [`Formatter`]: struct.Formatter.html//! [`Style`]: struct.Style.html//! [`Builder::format`]: ../struct.Builder.html#method.format//! [`Write`]: https://doc.rust-lang.org/stable/std/io/trait.Write.htmlis_stdoutis_stderr/*
This internal module contains the terminal detection implementation.

If the `atty` crate is available then we use it to detect whether we're
attached to a particular TTY. If the `atty` crate is not available we
assume we're not attached to anything. This effectively prevents styles
from being printed.
*/BufferWriter/// Logs will be sent to standard output./// Logs will be sent to standard error.Pipe/// Logs will be sent to a custom pipe./// Log target, either `stdout`, `stderr` or a custom pipe.WritableTarget/// Same as `Target`, except the pipe is wrapped in a mutex for interior mutability.Auto/// Try to print styles, but don't force the issue.Always/// Try very hard to print styles.Never/// Never print styles./// Whether or not to print styles to the target./// A terminal target with color awareness.is_test/// A builder for a terminal writer./// The target and style choice can be configured before building./// Initialize the writer builder with defaults./// Set the target to write to.parse_write_style/// Parses a style choice string./// See the [Disabling colors] section for more details./// [Disabling colors]: ../index.html#disabling-colors/// Whether or not to print style characters when writing./// Whether or not to capture logs for `cargo test`./// Build a terminal writer.parse_write_style_validparse_write_style_invalidColorChoiceColorSpecWriteColor/// Begin a new [`Style`]./// Create a bold, red colored style and use it to print the log level:/// use env_logger::fmt::Color;///     let mut level_style = buf.style();///     level_style.set_color(Color::Red).set_bold(true);///     writeln!(buf, "{}: {}",///         level_style.value(record.level()),///         record.args())/// [`Style`]: struct.Style.htmldefault_level_style/// Get the default [`Style`] for the given level./// The style can be used to print other values besides the level.default_styled_level/// Get a printable [`Style`] for the given level./// The style can only be used to print the level.uncolored_targethas_uncolored_targetstdoutpipeset_colorinto_color_choice/// A set of styles to apply to the terminal output./// Call [`Formatter::style`] to get a `Style` and use the builder methods to/// set styling properties, like [color] and [weight]./// To print a value using the style, wrap it in a call to [`value`] when the log/// record is formatted./// Styles can be re-used to output multiple values:///     let mut bold = buf.style();///     bold.set_bold(true);///     writeln!(buf, "{}: {} {}",///         bold.value(record.level()),///         bold.value("some bold text"),/// [`Formatter::style`]: struct.Formatter.html#method.style/// [color]: #method.set_color/// [weight]: #method.set_bold/// [`value`]: #method.value/// A value that can be printed using the given styles./// It is the result of calling [`Style::value`]./// [`Style::value`]: struct.Style.html#method.valueColor/// Set the text color./// Create a style with red text:///     let mut style = buf.style();///     style.set_color(Color::Red);///     writeln!(buf, "{}", style.value(record.args()))set_bold/// Set the text weight./// If `yes` is true then text will be written in bold./// If `yes` is false then text will be written in the default weight./// Create a style with bold text:///     style.set_bold(true);set_intense/// Set the text intensity./// If `yes` is true then text will be written in a brighter color./// If `yes` is false then text will be written in the default color./// Create a style with intense text:///     style.set_intense(true);set_dimmed/// Set whether the text is dimmed./// If `yes` is true then text will be written in a dimmer color./// Create a style with dimmed text:///     style.set_dimmed(true);set_bg/// Set the background color./// Create a style with a yellow background:///     style.set_bg(Color::Yellow);/// Wrap a value in the style./// The same `Style` can be used to print multiple different values.///     style.set_color(Color::Red).set_bold(true);///         style.value(record.level()),/// Wrap a value in the style by taking ownership of it.impl_styled_value_fmtUpperExpLowerExpBlackBlueGreenRedCyanMagentaYellowWhiteAnsi256Rgb/// The set of available colors for the terminal foreground/background./// The `Ansi256` and `Rgb` colors will only output the correct codes when/// paired with the `Ansi` `WriteColor` implementation./// The `Ansi256` and `Rgb` color types are not supported when writing colors/// on Windows using the console. If they are used on Windows, then they are/// silently ignored and no colors will be emitted./// This set may expand over time./// This type has a `FromStr` impl that can parse colors from their human/// readable form. The format is as follows:/// 1. Any of the explicitly listed colors in English. They are matched///    case insensitively./// 2. A single 8-bit integer, in either decimal or hexadecimal format./// 3. A triple of 8-bit integers separated by a comma, where each integer is///    in decimal or hexadecimal format./// Hexadecimal numbers are written with a `0x` prefix.into_termcolor// The `Color` type is copied from https://github.com/BurntSushi/termcolor/*
This internal module contains the style and terminal writing implementation.

Its public API is available when the `termcolor` crate is available.
The terminal printing is shimmed when the `termcolor` crate is not available.
*/LogSetLoggerErrorDEFAULT_FILTER_ENV/// The default name for the environment variable to read filters from.DEFAULT_WRITE_STYLE_ENV/// The default name for the environment variable to read style preferences from.Var/// Set of environment variables to configure from./// # Default environment variables/// By default, the `Env` will read the following environment variables:/// - `RUST_LOG`: the level filter/// - `RUST_LOG_STYLE`: whether or not to print styles with records./// These sources can be configured using the builder methods on `Env`.Logger/// The env logger./// This struct implements the `Log` trait from the [`log` crate][log-crate-url],/// which allows it to act as a logger./// The [`init()`], [`try_init()`], [`Builder::init()`] and [`Builder::try_init()`]/// methods will each construct a `Logger` and immediately initialize it as the/// default global logger./// If you'd instead need access to the constructed `Logger`, you can use/// the associated [`Builder`] and install it with the/// [`log` crate][log-crate-url] directly./// [log-crate-url]: https://docs.rs/log//// [`init()`]: fn.init.html/// [`try_init()`]: fn.try_init.html/// [`Builder::init()`]: struct.Builder.html#method.init/// [`Builder::try_init()`]: struct.Builder.html#method.try_init/// `Builder` acts as builder for initializing a `Logger`./// It can be used to customize the log format, change the environment variable used/// to provide the logging directives and also set the default log level filter./// # use std::io::Write;/// use env_logger::Builder;/// let mut builder = Builder::from_default_env();/// builder///     .format(|buf, record| writeln!(buf, "{} - {}", record.level(), record.args()))///     .filter(None, LevelFilter::Info)///     .init();/// error!("error message");/// info!("info message");/// Initializes the log builder with defaults./// **NOTE:** This method won't read from any environment variables./// Use the [`filter`] and [`write_style`] methods to configure the builder/// or use [`from_env`] or [`from_default_env`] instead./// Create a new builder and configure filters and style:/// use env_logger::{Builder, WriteStyle};///     .write_style(WriteStyle::Always)/// [`filter`]: #method.filter/// [`write_style`]: #method.write_style/// [`from_env`]: #method.from_env/// [`from_default_env`]: #method.from_default_env/// Initializes the log builder from the environment./// The variables used to read configuration from can be tweaked before/// passing in./// Initialise a logger reading the log filter from an environment variable/// called `MY_LOG`:/// let mut builder = Builder::from_env("MY_LOG");/// builder.init();/// Initialise a logger using the `MY_LOG` variable for filtering and/// `MY_LOG_STYLE` for whether or not to write styles:/// use env_logger::{Builder, Env};/// let env = Env::new().filter("MY_LOG").write_style("MY_LOG_STYLE");/// let mut builder = Builder::from_env(env);parse_env/// Applies the configuration from the environment./// This function allows a builder to be configured with default parameters,/// to be then overridden by the environment./// Initialise a logger with filter level `Off`, then override the log/// filter from an environment variable called `MY_LOG`:/// builder.filter_level(LevelFilter::Off);/// builder.parse_env("MY_LOG");/// Initialise a logger with filter level `Off`, then use the `MY_LOG`/// variable to override filtering and `MY_LOG_STYLE` to override  whether/// or not to write styles:/// builder.parse_env(env);from_default_env/// Initializes the log builder from the environment using default variable names./// This method is a convenient way to call `from_env(Env::default())` without/// having to use the `Env` type explicitly. The builder will use the/// [default environment variables]./// Initialise a logger using the default environment variables:/// [default environment variables]: struct.Env.html#default-environment-variablesparse_default_env/// Applies the configuration from the environment using default variable names./// This method is a convenient way to call `parse_env(Env::default())` without/// Initialise a logger with filter level `Off`, then configure it using the/// default environment variables:/// builder.parse_default_env();/// Sets the format function for formatting the log output./// This function is called on each record logged and should format the/// log record and output it to the given [`Formatter`]./// The format function is expected to output the string directly to the/// `Formatter` so that implementations can use the [`std::fmt`] macros/// to format and output without intermediate heap allocations. The default/// `env_logger` formatter takes advantage of this./// Use a custom format to write only the log message:/// builder.format(|buf, record| writeln!(buf, "{}", record.args()));/// [`Formatter`]: fmt/struct.Formatter.html/// [`String`]: https://doc.rust-lang.org/stable/std/string/struct.String.html/// [`std::fmt`]: https://doc.rust-lang.org/std/fmt/index.htmldefault_format/// Use the default format./// This method will clear any custom format set on the builder./// Whether or not to write the level in the default format./// Whether or not to write the module path in the default format./// Whether or not to write the target in the default format./// Configures the amount of spaces to use to indent multiline log records./// A value of `None` disables any kind of indentation./// Configures if timestamp should be included and in what precision.format_timestamp_secs/// Configures the timestamp to use second precision.format_timestamp_millis/// Configures the timestamp to use millisecond precision.format_timestamp_micros/// Configures the timestamp to use microsecond precision.format_timestamp_nanos/// Configures the timestamp to use nanosecond precision./// Configures the end of line suffix./// Only include messages for info and above for logs in `path::to::module`:/// builder.filter_module("path::to::module", LevelFilter::Info);/// Only include messages for info and above for logs globally:/// builder.filter_level(LevelFilter::Info);/// Adds filters to the logger./// builder.filter(Some("path::to::module"), LevelFilter::Info);parse_filters/// Parses the directives string in the same form as the `RUST_LOG`/// environment variable./// See the module documentation for more details./// Sets the target for the log output./// Env logger can log to either stdout, stderr or a custom pipe. The default is stderr./// The custom pipe can be used to send the log messages to a custom sink (for example a file)./// Do note that direct writes to a file can become a bottleneck due to IO operation times./// Write log message to `stdout`:/// use env_logger::{Builder, Target};/// builder.target(Target::Stdout);/// Sets whether or not styles will be written./// This can be useful in environments that don't support control characters/// for setting colors./// Never attempt to write styles:/// builder.write_style(WriteStyle::Never);/// Parses whether or not to write styles in the same form as the `RUST_LOG_STYLE`/// Sets whether or not the logger will be used in unit tests./// If `is_test` is `true` then the logger will allow the testing framework to/// capture log records rather than printing them to the terminal directly.try_init/// Initializes the global logger with the built env logger./// This should be called early in the execution of a Rust program. Any log/// events that occur before initialization will be ignored./// This function will fail if it is called more than once, or if another/// library has already initialized a global logger./// This function will panic if it is called more than once, or if another/// Build an env logger./// The returned logger implements the `Log` trait and can be installed manually/// or nested within another logger./// Creates the logger from the environment./// Create a logger reading the log filter from an environment variable/// use env_logger::Logger;/// let logger = Logger::from_env("MY_LOG");/// Create a logger using the `MY_LOG` variable for filtering and/// use env_logger::{Logger, Env};/// let env = Env::new().filter_or("MY_LOG", "info").write_style_or("MY_LOG_STYLE", "always");/// let logger = Logger::from_env(env);/// Creates the logger from the environment using default variable names./// having to use the `Env` type explicitly. The logger will use the/// Creates a logger using the default environment variables:/// let logger = Logger::from_default_env();/// Returns the maximum `LevelFilter` that this env logger instance is/// Get a default set of environment variables./// Specify an environment variable to read the filter from.filter_or/// If the variable is not set, the default value will be used.default_filter_or/// Use the default environment variable to read the filter from.get_filter/// Specify an environment variable to read the style from.write_style_ordefault_write_style_or/// Use the default environment variable to read the style from.get_write_stylenew_with_defaultstd_fmt_impls/// Attempts to initialize the global logger with an env logger./// Initializes the global logger with an env logger.try_init_from_env/// Attempts to initialize the global logger with an env logger from the given/// environment variables./// Initialise a logger using the `MY_LOG` environment variable for filters/// and `MY_LOG_STYLE` for writing colors:/// # fn run() -> Result<(), Box<::std::error::Error>> {/// env_logger::try_init_from_env(env)?;/// Ok(())/// # run().unwrap();init_from_env/// Initializes the global logger with an env logger from the given environment/// variables./// env_logger::init_from_env(env);/// Create a new builder with the default environment variables./// The builder can be configured before being initialized./// This is a convenient way of calling [`Builder::from_default_env`]./// [`Builder::from_default_env`]: struct.Builder.html#method.from_default_env/// Create a builder from the given environment variables.env_get_filter_reads_from_var_if_setenv_get_filter_reads_from_default_if_var_not_setenv_get_write_style_reads_from_var_if_setenv_get_write_style_reads_from_default_if_var_not_setbuilder_parse_env_overrides_existing_filters//! A simple logger that can be configured via environment variables, for use//! with the logging facade exposed by the [`log` crate][log-crate-url].//! Despite having "env" in its name, **`env_logger`** can also be configured by//! other means besides environment variables. See [the examples][gh-repo-examples]//! in the source repository for more approaches.//! By default, `env_logger` writes logs to `stderr`, but can be configured to//! instead write them to `stdout`.//! use log::{debug, error, log_enabled, info, Level};//! env_logger::init();//! debug!("this is a debug {}", "message");//! error!("this is printed by default");//! if log_enabled!(Level::Info) {//!     let x = 3 * 4; // expensive computation//!     info!("the answer was: {}", x);//! Assumes the binary is `main`://! ```{.bash}//! $ RUST_LOG=error ./main//! [2017-11-09T02:12:24Z ERROR main] this is printed by default//! $ RUST_LOG=info ./main//! [2017-11-09T02:12:24Z INFO main] the answer was: 12//! $ RUST_LOG=debug ./main//! [2017-11-09T02:12:24Z DEBUG main] this is a debug message//! You can also set the log level on a per module basis://! $ RUST_LOG=main=info ./main//! And enable all logging://! $ RUST_LOG=main ./main//! If the binary name contains hyphens, you will need to replace//! them with underscores://! $ RUST_LOG=my_app ./my-app//! [2017-11-09T02:12:24Z DEBUG my_app] this is a debug message//! [2017-11-09T02:12:24Z ERROR my_app] this is printed by default//! [2017-11-09T02:12:24Z INFO my_app] the answer was: 12//! This is because Rust modules and crates cannot contain hyphens//! in their name, although `cargo` continues to accept them.//! See the documentation for the [`log` crate][log-crate-url] for more//! information about its API.//! ## Enabling logging//! Log levels are controlled on a per-module basis, and **by default all//! logging is disabled except for the `error` level**.//! Logging is controlled via the **`RUST_LOG`** environment variable. The//! value of this environment variable is a comma-separated list of *logging//! directives*. A logging directive is of the form://! example::log::target=level//! The log target is typically equal to the path of the module the message//! in question originated from, though it can be overriden.//! The path is rooted in the name of the crate it was compiled for, so if//! your program is in a file called, for example, `hello.rs`, the path would//! simply be be `hello`.//! Furthermore, the log can be filtered using prefix-search based on the//! specified log target. A value of, for example, `RUST_LOG=example`, would//! match all of the messages with targets://! * `example`//! * `example::test`//! * `example::test::module::submodule`//! * `examples::and_more_examples`//! When providing the crate name or a module path, explicitly specifying the//! log level is optional. If omitted, all logging for the item will be//! enabled.//! The names of the log levels that may be specified correspond to the//! variations of the [`log::Level`][level-enum] enum from the `log`//! crate. They are://! * `error`//! * `warn`//! * `info`//! * `debug`//! * `trace`//! There is also a pseudo logging level, `off`, which may be specified to//! disable all logging for a given module or for the entire application. As//! with the logging levels, the letter case is not significant[^fn-off].//! [^fn-off]: Similar to the universe of log level names, the `off` pseudo//!    log level feature is also provided by the underlying `log` crate.//! The letter case is not significant for the logging level names; e.g.,//! `debug`, `DEBUG`, and `dEbuG` all represent the same logging level. For//! consistency, our convention is to use the lower case names. Where our docs//! do use other forms, they do so in the context of specific examples, so you//! won't be surprised if you see similar usage in the wild.//! As the log level for a module is optional, the module to enable logging for//! is also optional. **If only a level is provided, then the global log//! level for all modules is set to this value.**//! Some examples of valid values of `RUST_LOG` are://! * `hello` turns on all logging for the 'hello' module//! * `trace` turns on all logging for the application, regardless of its name//! * `TRACE` turns on all logging for the application, regardless of its name (same as previous)//! * `info` turns on all info logging//! * `INFO` turns on all info logging (same as previous)//! * `hello=debug` turns on debug logging for 'hello'//! * `hello=DEBUG` turns on debug logging for 'hello' (same as previous)//! * `hello,std::option` turns on hello, and std's option logging//! * `error,hello=warn` turn on global error logging and also warn for hello//! * `error,hello=off`  turn on global error logging, but turn off logging for hello//! * `off` turns off all logging for the application//! * `OFF` turns off all logging for the application (same as previous)//! ## Filtering results//! A `RUST_LOG` directive may include a regex filter. The syntax is to append `/`//! followed by a regex. Each message is checked against the regex, and is only//! logged if it matches. Note that the matching is done after formatting the//! log string but before adding any logging meta-data. There is a single filter//! for all modules.//! Some examples://! * `hello/foo` turns on all logging for the 'hello' module where the log//!   message includes 'foo'.//! * `info/f.o` turns on all info logging where the log message includes 'foo',//!   'f1o', 'fao', etc.//! * `hello=debug/foo*foo` turns on debug logging for 'hello' where the log//!   message includes 'foofoo' or 'fofoo' or 'fooooooofoo', etc.//! * `error,hello=warn/[0-9]scopes` turn on global error logging and also//!   warn for hello. In both cases the log message must include a single digit//!   number followed by 'scopes'.//! ## Capturing logs in tests//! Records logged during `cargo test` will not be captured by the test harness by default.//! The [`Builder::is_test`] method can be used in unit tests to ensure logs will be captured://! # #[macro_use] extern crate log;//! #[cfg(test)]//! mod tests {//!     fn init() {//!         let _ = env_logger::builder().is_test(true).try_init();//!     #[test]//!     fn it_works() {//!         init();//!         info!("This record will be captured by `cargo test`");//!         assert_eq!(2, 1 + 1);//! Enabling test capturing comes at the expense of color and other style support//! and may have performance implications.//! ## Disabling colors//! Colors and other styles can be configured with the `RUST_LOG_STYLE`//! environment variable. It accepts the following values://! * `auto` (default) will attempt to print style characters, but don't force the issue.//! If the console isn't available on Windows, or if TERM=dumb, for example, then don't print colors.//! * `always` will always print style characters even if they aren't supported by the terminal.//! This includes emitting ANSI colors on Windows if the console API is unavailable.//! * `never` will never print style characters.//! ## Tweaking the default format//! Parts of the default format can be excluded from the log output using the [`Builder`].//! The following example excludes the timestamp from the log output://! env_logger::builder()//!     .format_timestamp(None)//!     .init();//! ### Stability of the default format//! The default format won't optimise for long-term stability, and explicitly makes no//! guarantees about the stability of its output across major, minor or patch version//! bumps during `0.x`.//! If you want to capture or interpret the output of `env_logger` programmatically//! then you should use a custom format.//! ### Using a custom format//! Custom formats can be provided as closures to the [`Builder`].//! These closures take a [`Formatter`] and `log::Record` as arguments://!     .format(|buf, record| {//!         writeln!(buf, "{}: {}", record.level(), record.args())//! See the [`fmt`] module for more details about custom formats.//! ## Specifying defaults for environment variables//! `env_logger` can read configuration from environment variables.//! If these variables aren't present, the default value to use can be tweaked with the [`Env`] type.//! The following example defaults to log `warn` and above if the `RUST_LOG` environment variable//! isn't set://! use env_logger::Env;//! env_logger::Builder::from_env(Env::default().default_filter_or("warn")).init();//! [gh-repo-examples]: https://github.com/env-logger-rs/env_logger/tree/main/examples//! [level-enum]: https://docs.rs/log/latest/log/enum.Level.html//! [log-crate-url]: https://docs.rs/log///! [`Builder`]: struct.Builder.html//! [`Builder::is_test`]: struct.Builder.html#method.is_test//! [`Env`]: struct.Env.html//! [`fmt`]: fmt/index.html// When compiled for the rustc compiler itself we want to make sure that this is// an unstable crate/// Compare self to `key` and return `true` if they are equal.Equivalent/// Key equivalence trait./// This trait allows hash table lookup to be customized. It has one blanket/// implementation that uses the regular solution with `Borrow` and `Eq`, just/// like `HashMap` does, so that you can pass `&str` to lookup into a map with/// `String` keys and so on./// # Contract/// The implementor **must** hash like `K`, if it is hashable.compare/// Compare self to `key` and return their ordering.Comparable/// Key ordering trait./// This trait allows ordered map lookup to be customized. It has one blanket/// implementation that uses the regular solution with `Borrow` and `Ord`, just/// like `BTreeMap` does, so that you can pass `&str` to lookup into a map with//! [`Equivalent`] and [`Comparable`] are traits for key comparison in maps.//! These may be used in the implementation of maps where the lookup type `Q`//! may be different than the stored key type `K`.//! * `Q: Equivalent<K>` checks for equality, similar to the `HashMap<K, V>`//!   constraint `K: Borrow<Q>, Q: Eq`.//! * `Q: Comparable<K>` checks the ordering, similar to the `BTreeMap<K, V>`//!   constraint `K: Borrow<Q>, Q: Ord`.//! These traits are not used by the maps in the standard library, but they may//! add more flexibility in third-party map implementations, especially in//! situations where a strict `K: Borrow<Q>` relationship is not available.//! use equivalent::*;//! use std::cmp::Ordering;//! pub struct Pair<A, B>(pub A, pub B);//! impl<'a, A: ?Sized, B: ?Sized, C, D> Equivalent<(C, D)> for Pair<&'a A, &'a B>//!     A: Equivalent<C>,//!     B: Equivalent<D>,//!     fn equivalent(&self, key: &(C, D)) -> bool {//!         self.0.equivalent(&key.0) && self.1.equivalent(&key.1)//! impl<'a, A: ?Sized, B: ?Sized, C, D> Comparable<(C, D)> for Pair<&'a A, &'a B>//!     A: Comparable<C>,//!     B: Comparable<D>,//!     fn compare(&self, key: &(C, D)) -> Ordering {//!         match self.0.compare(&key.0) {//!             Ordering::Equal => self.1.compare(&key.1),//!             not_equal => not_equal,//!     let key = (String::from("foo"), String::from("bar"));//!     let q1 = Pair("foo", "bar");//!     let q2 = Pair("boo", "bar");//!     let q3 = Pair("foo", "baz");//!     assert!(q1.equivalent(&key));//!     assert!(!q2.equivalent(&key));//!     assert!(!q3.equivalent(&key));//!     assert_eq!(q1.compare(&key), Ordering::Equal);//!     assert_eq!(q2.compare(&key), Ordering::Less);//!     assert_eq!(q3.compare(&key), Ordering::Greater);/// A probe object, which is used for probing for features./// Create this with [`ProbeProbeo::new`](#method.new), and then probe with/// one of the probing methods./// Creates a new [`Probe`](struct.Probe.html) object with a default/// In particular, it consults the environment variable `"RUSTC"` to determine/// what Rust compiler to use, and the environment variable `"OUT_DIR"` to/// determine where to put object files. If these are not set, they default to/// the values `"rustc"` and `"target"`, respectively./// If the child `rustc` cannot be started or communicated with./// use feature_probe::Probe;/// let probe = Probe::new();/// assert!( probe.probe_type("u32") );/// Probes for the existence of the given type by name./// assert!(   probe.probe_type("u32") );/// assert!( ! probe.probe_type("u512") );/// Probes whether the given expression can be compiled./// assert!(   probe.probe_expression("3 + 4") );/// assert!( ! probe.probe_expression("3 + true") );/// Probes for whether a whole program can be compiled./// # extern crate feature_probe;/// assert!(   probe.probe("fn main() { }") );/// assert!( ! probe.probe("fn main(args: Vec<String>) { }") );probe_result/// assert_eq!( probe.probe_result("fn main() { }").unwrap(),                  true );/// assert_eq!( probe.probe_result("fn main(args: Vec<String>) { }").unwrap(), false );env_var_or//! To support multiple versions of Rust, it's often necessary to conditionally//! compile parts of our libraries or programs. It's possible to allow users to//! specify what features to enable, but detection is better, because users get//! all the features that their version of Rust supports. And while we could check//! the rustc version, it's better to probe for individual features. That way,//! code will work both on nightly, and on stable releases after particular features//! stabilize, without changes.//! It’s [on crates.io](https://crates.io/crates/feature-probe), so you can add//! feature-probe = "0.1.1"//! Then add to your `build.rs`://! ```no_compile//! extern crate feature_probe;//! use feature_probe::Probe;//! Then you can probe for features such as types or expressions. For example://! fn main () {//!     let probe = Probe::new();//!     if probe.probe_type("i128") {//!         println!("cargo:rustc-cfg=int_128");//!     if probe.probe_type("::std::ops::RangeInclusive<u64>") {//!         println!("cargo:rustc-cfg=inclusive_range");//! This crate supports Rust version 1.16.0 and later.BuildHasherDefaultFnvHasher/// An implementation of the Fowler–Noll–Vo hash function./// See the [crate documentation](index.html) for more details.with_key/// Create an FNV hasher starting with a state corresponding/// to the hash `key`.FnvBuildHasher/// A builder for default FNV hashers.FnvHashMap/// A `HashMap` using a default FNV hasher./// A `HashSet` using a default FNV hasher.fnv1arepeat_10repeat_500basic_tests//! An implementation of the [Fowler–Noll–Vo hash function][chongo].//! The FNV hash function is a custom `Hasher` implementation that is more//! efficient for smaller hash keys.//! [The Rust FAQ states that][faq] while the default `Hasher` implementation,//! SipHash, is good in many cases, it is notably slower than other algorithms//! with short keys, such as when you have a map of integers to other values.//! In cases like these, [FNV is demonstrably faster][graphs].//! Its disadvantages are that it performs badly on larger inputs, and//! provides no protection against collision attacks, where a malicious user//! can craft specific keys designed to slow a hasher down. Thus, it is//! important to profile your program to ensure that you are using small hash//! keys, and be certain that your program could not be exposed to malicious//! inputs (including being a networked server).//! The Rust compiler itself uses FNV, as it is not worried about//! denial-of-service attacks, and can assume that its inputs are going to be//! small—a perfect use case for FNV.//! [chongo]: http://www.isthe.com/chongo/tech/comp/fnv/index.html//! [faq]: https://www.rust-lang.org/en-US/faq.html#why-are-rusts-hashmaps-slow//! [graphs]: https://cglab.ca/~abeinges/blah/hash-rs//// Resulting lengthAddLength/// Helper trait for `arr!` macroN1N2Inc/// Helper type for `arr!` macroarr_implarr/// Macro allowing for easy generation of Generic Arrays./// Example: `let test = arr![u32; 1, 2, 3];`DocTests/// # With ellision/// Testing that lifetimes aren't transmuted when they're ellided./// ```compile_fail/// #[macro_use] extern crate generic_array;/// fn main() {///    fn unsound_lifetime_extension<'a, A>(a: &'a A) -> &'static A {///        arr![&A; a][0]///    }///    fn unsound_lifetime_extension<'a, A>(a: &'a A) -> &'a A {/// # Without ellision/// Testing that lifetimes aren't transmuted when they're specified explicitly.///        arr![&'a A; a][0]///        arr![&'static A; a][0]doctests_only//! Implementation for `arr!` macro.sequenceMappedLengthGenericSequence/// Mapped sequence typeMappedGenericSequence/// Defines the relationship between one generic sequence and another,/// for operations such as `map` and `zip`.MappedSequence/// Accessor type for a mapped generic sequence/// Maps a `GenericSequence` to another `GenericSequence`./// If the mapping function panics, any already initialized elements in the new sequence/// will be dropped, AND any unused elements in the source sequence will also be dropped.Rhszip/// Combines two `GenericSequence` instances and iterates through both of them,/// initializing a new `GenericSequence` with the result of the zipped mapping function./// will be dropped, AND any unused elements in the source sequences will also be dropped./// Folds (or reduces) a sequence of data into a single value./// If the fold function panics, any unused elements will be dropped.FunctionalSequence/// Defines functional programming methods for generic sequences//! Functional programming with generic sequences//! Please see `tests/generics.rs` for examples of how to best use these in your generic functions.LOWER_CHARSUPPER_CHARS//! Generic array are commonly used as a return value for hash digests, so//! it's a good idea to allow to hexlify them easily. This module implements//! `std::fmt::LowerHex` and `std::fmt::UpperHex` traits.//! Example://! # #[macro_use]//! # extern crate generic_array;//! # extern crate typenum;//! # fn main() {//! let array = arr![u8; 10, 20, 30];//! assert_eq!(format!("{:x}", array), "0a141e");//! # }SeqAccess_t_nGAVisitorvisit_seqtest_deserializetest_serialized_size//! Serde serialization/deserialization implementationtest_zeroizefunctionalArrayTypeimpl_from33343536373839414243444546474950515253545556575960616263708090200300500// Invariants: index <= index_back <= N// Only values in array[index..index_back] are alive at any given time.// Values from array[..index] and array[index_back..] are already moved/dropped.index_backGenericArrayIter/// An iterator that moves out of a `GenericArray`sendtest_send_iter/// Returns the remaining items of this iterator as a slice/// Returns the remaining items of this iterator as a mutable slice// Based on work in rust-lang/rust#49000//! `GenericArray` iterator implementation.// TODO: Implement `TrustedLen` when stabilizedimpl_serdebitB0B1uintUIntUTerm/// Associated type representing the array type for the number/// Trait making `GenericArray` work, marking types to be used as length of an arrayparent1parent2GenericArrayImplEven/// Internal type used to generate a struct of appropriate sizeGenericArrayImplOdd/// Struct representing a generic array - `GenericArray<T, N>` works like [T; N]ArrayBuilder/// Creates an array one element at a time using a mutable iterator/// you can write to with `ptr::write`./// Increment the position while iterating to mark off created elements,/// which will be dropped if `into_inner` is not called.iter_position/// Creates a mutable iterator for writing to the array using `ptr::write`./// Increment the position value given as a mutable reference as you iterate/// to mark how many elements have been created./// When done writing (assuming all elements have been written to),/// get the inner array.ArrayConsumer/// Consumes an array./// Increment the position while iterating and any leftover elements/// will be dropped if position does not go to N/// Creates an iterator and mutable reference to the internal position/// to keep track of consumed elements./// Increment the position as you iterate to mark off consumed elementsfrom_iter_length_failinverted_zipLhsinverted_zip2/// Extracts a slice containing the entire array./// Extracts a mutable slice containing the entire array./// Converts slice to a generic array reference with inferred length;/// # Panics/// Panics if the slice is not equal to the length of the array.from_mut_slice/// Converts mutable slice to a mutable generic array referenceclone_from_slice/// Construct a `GenericArray` from a slice by cloning its contentfrom_exact_iter/// Creates a new `GenericArray` instance from an iterator with a specific size./// Returns `None` if the size is not equal to the number of elements in the `GenericArray`./// A reimplementation of the `transmute` function, avoiding problems/// when the compiler can't prove equal sizes.black_box// Compile with:// cargo rustc --lib --profile test --release --//      -C target-cpu=native -C opt-level=3 --emit asm// and view the assembly to make sure test_assembly generates// SIMD instructions instead of a naive loop.test_assembly//! This crate implements a structure that can be used as a generic array type.//! Core Rust array types `[T; N]` can't be used generically with//! respect to `N`, so for example this://! ```rust{compile_fail}//! struct Foo<T, N> {//!     data: [T; N]//! won't work.//! **generic-array** exports a `GenericArray<T,N>` type, which lets//! the above be implemented as://! use generic_array::{ArrayLength, GenericArray};//! struct Foo<T, N: ArrayLength<T>> {//!     data: GenericArray<T,N>//! The `ArrayLength<T>` trait is implemented by default for//! [unsigned integer types](../typenum/uint/index.html) from//! [typenum](../typenum/index.html)://! # use generic_array::{ArrayLength, GenericArray};//! use generic_array::typenum::U5;//! struct Foo<N: ArrayLength<i32>> {//!     data: GenericArray<i32, N>//! let foo = Foo::<U5>{data: GenericArray::default()};//! For example, `GenericArray<T, U5>` would work almost like `[T; 5]`://!     data: GenericArray<T, N>//! let foo = Foo::<i32, U5>{data: GenericArray::default()};//! For ease of use, an `arr!` macro is provided - example below://! let array = arr![u32; 1, 2, 3];//! assert_eq!(array[2], 3);/// `GenericArray` associated length/// Concrete sequence type used in conjuction with reference implementations of `GenericSequence`/// Initializes a new sequence instance using the given function./// If the generator function panics while initializing the sequence,/// any already initialized elements will be dropped./// Defines some sequence with an associated length and iteration capabilities./// This is useful for passing N-length generic arrays as generics.SequenceItem/// Accessor for `GenericSequence` item type, which is really `IntoIterator::Item`/// For deeply nested generic mapped sequence types, like shown in `tests/generics.rs`,/// this can be useful for keeping things organized.LongerShorterShorten/// `GenericSequence` that has one more element than `Self`/// Returns a new array with the given element appended to the end of it./// Example:/// # use generic_array::{arr, sequence::Lengthen};/// # fn main() {/// let a = arr![i32; 1, 2, 3];/// let b = a.append(4);/// assert_eq!(b, arr![i32; 1, 2, 3, 4]);/// # }prepend/// Returns a new array with the given element prepended to the front of it./// let b = a.prepend(4);/// assert_eq!(b, arr![i32; 4, 1, 2, 3]);Lengthen/// Defines any `GenericSequence` which can be lengthened or extended by appending/// or prepending an element to it./// Any lengthened sequence can be shortened back to the original using `pop_front` or `pop_back`/// `GenericSequence` that has one less element than `Self`pop_back/// Returns a new array without the last element, and the last element./// # use generic_array::{arr, sequence::Shorten};/// let a = arr![i32; 1, 2, 3, 4];/// let (init, last) = a.pop_back();/// assert_eq!(init, arr![i32; 1, 2, 3]);/// assert_eq!(last, 4);pop_front/// Returns a new array without the first element, and the first element./// let (head, tail) = a.pop_front();/// assert_eq!(head, 1);/// assert_eq!(tail, arr![i32; 2, 3, 4]);/// Defines a `GenericSequence` which can be shortened by removing the first or last element from it./// Additionally, any shortened sequence can be lengthened by/// appending or prepending an element to it.Add1Sub1First/// First part of the resulting split array/// Second part of the resulting split array/// Splits an array at the given index, returning the separate parts of the array.Split/// Defines a `GenericSequence` that can be split into two parts at a given pivot index.DiffRest/// Sequence to be concatenated with `self`/// Resulting sequence formed by the concatenation./// Concatenate, or join, two sequences.Concat/// Defines `GenericSequence`s which can be joined together, forming a larger array.//! Useful traits for manipulating sequences of data stored in `GenericArray`sFailHasArgNameOccurOptvalUnicodeWidthStrgrpsOptGroupparsing_styleParsingStylelong_only/// A description of the options that a program can handle./// Create a blank set of options./// Set the parsing style./// Set or clear "long options only" mode./// In "long options only" mode, short options cannot be clustered/// together, and long options can be given with either a single/// "-" or the customary "--".  This mode also changes the meaning/// of "-a=b"; in the ordinary mode this will parse a short option/// "-a" with argument "=b"; whereas in long-options-only mode the/// argument will be simply "b".opt/// Create a generic option group, stating all parameters explicitly.optflag/// Create a long option that is optional and does not take an argument./// * `short_name` - e.g. `"h"` for a `-h` option, or `""` for none/// * `long_name` - e.g. `"help"` for a `--help` option, or `""` for none/// * `desc` - Description for usage help/// # use getopts::Options;/// let mut opts = Options::new();/// opts.optflag("h", "help", "help flag");/// let matches = opts.parse(&["-h"]).unwrap();/// assert!(matches.opt_present("h"));optflagmulti/// Create a long option that can occur more than once and does not/// take an argument./// opts.optflagmulti("v", "verbose", "verbosity flag");/// let matches = opts.parse(&["-v", "--verbose"]).unwrap();/// assert_eq!(2, matches.opt_count("v"));optflagopt/// Create a long option that is optional and takes an optional argument./// * `hint` - Hint that is used in place of the argument in the usage help,///   e.g. `"FILE"` for a `-o FILE` option/// opts.optflagopt("t", "text", "flag with optional argument", "TEXT");/// let matches = opts.parse(&["--text"]).unwrap();/// assert_eq!(None, matches.opt_str("text"));/// let matches = opts.parse(&["--text=foo"]).unwrap();/// assert_eq!(Some("foo".to_owned()), matches.opt_str("text"));optmulti/// Create a long option that is optional, takes an argument, and may occur/// multiple times./// opts.optmulti("t", "text", "text option", "TEXT");/// let matches = opts.parse(&["-t", "foo", "--text=bar"]).unwrap();/// let values = matches.opt_strs("t");/// assert_eq!(2, values.len());/// assert_eq!("foo", values[0]);/// assert_eq!("bar", values[1]);optopt/// Create a long option that is optional and takes an argument./// # use getopts::Fail;/// opts.optopt("o", "optional", "optional text option", "TEXT");/// let matches = opts.parse(&["arg1"]).unwrap();/// assert_eq!(None, matches.opt_str("optional"));/// let matches = opts.parse(&["--optional", "foo", "arg1"]).unwrap();/// assert_eq!(Some("foo".to_owned()), matches.opt_str("optional"));reqopt/// Create a long option that is required and takes an argument./// opts.reqopt("m", "mandatory", "madatory text option", "TEXT");/// let result = opts.parse(&["--mandatory", "foo"]);/// let result = opts.parse(&["--optional", "foo"]);/// assert_eq!(Fail::OptionMissing("mandatory".to_owned()), result.unwrap_err());/// Parse command line arguments according to the provided options./// On success returns `Ok(Matches)`. Use methods such as `opt_present`/// `opt_str`, etc. to interrogate results./// Returns `Err(Fail)` on failure: use the `Debug` implementation of `Fail`/// to display information about it.short_usage/// Derive a short one-line usage summary from a set of long options./// Derive a formatted message from a set of options.usage_with_format/// Derive a custom formatted message from a set of options. The formatted options provided to/// a closure as an iterator.usage_items/// Derive usage items from a set of options.validate_namesFloatingFrees/// Flags and "free" arguments can be freely inter-mixed.StopAtFirstFree/// As soon as a "free" argument (i.e. non-flag) is encountered, stop/// considering any remaining arguments as flags./// What parsing style to use when parsing arguments.Long/// A string representing the long name of an option./// For example: "help"Short/// A char representing the short name of an option./// For example: 'h'/// Name of an option. Either a string or a single char./// The option requires an argument./// The option takes no argument./// The option argument is optional./// Describes whether an option has an argument.Req/// The option occurs once.Optional/// The option occurs at most once.Multi/// The option occurs zero or more times./// Describes how often an option may occur./// Name of the optionhasarg/// Whether it has an argumentoccur/// How often it can occuraliasesOpt/// Which options it aliases/// A description of a possible option.short_name/// Short name of the option, e.g. `h` for a `-h` optionlong_name/// Long name of the option, e.g. `help` for a `--help` option/// Hint for argument, e.g. `FILE` for a `-o FILE` optiondesc/// Description for usage help text/// Whether option has an argument/// One group of options, e.g., both `-h` and `--help`, along with/// their shared description and properties.Given/// Describes whether an option is given at all or has a value.opts/// Options that matchedvals/// Values of the Options that matched and their positionsfree/// Free string fragmentsargs_end/// Index of first free fragment after "--" separatorMatches/// The result of checking command line arguments. Contains a vector/// of matches and a vector of free strings.ArgumentMissing/// The option requires an argument but none was passed.UnrecognizedOption/// The passed option is not declared among the possible options.OptionMissing/// A required option is not present.OptionDuplicated/// A single occurrence option is being used multiple times.UnexpectedArgument/// There's an argument being passed to a non-argument option./// The type returned when the command line does not conform to the/// expected format. Use the `Debug` implementation to output detailed/// The result of parsing a command line with a set of options.long_to_short/// Translate OptGroup into Opt./// (Both short and long names correspond to different Opts).opt_valsopt_valopt_defined/// Returns true if an option was definedopt_present/// Returns true if an option was matched./// This function will panic if the option name is not defined.opt_count/// Returns the number of times an option was matched.opt_positions/// Returns a vector of all the positions in which an option was matched.opts_present/// Returns true if any of several options were matched.opts_present_any/// Similar to `opts_present` but accepts any argument that can be converted/// into an iterator over string references./// This function might panic if some option name is not defined./// opts.optopt("a", "alpha", "first option", "STR");/// opts.optopt("b", "beta", "second option", "STR");/// let args = vec!["-a", "foo"];/// let matches = &match opts.parse(&args) {///     Ok(m) => m,///     _ => panic!(),/// assert!(matches.opts_present_any(&["alpha"]));/// assert!(!matches.opts_present_any(&["beta"]));opts_str/// Returns the string argument supplied to one of several matching options or `None`.opts_str_first/// Returns the string argument supplied to the first matching option of/// several options or `None`./// Similar to `opts_str` but accepts any argument that can be converted/// let args = vec!["-a", "foo", "--beta", "bar"];/// assert_eq!(Some("foo".to_string()), matches.opts_str_first(&["alpha", "beta"]));/// assert_eq!(Some("bar".to_string()), matches.opts_str_first(&["beta", "alpha"]));opt_strs/// Returns a vector of the arguments provided to all matches of the given/// option./// Used when an option accepts multiple values.opt_strs_pos/// option, together with their positions.opt_str/// Returns the string argument supplied to a matching option or `None`.opt_default/// Returns the matching string, a default, or `None`./// Returns `None` if the option was not present, `def` if the option was/// present but no argument was provided, and the argument if the option was/// present and an argument was provided.opt_get/// Returns some matching value or `None`./// Similar to opt_str, also converts matching argument using FromStr.opt_get_default/// Returns a matching value or default./// Similar to opt_default, except the two differences./// Instead of returning None when argument was not present, return `def`./// Instead of returning &str return type T, parsed using str::parse().free_trailing_start/// Returns index of first free argument after "--"./// If double-dash separator is present and there are some args after it in/// the argument list then the method returns index into `free` vector/// indicating first argument after it./// behind it./// let matches = opts.parse(&vec!["arg1", "--", "arg2"]).unwrap();/// let end_pos = matches.free_trailing_start().unwrap();/// assert_eq!(end_pos, 1);/// assert_eq!(matches.free[end_pos], "arg2".to_owned());/// If the double-dash is missing from argument list or if there are no/// arguments after it:/// let matches = opts.parse(&vec!["arg1", "--"]).unwrap();/// assert_eq!(matches.free_trailing_start(), None);/// let matches = opts.parse(&vec!["arg1", "arg2"]).unwrap();is_argfind_optformat_optioneach_split_within/// Splits a string into substrings with possibly internal whitespace,/// each of them at most `lim` bytes long, if possible. The substrings/// have leading and trailing whitespace removed, and are only cut at/// whitespace boundaries.// ignore-lexer-test FIXME #15677//! Simple getopt alternative.//! Construct instance of `Options` and configure it by using  `reqopt()`,//! `optopt()` and other methods that add option configuration. Then call//! `parse()` method and pass into it a vector of actual arguments (not//! including `argv[0]`).//! You'll either get a failure code back, or a match. You'll have to verify//! whether the amount of 'free' arguments in the match is what you expect. Use//! `opt_*` accessors to get argument values out of the matches object.//! Single-character options are expected to appear on the command line with a//! single preceding dash; multiple-character options are expected to be//! proceeded by two dashes. Options that expect an argument accept their//! argument following either a space or an equals sign. Single-character//! options don't require the space. Everything after double-dash "--"  argument//! is considered to be a 'free' argument, even if it starts with dash.//! This crate is [on crates.io](https://crates.io/crates/getopts) and can be//! used by adding `getopts` to the dependencies in your project's `Cargo.toml`.//! getopts = "0.2"//! and this to your crate root://! extern crate getopts;//! The following example shows simple command line parsing for an application//! that requires an input file to be specified, accepts an optional output file//! name following `-o`, and accepts both `-h` and `--help` as optional flags.//! ```{.rust}//! use getopts::Options;//! use std::env;//! fn do_work(inp: &str, out: Option<String>) {//!     println!("{}", inp);//!     match out {//!         Some(x) => println!("{}", x),//!         None => println!("No Output"),//! fn print_usage(program: &str, opts: Options) {//!     let brief = format!("Usage: {} FILE [options]", program);//!     print!("{}", opts.usage(&brief));//!     let args: Vec<String> = env::args().collect();//!     let program = args[0].clone();//!     let mut opts = Options::new();//!     opts.optopt("o", "", "set output file name", "NAME");//!     opts.optflag("h", "help", "print this help menu");//!     let matches = match opts.parse(&args[1..]) {//!         Ok(m) => { m }//!         Err(f) => { panic!("{}", f.to_string()) }//!     };//!     if matches.opt_present("h") {//!         print_usage(&program, opts);//!         return;//!     let output = matches.opt_str("o");//!     let input = if !matches.free.is_empty() {//!         matches.free[0].clone()//!     do_work(&input, output);test_split_withintest_reqopt// Tests for reqopttest_reqopt_missingtest_reqopt_no_argtest_reqopt_multitest_optopt// Tests for optopttest_optopt_missingtest_optopt_no_argtest_optopt_multitest_optflag// Tests for optflagtest_optflag_missingtest_free_trailing_missingtest_free_trailingtest_free_trailing_onlytest_free_trailing_argstest_optflag_long_argtest_optflag_multitest_optflag_short_argtest_optflagmulti_short1// Tests for optflagmultitest_optflagmulti_short2atest_optflagmulti_short2btest_optflagmulti_long1test_optflagmulti_long2test_optflagmulti_mixtest_optflagopt// Tests for optflagopttest_optmulti// Tests for optmultitest_optmulti_missingtest_optmulti_no_argtest_optmulti_multitest_free_argument_is_hyphentest_unrecognized_optiontest_combinedtest_mixed_stoptest_mixed_stop_hyphentest_multitest_nospacetest_nospace_conflicttest_long_to_shorttest_aliases_long_and_shorttest_usagetest_usage_description_wrappingtest_usage_description_multibyte_handlingtest_usage_description_newline_handlingtest_usage_multiwidthtest_usage_short_onlytest_usage_long_onlytest_short_usagetest_nonexistant_opttest_args_with_equalstest_long_only_usagetest_long_only_modetest_long_only_mode_no_short_parsetest_normal_mode_no_long_parsetest_long_name_too_shorttest_undefined_opt_presenttest_opt_defaulttest_opt_gettest_opt_get_defaulttest_opt_positionstest_opt_strs_posutil_libcsys_fill_exactkern_arndssize_tgetrandom_inner// Copyright 2018 Developers of the Rand project.//! Implementation for FreeBSD and NetBSDcloudabi_sys_random_get//! Implementation for CloudABIUNSUPPORTED//! A dummy implementation for unsupported targets which always fails/// A small and `no_std` compatible error type./// The [`Error::raw_os_error()`] will indicate if the error is from the OS, and/// if so, which error code the OS gave the application. If such an error is/// encountered, please consult with your system documentation./// Internally this type is a NonZeroU32, with certain values reserved for/// certain purposes, see [`Error::INTERNAL_START`] and [`Error::CUSTOM_START`].UNKNOWN/// Unknown error.UNAVAILABLE/// System entropy source is unavailable.INTERNAL_START/// Codes below this point represent OS Errors (i.e. positive i32 values)./// Codes at or above this point, but below [`Error::CUSTOM_START`] are/// reserved for use by the `rand` and `getrandom` crates.CUSTOM_START/// Codes at or above this point can be used by users to define their own/// custom errors.raw_os_error/// Extract the raw OS error code (if this error came from the OS)/// This method is identical to `std::io::Error::raw_os_error()`, except/// that it works in `no_std` contexts. If this method returns `None`, the/// error value can still be formatted via the `Display` implementation./// Extract the bare error code./// This code can either come from the underlying OS, or be a custom error./// Use [`Error::raw_os_error()`] to disambiguate.os_errinternal_error// TODO: Convert to a function when min_version >= 1.33/// Internal Error constantsERRNO_NOT_POSITIVEUNKNOWN_IO_ERRORSEC_RANDOM_FAILEDRTL_GEN_RANDOM_FAILEDFAILED_RDRANDNO_RDRANDBINDGEN_CRYPTO_UNDEFBINDGEN_GRV_UNDEFSTDWEB_NO_RNGSTDWEB_RNG_FAILEDRAND_SECURE_FATALinternal_desctest_sizezx_cprng_draw//! Implementation for Fuchsia ZirconSecRandom// TODO: Make extern once extern_types feature is stabilized. See://   https://github.com/rust-lang/rust/issues/43467kSecRandomDefaultSecRandomCopyBytes//! Implementation for iOSerror_impls// For backwards compatibility, we provide the std-only trait implementations// for some platforms, even if they don't enable the "std" feature.use_file"macos.rs"// System-specific implementations.// These should all provide getrandom_inner with the same signature as getrandom./// Fill `dest` with random bytes from the system's preferred random number/// source./// This function returns an error on any failure, including partial reads. We/// make no guarantees regarding the contents of `dest` on error. If `dest` is/// empty, `getrandom` immediately returns success, making no calls to the/// underlying operating system./// Blocking is possible, at least during early boot; see module documentation./// In general, `getrandom` will be fast enough for interactive usage, though/// significantly slower than a user-space CSPRNG; for the latter consider/// [`rand::thread_rng`](https://docs.rs/rand/*/rand/fn.thread_rng.html).// Copyright 2019 Developers of the Rand project.//! Interface to the random number generator of the operating system.//! # Platform sources//! | OS               | interface//! |------------------|---------------------------------------------------------//! | Linux, Android   | [`getrandom`][1] system call if available, otherwise [`/dev/urandom`][2] after successfully polling `/dev/random`//! | Windows          | [`RtlGenRandom`][3]//! | macOS            | [`getentropy()`][19] if available, otherwise [`/dev/random`][20] (identical to `/dev/urandom`)//! | iOS              | [`SecRandomCopyBytes`][4]//! | FreeBSD          | [`getrandom()`][21] if available, otherwise [`kern.arandom`][5]//! | OpenBSD          | [`getentropy`][6]//! | NetBSD           | [`kern.arandom`][7]//! | Dragonfly BSD    | [`/dev/random`][8]//! | Solaris, illumos | [`getrandom`][9] system call if available, otherwise [`/dev/random`][10]//! | Fuchsia OS       | [`cprng_draw`][11]//! | Redox            | [`rand:`][12]//! | CloudABI         | [`cloudabi_sys_random_get`][13]//! | Haiku            | `/dev/random` (identical to `/dev/urandom`)//! | L4RE, SGX, UEFI  | [RDRAND][18]//! | Hermit           | [RDRAND][18] as [`sys_rand`][22] is currently broken.//! | VxWorks          | `randABytes` after checking entropy pool initialization with `randSecure`//! | Web browsers     | [`Crypto.getRandomValues`][14] (see [Support for WebAssembly and asm.js][16])//! | Node.js          | [`crypto.randomBytes`][15] (see [Support for WebAssembly and asm.js][16])//! | WASI             | [`__wasi_random_get`][17]//! Getrandom doesn't have a blanket implementation for all Unix-like operating//! systems that reads from `/dev/urandom`. This ensures all supported operating//! systems are using the recommended interface and respect maximum buffer//! sizes.//! ## Unsupported targets//! By default, compiling `getrandom` for an unsupported target will result in//! a compilation error. If you want to build an application which uses `getrandom`//! for such target, you can either://! - Use [`[replace]`][replace] or [`[patch]`][patch] section in your `Cargo.toml`//! to switch to a custom implementation with a support of your target.//! - Enable the `dummy` feature to have getrandom use an implementation that always//! fails at run-time on unsupported targets.//! [replace]: https://doc.rust-lang.org/cargo/reference/manifest.html#the-replace-section//! [patch]: https://doc.rust-lang.org/cargo/reference/manifest.html#the-patch-section//! ## Support for WebAssembly and asm.js//! Getrandom supports all of Rust's current `wasm32` targets, and it works with//! both Node.js and web browsers. The three Emscripten targets//! `asmjs-unknown-emscripten`, `wasm32-unknown-emscripten`, and//! `wasm32-experimental-emscripten` use Emscripten's `/dev/random` emulation.//! The WASI target `wasm32-wasi` uses the [`__wasi_random_get`][17] function//! defined by the WASI standard.//! Getrandom also supports `wasm32-unknown-unknown` by directly calling//! JavaScript methods. Rust currently has two ways to do this: [bindgen] and//! [stdweb]. Getrandom supports using either one by enabling the//! `wasm-bindgen` or `stdweb` crate features. Note that if both features are//! enabled, `wasm-bindgen` will be used. If neither feature is enabled, calls//! to `getrandom` will always fail at runtime.//! [bindgen]: https://github.com/rust-lang/rust-bindgen//! [stdweb]: https://github.com/koute/stdweb//! ## Early boot//! It is possible that early in the boot process the OS hasn't had enough time//! yet to collect entropy to securely seed its RNG, especially on virtual//! machines.//! Some operating systems always block the thread until the RNG is securely//! seeded. This can take anywhere from a few seconds to more than a minute.//! Others make a best effort to use a seed from before the shutdown and don't//! document much.//! A few, Linux, NetBSD and Solaris, offer a choice between blocking and//! getting an error; in these cases we always choose to block.//! On Linux (when the `getrandom` system call is not available) and on NetBSD//! reading from `/dev/urandom` never blocks, even when the OS hasn't collected//! enough entropy yet. To avoid returning low-entropy bytes, we first read from//! `/dev/random` and only switch to `/dev/urandom` once this has succeeded.//! # Error handling//! We always choose failure over returning insecure "random" bytes. In general,//! on supported platforms, failure is highly unlikely, though not impossible.//! If an error does occur, then it is likely that it will occur on every call to//! `getrandom`, hence after the first successful call one can be reasonably//! confident that no errors will occur.//! On unsupported platforms, `getrandom` always fails. See the [`Error`] type//! for more information on what data is returned on failure.//! [1]: http://man7.org/linux/man-pages/man2/getrandom.2.html//! [2]: http://man7.org/linux/man-pages/man4/urandom.4.html//! [3]: https://docs.microsoft.com/en-us/windows/desktop/api/ntsecapi/nf-ntsecapi-rtlgenrandom//! [4]: https://developer.apple.com/documentation/security/1399291-secrandomcopybytes?language=objc//! [5]: https://www.freebsd.org/cgi/man.cgi?query=random&sektion=4//! [6]: https://man.openbsd.org/getentropy.2//! [7]: https://netbsd.gw.com/cgi-bin/man-cgi?sysctl+7+NetBSD-8.0//! [8]: https://leaf.dragonflybsd.org/cgi/web-man?command=random&section=4//! [9]: https://docs.oracle.com/cd/E88353_01/html/E37841/getrandom-2.html//! [10]: https://docs.oracle.com/cd/E86824_01/html/E54777/random-7d.html//! [11]: https://fuchsia.dev/fuchsia-src/zircon/syscalls/cprng_draw//! [12]: https://github.com/redox-os/randd/blob/master/src/main.rs//! [13]: https://github.com/nuxinl/cloudabi#random_get//! [14]: https://www.w3.org/TR/WebCryptoAPI/#Crypto-method-getRandomValues//! [15]: https://nodejs.org/api/crypto.html#crypto_crypto_randombytes_size_callback//! [16]: #support-for-webassembly-and-asmjs//! [17]: https://github.com/WebAssembly/WASI/blob/master/design/WASI-core.md#__wasi_random_get//! [18]: https://software.intel.com/en-us/articles/intel-digital-random-number-generator-drng-software-implementation-guide//! [19]: https://www.unix.com/man-page/mojave/2/getentropy///! [20]: https://www.unix.com/man-page/mojave/4/random///! [21]: https://www.freebsd.org/cgi/man.cgi?query=getrandom&manpath=FreeBSD+12.0-stable//! [22]: https://github.com/hermitcore/libhermit-rs/blob/09c38b0371cee6f56a541400ba453e319e43db53/src/syscalls/random.rs#L21LazyBoollast_os_erroris_getrandom_availablesize_tc_uint//! Implementation for Linux / AndroidWeakGetEntropyFn//! Implementation for macOS//! Implementation for OpenBSD_rdrand64_stepRETRY_LIMIT// Recommendation from "Intel® Digital Random Number Generator (DRNG) Software// Implementation Guide" - Section 5.2.1 and "Intel® 64 and IA-32 Architectures// Software Developer’s Manual" - Volume 1 - Section 7.3.17.1.rdrand// "rdrand" target feature requires "+rdrnd" flag, see https://github.com/rust-lang/rust/issues/49653.is_rdrand_supported// TODO use is_x86_feature_detected!("rdrand") when that works in core. See:// https://github.com/rust-lang-nursery/stdsimd/issues/464rdrand_exact//! Implementation for SGX using RDRAND instructionGetRandomFn//! Implementation for the Solaris family//! Read from `/dev/random`, with chunks of limited size (256 bytes).//! `/dev/random` uses the Hash_DRBG with SHA512 algorithm from NIST SP 800-90A.//! `/dev/urandom` uses the FIPS 186-2 algorithm, which is considered less//! secure. We choose to read from `/dev/random`.//! Since Solaris 11.3 and mid-2015 illumos, the `getrandom` syscall is available.//! To make sure we can compile on both Solaris and its derivatives, as well as//! function, we check for the existence of getrandom(2) in libc by calling//! libc::dlsym.LazyUsizeopen_readonlyFILE_PATHget_rng_fd// Returns the file descriptor for the device file used to retrieve random// bytes. The file will be opened exactly once. All successful calls will// return the same file descriptor. This file descriptor is never closed.pthread_mutex_tunlockDropGuard//! Implementations that just need to read from a file// This structure represents a lazily initialized static usize value. Useful// when it is preferable to just rerun initialization instead of locking.// Both unsync_init and sync_init will invoke an init() function until it// succeeds, then return the cached value for future calls.// Both methods support init() "failing". If the init() method returns UNINIT,// that value will be returned as normal, but will not be cached.// Users should only depend on the _value_ returned by init() functions.// Specifically, for the following init() function://      fn init() -> usize {//          a();//          let v = b();//          c();//          v//      }// the effects of c() or writes to shared memory will not necessarily be// observed and additional synchronization methods with be needed.UNINIT// The initialization is not completed.unsync_init// Runs the init() function at least once, returning the value of some run// of init(). Multiple callers can run their init() functions in parallel.// init() should always return the same value, if it succeeds.// Identical to LazyUsize except with bool instead of usize.__errorerrno_locationget_errno// Fill a buffer by repeatedly invoking a system call. The `sys_fill` function://   - should return -1 and set errno on failure//   - should return the number of bytes written on successaddr// A "weak" binding to a C function that may or may not be present at runtime.// Used for supporting newer OS features while still building on older systems.// F must be a function pointer of type `unsafe extern "C" fn`. Based off of the// weak! macro in libstd.// Construct a binding to a C function with a given name. This function is// unsafe because `name` _must_ be null terminated.// Return a function pointer if present at runtime. Otherwise, return null.// SAFETY: path must be null terminated, FD must be manually closed.//! Implementation for VxWorkswasirandom_get//! Implementation for WASIjs_sysUint8Arraybindgen// We have to rename wasm_bindgen to bindgen in the Cargo.toml for backwards// compatibility. We have to rename it back here or else the macros will break.CHUNK_SIZERngSourceNodeCryptoBrowserCryptoBrowser// JsValues are always per-thread, so we initialize RngSource for each thread.//   See: https://github.com/rustwasm/wasm-bindgen/pull/955getrandom_initget_selfSelf_JsValuems_cryptocryptoget_random_values_fn// TODO: these `structural` annotations here ideally wouldn't be here to// avoid a JS shim, but for now with feature detection they're// unavoidable.get_random_valuesrandom_fill_syncNodeModuleMODULE//! Implementation for WASM via wasm-bindgenstdwebjsunstablewebWebErrorgetrandom_fill//! Implementation for WASM via stdweb"SystemFunction036"link_nameRtlGenRandom//! Implementation for WindowsBCRYPT_USE_SYSTEM_PREFERRED_RNGBCryptGenRandom//! Implementation for Windows UWP targets. After deprecation of Windows XP//! and Vista, this can supersede the `RtlGenRandom`-based implementation.CCRandomGenerateBytes// This RNG uses a thread-local CSPRNG to provide data, which is seeded by the operating system's root CSPRNG.// Its the best option after `getentropy` on modern Darwin-based platforms that also avoids the// high startup costs and linking of Security.framework.// While its just an implementation detail, `Security.framework` just calls into this anyway.//! Implementation for iOS, tvOS, and watchOS where `getentropy` is unavailable.// libsystem contains the libc of Darwin, and every binary ends up linked against it either way. This// makes it a more lightweight choice compared to `Security.framework`.uninit_slice_fill_zeroregister_custom_getrandom/// Register a function to be invoked by `getrandom` on unsupported targets./// ## Writing a custom `getrandom` implementation/// The function to register must have the same signature as/// [`getrandom::getrandom`](crate::getrandom). The function can be defined/// wherever you want, either in root crate or a dependent crate./// For example, if we wanted a `failure-getrandom` crate containing an/// implementation that always fails, we would first depend on `getrandom`/// (for the [`Error`] type) in `failure-getrandom/Cargo.toml`:/// getrandom = "0.2"/// Note that the crate containing this function does **not** need to enable the/// `"custom"` Cargo feature./// Next, in `failure-getrandom/src/lib.rs`, we define our function:/// use core::num::NonZeroU32;/// use getrandom::Error;/// // Some application-specific error code/// const MY_CUSTOM_ERROR_CODE: u32 = Error::CUSTOM_START + 42;/// pub fn always_fail(buf: &mut [u8]) -> Result<(), Error> {///     let code = NonZeroU32::new(MY_CUSTOM_ERROR_CODE).unwrap();///     Err(Error::from(code))/// ## Registering a custom `getrandom` implementation/// Functions can only be registered in the root binary crate. Attempting to/// register a function in a non-root crate will result in a linker error./// This is similar to/// [`#[panic_handler]`](https://doc.rust-lang.org/nomicon/panic-handler.html) or/// [`#[global_allocator]`](https://doc.rust-lang.org/edition-guide/rust-2018/platform-and-target-support/global-allocators.html),/// where helper crates define handlers/allocators but only the binary crate/// actually _uses_ the functionality./// To register the function, we first depend on `failure-getrandom` _and_/// `getrandom` in `Cargo.toml`:/// failure-getrandom = "0.1"/// getrandom = { version = "0.2", features = ["custom"] }/// Then, we register the function in `src/main.rs`:/// # mod failure_getrandom { pub fn always_fail(_: &mut [u8]) -> Result<(), getrandom::Error> { unimplemented!() } }/// use failure_getrandom::always_fail;/// use getrandom::register_custom_getrandom;/// register_custom_getrandom!(always_fail);/// Now any user of `getrandom` (direct or indirect) on this target will use the/// registered function. As noted in the/// [top-level documentation](index.html#custom-implementations) this/// registration only has an effect on unsupported targets.//! An implementation which calls out to an externally defined function./// A small and `no_std` compatible error type/// *If this crate's `"std"` Cargo feature is enabled*, then:/// - [`getrandom::Error`][Error] implements///   [`std::error::Error`](https://doc.rust-lang.org/std/error/trait.Error.html)/// - [`std::io::Error`](https://doc.rust-lang.org/std/io/struct.Error.html) implements///   [`From<getrandom::Error>`](https://doc.rust-lang.org/std/convert/trait.From.html)./// This target/platform is not supported by `getrandom`./// The platform-specific `errno` returned a non-positive value.UNEXPECTED/// Encountered an unexpected situation which should not happen in practice.IOS_SEC_RANDOM/// Call to [`CCRandomGenerateBytes`](https://opensource.apple.com/source/CommonCrypto/CommonCrypto-60074/include/CommonRandom.h.auto.html) failed/// on iOS, tvOS, or waatchOS.// TODO: Update this constant name in the next breaking release.WINDOWS_RTL_GEN_RANDOM/// Call to Windows [`RtlGenRandom`](https://docs.microsoft.com/en-us/windows/win32/api/ntsecapi/nf-ntsecapi-rtlgenrandom) failed./// RDRAND instruction failed due to a hardware issue./// RDRAND instruction unsupported on this target.WEB_CRYPTO/// The environment does not support the Web Crypto API.WEB_GET_RANDOM_VALUES/// Calling Web Crypto API `crypto.getRandomValues` failed.VXWORKS_RAND_SECURE/// On VxWorks, call to `randSecure` failed (random number generator is not yet initialized).NODE_CRYPTO/// Node.js does not have the `crypto` CommonJS module.NODE_RANDOM_FILL_SYNC/// Calling Node.js function `crypto.randomFillSync` failed.NODE_ES_MODULE/// Called from an ES module on Node.js. This is unsupported, see:/// <https://docs.rs/getrandom#nodejs-es-module-support>./// This method is identical to [`std::io::Error::raw_os_error()`][1], except/// [1]: https://doc.rust-lang.org/std/io/struct.Error.html#method.raw_os_erroresp_fill_random//! Implementation for ESP-IDF//! Implementation using getentropy(2)//! Available since://!   - macOS 10.12//!   - OpenBSD 5.6//!   - Emscripten 2.0.5//!   - vita newlib since Dec 2021//! For these targets, we use getentropy(2) because getrandom(2) doesn't exist.//! Implementation using getrandom(2).//!   - Linux Kernel 3.17, Glibc 2.25, Musl 1.1.20//!   - Android API level 23 (Marshmallow)//!   - NetBSD 10.0//!   - FreeBSD 12.0//!   - illumos since Dec 2018//!   - DragonFly 5.7//!   - Hurd Glibc 2.31//!   - shim-3ds since Feb 2022//! For these platforms, we always use the default pool and never set the//! GRND_RANDOM flag to use the /dev/random pool. On Linux/Android/Hurd, using//! GRND_RANDOM is not recommended. On NetBSD/FreeBSD/Dragonfly/3ds, it does//! nothing. On illumos, the default pool is used to implement getentropy(2),//! so we assume it is acceptable here.MIN_RET_CODE/// Minimum return value which we should get from syscalls in practice,/// because Hermit uses positive `i32`s for error codes:/// https://github.com/hermitcore/libhermit-rs/blob/main/src/errno.rssys_read_entropy//! Implementation for HermitFunctionJsCastWEB_CRYPTO_BUFFER_SIZE// Size of our temporary Uint8Array buffer used with WebCrypto methods// Maximum is 65536 bytes see https://developer.mozilla.org/en-US/docs/Web/API/Crypto/getRandomValuesNODE_MAX_BUFFER_SIZE// Node.js's crypto.randomFillSync requires the size to be less than 2**31.WebCryptoWebis_node// Taken from https://www.npmjs.com/package/browser-or-node// Return type of js_sys::global()// Web Crypto API: Crypto interface (https://www.w3.org/TR/WebCryptoAPI/)// Getters for the WebCrypto API// Crypto.getRandomValues()// Node JS crypto module (https://nodejs.org/api/crypto.html)// crypto.randomFillSync()Module// Ideally, we would just use `fn require(s: &str)` here. However, doing// this causes a Webpack warning. So we instead return the function itself// and manually invoke it using call1. This also lets us to check that the// function actually exists, allowing for better error messages. See://   https://github.com/rust-random/getrandom/issues/224//   https://github.com/rust-random/getrandom/issues/256require_fn// Node JS process Object (https://nodejs.org/api/process.html)versionsVersionsnode//! Implementation for WASM based on Web and Node.js// unsync_init will invoke an init() function until it succeeds, then return the// cached value for future calls.// unsync_init supports init() "failing". If the init() method returns UNINIT,// observed and additional synchronization methods may be needed.// Runs the init() function at most once, returning the value of some run of// init(). Multiple callers can run their init() functions in parallel.slice_as_uninit_mutslice_assume_init_mut// To prevent a breaking change when targets are added, we always export the// register_custom_getrandom macro, so old Custom RNG crates continue to build."getentropy.rs"// These should all provide getrandom_inner with the signature// `fn getrandom_inner(dest: &mut [MaybeUninit<u8>]) -> Result<(), Error>`.// The function MUST fully initialize `dest` when `Ok(())` is returned.// The function MUST NOT ever write uninitialized bytes into `dest`,// regardless of what value it returns.getrandom_uninit/// Version of the `getrandom` function which fills `dest` with random bytes/// returns a mutable reference to those bytes./// On successful completion this function is guaranteed to return a slice/// which points to the same memory as `dest` and has the same length./// In other words, it's safe to assume that `dest` is initialized after/// this function has returned `Ok`./// No part of `dest` will ever be de-initialized at any point, regardless/// of what is returned./// # // We ignore this test since `uninit_array` is unstable./// #![feature(maybe_uninit_uninit_array)]/// # fn main() -> Result<(), getrandom::Error> {/// let mut buf = core::mem::MaybeUninit::uninit_array::<1024>();/// let buf: &mut [u8] = getrandom::getrandom_uninit(&mut buf)?;/// # Ok(()) }//! Interface to the operating system's random number generator.//! # Supported targets//! | Target            | Target Triple      | Implementation//! | ----------------- | ------------------ | --------------//! | Linux, Android    | `*‑linux‑*`        | [`getrandom`][1] system call if available, otherwise [`/dev/urandom`][2] after successfully polling `/dev/random`//! | Windows           | `*‑windows‑*`      | [`BCryptGenRandom`]//! | macOS             | `*‑apple‑darwin`   | [`getentropy`][3]//! | iOS, tvOS, watchOS | `*‑apple‑ios`, `*-apple-tvos`, `*-apple-watchos` | [`CCRandomGenerateBytes`]//! | FreeBSD           | `*‑freebsd`        | [`getrandom`][5]//! | OpenBSD           | `*‑openbsd`        | [`getentropy`][7]//! | NetBSD            | `*‑netbsd`         | [`getrandom`][16] if available, otherwise [`kern.arandom`][8]//! | Dragonfly BSD     | `*‑dragonfly`      | [`getrandom`][9]//! | Solaris           | `*‑solaris`        | [`getrandom`][11] (with `GRND_RANDOM`)//! | illumos           | `*‑illumos`        | [`getrandom`][12]//! | Fuchsia OS        | `*‑fuchsia`        | [`cprng_draw`]//! | Redox             | `*‑redox`          | `/dev/urandom`//! | Haiku             | `*‑haiku`          | `/dev/urandom` (identical to `/dev/random`)//! | Hermit            | `*-hermit`         | [`sys_read_entropy`]//! | Hurd              | `*-hurd-*`         | [`getrandom`][17]//! | SGX               | `x86_64‑*‑sgx`     | [`RDRAND`]//! | VxWorks           | `*‑wrs‑vxworks‑*`  | `randABytes` after checking entropy pool initialization with `randSecure`//! | ESP-IDF           | `*‑espidf`         | [`esp_fill_random`]//! | Emscripten        | `*‑emscripten`     | [`getentropy`][13]//! | WASI              | `wasm32‑wasi`      | [`random_get`]//! | Web Browser and Node.js | `wasm*‑*‑unknown` | [`Crypto.getRandomValues`] if available, then [`crypto.randomFillSync`] if on Node.js, see [WebAssembly support]//! | SOLID             | `*-kmc-solid_*`    | `SOLID_RNG_SampleRandomBytes`//! | Nintendo 3DS      | `*-nintendo-3ds`   | [`getrandom`][18]//! | PS Vita           | `*-vita-*`         | [`getentropy`][13]//! | QNX Neutrino      | `*‑nto-qnx*`       | [`/dev/urandom`][14] (identical to `/dev/random`)//! | AIX               | `*-ibm-aix`        | [`/dev/urandom`][15]//! | Cygwin            | `*-cygwin`         | [`getrandom`][19] (based on [`RtlGenRandom`])//! Pull Requests that add support for new targets to `getrandom` are always welcome.//! By default, `getrandom` will not compile on unsupported targets, but certain//! features allow a user to select a "fallback" implementation if no supported//! implementation exists.//! All of the below mechanisms only affect unsupported//! targets. Supported targets will _always_ use their supported implementations.//! This prevents a crate from overriding a secure source of randomness//! (either accidentally or intentionally).//! ## `/dev/urandom` fallback on Linux and Android//! On Linux targets the fallback is present only if either `target_env` is `musl`,//! or `target_arch` is one of the following: `aarch64`, `arm`, `powerpc`, `powerpc64`,//! `s390x`, `x86`, `x86_64`. Other supported targets [require][platform-support]//! kernel versions which support `getrandom` system call, so fallback is not needed.//! On Android targets the fallback is present only for the following `target_arch`es://! `aarch64`, `arm`, `x86`, `x86_64`. Other `target_arch`es (e.g. RISC-V) require//! sufficiently high API levels.//! The fallback can be disabled by enabling the `linux_disable_fallback` crate feature.//! Note that doing so will bump minimum supported Linux kernel version to 3.17 and//! Android API level to 23 (Marshmallow).//! ### RDRAND on x86//! *If the `rdrand` Cargo feature is enabled*, `getrandom` will fallback to using//! the [`RDRAND`] instruction to get randomness on `no_std` `x86`/`x86_64`//! targets. This feature has no effect on other CPU architectures.//! ### WebAssembly support//! This crate fully supports the//! [`wasm32-wasi`](https://github.com/CraneStation/wasi) and//! [`wasm32-unknown-emscripten`](https://www.hellorust.com/setup/emscripten/)//! targets. However, the `wasm32-unknown-unknown` target (i.e. the target used//! by `wasm-pack`) is not automatically//! supported since, from the target name alone, we cannot deduce which//! JavaScript interface is in use (or if JavaScript is available at all).//! Instead, *if the `js` Cargo feature is enabled*, this crate will assume//! that you are building for an environment containing JavaScript, and will//! call the appropriate methods. Both web browser (main window and Web Workers)//! and Node.js environments are supported, invoking the methods//! [described above](#supported-targets) using the [`wasm-bindgen`] toolchain.//! To enable the `js` Cargo feature, add the following to the `dependencies`//! section in your `Cargo.toml` file://! getrandom = { version = "0.2", features = ["js"] }//! This can be done even if `getrandom` is not a direct dependency. Cargo//! allows crates to enable features for indirect dependencies.//! This feature should only be enabled for binary, test, or benchmark crates.//! Library crates should generally not enable this feature, leaving such a//! decision to *users* of their library. Also, libraries should not introduce//! their own `js` features *just* to enable `getrandom`'s `js` feature.//! This feature has no effect on targets other than `wasm32-unknown-unknown`.//! #### Node.js ES module support//! Node.js supports both [CommonJS modules] and [ES modules]. Due to//! limitations in wasm-bindgen's [`module`] support, we cannot directly//! support ES Modules running on Node.js. However, on Node v15 and later, the//! module author can add a simple shim to support the Web Cryptography API://! ```js//! import { webcrypto } from 'node:crypto'//! globalThis.crypto = webcrypto//! This crate will then use the provided `webcrypto` implementation.//! ### Platform Support//! This crate generally supports the same operating system and platform versions//! that the Rust standard library does. Additional targets may be supported using//! pluggable custom implementations.//! This means that as Rust drops support for old versions of operating systems//! (such as old Linux kernel versions, Android API levels, etc) in stable releases,//! `getrandom` may create new patch releases (`0.N.x`) that remove support for//! outdated platform versions.//! ### Custom implementations//! The [`register_custom_getrandom!`] macro allows a user to mark their own//! function as the backing implementation for [`getrandom`]. See the macro's//! documentation for more information about writing and registering your own//! custom implementations.//! Note that registering a custom implementation only has an effect on targets//! that would otherwise not compile. Any supported targets (including those//! using `rdrand` and `js` Cargo features) continue using their normal//! implementations even if a function is registered.//! Sometimes, early in the boot process, the OS has not collected enough//! entropy to securely seed its RNG. This is especially common on virtual//! machines, where standard "random" events are hard to come by.//! Some operating system interfaces always block until the RNG is securely//! A few (Linux, NetBSD and Solaris) offer a choice between blocking and//! getting an error; in these cases, we always choose to block.//! On Linux (when the `getrandom` system call is not available), reading from//! `/dev/urandom` never blocks, even when the OS hasn't collected enough//! entropy yet. To avoid returning low-entropy bytes, we first poll//! On OpenBSD, this kind of entropy accounting isn't available, and on//! NetBSD, blocking on it is discouraged. On these platforms, nonblocking//! interfaces are used, even when reliable entropy may not be available.//! On the platforms where it is used, the reliability of entropy accounting//! itself isn't free from controversy. This library provides randomness//! sourced according to the platform's best practices, but each platform has//! its own limits on the grade of randomness it can promise in environments//! with few sources of entropy.//! ## Error handling//! We always choose failure over returning known insecure "random" bytes. In//! general, on supported platforms, failure is highly unlikely, though not//! impossible. If an error does occur, then it is likely that it will occur//! on every call to `getrandom`, hence after the first successful call one//! can be reasonably confident that no errors will occur.//! [1]: https://manned.org/getrandom.2//! [2]: https://manned.org/urandom.4//! [3]: https://www.unix.com/man-page/mojave/2/getentropy///! [4]: https://www.unix.com/man-page/mojave/4/urandom///! [5]: https://www.freebsd.org/cgi/man.cgi?query=getrandom&manpath=FreeBSD+12.0-stable//! [7]: https://man.openbsd.org/getentropy.2//! [8]: https://man.netbsd.org/sysctl.7//! [9]: https://leaf.dragonflybsd.org/cgi/web-man?command=getrandom//! [11]: https://docs.oracle.com/cd/E88353_01/html/E37841/getrandom-2.html//! [12]: https://illumos.org/man/2/getrandom//! [13]: https://github.com/emscripten-core/emscripten/pull/12240//! [14]: https://www.qnx.com/developers/docs/7.1/index.html#com.qnx.doc.neutrino.utilities/topic/r/random.html//! [15]: https://www.ibm.com/docs/en/aix/7.3?topic=files-random-urandom-devices//! [16]: https://man.netbsd.org/getrandom.2//! [17]: https://www.gnu.org/software/libc/manual/html_mono/libc.html#index-getrandom//! [18]: https://github.com/rust3ds/shim-3ds/commit/b01d2568836dea2a65d05d662f8e5f805c64389d//! [19]: https://github.com/cygwin/cygwin/blob/main/winsup/cygwin/libc/getentropy.cc//! [`BCryptGenRandom`]: https://docs.microsoft.com/en-us/windows/win32/api/bcrypt/nf-bcrypt-bcryptgenrandom//! [`RtlGenRandom`]: https://learn.microsoft.com/en-us/windows/win32/api/ntsecapi/nf-ntsecapi-rtlgenrandom//! [`Crypto.getRandomValues`]: https://www.w3.org/TR/WebCryptoAPI/#Crypto-method-getRandomValues//! [`RDRAND`]: https://software.intel.com/en-us/articles/intel-digital-random-number-generator-drng-software-implementation-guide//! [`CCRandomGenerateBytes`]: https://opensource.apple.com/source/CommonCrypto/CommonCrypto-60074/include/CommonRandom.h.auto.html//! [`cprng_draw`]: https://fuchsia.dev/fuchsia-src/zircon/syscalls/cprng_draw//! [`crypto.randomFillSync`]: https://nodejs.org/api/crypto.html#cryptorandomfillsyncbuffer-offset-size//! [`esp_fill_random`]: https://docs.espressif.com/projects/esp-idf/en/latest/esp32/api-reference/system/random.html#_CPPv415esp_fill_randomPv6size_t//! [`random_get`]: https://github.com/WebAssembly/WASI/blob/main/phases/snapshot/docs.md#-random_getbuf-pointeru8-buf_len-size---errno//! [WebAssembly support]: #webassembly-support//! [`wasm-bindgen`]: https://github.com/rustwasm/wasm-bindgen//! [`module`]: https://rustwasm.github.io/wasm-bindgen/reference/attributes/on-js-imports/module.html//! [CommonJS modules]: https://nodejs.org/api/modules.html//! [ES modules]: https://nodejs.org/api/esm.html//! [`sys_read_entropy`]: https://github.com/hermit-os/kernel/blob/315f58ff5efc81d9bf0618af85a59963ff55f8b1/src/syscalls/entropy.rs#L47-L55//! [platform-support]: https://doc.rust-lang.org/stable/rustc/platform-support.html//! Implementation for Linux / Android without `/dev/urandom` fallbacklazygetrandom_syscall//! Implementation for Linux / Android with `/dev/urandom` fallback//! Implementation for NetBSDslice_as_uninit// "rdrand" target feature requires "+rdrand" flag, see https://github.com/rust-lang/rust/issues/49653.self_test// Run a small self-test to make sure we aren't repeating values// Adapted from Linux's test in arch/x86/kernel/cpu/rdrand.c// Fails with probability < 2^(-90) on 32-bit systemsis_rdrand_good// TODO: make this function safe when we have feature(target_feature_11)//! RDRAND backend for x86(-64) targetsMAX_BYTES//! Solaris implementation using getrandom(2).//! While getrandom(2) has been available since Solaris 11.3, it has a few//! quirks not present on other OSes. First, on Solaris 11.3, calls will always//! fail if bufsz > 1024. Second, it will always either fail or completely fill//! the buffer (returning bufsz). Third, error is indicated by returning 0,//! rather than by returning -1. Finally, "if GRND_RANDOM is not specified//! then getrandom(2) is always a non blocking call". This _might_ imply that//! in early-boot scenarios with low entropy, getrandom(2) will not properly//! block. To be safe, we set GRND_RANDOM, mirroring the man page examples.//! For more information, see the man page linked in lib.rs and this blog post://! https://blogs.oracle.com/solaris/post/solaris-new-system-calls-getentropy2-and-getrandom2//! which also explains why this crate should not use getentropy(2).SOLID_RNG_SampleRandomBytes//! Implementation for SOLID/// For all platforms, we use `/dev/urandom` rather than `/dev/random`./// For more information see the linked man pages in lib.rs.///   - On Linux, "/dev/urandom is preferred and sufficient in all use cases".///   - On Redox, only /dev/urandom is provided.///   - On AIX, /dev/urandom will "provide cryptographically secure output".///   - On Haiku and QNX Neutrino they are identical.FD_UNINIT// bytes. The file will be opened exactly once. All subsequent calls willwait_until_rng_ready// Succeeds once /dev/urandom is safe to read from/// Polyfill for `maybe_uninit_slice` feature's/// `MaybeUninit::slice_assume_init_mut`. Every element of `slice` must have/// been initialized./// View an mutable initialized array as potentially-uninitialized./// This is unsafe because it allows assigning uninitialized values into/// `slice`, which would be undefined behavior.// Based off of the DlsymWeak struct in libstd:// https://github.com/rust-lang/rust/blob/1.61.0/library/std/src/sys/unix/weak.rs#L84// except that the caller must manually cast self.ptr() to a function pointer.// A non-null pointer value which indicates we are uninitialized. This// constant should ideally not be a valid address of a function pointer.// However, if by chance libc::dlsym does return UNINIT, there will not// be undefined behavior. libc::dlsym will just be called each time ptr()// is called. This would be inefficient, but correct.// TODO: Replace with core::ptr::invalid_mut(1) when that is stable.// Return the address of a function if present at runtime. Otherwise,// return None. Multiple callers can call ptr() concurrently. It will// always return _some_ value returned by libc::dlsym. However, the// dlsym function may be called multiple times.// Forbidden when targetting UWPIntoParallelIteratorParallelIterator/// Helper for collecting parallel iterators to an intermediaryRawIntoParIterRawParDrainRawParIterAllocatorplumbingUnindexedConsumerFromParallelIteratorParallelExtendParIter/// Parallel iterator over shared references to entries in a map./// This iterator is created by the [`par_iter`] method on [`HashMap`]/// (provided by the [`IntoParallelRefIterator`] trait)./// See its documentation for more./// [`par_iter`]: /hashbrown/struct.HashMap.html#method.par_iter/// [`HashMap`]: /hashbrown/struct.HashMap.html/// [`IntoParallelRefIterator`]: https://docs.rs/rayon/1.0/rayon/iter/trait.IntoParallelRefIterator.htmldrive_unindexedParKeys/// Parallel iterator over shared references to keys in a map./// This iterator is created by the [`par_keys`] method on [`HashMap`]./// [`par_keys`]: /hashbrown/struct.HashMap.html#method.par_keysParValues/// Parallel iterator over shared references to values in a map./// This iterator is created by the [`par_values`] method on [`HashMap`]./// [`par_values`]: /hashbrown/struct.HashMap.html#method.par_valuesParIterMut/// Parallel iterator over mutable references to entries in a map./// This iterator is created by the [`par_iter_mut`] method on [`HashMap`]/// (provided by the [`IntoParallelRefMutIterator`] trait)./// [`par_iter_mut`]: /hashbrown/struct.HashMap.html#method.par_iter_mut/// [`IntoParallelRefMutIterator`]: https://docs.rs/rayon/1.0/rayon/iter/trait.IntoParallelRefMutIterator.htmlParValuesMut/// Parallel iterator over mutable references to values in a map./// This iterator is created by the [`par_values_mut`] method on [`HashMap`]./// [`par_values_mut`]: /hashbrown/struct.HashMap.html#method.par_values_mutIntoParIter/// Parallel iterator over entries of a consumed map./// This iterator is created by the [`into_par_iter`] method on [`HashMap`]/// (provided by the [`IntoParallelIterator`] trait)./// [`into_par_iter`]: /hashbrown/struct.HashMap.html#method.into_par_iter/// [`IntoParallelIterator`]: https://docs.rs/rayon/1.0/rayon/iter/trait.IntoParallelIterator.htmlParDrain/// Parallel draining iterator over entries of a map./// This iterator is created by the [`par_drain`] method on [`HashMap`]./// [`par_drain`]: /hashbrown/struct.HashMap.html#method.par_drainpar_keys/// Visits (potentially in parallel) immutably borrowed keys in an arbitrary order.par_values/// Visits (potentially in parallel) immutably borrowed values in an arbitrary order.par_values_mut/// Visits (potentially in parallel) mutably borrowed values in an arbitrary order.par_drain/// Consumes (potentially in parallel) all values in an arbitrary order,/// while preserving the map's allocated memory for reuse.par_eq/// Returns `true` if the map is equal to another,/// i.e. both maps contain the same keys mapped to the same values./// This method runs in a potentially parallel fashion.into_par_iterfrom_par_iter/// Collect (key, value) pairs from a parallel iterator into a/// hashmap. If multiple pairs correspond to the same key, then the/// ones produced earlier in the parallel iterator will be/// overwritten, just as with a sequential iterator.par_extend/// Extend a hash map with items from a parallel iterator./// Extend a hash map with copied items from a parallel iterator.// This is equal to the normal `HashMap` -- no custom advantage.Dropabletest_into_iter_dropstest_drain_dropstest_empty_itertest_iteratetest_keystest_valuestest_values_muttest_eqtest_from_itertest_extend_reftest_par_map//! Rayon extensions for `HashMap`.BucketRawIterRawIterRangeRawTablescopeguardFolderUnindexedProducer/// Parallel iterator which returns a raw pointer to every full bucket in the table.ParIterProducer/// Producer which returns a `Bucket<T>` for every element.fold_with/// Parallel iterator which consumes a table and returns elements.par_iter// We don't use a &'a mut RawTable<T> because we want RawParDrain to be// covariant over T./// Parallel iterator which consumes elements without freeing the table storage.ParDrainProducer/// Producer which will consume all elements in the range, even if it is dropped/// halfway through./// Returns a parallel iterator over the elements in a `RawTable`./// Returns a parallel iterator which consumes all elements of a `RawTable`/// without freeing its memory allocation./// Parallel iterator over elements of a consumed set./// This iterator is created by the [`into_par_iter`] method on [`HashSet`]/// [`into_par_iter`]: /hashbrown/struct.HashSet.html#method.into_par_iter/// [`HashSet`]: /hashbrown/struct.HashSet.html/// Parallel draining iterator over entries of a set./// This iterator is created by the [`par_drain`] method on [`HashSet`]./// [`par_drain`]: /hashbrown/struct.HashSet.html#method.par_drain/// Parallel iterator over shared references to elements in a set./// This iterator is created by the [`par_iter`] method on [`HashSet`]/// [`par_iter`]: /hashbrown/struct.HashSet.html#method.par_iterParDifference/// Parallel iterator over shared references to elements in the difference of/// sets./// This iterator is created by the [`par_difference`] method on [`HashSet`]./// [`par_difference`]: /hashbrown/struct.HashSet.html#method.par_differenceParSymmetricDifference/// Parallel iterator over shared references to elements in the symmetric/// difference of sets./// This iterator is created by the [`par_symmetric_difference`] method on/// [`HashSet`]./// [`par_symmetric_difference`]: /hashbrown/struct.HashSet.html#method.par_symmetric_differenceParIntersection/// Parallel iterator over shared references to elements in the intersection of/// This iterator is created by the [`par_intersection`] method on [`HashSet`]./// [`par_intersection`]: /hashbrown/struct.HashSet.html#method.par_intersectionParUnion/// Parallel iterator over shared references to elements in the union of sets./// This iterator is created by the [`par_union`] method on [`HashSet`]./// [`par_union`]: /hashbrown/struct.HashSet.html#method.par_unionpar_union/// Visits (potentially in parallel) the values representing the union,/// i.e. all the values in `self` or `other`, without duplicates.par_difference/// Visits (potentially in parallel) the values representing the difference,/// i.e. the values that are in `self` but not in `other`.par_symmetric_difference/// Visits (potentially in parallel) the values representing the symmetric/// difference, i.e. the values that are in `self` or in `other` but not in both.par_intersection/// Visits (potentially in parallel) the values representing the/// intersection, i.e. the values that are both in `self` and `other`.par_is_disjoint/// Returns `true` if `self` has no elements in common with `other`./// This is equivalent to checking for an empty intersection.par_is_subset/// Returns `true` if the set is a subset of another,/// i.e. `other` contains at least all the values in `self`.par_is_superset/// Returns `true` if the set is a superset of another,/// i.e. `self` contains at least all the values in `other`./// Returns `true` if the set is equal to another,/// i.e. both sets contain the same values./// while preserving the set's allocated memory for reuse./// Collect values from a parallel iterator into a hashset./// Extend a hash set with items from a parallel iterator./// Extend a hash set with copied items from a parallel iterator.// This is equal to the normal `HashSet` -- no custom advantage.test_disjointtest_subset_and_supersettest_intersectiontest_differencetest_symmetric_differencetest_uniontest_move_itertest_par_set//! Rayon extensions for `HashSet`./// This presumably exists to prevent denial of service attacks./// Original discussion: https://github.com/serde-rs/serde/issues/1114.MapAccessexternal_trait_impls//! A hash map implemented with quadratic probing and SIMD lookup.//! A hash set implemented as a `HashMap` where the value is `()`.TryReserveError/// The layout of the allocation request that failed.AllocError/// The memory allocator returned an error/// The error type for `try_reserve` methods.//! This crate is a Rust port of Google's high-performance [SwissTable] hash//! map, adapted to make it a drop-in replacement for Rust's standard `HashMap`//! and `HashSet` types.//! The original C++ version of [SwissTable] can be found [here], and this//! [CppCon talk] gives an overview of how the algorithm works.//! [SwissTable]: https://abseil.io/blog/20180927-swisstables//! [here]: https://github.com/abseil/abseil-cpp/blob/master/absl/container/internal/raw_hash_set.h//! [CppCon talk]: https://www.youtube.com/watch?v=ncHmEUmJZf4// Collects all the negated cfgs in a list at the beginning and after the// semicolon is all the remaining items// Internal macro to Apply a cfg attribute to a list of items// See the cfg-if crate.default_fnRawDrainRawIntoIterDefaultHashBuilder/// Default hasher for `HashMap`.hash_builder/// A hash map implemented with quadratic probing and SIMD lookup./// The default hashing algorithm is currently [`AHash`], though this is/// subject to change at any point in the future. This hash function is very/// fast for all types of keys, but this algorithm will typically *not* protect/// against attacks such as HashDoS./// The hashing algorithm can be replaced on a per-`HashMap` basis using the/// [`default`], [`with_hasher`], and [`with_capacity_and_hasher`] methods. Many/// alternative algorithms are available on crates.io, such as the [`fnv`] crate./// It is required that the keys implement the [`Eq`] and [`Hash`] traits, although/// this can frequently be achieved by using `#[derive(PartialEq, Eq, Hash)]`./// If you implement these yourself, it is important that the following/// property holds:/// k1 == k2 -> hash(k1) == hash(k2)/// In other words, if two keys are equal, their hashes must be equal./// It is a logic error for a key to be modified in such a way that the key's/// hash, as determined by the [`Hash`] trait, or its equality, as determined by/// the [`Eq`] trait, changes while it is in the map. This is normally only/// possible through [`Cell`], [`RefCell`], global state, I/O, or unsafe code./// It is also a logic error for the [`Hash`] implementation of a key to panic./// This is generally only possible if the trait is implemented manually. If a/// panic does occur then the contents of the `HashMap` may become corrupted and/// some items may be dropped from the table./// use hashbrown::HashMap;/// // Type inference lets us omit an explicit type signature (which/// // would be `HashMap<String, String>` in this example)./// let mut book_reviews = HashMap::new();/// // Review some books./// book_reviews.insert(///     "Adventures of Huckleberry Finn".to_string(),///     "My favorite book.".to_string(),///     "Grimms' Fairy Tales".to_string(),///     "Masterpiece.".to_string(),///     "Pride and Prejudice".to_string(),///     "Very enjoyable.".to_string(),///     "The Adventures of Sherlock Holmes".to_string(),///     "Eye lyked it alot.".to_string(),/// // Check for a specific one./// // When collections store owned values (String), they can still be/// // queried using references (&str)./// if !book_reviews.contains_key("Les Misérables") {///     println!("We've got {} reviews, but Les Misérables ain't one.",///              book_reviews.len());/// // oops, this review has a lot of spelling mistakes, let's delete it./// book_reviews.remove("The Adventures of Sherlock Holmes");/// // Look up the values associated with some keys./// let to_find = ["Pride and Prejudice", "Alice's Adventure in Wonderland"];/// for &book in &to_find {///     match book_reviews.get(book) {///         Some(review) => println!("{}: {}", book, review),///         None => println!("{} is unreviewed.", book)/// // Look up the value for a key (will panic if the key is not found)./// println!("Review for Jane: {}", book_reviews["Pride and Prejudice"]);/// // Iterate over everything./// for (book, review) in &book_reviews {///     println!("{}: \"{}\"", book, review);/// `HashMap` also implements an [`Entry API`](#method.entry), which allows/// for more complex methods of getting, setting, updating and removing keys and/// their values:/// // type inference lets us omit an explicit type signature (which/// // would be `HashMap<&str, u8>` in this example)./// let mut player_stats = HashMap::new();/// fn random_stat_buff() -> u8 {///     // could actually return some random value here - let's just return///     // some fixed value for now///     42/// // insert a key only if it doesn't already exist/// player_stats.entry("health").or_insert(100);/// // insert a key using a function that provides a new value only if it/// // doesn't already exist/// player_stats.entry("defence").or_insert_with(random_stat_buff);/// // update a key, guarding against the key possibly not being set/// let stat = player_stats.entry("attack").or_insert(100);/// *stat += random_stat_buff();/// The easiest way to use `HashMap` with a custom key type is to derive [`Eq`] and [`Hash`]./// We must also derive [`PartialEq`]./// [`Eq`]: https://doc.rust-lang.org/std/cmp/trait.Eq.html/// [`Hash`]: https://doc.rust-lang.org/std/hash/trait.Hash.html/// [`PartialEq`]: https://doc.rust-lang.org/std/cmp/trait.PartialEq.html/// [`RefCell`]: https://doc.rust-lang.org/std/cell/struct.RefCell.html/// [`Cell`]: https://doc.rust-lang.org/std/cell/struct.Cell.html/// [`default`]: #method.default/// [`with_hasher`]: #method.with_hasher/// [`with_capacity_and_hasher`]: #method.with_capacity_and_hasher/// [`fnv`]: https://crates.io/crates/fnv/// [`AHash`]: https://crates.io/crates/ahash/// #[derive(Hash, Eq, PartialEq, Debug)]/// struct Viking {///     country: String,/// impl Viking {///     /// Creates a new Viking.///     fn new(name: &str, country: &str) -> Viking {///         Viking { name: name.to_string(), country: country.to_string() }/// // Use a HashMap to store the vikings' health points./// let mut vikings = HashMap::new();/// vikings.insert(Viking::new("Einar", "Norway"), 25);/// vikings.insert(Viking::new("Olaf", "Denmark"), 24);/// vikings.insert(Viking::new("Harald", "Iceland"), 12);/// // Use derived implementation to print the status of the vikings./// for (viking, health) in &vikings {///     println!("{:?} has {} hp", viking, health);/// A `HashMap` with fixed list of elements can be initialized from an array:/// let timber_resources: HashMap<&str, i32> = [("Norway", 100), ("Denmark", 50), ("Iceland", 10)]///     .iter().cloned().collect();/// // use the values stored in mapmake_hasher/// Ensures that a single closure type across uses of this which, in turn prevents multiple/// instances of any functions like RawTable::reserve from being generatedequivalent_keymake_hashmake_insert_hash/// Creates an empty `HashMap`./// The hash map is initially created with a capacity of 0, so it will not allocate until it/// is first inserted into./// let mut map: HashMap<&str, i32> = HashMap::new();/// Creates an empty `HashMap` with the specified capacity./// The hash map will be able to hold at least `capacity` elements without/// reallocating. If `capacity` is 0, the hash map will not allocate./// let mut map: HashMap<&str, i32> = HashMap::with_capacity(10);/// Creates an empty `HashMap` using the given allocator./// Creates an empty `HashMap` with the specified capacity using the given allocator./// Creates an empty `HashMap` which will use the given hash builder to hash/// keys./// The created map has the default initial capacity./// Warning: `hash_builder` is normally randomly generated, and/// is designed to allow HashMaps to be resistant to attacks that/// cause many collisions and very poor performance. Setting it/// manually using this function can expose a DoS attack vector./// The `hash_builder` passed should implement the [`BuildHasher`] trait for/// the HashMap to be useful, see its documentation for details./// use hashbrown::hash_map::DefaultHashBuilder;/// let s = DefaultHashBuilder::default();/// let mut map = HashMap::with_hasher(s);/// map.insert(1, 2);/// [`BuildHasher`]: ../../std/hash/trait.BuildHasher.html/// Creates an empty `HashMap` with the specified capacity, using `hash_builder`/// to hash the keys./// let mut map = HashMap::with_capacity_and_hasher(10, s);with_hasher_in/// keys. It will be allocated with the given allocator.with_capacity_and_hasher_in/// to hash the keys. It will be allocated with the given allocator./// Returns a reference to the map's [`BuildHasher`]./// [`BuildHasher`]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.html/// let hasher = DefaultHashBuilder::default();/// let map: HashMap<i32, i32> = HashMap::with_hasher(hasher);/// let hasher: &DefaultHashBuilder = map.hasher();/// Returns the number of elements the map can hold without reallocating./// This number is a lower bound; the `HashMap<K, V>` might be able to hold/// more, but is guaranteed to be able to hold at least this many./// let map: HashMap<i32, i32> = HashMap::with_capacity(100);/// assert!(map.capacity() >= 100);Keys/// An iterator visiting all keys in arbitrary order./// The iterator element type is `&'a K`./// map.insert("a", 1);/// map.insert("b", 2);/// map.insert("c", 3);/// for key in map.keys() {///     println!("{}", key);values/// An iterator visiting all values in arbitrary order./// The iterator element type is `&'a V`./// for val in map.values() {///     println!("{}", val);values_mutValuesMut/// An iterator visiting all values mutably in arbitrary order./// The iterator element type is `&'a mut V`./// for val in map.values_mut() {///     *val = *val + 10;/// An iterator visiting all key-value pairs in arbitrary order./// The iterator element type is `(&'a K, &'a V)`./// for (key, val) in map.iter() {///     println!("key: {} val: {}", key, val);/// An iterator visiting all key-value pairs in arbitrary order,/// with mutable references to the values./// The iterator element type is `(&'a K, &'a mut V)`./// // Update all values/// for (_, val) in map.iter_mut() {///     *val *= 2;/// for (key, val) in &map {raw_capacity/// Returns the number of elements in the map./// let mut a = HashMap::new();/// assert_eq!(a.len(), 0);/// a.insert(1, "a");/// assert_eq!(a.len(), 1);/// Returns `true` if the map contains no elements./// assert!(a.is_empty());/// assert!(!a.is_empty());/// Clears the map, returning all key-value pairs as an iterator. Keeps the/// allocated memory for reuse./// a.insert(2, "b");/// for (k, v) in a.drain().take(1) {///     assert!(k == 1 || k == 2);///     assert!(v == "a" || v == "b");/// In other words, remove all pairs `(k, v)` such that `f(&k,&mut v)` returns `false`./// let mut map: HashMap<i32, i32> = (0..8).map(|x|(x, x*10)).collect();/// map.retain(|&k, _| k % 2 == 0);/// assert_eq!(map.len(), 4);/// Drains elements which are true under the given predicate,/// and returns an iterator over the removed items./// In other words, move all pairs `(k, v)` such that `f(&k,&mut v)` returns `true` out/// into another iterator./// When the returned DrainedFilter is dropped, any remaining elements that satisfy/// the predicate are dropped from the table./// let mut map: HashMap<i32, i32> = (0..8).map(|x| (x, x)).collect();/// let drained: HashMap<i32, i32> = map.drain_filter(|k, _v| k % 2 == 0).collect();/// let mut evens = drained.keys().cloned().collect::<Vec<_>>();/// let mut odds = map.keys().cloned().collect::<Vec<_>>();/// evens.sort();/// odds.sort();/// assert_eq!(evens, vec![0, 2, 4, 6]);/// assert_eq!(odds, vec![1, 3, 5, 7]);/// Clears the map, removing all key-value pairs. Keeps the allocated memory/// for reuse./// a.clear();/// in the `HashMap`. The collection may reserve more space to avoid/// frequent reallocations./// Panics if the new allocation size overflows [`usize`]./// map.reserve(10);/// Tries to reserve capacity for at least `additional` more elements to be inserted/// in the given `HashMap<K,V>`. The collection may reserve more space to avoid/// If the capacity overflows, or the allocator reports a failure, then an error/// let mut map: HashMap<&str, isize> = HashMap::new();/// map.try_reserve(10).expect("why is the test harness OOMing on 10 bytes?");/// Shrinks the capacity of the map as much as possible. It will drop/// down as much as possible while maintaining the internal rules/// and possibly leaving some space in accordance with the resize policy./// let mut map: HashMap<i32, i32> = HashMap::with_capacity(100);/// map.insert(3, 4);/// map.shrink_to_fit();/// assert!(map.capacity() >= 2);shrink_to/// Shrinks the capacity of the map with a lower limit. It will drop/// down no lower than the supplied limit while maintaining the internal rules/// This function does nothing if the current capacity is smaller than the/// supplied minimum capacity./// map.shrink_to(10);/// assert!(map.capacity() >= 10);/// map.shrink_to(0);/// Gets the given key's corresponding entry in the map for in-place manipulation./// let mut letters = HashMap::new();/// for ch in "a short treatise on fungi".chars() {///     let counter = letters.entry(ch).or_insert(0);///     *counter += 1;/// assert_eq!(letters[&'s'], 2);/// assert_eq!(letters[&'t'], 3);/// assert_eq!(letters[&'u'], 1);/// assert_eq!(letters.get(&'y'), None);get_innerget_key_value_mut/// Returns the key-value pair corresponding to the supplied key, with a mutable reference to value./// let (k, v) = map.get_key_value_mut(&1).unwrap();/// assert_eq!(k, &1);/// assert_eq!(v, &mut "a");/// *v = "b";/// assert_eq!(map.get_key_value_mut(&1), Some((&1, &mut "b")));/// assert_eq!(map.get_key_value_mut(&2), None);contains_key/// Returns `true` if the map contains a value for the specified key./// assert_eq!(map.contains_key(&1), true);/// assert_eq!(map.contains_key(&2), false);get_inner_mut/// [module-level documentation]: index.html#insert-and-complex-keysOccupiedError/// Tries to insert a key-value pair into the map, and returns/// a mutable reference to the value in the entry./// If the map already had this key present, nothing is updated, and/// an error containing the occupied entry and the value is returned./// assert_eq!(map.try_insert(37, "a").unwrap(), &"a");/// let err = map.try_insert(37, "b").unwrap_err();/// assert_eq!(err.entry.key(), &37);/// assert_eq!(err.entry.get(), &"a");/// assert_eq!(err.value, "b");remove_entry/// Removes a key from the map, returning the stored key and value if the/// key was previously in the map./// assert_eq!(map.remove_entry(&1), Some((1, "a")));raw_entry_mutRawEntryBuilderMut/// Creates a raw entry builder for the HashMap./// Raw entries provide the lowest level of control for searching and/// manipulating a map. They must be manually initialized with a hash and/// then manually searched. After this, insertions into a vacant entry/// still require an owned key to be provided./// Raw entries are useful for such exotic situations as:/// * Hash memoization/// * Deferring the creation of an owned key until it is known to be required/// * Using a search key that doesn't work with the Borrow trait/// * Using custom comparison logic without newtype wrappers/// Because raw entries provide much more low-level control, it's much easier/// to put the HashMap into an inconsistent state which, while memory-safe,/// will cause the map to produce seemingly random results. Higher-level and/// more foolproof APIs like `entry` should be preferred when possible./// In particular, the hash used to initialized the raw entry must still be/// consistent with the hash of the key that is ultimately stored in the entry./// This is because implementations of HashMap may need to recompute hashes/// when resizing, at which point only the keys are available./// Raw entries give mutable access to the keys. This must not be used/// to modify how the key would compare or hash, as the map will not re-evaluate/// where the key should go, meaning the keys may become "lost" if their/// location does not reflect their state. For instance, if you change a key/// so that the map now contains keys which compare equal, search may start/// acting erratically, with two keys randomly masking each other. Implementations/// are free to assume this doesn't happen (within the limits of memory-safety).raw_entryRawEntryBuilder/// Creates a raw immutable entry builder for the HashMap./// then manually searched./// This is useful for/// Unless you are in such a situation, higher-level and more foolproof APIs like/// `get` should be preferred./// Immutable raw entries have very limited use; you might instead want `raw_entry_mut`./// Creates an empty `HashMap<K, V, S, A>`, with the `Default` value for the hasher and allocator./// An iterator over the entries of a `HashMap`./// This `struct` is created by the [`iter`] method on [`HashMap`]. See its/// documentation for more./// [`iter`]: struct.HashMap.html#method.iter/// [`HashMap`]: struct.HashMap.html// FIXME(#26925) Remove in favor of `#[derive(Clone)]`// To ensure invariance with respect to V/// A mutable iterator over the entries of a `HashMap`./// This `struct` is created by the [`iter_mut`] method on [`HashMap`]. See its/// [`iter_mut`]: struct.HashMap.html#method.iter_mut// We override the default Send impl which has K: Sync instead of K: Send. Both// are correct, but this one is more general since it allows keys which// implement Send but not Sync./// Returns a iterator of references over the remaining items./// An owning iterator over the entries of a `HashMap`./// This `struct` is created by the [`into_iter`] method on [`HashMap`]/// (provided by the `IntoIterator` trait). See its documentation for more./// [`into_iter`]: struct.HashMap.html#method.into_iter/// An iterator over the keys of a `HashMap`./// This `struct` is created by the [`keys`] method on [`HashMap`]. See its/// [`keys`]: struct.HashMap.html#method.keys/// An iterator over the values of a `HashMap`./// This `struct` is created by the [`values`] method on [`HashMap`]. See its/// [`values`]: struct.HashMap.html#method.values/// A draining iterator over the entries of a `HashMap`./// This `struct` is created by the [`drain`] method on [`HashMap`]. See its/// [`drain`]: struct.HashMap.html#method.drainDrainFilterInner/// A draining iterator over entries of a `HashMap` which don't satisfy the predicate `f`./// This `struct` is created by the [`drain_filter`] method on [`HashMap`]. See its/// [`drain_filter`]: struct.HashMap.html#method.drain_filterConsumeAllOnDrop/// Portions of `DrainFilter` shared with `set::DrainFilter`/// A mutable iterator over the values of a `HashMap`./// This `struct` is created by the [`values_mut`] method on [`HashMap`]. See its/// [`values_mut`]: struct.HashMap.html#method.values_mut/// A builder for computing where in a [`HashMap`] a key-value pair would be stored./// See the [`HashMap::raw_entry_mut`] docs for usage examples./// [`HashMap::raw_entry_mut`]: struct.HashMap.html#method.raw_entry_mutRawEntryMutRawOccupiedEntryMutOccupied/// An occupied entry.RawVacantEntryMutVacant/// A vacant entry./// A view into a single entry in a map, which may either be vacant or occupied./// This is a lower-level version of [`Entry`]./// This `enum` is constructed through the [`raw_entry_mut`] method on [`HashMap`],/// then calling one of the methods of that [`RawEntryBuilderMut`]./// [`Entry`]: enum.Entry.html/// [`raw_entry_mut`]: struct.HashMap.html#method.raw_entry_mut/// [`RawEntryBuilderMut`]: struct.RawEntryBuilderMut.htmlelem/// A view into an occupied entry in a `HashMap`./// It is part of the [`RawEntryMut`] enum./// [`RawEntryMut`]: enum.RawEntryMut.html/// A view into a vacant entry in a `HashMap`./// See the [`HashMap::raw_entry`] docs for usage examples./// [`HashMap::raw_entry`]: struct.HashMap.html#method.raw_entryfrom_key/// Creates a `RawEntryMut` from the given key.from_key_hashed_nocheck/// Creates a `RawEntryMut` from the given key and its hash./// Creates a `RawEntryMut` from the given hash./// Access an entry by key./// Access an entry by a key and its hash./// Access an entry by hash./// Sets the value of the entry, and returns a RawOccupiedEntryMut./// let mut map: HashMap<&str, u32> = HashMap::new();/// let entry = map.raw_entry_mut().from_key("horseyland").insert("horseyland", 37);/// assert_eq!(entry.remove_entry(), ("horseyland", 37));or_insert/// Ensures a value is in the entry by inserting the default if empty, and returns/// mutable references to the key and value in the entry./// map.raw_entry_mut().from_key("poneyland").or_insert("poneyland", 3);/// assert_eq!(map["poneyland"], 3);/// *map.raw_entry_mut().from_key("poneyland").or_insert("poneyland", 10).1 *= 2;/// assert_eq!(map["poneyland"], 6);or_insert_with/// Ensures a value is in the entry by inserting the result of the default function if empty,/// and returns mutable references to the key and value in the entry./// let mut map: HashMap<&str, String> = HashMap::new();/// map.raw_entry_mut().from_key("poneyland").or_insert_with(|| {///     ("poneyland", "hoho".to_string())/// assert_eq!(map["poneyland"], "hoho".to_string());and_modify/// Provides in-place mutable access to an occupied entry before any/// potential inserts into the map./// map.raw_entry_mut()///    .from_key("poneyland")///    .and_modify(|_k, v| { *v += 1 })///    .or_insert("poneyland", 42);/// assert_eq!(map["poneyland"], 42);///    .or_insert("poneyland", 0);/// assert_eq!(map["poneyland"], 43);and_replace_entry_with/// Provides shared access to the key and owned access to the value of/// an occupied entry and allows to replace or remove it based on the/// value of the returned option./// use hashbrown::hash_map::RawEntryMut;/// let entry = map///     .raw_entry_mut()///     .from_key("poneyland")///     .and_replace_entry_with(|_k, _v| panic!());/// match entry {///     RawEntryMut::Vacant(_) => {},///     RawEntryMut::Occupied(_) => panic!(),/// map.insert("poneyland", 42);///     .and_replace_entry_with(|k, v| {///         assert_eq!(k, &"poneyland");///         assert_eq!(v, 42);///         Some(v + 1)///     RawEntryMut::Occupied(e) => {///         assert_eq!(e.key(), &"poneyland");///         assert_eq!(e.get(), &43);///     RawEntryMut::Vacant(_) => panic!(),///     .and_replace_entry_with(|_k, _v| None);/// assert!(!map.contains_key("poneyland"));/// Gets a reference to the key in the entry.key_mut/// Gets a mutable reference to the key in the entry.into_key/// Converts the entry into a mutable reference to the key in the entry/// with a lifetime bound to the map itself./// Gets a reference to the value in the entry.into_mut/// Converts the OccupiedEntry into a mutable reference to the value in the entry/// Gets a mutable reference to the value in the entry./// Gets a reference to the key and value in the entry./// Gets a mutable reference to the key and value in the entry.into_key_value/// Converts the OccupiedEntry into a mutable reference to the key and value in the entry/// Sets the value of the entry, and returns the entry's old value.insert_key/// Takes the value out of the entry, and returns it./// Take the ownership of the key and value from the map.replace_entry_with/// the entry and allows to replace or remove it based on the/// Sets the value of the entry with the VacantEntry's key,/// and returns a mutable reference to it.insert_hashed_nocheckinsert_with_hasher/// Set the value of an entry with a custom hasher function.insert_entryOccupiedEntryVacantEntry/// This `enum` is constructed from the [`entry`] method on [`HashMap`]./// [`entry`]: struct.HashMap.html#method.entry/// It is part of the [`Entry`] enum./// The entry in the map that was already occupied./// The value which was not inserted, because the entry was already occupied./// The error returned by [`try_insert`](HashMap::try_insert) when the key already exists./// Contains the occupied entry, and the value that was not inserted./// Creates a consuming iterator, that is, one that moves each key-value/// pair out of the map in arbitrary order. The map cannot be used after/// calling this./// // Not possible with .iter()/// let vec: Vec<(&str, i32)> = map.into_iter().collect();/// Sets the value of the entry, and returns an OccupiedEntry./// let entry = map.entry("horseyland").insert(37);/// assert_eq!(entry.key(), &"horseyland");/// map.entry("poneyland").or_insert(3);/// *map.entry("poneyland").or_insert(10) *= 2;/// and returns a mutable reference to the value in the entry./// let s = "hoho".to_string();/// map.entry("poneyland").or_insert_with(|| s);or_insert_with_key/// Ensures a value is in the entry by inserting, if empty, the result of the default function./// This method allows for generating key-derived values for insertion by providing the default/// function a reference to the key that was moved during the `.entry(key)` method call./// The reference to the moved key is provided so that cloning or copying the key is/// unnecessary, unlike with `.or_insert_with(|| ... )`./// let mut map: HashMap<&str, usize> = HashMap::new();/// map.entry("poneyland").or_insert_with_key(|key| key.chars().count());/// assert_eq!(map["poneyland"], 9);/// Returns a reference to this entry's key./// assert_eq!(map.entry("poneyland").key(), &"poneyland");/// map.entry("poneyland")///    .and_modify(|e| { *e += 1 })///    .or_insert(42);/// use hashbrown::hash_map::Entry;///     .entry("poneyland")///     Entry::Vacant(e) => {///     Entry::Occupied(_) => panic!(),///     Entry::Occupied(e) => {///     Entry::Vacant(_) => panic!(),///     Entry::Vacant(e) => assert_eq!(e.key(), &"poneyland"),or_default/// Ensures a value is in the entry by inserting the default value if empty,/// let mut map: HashMap<&str, Option<u32>> = HashMap::new();/// map.entry("poneyland").or_default();/// assert_eq!(map["poneyland"], None);/// map.entry("poneyland").or_insert(12);/// if let Entry::Occupied(o) = map.entry("poneyland") {///     // We delete the entry from the map.///     o.remove_entry();/// assert_eq!(map.contains_key("poneyland"), false);///     assert_eq!(o.get(), &12);/// If you need a reference to the `OccupiedEntry` which may outlive the/// destruction of the `Entry` value, see [`into_mut`]./// [`into_mut`]: #method.into_mut/// assert_eq!(map["poneyland"], 12);/// if let Entry::Occupied(mut o) = map.entry("poneyland") {///     *o.get_mut() += 10;///     assert_eq!(*o.get(), 22);///     // We can use the same Entry multiple times.///     *o.get_mut() += 2;/// assert_eq!(map["poneyland"], 24);/// If you need multiple references to the `OccupiedEntry`, see [`get_mut`]./// [`get_mut`]: #method.get_mut///     *o.into_mut() += 10;/// assert_eq!(map["poneyland"], 22);///     assert_eq!(o.insert(15), 12);/// assert_eq!(map["poneyland"], 15);///     assert_eq!(o.remove(), 12);replace_entry/// Replaces the entry, returning the old key and value. The new key in the hash map will be/// the key used to create this entry./// Will panic if this OccupiedEntry was created through [`Entry::insert`]./// use hashbrown::hash_map::{Entry, HashMap};/// use std::rc::Rc;/// let mut map: HashMap<Rc<String>, u32> = HashMap::new();/// map.insert(Rc::new("Stringthing".to_string()), 15);/// let my_key = Rc::new("Stringthing".to_string());/// if let Entry::Occupied(entry) = map.entry(my_key) {///     // Also replace the key with a handle to our other key.///     let (old_key, old_value): (Rc<String>, u32) = entry.replace_entry(16);replace_key/// Replaces the key in the hash map with the key used to create this entry./// let mut known_strings: Vec<Rc<String>> = Vec::new();/// // Initialise known strings, run program, etc./// reclaim_memory(&mut map, &known_strings);/// fn reclaim_memory(map: &mut HashMap<Rc<String>, u32>, known_strings: &[Rc<String>] ) {///     for s in known_strings {///         if let Entry::Occupied(entry) = map.entry(s.clone()) {///             // Replaces the entry's key with our version of it in `known_strings`.///             entry.replace_key();/// let entry = match map.entry("poneyland") {///         e.replace_entry_with(|k, v| {///             assert_eq!(k, &"poneyland");///             assert_eq!(v, 42);///             Some(v + 1)///     Entry::Occupied(e) => e.replace_entry_with(|_k, _v| None),/// Gets a reference to the key that would be used when inserting a value/// through the `VacantEntry`./// Take ownership of the key./// if let Entry::Vacant(v) = map.entry("poneyland") {///     v.into_key();/// if let Entry::Vacant(o) = map.entry("poneyland") {///     o.insert(37);/// assert_eq!(map["poneyland"], 37);/// Inserts all new key-values from the iterator and replaces values with existing/// keys with new values returned from the iterator.assert_covarianceSmallRngtest_zero_capacitiestest_create_capacity_zerotest_inserttest_clonetest_clone_fromDROP_VECTORDroppabletest_dropstest_empty_removetest_empty_entrytest_lots_of_insertions// FIXME: takes too longtest_find_muttest_insert_overwritetest_insert_conflictstest_conflict_removetest_is_emptytest_removetest_remove_entrytest_findtest_showtest_behavior_resize_policytest_reserve_shrink_to_fittest_size_hinttest_iter_lentest_mut_size_hinttest_iter_mut_lentest_indextest_index_nonexistenttest_entrytest_entry_take_doesnt_corrupttest_capacity_not_less_than_lentest_occupied_entry_keytest_vacant_entry_keytest_occupied_entry_replace_entry_withtest_entry_and_replace_entry_withtest_raw_occupied_entry_replace_entry_withtest_raw_entry_and_replace_entry_withtest_replace_entry_with_doesnt_corrupttest_retaintest_drain_filtertest_try_reserve// FIXME: no OOM signalling (https://github.com/rust-lang/miri/issues/613)test_raw_entrytest_key_without_hash_impltest_const_with_hashertest_mapdo_allocdeallocateBitMaskWordBITMASK_MASKBITMASK_STRIDEBitMask/// A bit mask which contains the result of a `Match` operation on a `Group` and/// allows iterating through them./// The bit mask is arranged so that low-order bits represent lower memory/// addresses for group match results./// For implementation reasons, the bits in the set may be sparsely packed, so/// that there is only one bit-per-byte used (the high bit, 7). If this is the/// case, `BITMASK_STRIDE` will be 8 to indicate a divide-by-8 should be/// performed on counts/indices to normalize this difference. `BITMASK_MASK` is/// similarly a mask of all the actually-used bits./// Returns a new `BitMask` with all bits inverted.remove_lowest_bit/// Returns a new `BitMask` with the lowest bit removed.any_bit_set/// Returns whether the `BitMask` has at least one set bit.lowest_set_bit/// Returns the first set bit in the `BitMask`, if there is one.lowest_set_bit_nonzerotrailing_zeros/// Returns the number of trailing zeroes in the `BitMask`./// Returns the number of leading zeroes in the `BitMask`.BitMaskIter/// Iterator over the contents of a `BitMask`, returning the indicies of setbitmaskGroupWord// Use the native word size as the group size. Using a 64-bit group size on// a 32-bit architecture will just end up being more expensive because// shifts and multiplies will need to be emulated.// We only care about the highest bit of each byte for the mask./// Helper function to replicate a byte across a `GroupWord`./// Abstraction over a group of control bytes which can be scanned in/// parallel./// This implementation uses a word-sized integer.WIDTH/// Number of bytes in the group.static_empty/// Returns a full group of empty bytes, suitable for use as the initial/// value for an empty hash table./// This is guaranteed to be aligned to the group size./// Loads a group of bytes starting at the given address.// unaligned loadload_aligned/// Loads a group of bytes starting at the given address, which must be/// aligned to `mem::align_of::<Group>()`.store_aligned/// Stores the group of bytes to the given address, which must bematch_byte/// Returns a `BitMask` indicating all bytes in the group which *may*/// have the given value./// This function may return a false positive in certain cases where/// the byte in the group differs from the searched value only in its/// lowest bit. This is fine because:/// - This never happens for `EMPTY` and `DELETED`, only full entries./// - The check for key equality will catch these./// - This only happens if there is at least 1 true match./// - The chance of this happening is very low (< 1% chance per byte).match_empty/// Returns a `BitMask` indicating all bytes in the group which are/// `EMPTY`.match_empty_or_deleted/// `EMPTY` or `DELETED`.match_full/// Returns a `BitMask` indicating all bytes in the group which are full.convert_special_to_empty_and_full_to_deleted/// Performs the following transformation on all bytes in the group:/// - `EMPTY => EMPTY`/// - `DELETED => EMPTY`/// - `FULL => DELETED`// We perform all operations in the native endianess, and convert to// little-endian just before creating a BitMask. The can potentially// enable the compiler to eliminate unnecessary byte swaps if we are// only checking whether a BitMask is empty."generic.rs"// On stable we can use #[cold] to get a equivalent effect: this attributes// suggests that the function is unlikely to be calledlikelyunlikely/// Whether memory allocation errors should return an error or abort./// Error to return on capacity overflow.alloc_err/// Error to return on allocation error./// Control byte value for an empty bucket.DELETED/// Control byte value for a deleted bucket./// Checks whether a control byte represents a full bucket (top bit is clear)./// Checks whether a control byte represents a special value (top bit is set).special_is_empty/// Checks whether a special control value is EMPTY (just check 1 bit).h1/// Primary hash function, used to select the initial bucket to probe from.h2/// Secondary hash function, saved in the low 7 bits of the control byte.ProbeSeq/// Probe sequence based on triangular numbers, which is guaranteed (since our/// table size is a power of two) to visit every group of elements exactly once./// A triangular probe has us jump by 1 more group every time. So first we/// jump by 1 group (meaning we just continue our linear scan), then 2 groups/// (skipping over 1 group), then 3 groups (skipping over 2 groups), and so on./// Proof that the probe will visit every group in the table:/// <https://fgiesen.wordpress.com/2015/02/22/triangular-numbers-mod-2n/>move_nextcapacity_to_buckets/// Returns the number of buckets needed to hold the given number of items,/// taking the maximum load factor into account./// Returns `None` if an overflow occurs.// Workaround for emscripten bug emscripten-core/emscripten-fastcomp#258bucket_mask_to_capacity/// Returns the maximum effective capacity for the given bucket mask, taking/// the maximum load factor into account.ctrl_alignTableLayout/// Helper which allows the max calculation for ctrl_align to be statically computed for each T/// while keeping the rest of `calculate_layout_for` independent of `T`calculate_layout_forcalculate_layout/// Returns a Layout which describes the allocation required for a hash table,/// and the offset of the control bytes in the allocation./// (the offset is also one past last element of buckets)// Actually it is pointer to next element than element itself// this is needed to maintain pointer arithmetic invariants// keeping direct pointer to element introduces difficulty.// Using `NonNull` for variance and niche layout/// A reference to a hash table bucket containing a `T`./// This is usually just a pointer to the element itself. However if the element/// is a ZST, then we instead track the index of the element in the table so/// that `erase` works properly.// This Send impl is needed for rayon support. This is safe since Bucket is// never exposed in a public API.from_base_indexto_base_indexnext_ncopy_from_nonoverlappingRawTableInner// Tell dropck that we own instances of T./// A raw hash table with an unsafe API.bucket_mask// Mask to get an index from a hash value. The value is one less than the// number of buckets in the table.ctrl// [Padding], T1, T2, ..., Tlast, C1, C2, ...//                                ^ points heregrowth_left// Number of elements that can be inserted before we need to grow the table// Number of elements in the table, only really used by len()/// Non-generic part of `RawTable` which allows functions to be instantiated only once regardless/// of how many different key-value types are used./// Creates a new empty hash table without allocating any memory./// In effect this returns a table with exactly 1 bucket. However we can/// leave the data pointer dangling since that bucket is never written to/// due to our load factor forcing us to always have at least 1 free bucket./// Allocates a new hash table with at least enough capacity for inserting/// the given number of elements without reallocating./// Creates a new empty hash table without allocating any memory, using the/// given allocator.new_uninitialized/// Allocates a new hash table with the given number of buckets./// The control bytes are left uninitialized.fallible_with_capacity/// Attempts to allocate a new hash table with at least enough capacity/// for inserting the given number of elements without reallocating./// Allocates a new hash table using the given allocator, with at least enough capacity for/// inserting the given number of elements without reallocating.free_buckets/// Deallocates the table without dropping any entries.data_end/// Returns pointer to one past last element of data table.bucket_index/// Returns the index of a bucket from a `Bucket`.bucket/// Returns a pointer to an element in the table.erase_no_drop/// Erases an element from the table without dropping it./// Erases an element from the table, dropping it in place./// Removes an element from the table, returning it./// Finds and removes an element from the table, returning it.clear_no_drop/// Marks all table buckets as empty without dropping their contents./// Removes all elements from the table without freeing the backing memory.drop_elements/// Shrinks the table to fit `max(self.len(), min_size)` elements./// Ensures that at least `additional` items can be inserted into the table/// without reallocation./// Tries to ensure that at least `additional` items can be inserted into/// the table without reallocation.reserve_rehash/// Out-of-line slow path for `reserve` and `try_reserve`.rehash_in_place/// Rehashes the contents of the table in place (i.e. without changing the/// allocation)./// If `hasher` panics then some the table's contents may be lost./// Allocates a new table of a different size and moves the contents of the/// current table into it./// Inserts a new element into the table, and returns its raw bucket./// This does not check if the given element already exists in the table./// Inserts a new element into the table, and returns a mutable reference to it.replace_bucket_with/// Temporary removes a bucket, applying the given function to the removed/// element and optionally put back the returned value in the same bucket./// Returns `true` if the bucket still contains an element/// This does not check if the given bucket is actually occupied./// Searches for an element in the table./// Gets a reference to an element in the table./// Gets a mutable reference to an element in the table./// This number is a lower bound; the table might be able to hold/// Returns the number of elements in the table./// Returns the number of buckets in the table./// Returns an iterator over every element in the table. It is up to/// the caller to ensure that the `RawTable` outlives the `RawIter`./// Because we cannot make the `next` method unsafe on the `RawIter`/// struct, we have to make the `iter` method unsafe.iter_hashRawIterHash/// Returns an iterator over occupied buckets that could match a given hash./// In rare cases, the iterator may return a bucket with a different hash./// It is up to the caller to ensure that the `RawTable` outlives the/// `RawIterHash`. Because we cannot make the `next` method unsafe on the/// `RawIterHash` struct, we have to make the `iter_hash` method unsafe./// Returns an iterator which removes all elements from the table without/// freeing the memory.drain_iter_from/// Iteration starts at the provided iterator's current location./// It is up to the caller to ensure that the iterator is valid for this/// `RawTable` and covers all items that remain in the table.into_iter_from/// Returns an iterator which consumes all elements from the table.into_allocation/// Converts the table into a raw allocation. The contents of the table/// should be dropped using a `RawIter` before freeing the allocation.prepare_insert_slot/// Searches for an empty or deleted bucket which is suitable for inserting/// a new element and sets the hash for that slot./// There must be at least 1 empty bucket in the table.find_insert_slot/// a new element.prepare_rehash_in_placeprobe_seq/// Returns an iterator-like object for a probe sequence on the table./// This iterator never terminates, but is guaranteed to visit each bucket/// group exactly once. The loop using `probe_seq` must terminate upon/// reaching a group containing an empty bucket.record_item_insert_atis_in_same_groupset_ctrl_h2/// Sets a control byte to the hash, and possibly also the replicated control byte at/// the end of the array.replace_ctrl_h2set_ctrl/// Sets a control byte, and possibly also the replicated control byte at/// Returns a pointer to a control byte.num_ctrl_bytesis_empty_singletonprepare_resizeScopeGuardclone_from_specRawTableClone/// Specialization of `clone_from` for `Copy` typesclone_from_impl/// Common code for clone and clone_from. Assumes `self.buckets() == source.buckets()`.current_group// Mask of full buckets in the current group. Bits are cleared from this// mask as each element is processed.// Pointer to the buckets for the current group.next_ctrl// Pointer to the next group of control bytes,// Must be aligned to the group size.// Pointer one past the last control byte of this range./// Iterator over a sub-range of a table. Unlike `RawIter` this iterator does/// not track an item count./// Returns a `RawIterRange` covering a subset of a table./// The control byte address must be aligned to the group size.// We make raw iterators unconditionally Send and Sync, and let the PhantomData// in the actual iterator implementations determine the real Send/Sync bounds./// Iterator which returns a raw pointer to every full bucket in the table./// For maximum flexibility this iterator is not bound by a lifetime, but you/// must observe several rules when using it:/// - You must not free the hash table while iterating (including via growing/shrinking)./// - It is fine to erase a bucket that has been yielded by the iterator./// - Erasing a bucket that has not yet been yielded by the iterator may still///   result in the iterator yielding that bucket (unless `reflect_remove` is called)./// - It is unspecified whether an element inserted after the iterator was///   created will be yielded by that iterator (unless `reflect_insert` is called)./// - The order in which the iterator yields bucket is unspecified and may///   change in the future.allocation/// Iterator which consumes a table and returns elements.// The table is moved into the iterator for the duration of the drain. This// ensures that an empty table is left if the drain iterator is leaked// without dropping.orig_table// We don't use a &'a mut RawTable<T> because we want RawDrain to be/// Iterator which consumes elements without freeing the table storage.RawIterHashInner/// Iterator over occupied buckets that could match a given hash.h2_hash// The top 7 bits of the hash.// The sequence of groups to probe in the search.// The elements within the group with a matching h2-hash.rehash/// This implementation uses a 128-bit SSE value./// Returns a `BitMask` indicating all bytes in the group which have/// the given value.// FIXME: https://github.com/rust-lang/rust-clippy/issues/3859RustcEntryrustc_entry///     let counter = letters.rustc_entry(ch).or_insert(0);RustcOccupiedEntryRustcVacantEntry/// [`entry`]: struct.HashMap.html#method.rustc_entry/// It is part of the [`RustcEntry`] enum./// [`RustcEntry`]: enum.RustcEntry.html/// Sets the value of the entry, and returns a RustcOccupiedEntry./// map.rustc_entry("poneyland").or_insert(3);/// *map.rustc_entry("poneyland").or_insert(10) *= 2;/// map.rustc_entry("poneyland").or_insert_with(|| s);/// assert_eq!(map.rustc_entry("poneyland").key(), &"poneyland");/// map.rustc_entry("poneyland")/// map.rustc_entry("poneyland").or_default();/// map.rustc_entry("poneyland").or_insert(12);/// use hashbrown::hash_map::RustcEntry;/// if let RustcEntry::Occupied(o) = map.rustc_entry("poneyland") {/// If you need a reference to the `RustcOccupiedEntry` which may outlive the/// destruction of the `RustcEntry` value, see [`into_mut`]./// if let RustcEntry::Occupied(mut o) = map.rustc_entry("poneyland") {///     // We can use the same RustcEntry multiple times./// Converts the RustcOccupiedEntry into a mutable reference to the value in the entry/// If you need multiple references to the `RustcOccupiedEntry`, see [`get_mut`]./// use hashbrown::hash_map::{RustcEntry, HashMap};/// if let RustcEntry::Occupied(entry) = map.rustc_entry(my_key) {///         if let RustcEntry::Occupied(entry) = map.rustc_entry(s.clone()) {/// through the `RustcVacantEntry`./// if let RustcEntry::Vacant(v) = map.rustc_entry("poneyland") {/// Sets the value of the entry with the RustcVacantEntry's key,/// if let RustcEntry::Vacant(o) = map.rustc_entry("poneyland") {/// and returns a RustcOccupiedEntry.///     let o = v.insert_entry(37);///     assert_eq!(o.get(), &37);rustc_iter// Extracted from the scopeguard cratedropfn/// A hash set implemented as a `HashMap` where the value is `()`./// As with the [`HashMap`] type, a `HashSet` requires that the elements/// implement the [`Eq`] and [`Hash`] traits. This can frequently be achieved by/// using `#[derive(PartialEq, Eq, Hash)]`. If you implement these yourself,/// it is important that the following property holds:/// It is a logic error for an item to be modified in such a way that the/// item's hash, as determined by the [`Hash`] trait, or its equality, as/// determined by the [`Eq`] trait, changes while it is in the set. This is/// normally only possible through [`Cell`], [`RefCell`], global state, I/O, or/// unsafe code./// panic does occur then the contents of the `HashSet` may become corrupted and/// use hashbrown::HashSet;/// // would be `HashSet<String>` in this example)./// let mut books = HashSet::new();/// // Add some books./// books.insert("A Dance With Dragons".to_string());/// books.insert("To Kill a Mockingbird".to_string());/// books.insert("The Odyssey".to_string());/// books.insert("The Great Gatsby".to_string());/// if !books.contains("The Winds of Winter") {///     println!("We have {} books, but The Winds of Winter ain't one.",///              books.len());/// // Remove a book./// books.remove("The Odyssey");/// for book in &books {///     println!("{}", book);/// The easiest way to use `HashSet` with a custom type is to derive/// [`Eq`] and [`Hash`]. We must also derive [`PartialEq`]. This will in the/// future be implied by [`Eq`].///     power: usize,/// let mut vikings = HashSet::new();/// vikings.insert(Viking { name: "Einar".to_string(), power: 9 });/// vikings.insert(Viking { name: "Olaf".to_string(), power: 4 });/// vikings.insert(Viking { name: "Harald".to_string(), power: 8 });/// // Use derived implementation to print the vikings./// for x in &vikings {///     println!("{:?}", x);/// A `HashSet` with fixed list of elements can be initialized from an array:/// let viking_names: HashSet<&'static str> =///     [ "Einar", "Olaf", "Harald" ].iter().cloned().collect();/// // use the values stored in the set/// Creates an empty `HashSet`./// The hash set is initially created with a capacity of 0, so it will not allocate until it/// let set: HashSet<i32> = HashSet::new();/// Creates an empty `HashSet` with the specified capacity./// The hash set will be able to hold at least `capacity` elements without/// reallocating. If `capacity` is 0, the hash set will not allocate./// let set: HashSet<i32> = HashSet::with_capacity(10);/// assert!(set.capacity() >= 10);/// Returns the number of elements the set can hold without reallocating./// let set: HashSet<i32> = HashSet::with_capacity(100);/// assert!(set.capacity() >= 100);/// An iterator visiting all elements in arbitrary order./// The iterator element type is `&'a T`./// let mut set = HashSet::new();/// set.insert("a");/// set.insert("b");/// // Will print in an arbitrary order./// for x in set.iter() {/// Returns the number of elements in the set./// let mut v = HashSet::new();/// assert_eq!(v.len(), 0);/// v.insert(1);/// assert_eq!(v.len(), 1);/// Returns `true` if the set contains no elements./// Clears the set, returning all elements in an iterator./// let mut set: HashSet<_> = [1, 2, 3].iter().cloned().collect();/// assert!(!set.is_empty());/// // print 1, 2, 3 in an arbitrary order/// for i in set.drain() {///     println!("{}", i);/// assert!(set.is_empty());/// let xs = [1,2,3,4,5,6];/// let mut set: HashSet<i32> = xs.iter().cloned().collect();/// set.retain(|&k| k % 2 == 0);/// assert_eq!(set.len(), 3);/// In other words, move all elements `e` such that `f(&e)` returns `true` out/// the predicate are dropped from the set./// let mut set: HashSet<i32> = (0..8).collect();/// let drained: HashSet<i32> = set.drain_filter(|v| v % 2 == 0).collect();/// let mut evens = drained.into_iter().collect::<Vec<_>>();/// let mut odds = set.into_iter().collect::<Vec<_>>();/// Clears the set, removing all values./// Creates a new empty hash set which will use the given hasher to hash/// The hash set is also created with the default initial capacity./// Warning: `hasher` is normally randomly generated, and/// is designed to allow `HashSet`s to be resistant to attacks that/// let mut set = HashSet::with_hasher(s);/// set.insert(2);/// Creates an empty `HashSet` with the specified capacity, using/// `hasher` to hash the keys./// let mut set = HashSet::with_capacity_and_hasher(10, s);/// set.insert(1);/// Returns a reference to the set's [`BuildHasher`]./// let set: HashSet<i32> = HashSet::with_hasher(hasher);/// let hasher: &DefaultHashBuilder = set.hasher();/// in the `HashSet`. The collection may reserve more space to avoid/// Panics if the new allocation size overflows `usize`./// let mut set: HashSet<i32> = HashSet::new();/// set.reserve(10);/// in the given `HashSet<K,V>`. The collection may reserve more space to avoid/// set.try_reserve(10).expect("why is the test harness OOMing on 10 bytes?");/// Shrinks the capacity of the set as much as possible. It will drop/// let mut set = HashSet::with_capacity(100);/// set.shrink_to_fit();/// assert!(set.capacity() >= 2);/// Shrinks the capacity of the set with a lower limit. It will drop/// Panics if the current capacity is smaller than the supplied/// minimum capacity./// set.shrink_to(10);/// set.shrink_to(0);Difference/// Visits the values representing the difference,/// i.e., the values that are in `self` but not in `other`./// let a: HashSet<_> = [1, 2, 3].iter().cloned().collect();/// let b: HashSet<_> = [4, 2, 3, 4].iter().cloned().collect();/// // Can be seen as `a - b`./// for x in a.difference(&b) {///     println!("{}", x); // Print 1/// let diff: HashSet<_> = a.difference(&b).collect();/// assert_eq!(diff, [1].iter().collect());/// // Note that difference is not symmetric,/// // and `b - a` means something else:/// let diff: HashSet<_> = b.difference(&a).collect();/// assert_eq!(diff, [4].iter().collect());SymmetricDifference/// Visits the values representing the symmetric difference,/// i.e., the values that are in `self` or in `other` but not in both./// // Print 1, 4 in arbitrary order./// for x in a.symmetric_difference(&b) {/// let diff1: HashSet<_> = a.symmetric_difference(&b).collect();/// let diff2: HashSet<_> = b.symmetric_difference(&a).collect();/// assert_eq!(diff1, diff2);/// assert_eq!(diff1, [1, 4].iter().collect());Intersection/// Visits the values representing the intersection,/// i.e., the values that are both in `self` and `other`./// // Print 2, 3 in arbitrary order./// for x in a.intersection(&b) {/// let intersection: HashSet<_> = a.intersection(&b).collect();/// assert_eq!(intersection, [2, 3].iter().collect());Union/// Visits the values representing the union,/// i.e., all the values in `self` or `other`, without duplicates./// // Print 1, 2, 3, 4 in arbitrary order./// for x in a.union(&b) {/// let union: HashSet<_> = a.union(&b).collect();/// assert_eq!(union, [1, 2, 3, 4].iter().collect());/// Returns `true` if the set contains a value./// The value may be any borrowed form of the set's value type, but/// the value type./// let set: HashSet<_> = [1, 2, 3].iter().cloned().collect();/// assert_eq!(set.contains(&1), true);/// assert_eq!(set.contains(&4), false);/// Returns a reference to the value in the set, if any, that is equal to the given value./// assert_eq!(set.get(&2), Some(&2));/// assert_eq!(set.get(&4), None);get_or_insert/// Inserts the given `value` into the set if it is not present, then/// returns a reference to the value in the set./// assert_eq!(set.get_or_insert(2), &2);/// assert_eq!(set.get_or_insert(100), &100);/// assert_eq!(set.len(), 4); // 100 was insertedget_or_insert_owned/// Inserts an owned copy of the given `value` into the set if it is not/// present, then returns a reference to the value in the set./// let mut set: HashSet<String> = ["cat", "dog", "horse"]///     .iter().map(|&pet| pet.to_owned()).collect();/// for &pet in &["cat", "dog", "fish"] {///     let value = set.get_or_insert_owned(pet);///     assert_eq!(value, pet);/// assert_eq!(set.len(), 4); // a new "fish" was insertedget_or_insert_with/// Inserts a value computed from `f` into the set if the given `value` is/// not present, then returns a reference to the value in the set.///     let value = set.get_or_insert_with(pet, str::to_owned);is_disjoint/// let mut b = HashSet::new();/// assert_eq!(a.is_disjoint(&b), true);/// b.insert(4);/// b.insert(1);/// assert_eq!(a.is_disjoint(&b), false);/// i.e., `other` contains at least all the values in `self`./// let sup: HashSet<_> = [1, 2, 3].iter().cloned().collect();/// assert_eq!(set.is_subset(&sup), true);/// set.insert(4);/// assert_eq!(set.is_subset(&sup), false);is_superset/// i.e., `self` contains at least all the values in `other`./// let sub: HashSet<_> = [1, 2].iter().cloned().collect();/// assert_eq!(set.is_superset(&sub), false);/// set.insert(0);/// assert_eq!(set.is_superset(&sub), true);/// Adds a value to the set./// If the set did not have this value present, `true` is returned./// If the set did have this value present, `false` is returned./// assert_eq!(set.insert(2), true);/// assert_eq!(set.insert(2), false);/// assert_eq!(set.len(), 1);replace/// Adds a value to the set, replacing the existing value, if any, that is equal to the given/// one. Returns the replaced value./// set.insert(Vec::<i32>::new());/// assert_eq!(set.get(&[][..]).unwrap().capacity(), 0);/// set.replace(Vec::with_capacity(10));/// assert_eq!(set.get(&[][..]).unwrap().capacity(), 10);/// Removes a value from the set. Returns whether the value was/// present in the set./// assert_eq!(set.remove(&2), true);/// assert_eq!(set.remove(&2), false);/// Removes and returns the value in the set, if any, that is equal to the given one./// assert_eq!(set.take(&2), Some(2));/// assert_eq!(set.take(&2), None);/// Creates an empty `HashSet<T, S>` with the `Default` value for the hasher./// Returns the union of `self` and `rhs` as a new `HashSet<T, S>`./// let a: HashSet<_> = vec![1, 2, 3].into_iter().collect();/// let b: HashSet<_> = vec![3, 4, 5].into_iter().collect();/// Returns the intersection of `self` and `rhs` as a new `HashSet<T, S>`./// let b: HashSet<_> = vec![2, 3, 4].into_iter().collect();/// Returns the symmetric difference of `self` and `rhs` as a new `HashSet<T, S>`./// Returns the difference of `self` and `rhs` as a new `HashSet<T, S>`./// An iterator over the items of a `HashSet`./// This `struct` is created by the [`iter`] method on [`HashSet`]./// [`HashSet`]: struct.HashSet.html/// [`iter`]: struct.HashSet.html#method.iter/// An owning iterator over the items of a `HashSet`./// This `struct` is created by the [`into_iter`] method on [`HashSet`]/// [`into_iter`]: struct.HashSet.html#method.into_iter/// A draining iterator over the items of a `HashSet`./// This `struct` is created by the [`drain`] method on [`HashSet`]./// [`drain`]: struct.HashSet.html#method.drain/// A draining iterator over entries of a `HashSet` which don't satisfy the predicate `f`./// This `struct` is created by the [`drain_filter`] method on [`HashSet`]. See its/// [`drain_filter`]: struct.HashSet.html#method.drain_filter// iterator of the first setother// the second set/// A lazy iterator producing elements in the intersection of `HashSet`s./// This `struct` is created by the [`intersection`] method on [`HashSet`]./// [`intersection`]: struct.HashSet.html#method.intersection/// A lazy iterator producing elements in the difference of `HashSet`s./// This `struct` is created by the [`difference`] method on [`HashSet`]./// [`difference`]: struct.HashSet.html#method.difference/// A lazy iterator producing elements in the symmetric difference of `HashSet`s./// This `struct` is created by the [`symmetric_difference`] method on/// [`HashSet`]. See its documentation for more./// [`symmetric_difference`]: struct.HashSet.html#method.symmetric_difference/// A lazy iterator producing elements in the union of `HashSet`s./// This `struct` is created by the [`union`] method on [`HashSet`]./// [`union`]: struct.HashSet.html#method.union/// Creates a consuming iterator, that is, one that moves each value out/// of the set in arbitrary order. The set cannot be used after calling/// set.insert("a".to_string());/// set.insert("b".to_string());/// // Not possible to collect to a Vec<String> with a regular `.iter()`./// let v: Vec<String> = set.into_iter().collect();/// for x in &v {test_from_maptest_trivial_draintest_draintest_replacetest_set// Future Optimization (FIXME!)// =============================// Iteration over zero sized values is a noop. There is no need// for `bucket.val` in the case of HashSet. I suppose we would need HKT// to get rid of it properly.// yes, we need linked list here for efficient appending!/// Checks if this value is equivalent to the given key./// Returns `true` if both values are equivalent, and `false` otherwise./// # Correctness/// When this function returns `true`, both `self` and `key` must hash to/// the same value./// This trait defines the function used to compare the input value with the/// map keys (or set values) during a lookup operation such as [`HashMap::get`]/// or [`HashSet::contains`]./// It is provided with a blanket implementation based on the/// [`Borrow`](core::borrow::Borrow) trait./// Equivalent values must hash to the same value./// # HashDoS resistance/// The `hash_builder` normally use a fixed key by default and that does/// not allow the `HashMap` to be protected against attacks such as [`HashDoS`]./// Users who require HashDoS resistance should explicitly use/// [`ahash::RandomState`] or [`std::collections::hash_map::RandomState`]/// as the hasher when creating a [`HashMap`], for example with/// [`with_hasher`](HashMap::with_hasher) method./// [`HashDoS`]: https://en.wikipedia.org/wiki/Collision_attack/// [`std::collections::hash_map::RandomState`]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html/// assert_eq!(map.len(), 0);/// assert_eq!(map.capacity(), 0);/// [`with_capacity_and_hasher`](HashMap::with_capacity_and_hasher) method./// [`with_hasher_in`](HashMap::with_hasher_in) method./// # #[cfg(feature = "bumpalo")]/// # fn test() {/// use hashbrown::{HashMap, BumpWrapper};/// let mut map = HashMap::new_in(BumpWrapper(&bump));/// // The created HashMap holds none elements/// // The created HashMap also doesn't allocate memory/// // Now we insert element inside created HashMap/// map.insert("One", 1);/// // We can see that the HashMap holds 1 element/// assert_eq!(map.len(), 1);/// // And it also allocates some capacity/// assert!(map.capacity() > 1);/// #     #[cfg(feature = "bumpalo")]/// #     test()/// [`with_capacity_and_hasher_in`](HashMap::with_capacity_and_hasher_in) method./// let mut map = HashMap::with_capacity_in(5, BumpWrapper(&bump));/// // But it can hold at least 5 elements without reallocating/// let empty_map_capacity = map.capacity();/// assert!(empty_map_capacity >= 5);/// // Now we insert some 5 elements inside created HashMap/// map.insert("One",   1);/// map.insert("Two",   2);/// map.insert("Three", 3);/// map.insert("Four",  4);/// map.insert("Five",  5);/// // We can see that the HashMap holds 5 elements/// assert_eq!(map.len(), 5);/// // But its capacity isn't changed/// assert_eq!(map.capacity(), empty_map_capacity)/// The hash map is initially created with a capacity of 0, so it will not/// allocate until it is first inserted into./// as the hasher when creating a [`HashMap`].allocator/// Returns a reference to the underlying allocator./// assert_eq!(map.len(), 3);/// let mut vec: Vec<&str> = Vec::new();///     vec.push(*key);/// // The `Keys` iterator produces keys in arbitrary order, so the/// let mut vec: Vec<i32> = Vec::new();///     vec.push(*val);/// // The `Values` iterator produces values in arbitrary order, so the/// // values must be sorted to test them against a sorted array./// assert_eq!(vec, [11, 12, 13]);/// let mut vec: Vec<(&str, i32)> = Vec::new();///     vec.push((*key, *val));/// // The `Iter` iterator produces items in arbitrary order, so the/// // items must be sorted to test them against a sorted array./// assert_eq!(vec, [("a", 1), ("b", 2), ("c", 3)]);/// assert_eq!(vec, [("a", 2), ("b", 4), ("c", 6)]);/// If the returned iterator is dropped before being fully consumed, it/// drops the remaining key-value pairs. The returned iterator keeps a/// mutable borrow on the vector to optimize its implementation./// let capacity_before_drain = a.capacity();/// // As we can see, the map is empty and contains no element./// assert!(a.is_empty() && a.len() == 0);/// // But map capacity is equal to old one./// assert_eq!(a.capacity(), capacity_before_drain);/// {   // Iterator is dropped without being consumed.///     let d = a.drain();/// // But the map is empty even if we do not use Drain iterator./// Retains only the elements specified by the predicate. Keeps the/// In other words, remove all pairs `(k, v)` such that `f(&k, &mut v)` returns `false`./// The elements are visited in unsorted (and unspecified) order./// assert_eq!(map.len(), 8);/// // We can see, that the number of elements inside map is changed./// let mut vec: Vec<(i32, i32)> = map.iter().map(|(&k, &v)| (k, v)).collect();/// assert_eq!(vec, [(0, 0), (2, 20), (4, 40), (6, 60)]);/// In other words, move all pairs `(k, v)` such that `f(&k, &mut v)` returns `true` out/// Note that `drain_filter` lets you mutate every value in the filter closure, regardless of/// whether you choose to keep or remove it./// It is unspecified how many more elements will be subjected to the closure/// if a panic occurs in the closure, or a panic occurs while dropping an element,/// or if the `DrainFilter` value is leaked./// Keeps the allocated memory for reuse.///     let d = map.drain_filter(|k, _v| k % 2 != 0);/// // But the map lens have been reduced by half/// // even if we do not use DrainFilter iterator./// let capacity_before_clear = a.capacity();/// // Map is empty./// assert_eq!(a.capacity(), capacity_before_clear);/// Panics if the new capacity exceeds [`isize::MAX`] bytes and [`abort`] the program/// in case of allocation error. Use [`try_reserve`](HashMap::try_reserve) instead/// if you want to handle memory allocation failure./// [`isize::MAX`]: https://doc.rust-lang.org/std/primitive.isize.html/// [`abort`]: https://doc.rust-lang.org/alloc/alloc/fn.handle_alloc_error.html/// // Map is empty and doesn't allocate memory/// // And now map can hold at least 10 elements/// is returned:/// use hashbrown::TryReserveError;/// let mut map: HashMap<i32, i32> = HashMap::new();/// match map.try_reserve(usize::MAX) {///     Err(error) => match error {///         TryReserveError::CapacityOverflow => {}///         _ => panic!("TryReserveError::AllocError ?"),/// #     #[cfg(not(miri))]entry_refEntryRef/// Gets the given key's corresponding entry by reference in the map for in-place manipulation./// let mut words: HashMap<String, usize> = HashMap::new();/// let source = ["poneyland", "horseyland", "poneyland", "poneyland"];/// for (i, &s) in source.iter().enumerate() {///     let counter = words.entry_ref(s).or_insert(0);/// assert_eq!(words["poneyland"], 3);/// assert_eq!(words["horseyland"], 1);/// assert_eq!(map.get_mut(&2), None);get_many_mut/// Attempts to get mutable references to `N` values in the map at once./// Returns an array of length `N` with the results of each query. For soundness, at most one/// mutable reference will be returned to any value. `None` will be returned if any of the/// keys are duplicates or missing./// let mut libraries = HashMap::new();/// libraries.insert("Bodleian Library".to_string(), 1602);/// libraries.insert("Athenæum".to_string(), 1807);/// libraries.insert("Herzogin-Anna-Amalia-Bibliothek".to_string(), 1691);/// libraries.insert("Library of Congress".to_string(), 1800);/// let got = libraries.get_many_mut([///     "Athenæum",///     "Library of Congress",///     got,///     Some([///         &mut 1807,///         &mut 1800,///     ]),/// // Missing keys result in None///     "New York Public Library",/// assert_eq!(got, None);/// // Duplicate keys result in Noneget_many_unchecked_mut/// Attempts to get mutable references to `N` values in the map at once, without validating that/// the values are unique./// Returns an array of length `N` with the results of each query. `None` will be returned if/// any of the keys are missing./// For a safe alternative see [`get_many_mut`](`HashMap::get_many_mut`)./// Calling this method with overlapping keys is *[undefined behavior]* even if the resulting/// references are not used./// [undefined behavior]: https://doc.rust-lang.org/reference/behavior-considered-undefined.htmlget_many_key_value_mut/// Attempts to get mutable references to `N` values in the map at once, with immutable/// references to the corresponding keys./// mutable reference will be returned to any value. `None` will be returned if any of the keys/// are duplicates or missing./// let got = libraries.get_many_key_value_mut([///     "Bodleian Library",///     "Herzogin-Anna-Amalia-Bibliothek",///         (&"Bodleian Library".to_string(), &mut 1602),///         (&"Herzogin-Anna-Amalia-Bibliothek".to_string(), &mut 1691),///     "Gewandhaus",get_many_key_value_unchecked_mut/// references to the corresponding keys, without validating that the values are unique./// For a safe alternative see [`get_many_key_value_mut`](`HashMap::get_many_key_value_mut`).get_many_mut_innerget_many_unchecked_mut_innerbuild_hashes_inner/// types that can be `==` without being identical. See the [`std::collections`]/// [module-level documentation] for more./// [`std::collections`]: https://doc.rust-lang.org/std/collections/index.html/// [module-level documentation]: https://doc.rust-lang.org/std/collections/index.html#insert-and-complex-keysinsert_unique_unchecked/// Insert a key-value pair into the map without checking/// if the key already exists in the map./// Returns a reference to the key and value just inserted./// This operation is safe if a key does not exist in the map./// However, if a key exists in the map already, the behavior is unspecified:/// this operation may panic, loop forever, or any following operation with the map/// may panic, loop forever or return arbitrary result./// That said, this operation (and following operations) are guaranteed to/// not violate memory safety./// This operation is faster than regular insert, because it does not perform/// lookup before insertion./// This operation is useful during initial population of the map./// For example, when constructing a map from another map, we know/// that keys are unique./// let mut map1 = HashMap::new();/// assert_eq!(map1.insert(1, "a"), None);/// assert_eq!(map1.insert(2, "b"), None);/// assert_eq!(map1.insert(3, "c"), None);/// assert_eq!(map1.len(), 3);/// let mut map2 = HashMap::new();/// for (key, value) in map1.into_iter() {///     map2.insert_unique_unchecked(key, value);/// let (key, value) = map2.insert_unique_unchecked(4, "d");/// assert_eq!(key, &4);/// assert_eq!(value, &mut "d");/// *value = "e";/// assert_eq!(map2[&1], "a");/// assert_eq!(map2[&2], "b");/// assert_eq!(map2[&3], "c");/// assert_eq!(map2[&4], "e");/// assert_eq!(map2.len(), 4);/// use hashbrown::hash_map::OccupiedError;/// match map.try_insert(37, "b") {///     Err(OccupiedError { entry, value }) => {///         assert_eq!(entry.key(), &37);///         assert_eq!(entry.get(), &"a");///         assert_eq!(value, "b");///     _ => panic!()/// was previously in the map. Keeps the allocated memory for reuse./// // The map is empty/// assert!(map.is_empty() && map.capacity() == 0);/// // Now map holds none elements/// assert!(map.is_empty());/// key was previously in the map. Keeps the allocated memory for reuse./// // Now map hold none elements/// use core::hash::{BuildHasher, Hash};/// use hashbrown::hash_map::{HashMap, RawEntryMut};/// map.extend([("a", 100), ("b", 200), ("c", 300)]);/// fn compute_hash<K: Hash + ?Sized, S: BuildHasher>(hash_builder: &S, key: &K) -> u64 {///     use core::hash::Hasher;///     let mut state = hash_builder.build_hasher();///     key.hash(&mut state);///     state.finish()/// // Existing key (insert and update)/// match map.raw_entry_mut().from_key(&"a") {///     RawEntryMut::Vacant(_) => unreachable!(),///     RawEntryMut::Occupied(mut view) => {///         assert_eq!(view.get(), &100);///         let v = view.get_mut();///         let new_v = (*v) * 10;///         *v = new_v;///         assert_eq!(view.insert(1111), 1000);/// assert_eq!(map[&"a"], 1111);/// // Existing key (take)/// let hash = compute_hash(map.hasher(), &"c");/// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &"c") {///     RawEntryMut::Occupied(view) => {///         assert_eq!(view.remove_entry(), ("c", 300));/// assert_eq!(map.raw_entry().from_key(&"c"), None);/// assert_eq!(map.len(), 2);/// // Nonexistent key (insert and update)/// let key = "d";/// let hash = compute_hash(map.hasher(), &key);/// match map.raw_entry_mut().from_hash(hash, |q| *q == key) {///     RawEntryMut::Occupied(_) => unreachable!(),///     RawEntryMut::Vacant(view) => {///         let (k, value) = view.insert("d", 4000);///         assert_eq!((*k, *value), ("d", 4000));///         *value = 40000;/// assert_eq!(map[&"d"], 40000);///         assert_eq!(view.remove_entry(), ("d", 40000));/// assert_eq!(map.get(&"d"), None);/// for k in ["a", "b", "c", "d", "e", "f"] {///     let hash = compute_hash(map.hasher(), k);///     let v = map.get(&k).cloned();///     let kv = v.as_ref().map(|v| (&k, v));///     println!("Key: {} and value: {:?}", k, v);///     assert_eq!(map.raw_entry().from_key(&k), kv);///     assert_eq!(map.raw_entry().from_hash(hash, |q| *q == k), kv);///     assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &k), kv);/// use std::collections::hash_map::RandomState;/// // You can specify all types of HashMap, including hasher and allocator./// // Created map is empty and don't allocate memory/// let map: HashMap<u32, String> = Default::default();/// let map: HashMap<u32, String, RandomState> = HashMap::default();/// let map: HashMap<_, _> = [("a", "One"), ("b", "Two")].into();/// assert_eq!(map[&"a"], "One");/// assert_eq!(map[&"b"], "Two");/// let map1 = HashMap::from([(1, 2), (3, 4)]);/// let map2: HashMap<_, _> = [(1, 2), (3, 4)].into();// The default hasher is used to match the std implementation signature/// An iterator over the entries of a `HashMap` in arbitrary order./// let map: HashMap<_, _> = [(1, "a"), (2, "b"), (3, "c")].into();/// let mut iter = map.iter();/// let mut vec = vec![iter.next(), iter.next(), iter.next()];/// assert_eq!(vec, [Some((&1, &"a")), Some((&2, &"b")), Some((&3, &"c"))]);/// // It is fused iterator/// A mutable iterator over the entries of a `HashMap` in arbitrary order./// let mut map: HashMap<_, _> = [(1, "One".to_owned()), (2, "Two".into())].into();/// let mut iter = map.iter_mut();/// iter.next().map(|(_, v)| v.push_str(" Mississippi"));/// assert_eq!(map.get(&1).unwrap(), &"One Mississippi".to_owned());/// assert_eq!(map.get(&2).unwrap(), &"Two Mississippi".to_owned());/// An owning iterator over the entries of a `HashMap` in arbitrary order./// The iterator element type is `(K, V)`./// (provided by the [`IntoIterator`] trait). See its documentation for more./// The map cannot be used after calling that method./// [`IntoIterator`]: https://doc.rust-lang.org/core/iter/trait.IntoIterator.html/// let mut iter = map.into_iter();/// // The `IntoIter` iterator produces items in arbitrary order, so the/// assert_eq!(vec, [Some((1, "a")), Some((2, "b")), Some((3, "c"))]);/// An owning iterator over the keys of a `HashMap` in arbitrary order./// This `struct` is created by the [`into_keys`] method on [`HashMap`]./// [`into_keys`]: struct.HashMap.html#method.into_keys/// let mut keys = map.into_keys();/// let mut vec = vec![keys.next(), keys.next(), keys.next()];/// assert_eq!(vec, [Some(1), Some(2), Some(3)]);/// assert_eq!(keys.next(), None);/// An owning iterator over the values of a `HashMap` in arbitrary order./// This `struct` is created by the [`into_values`] method on [`HashMap`]./// See its documentation for more. The map cannot be used after calling that method./// [`into_values`]: struct.HashMap.html#method.into_values/// let mut values = map.into_values();/// let mut vec = vec![values.next(), values.next(), values.next()];/// assert_eq!(vec, [Some("a"), Some("b"), Some("c")]);/// assert_eq!(values.next(), None);/// An iterator over the keys of a `HashMap` in arbitrary order./// let mut keys = map.keys();/// assert_eq!(vec, [Some(&1), Some(&2), Some(&3)]);/// An iterator over the values of a `HashMap` in arbitrary order./// let mut values = map.values();/// assert_eq!(vec, [Some(&"a"), Some(&"b"), Some(&"c")]);/// A draining iterator over the entries of a `HashMap` in arbitrary/// order. The iterator element type is `(K, V)`./// let mut map: HashMap<_, _> = [(1, "a"), (2, "b"), (3, "c")].into();/// let mut drain_iter = map.drain();/// let mut vec = vec![drain_iter.next(), drain_iter.next(), drain_iter.next()];/// // The `Drain` iterator produces items in arbitrary order, so the/// assert_eq!(drain_iter.next(), None);/// A draining iterator over entries of a `HashMap` which don't satisfy the predicate/// `f(&k, &mut v)` in arbitrary order. The iterator element type is `(K, V)`./// let mut map: HashMap<i32, &str> = [(1, "a"), (2, "b"), (3, "c")].into();/// let mut drain_filter = map.drain_filter(|k, _v| k % 2 != 0);/// let mut vec = vec![drain_filter.next(), drain_filter.next()];/// // The `DrainFilter` iterator produces items in arbitrary order, so the/// assert_eq!(vec, [Some((1, "a")),Some((3, "c"))]);/// assert_eq!(drain_filter.next(), None);/// drop(drain_filter);/// A mutable iterator over the values of a `HashMap` in arbitrary order./// let mut values = map.values_mut();/// values.next().map(|v| v.push_str(" Mississippi"));/// use hashbrown::hash_map::{RawEntryBuilderMut, RawEntryMut::Vacant, RawEntryMut::Occupied};/// map.extend([(1, 11), (2, 12), (3, 13), (4, 14), (5, 15), (6, 16)]);/// assert_eq!(map.len(), 6);/// let builder: RawEntryBuilderMut<_, _, _> = map.raw_entry_mut();/// // Existing key/// match builder.from_key(&6) {///     Vacant(_) => unreachable!(),///     Occupied(view) => assert_eq!(view.get(), &16),/// for key in 0..12 {///     let hash = compute_hash(map.hasher(), &key);///     let value = map.get(&key).cloned();///     let key_value = value.as_ref().map(|v| (&key, v));///     println!("Key: {} and value: {:?}", key, value);///     match map.raw_entry_mut().from_key(&key) {///         Occupied(mut o) => assert_eq!(Some(o.get_key_value()), key_value),///         Vacant(_) => assert_eq!(value, None),///     match map.raw_entry_mut().from_key_hashed_nocheck(hash, &key) {///     match map.raw_entry_mut().from_hash(hash, |q| *q == key) {/// use hashbrown::{hash_map::RawEntryMut, HashMap};/// let mut map: HashMap<_, _> = [("a", 100), ("b", 200)].into();///     RawEntryMut::Occupied(_) => { }/// match map.raw_entry_mut().from_key("a") {///     RawEntryMut::Vacant(_) => { }/// use hashbrown::hash_map::{HashMap, RawEntryMut, RawOccupiedEntryMut};/// map.extend([('a', 1), ('b', 2), ('c', 3)]);/// // Existing key (insert)/// let raw: RawEntryMut<_, _, _> = map.raw_entry_mut().from_key(&'a');/// let _raw_o: RawOccupiedEntryMut<_, _, _> = raw.insert('a', 10);/// // Nonexistent key (insert)/// map.raw_entry_mut().from_key(&'d').insert('d', 40);/// // Existing key (or_insert)/// let hash = compute_hash(map.hasher(), &'b');/// let kv = map///     .from_key_hashed_nocheck(hash, &'b')///     .or_insert('b', 20);/// assert_eq!(kv, (&mut 'b', &mut 2));/// *kv.1 = 20;/// // Nonexistent key (or_insert)/// let hash = compute_hash(map.hasher(), &'e');///     .from_key_hashed_nocheck(hash, &'e')///     .or_insert('e', 50);/// assert_eq!(kv, (&mut 'e', &mut 50));/// // Existing key (or_insert_with)/// let hash = compute_hash(map.hasher(), &'c');///     .from_hash(hash, |q| q == &'c')///     .or_insert_with(|| ('c', 30));/// assert_eq!(kv, (&mut 'c', &mut 3));/// *kv.1 = 30;/// // Nonexistent key (or_insert_with)/// let hash = compute_hash(map.hasher(), &'f');///     .from_hash(hash, |q| q == &'f')///     .or_insert_with(|| ('f', 60));/// assert_eq!(kv, (&mut 'f', &mut 60));/// println!("Our HashMap: {:?}", map);/// let mut vec: Vec<_> = map.iter().map(|(&k, &v)| (k, v)).collect();/// assert_eq!(vec, [('a', 10), ('b', 20), ('c', 30), ('d', 40), ('e', 50), ('f', 60)]);/// map.extend([("a", 10), ("b", 20), ("c", 30)]);/// let _raw_o: RawOccupiedEntryMut<_, _, _> = map.raw_entry_mut().from_key(&"a").insert("a", 100);///         assert_eq!(view.remove_entry(), ("c", 30));/// let hash = compute_hash(map.hasher(), &"b");/// match map.raw_entry_mut().from_hash(hash, |q| *q == "b") {///         assert_eq!(view.remove_entry(), ("b", 20));/// assert_eq!(map.get(&"b"), None);/// use hashbrown::hash_map::{HashMap, RawEntryMut, RawVacantEntryMut};/// let mut map = HashMap::<&str, i32>::new();/// let raw_v: RawVacantEntryMut<_, _, _> = match map.raw_entry_mut().from_key(&"a") {///     RawEntryMut::Vacant(view) => view,/// raw_v.insert("a", 10);/// assert!(map[&"a"] == 10 && map.len() == 1);/// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &"b") {///         let (k, value) = view.insert("b", 2);///         assert_eq!((*k, *value), ("b", 2));///         *value = 20;/// assert!(map[&"b"] == 20 && map.len() == 2);/// match map.raw_entry_mut().from_hash(hash, |q| *q == "c") {///         assert_eq!(view.insert("c", 30), (&mut "c", &mut 30));/// assert!(map[&"c"] == 30 && map.len() == 3);/// use hashbrown::hash_map::{HashMap, RawEntryBuilder};/// map.extend([(1, 10), (2, 20), (3, 30)]);/// for k in 0..6 {///     let hash = compute_hash(map.hasher(), &k);///     let builder: RawEntryBuilder<_, _, _> = map.raw_entry();///     assert_eq!(builder.from_key(&k), kv);/// let key = "a";/// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_key(&key);/// entry.insert(key, 100);/// assert_eq!(map[&"a"], 100);/// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_key_hashed_nocheck(hash, &key);/// Creates a `RawEntryMut` from the given hash and matching function./// let entry: RawEntryMut<&str, u32, _> = map.raw_entry_mut().from_hash(hash, |k| k == &key);/// Access an immutable entry by key./// let map: HashMap<&str, u32> = [("a", 100), ("b", 200)].into();/// assert_eq!(map.raw_entry().from_key(&key), Some((&"a", &100)));/// Access an immutable entry by a key and its hash./// assert_eq!(map.raw_entry().from_key_hashed_nocheck(hash, &key), Some((&"a", &100)));/// Access an immutable entry by hash and matching function./// assert_eq!(map.raw_entry().from_hash(hash, |k| k == &key), Some((&"a", &100)));/// let mut map: HashMap<&str, u32> = [("a", 100), ("b", 200)].into();///     RawEntryMut::Occupied(o) => assert_eq!(o.key(), &"a")/// let key_one = Rc::new("a");/// let key_two = Rc::new("a");/// let mut map: HashMap<Rc<&str>, u32> = HashMap::new();/// map.insert(key_one.clone(), 10);/// assert_eq!(map[&key_one], 10);/// assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);/// match map.raw_entry_mut().from_key(&key_one) {///     RawEntryMut::Occupied(mut o) => {///         *o.key_mut() = key_two.clone();/// assert_eq!(map[&key_two], 10);/// assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);/// let inside_key: &mut Rc<&str>;///     RawEntryMut::Occupied(o) => inside_key = o.into_key(),/// *inside_key = key_two.clone();///     RawEntryMut::Occupied(o) => assert_eq!(o.get(), &100),/// let value: &mut u32;///     RawEntryMut::Occupied(o) => value = o.into_mut(),/// *value += 900;/// assert_eq!(map[&"a"], 1000);///     RawEntryMut::Occupied(mut o) => *o.get_mut() += 900,///     RawEntryMut::Occupied(o) => assert_eq!(o.get_key_value(), (&"a", &100)),///         let (inside_key, inside_value) = o.get_key_value_mut();///         *inside_key = key_two.clone();///         *inside_value = 100;/// assert_eq!(map[&key_two], 100);/// let inside_value: &mut u32;///     RawEntryMut::Occupied(o) => {///         let tuple = o.into_key_value();///         inside_key = tuple.0;///         inside_value = tuple.1;/// *inside_value = 100;///     RawEntryMut::Occupied(mut o) => assert_eq!(o.insert(1000), 100),///         let old_key = o.insert_key(key_two.clone());///         assert!(Rc::ptr_eq(&old_key, &key_one));///     RawEntryMut::Occupied(o) => assert_eq!(o.remove(), 100),/// assert_eq!(map.get(&"a"), None);///     RawEntryMut::Occupied(o) => assert_eq!(o.remove_entry(), ("a", 100)),/// let raw_entry = match map.raw_entry_mut().from_key(&"a") {///     RawEntryMut::Occupied(o) => o.replace_entry_with(|k, v| {///         assert_eq!(k, &"a");///         assert_eq!(v, 100);///         Some(v + 900)///     }),/// let raw_entry = match raw_entry {///         assert_eq!(v, 1000);///         None/// match raw_entry {///     RawEntryMut::Vacant(_) => { },/// match map.raw_entry_mut().from_key(&"c") {///     RawEntryMut::Vacant(v) => assert_eq!(v.insert("c", 300), (&mut "c", &mut 300)),/// assert_eq!(map[&"c"], 300);/// let key = "c";/// match map.raw_entry_mut().from_key_hashed_nocheck(hash, &key) {///     RawEntryMut::Vacant(v) => assert_eq!(///         v.insert_hashed_nocheck(hash, key, 300),///         (&mut "c", &mut 300)/// fn make_hasher<K, S>(hash_builder: &S) -> impl Fn(&K) -> u64 + '_///     K: Hash + ?Sized,///     S: BuildHasher,///     move |key: &K| {///         use core::hash::Hasher;///         let mut state = hash_builder.build_hasher();///         key.hash(&mut state);///         state.finish()/// let hash_builder = map.hasher().clone();/// let hash = make_hasher(&hash_builder)(&key);/// match map.raw_entry_mut().from_hash(hash, |q| q == &key) {///         v.insert_with_hasher(hash, key, 100, make_hasher(&hash_builder)),///         (&mut "a", &mut 100)/// map.extend([("b", 200), ("c", 300), ("d", 400), ("e", 500), ("f", 600)]);/// match map.entry("a") {///     Entry::Vacant(_) => unreachable!(),///     Entry::Occupied(_) => { }///     Entry::Occupied(_) => unreachable!(),///     Entry::Vacant(_) => { }/// use hashbrown::hash_map::{Entry, HashMap, OccupiedEntry};/// let entry: Entry<_, _, _> = map.entry("a");/// let _raw_o: OccupiedEntry<_, _, _> = entry.insert(1);/// map.entry("d").insert(4);/// let v = map.entry("b").or_insert(2);/// assert_eq!(std::mem::replace(v, 2), 20);/// map.entry("e").or_insert(5);/// let v = map.entry("c").or_insert_with(|| 3);/// assert_eq!(std::mem::replace(v, 3), 30);/// map.entry("f").or_insert_with(|| 6);/// assert_eq!(vec, [("a", 1), ("b", 2), ("c", 3), ("d", 4), ("e", 5), ("f", 6)]);/// let _entry_o: OccupiedEntry<_, _, _> = map.entry("a").insert(100);///     Entry::Occupied(mut view) => {///         *v *= 10;/// match map.entry("c") {///     Entry::Occupied(view) => {/// assert_eq!(map.get(&"c"), None);/// use hashbrown::hash_map::{Entry, HashMap, VacantEntry};/// let entry_v: VacantEntry<_, _, _> = match map.entry("a") {///     Entry::Vacant(view) => view,/// entry_v.insert(10);/// match map.entry("b") {///     Entry::Vacant(view) => {///         let value = view.insert(2);///         assert_eq!(*value, 2);OccupiedEntryRef/// use hashbrown::hash_map::{EntryRef, HashMap};/// let mut map: HashMap<_, _> = [("a".to_owned(), 100), ("b".into(), 200)].into();/// match map.entry_ref("a") {///     EntryRef::Vacant(_) => unreachable!(),///     EntryRef::Occupied(_) => { }VacantEntryRef/// let mut map: HashMap<String, i32> = HashMap::new();///     EntryRef::Occupied(_) => unreachable!(),///     EntryRef::Vacant(_) => { }/// A view into a single entry in a map, which may either be vacant or occupied,/// with any borrowed form of the map's key type./// This `enum` is constructed from the [`entry_ref`] method on [`HashMap`]./// [`Hash`] and [`Eq`] on the borrowed form of the map's key type *must* match those/// for the key type. It also require that key may be constructed from the borrowed/// form through the [`From`] trait./// [`entry_ref`]: struct.HashMap.html#method.entry_ref/// use hashbrown::hash_map::{EntryRef, HashMap, OccupiedEntryRef};/// map.extend([("a".to_owned(), 10), ("b".into(), 20), ("c".into(), 30)]);/// let key = String::from("a");/// let entry: EntryRef<_, _, _, _> = map.entry_ref(&key);/// let _raw_o: OccupiedEntryRef<_, _, _, _> = entry.insert(1);/// map.entry_ref("d").insert(4);/// let v = map.entry_ref("b").or_insert(2);/// map.entry_ref("e").or_insert(5);/// let v = map.entry_ref("c").or_insert_with(|| 3);/// map.entry_ref("f").or_insert_with(|| 6);/// for (key, value) in ["a", "b", "c", "d", "e", "f"].into_iter().zip(1..=6) {///     assert_eq!(map[key], value)KeyOrRefBorrowed/// It is part of the [`EntryRef`] enum./// [`EntryRef`]: enum.EntryRef.html/// let _entry_o: OccupiedEntryRef<_, _, _, _> = map.entry_ref(&key).insert(100);///     EntryRef::Occupied(mut view) => {/// assert_eq!(map["a"], 1111);/// match map.entry_ref("c") {///     EntryRef::Occupied(view) => {///         assert_eq!(view.remove_entry(), ("c".to_owned(), 30));/// assert_eq!(map.get("c"), None);/// use hashbrown::hash_map::{EntryRef, HashMap, VacantEntryRef};/// let mut map = HashMap::<String, i32>::new();/// let entry_v: VacantEntryRef<_, _, _, _> = match map.entry_ref("a") {///     EntryRef::Vacant(view) => view,/// assert!(map["a"] == 10 && map.len() == 1);/// match map.entry_ref("b") {///     EntryRef::Vacant(view) => {/// assert!(map["b"] == 20 && map.len() == 2);/// use hashbrown::hash_map::{HashMap, OccupiedError};/// let mut map: HashMap<_, _> = [("a", 10), ("b", 20)].into();/// // try_insert method returns mutable reference to the value if keys are vacant,/// // but if the map did have key present, nothing is updated, and the provided/// // value is returned inside `Err(_)` variant/// match map.try_insert("a", 100) {///     Err(OccupiedError { mut entry, value }) => {///         assert_eq!(entry.key(), &"a");///         assert_eq!(value, 100);///         assert_eq!(entry.insert(100), 10)///     _ => unreachable!(),/// Creates an iterator over the entries of a `HashMap` in arbitrary order./// Return the same `Iter` struct as by the [`iter`] method on [`HashMap`]./// let map_one: HashMap<_, _> = [(1, "a"), (2, "b"), (3, "c")].into();/// let mut map_two = HashMap::new();/// for (key, value) in &map_one {///     println!("Key: {}, Value: {}", key, value);///     map_two.insert_unique_unchecked(*key, *value);/// assert_eq!(map_one, map_two);/// Creates an iterator over the entries of a `HashMap` in arbitrary order/// with mutable references to the values. The iterator element type is/// `(&'a K, &'a mut V)`./// Return the same `IterMut` struct as by the [`iter_mut`] method on/// [`HashMap`]./// let mut map: HashMap<_, _> = [("a", 1), ("b", 2), ("c", 3)].into();/// for (key, value) in &mut map {///     *value *= 2;/// let mut vec = map.iter().collect::<Vec<_>>();/// assert_eq!(vec, [(&"a", &2), (&"b", &4), (&"c", &6)]);/// let map: HashMap<_, _> = [("a", 1), ("b", 2), ("c", 3)].into();/// let mut vec: Vec<(&str, i32)> = map.into_iter().collect();/// // The `IntoIter` iterator produces items in arbitrary order, so/// // the items must be sorted to test them against a sorted array./// // nonexistent key/// // existing key/// map.entry("poneyland").or_insert_with(|| 3);/// *map.entry("poneyland").or_insert_with(|| 10) *= 2;/// *map.entry("poneyland").or_insert_with_key(|key| key.chars().count() * 10) *= 2;/// assert_eq!(map["poneyland"], 18);/// assert_eq!(map.entry("horseland").key(), &"horseland");/// map.insert("horseland", Some(3));/// assert_eq!(map.entry("horseland").or_default(), &mut Some(3));/// match map.entry("poneyland") {///     Entry::Occupied(entry) => assert_eq!(entry.key(), &"poneyland"),///     assert_eq!(o.remove_entry(), ("poneyland", 12));///     Entry::Occupied(entry) => assert_eq!(entry.get(), &12),///     Entry::Occupied(entry) => value = entry.into_mut(),/// *value += 10;///  use hashbrown::hash_map::{Entry, HashMap};///  use std::rc::Rc;///  let mut map: HashMap<Rc<String>, u32> = HashMap::new();///  let key_one = Rc::new("Stringthing".to_string());///  let key_two = Rc::new("Stringthing".to_string());///  map.insert(key_one.clone(), 15);///  assert!(Rc::strong_count(&key_one) == 2 && Rc::strong_count(&key_two) == 1);///  match map.entry(key_two.clone()) {///      Entry::Occupied(entry) => {///          let (old_key, old_value): (Rc<String>, u32) = entry.replace_entry(16);///          assert!(Rc::ptr_eq(&key_one, &old_key) && old_value == 15);///      }///      Entry::Vacant(_) => panic!(),///  }///  assert!(Rc::strong_count(&key_one) == 1 && Rc::strong_count(&key_two) == 2);///  assert_eq!(map[&"Stringthing".to_owned()], 16);/// let mut map: HashMap<Rc<String>, usize> = HashMap::with_capacity(6);/// let mut keys_one: Vec<Rc<String>> = Vec::with_capacity(6);/// let mut keys_two: Vec<Rc<String>> = Vec::with_capacity(6);/// for (value, key) in ["a", "b", "c", "d", "e", "f"].into_iter().enumerate() {///     let rc_key = Rc::new(key.to_owned());///     keys_one.push(rc_key.clone());///     map.insert(rc_key.clone(), value);///     keys_two.push(Rc::new(key.to_owned()));/// assert!(///     keys_one.iter().all(|key| Rc::strong_count(key) == 2)///         && keys_two.iter().all(|key| Rc::strong_count(key) == 1)/// reclaim_memory(&mut map, &keys_two);///     keys_one.iter().all(|key| Rc::strong_count(key) == 1)///         && keys_two.iter().all(|key| Rc::strong_count(key) == 2)/// fn reclaim_memory(map: &mut HashMap<Rc<String>, usize>, keys: &[Rc<String>]) {///     for key in keys {///         if let Entry::Occupied(entry) = map.entry(key.clone()) {///         // Replaces the entry's key with our version of it in `keys`.///     Entry::Vacant(v) => assert_eq!(v.into_key(), "poneyland"),/// Sets the value of the entry, and returns an OccupiedEntryRef./// let mut map: HashMap<String, u32> = HashMap::new();/// let entry = map.entry_ref("horseyland").insert(37);/// assert_eq!(entry.key(), "horseyland");/// map.entry_ref("poneyland").or_insert(3);/// *map.entry_ref("poneyland").or_insert(10) *= 2;/// map.entry_ref("poneyland").or_insert_with(|| 3);/// *map.entry_ref("poneyland").or_insert_with(|| 10) *= 2;/// function an access to the borrower form of the key./// let mut map: HashMap<String, usize> = HashMap::new();/// map.entry_ref("poneyland").or_insert_with_key(|key| key.chars().count());/// *map.entry_ref("poneyland").or_insert_with_key(|key| key.chars().count() * 10) *= 2;/// assert_eq!(map.entry_ref("poneyland").key(), "poneyland");/// assert_eq!(map.entry_ref("horseland").key(), "horseland");/// map.entry_ref("poneyland")/// use hashbrown::hash_map::EntryRef;///     .entry_ref("poneyland")///     EntryRef::Vacant(e) => {///         assert_eq!(e.key(), "poneyland");///     EntryRef::Occupied(_) => panic!(),/// map.insert("poneyland".to_string(), 42);///         assert_eq!(k, "poneyland");///     EntryRef::Occupied(e) => {///     EntryRef::Vacant(_) => panic!(),///     EntryRef::Vacant(e) => assert_eq!(e.key(), "poneyland"),/// let mut map: HashMap<String, Option<u32>> = HashMap::new();/// map.entry_ref("poneyland").or_default();/// map.insert("horseland".to_string(), Some(3));/// assert_eq!(map.entry_ref("horseland").or_default(), &mut Some(3));/// map.entry_ref("poneyland").or_insert(12);/// match map.entry_ref("poneyland") {///     EntryRef::Occupied(entry) => assert_eq!(entry.key(), "poneyland"),/// if let EntryRef::Occupied(o) = map.entry_ref("poneyland") {///     assert_eq!(o.remove_entry(), ("poneyland".to_owned(), 12));/// // Now map hold none elements but capacity is equal to the old one///     EntryRef::Occupied(entry) => assert_eq!(entry.get(), &12),/// If you need a reference to the `OccupiedEntryRef` which may outlive the/// destruction of the `EntryRef` value, see [`into_mut`]./// if let EntryRef::Occupied(mut o) = map.entry_ref("poneyland") {/// Converts the OccupiedEntryRef into a mutable reference to the value in the entry/// If you need multiple references to the `OccupiedEntryRef`, see [`get_mut`].///     EntryRef::Occupied(entry) => value = entry.into_mut(),/// Will panic if this OccupiedEntryRef was created through [`EntryRef::insert`]./// let mut map: HashMap<Rc<str>, u32> = HashMap::new();/// let key: Rc<str> = Rc::from("Stringthing");/// map.insert(key.clone(), 15);/// assert_eq!(Rc::strong_count(&key), 2);/// match map.entry_ref("Stringthing") {///     EntryRef::Occupied(entry) => {///         let (old_key, old_value): (Rc<str>, u32) = entry.replace_entry(16);///         assert!(Rc::ptr_eq(&key, &old_key) && old_value == 15);/// assert_eq!(Rc::strong_count(&key), 1);/// assert_eq!(map["Stringthing"], 16);/// let mut map: HashMap<Rc<str>, usize> = HashMap::with_capacity(6);/// let mut keys: Vec<Rc<str>> = Vec::with_capacity(6);///     let rc_key: Rc<str> = Rc::from(key);///     keys.push(rc_key.clone());/// assert!(keys.iter().all(|key| Rc::strong_count(key) == 2));/// // It doesn't matter that we kind of use a vector with the same keys,/// // because all keys will be newly created from the references/// reclaim_memory(&mut map, &keys);/// assert!(keys.iter().all(|key| Rc::strong_count(key) == 1));/// fn reclaim_memory(map: &mut HashMap<Rc<str>, usize>, keys: &[Rc<str>]) {///         if let EntryRef::Occupied(entry) = map.entry_ref(key.as_ref()) {///             // Replaces the entry's key with our version of it in `keys`./// let entry = match map.entry_ref("poneyland") {///             assert_eq!(k, "poneyland");///     EntryRef::Occupied(e) => e.replace_entry_with(|_k, _v| None),/// through the `VacantEntryRef`./// let key: &str = "poneyland";/// assert_eq!(map.entry_ref(key).key(), "poneyland");/// match map.entry_ref(key) {///     EntryRef::Vacant(v) => assert_eq!(v.into_key(), "poneyland".to_owned()),/// Sets the value of the entry with the VacantEntryRef's key,/// if let EntryRef::Vacant(o) = map.entry_ref(key) {/// Inserts all new key-values from the iterator to existing `HashMap<K, V, S, A>`./// Replace values with existing keys with new values returned from the iterator./// use hashbrown::hash_map::HashMap;/// map.insert(1, 100);/// let some_iter = [(1, 1), (2, 2)].into_iter();/// map.extend(some_iter);/// // Replace values with existing keys with new values returned from the iterator./// // So that the map.get(&1) doesn't return Some(&100)./// assert_eq!(map.get(&1), Some(&1));/// let some_vec: Vec<_> = vec![(3, 3), (4, 4)];/// map.extend(some_vec);/// let some_arr = [(5, 5), (6, 6)];/// map.extend(some_arr);/// let old_map_len = map.len();/// // You can also extend from another HashMap/// let mut new_map = HashMap::new();/// new_map.extend(map);/// assert_eq!(new_map.len(), old_map_len);/// let mut vec: Vec<_> = new_map.into_iter().collect();/// assert_eq!(vec, [(1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)]);/// The keys and values must implement [`Copy`] trait./// [`Copy`]: https://doc.rust-lang.org/core/marker/trait.Copy.html/// let arr = [(1, 1), (2, 2)];/// let some_iter = arr.iter().map(|(k, v)| (k, v));/// map.extend(some_vec.iter().map(|(k, v)| (k, v)));/// map.extend(some_arr.iter().map(|(k, v)| (k, v)));/// new_map.extend(&map);/// assert_eq!(new_map, map);/// let some_iter = arr.iter();/// map.extend(&some_vec);/// map.extend(&some_arr);/// let mut vec: Vec<_> = map.into_iter().collect();test_empty_entry_reftest_insert_unique_uncheckedtest_into_keystest_into_valuestest_entry_reftest_entry_ref_take_doesnt_corrupttest_extend_ref_k_ref_vtest_extend_ref_kv_tupletest_occupied_entry_ref_keytest_vacant_entry_ref_keytest_occupied_entry_ref_replace_entry_withtest_entry_ref_and_replace_entry_withtest_replace_entry_ref_with_doesnt_corrupttest_get_each_mut"panic in drop"test_clone_from_double_drop// not exposed outside of this crate/// Iterator over the contents of a `BitMask`, returning the indices of set// We perform all operations in the native endianness, and convert toMIN_HASH_LEN// Constant for h2 function that grabing the top 7 bits of the hash.IS_ZERO_SIZED_TYPETABLE_LAYOUTDATA_NEEDS_DROP/// Attempts to get mutable references to `N` entries in the table at once./// Returns an array of length `N` with the results of each query./// At most one mutable reference will be returned to any entry. `None` will be returned if any/// of the hashes are duplicates. `None` will be returned if the hash is not found./// The `eq` argument should be a closure such that `eq(i, k)` returns true if `k` is equal to/// the `i`th key to be looked up.get_many_mut_pointers/// Returns `true` if the table contains no elements.is_bucket_full/// Checks whether the bucket at `index` is full./// The caller must ensure `index` is less than the number of buckets.find_inner/// Searches for an element in the table. This uses dynamic dispatch to reduce the amount of/// code generated, but it is eliminated by LLVM optimizations.bucket_ptrreserve_rehash_inner/// Reserves or rehashes to make room for `additional` more elements./// This uses dynamic dispatch to reduce the amount of/// code generated, but it is eliminated by LLVM optimizations when inlined.resize_innerallocation_info/// Common code for clone and clone_from. Assumes:/// - `self.buckets() == source.buckets()`./// - Any existing elements have been dropped./// - The control bytes are not initialized yet.DO_CHECK_PTR_RANGEnext_impl/// If DO_CHECK_PTR_RANGE is false, caller must ensure that we never try to iterate/// after yielding all elements./// `RawTable` only stores 7 bits of the hash value, so this iterator may return/// items that have a hash value different than the one provided. You should/// always validate the returned values before using them./// This `enum` is constructed from the [`rustc_entry`] method on [`HashMap`]./// [`rustc_entry`]: struct.HashMap.html#method.rustc_entry/// let entry = map.rustc_entry("horseyland").insert(37);/// not allow the `HashSet` to be protected against attacks such as [`HashDoS`]./// as the hasher when creating a [`HashSet`], for example with/// [`with_hasher`](HashSet::with_hasher) method./// [`with_capacity_and_hasher`](HashSet::with_capacity_and_hasher) method./// [`with_hasher_in`](HashSet::with_hasher_in) method./// [`with_capacity_and_hasher_in`](HashSet::with_capacity_and_hasher_in) method./// The hash set is initially created with a capacity of 0, so it will not/// as the hasher when creating a [`HashSet`]./// the HashSet to be useful, see its documentation for details./// in case of allocation error. Use [`try_reserve`](HashSet::try_reserve) instead/// Gets the given value's corresponding entry in the set for in-place manipulation./// use hashbrown::hash_set::Entry::*;/// let mut singles = HashSet::new();/// let mut dupes = HashSet::new();///     if let Vacant(dupe_entry) = dupes.entry(ch) {///         // We haven't already seen a duplicate, so///         // check if we've at least seen it once.///         match singles.entry(ch) {///             Vacant(single_entry) => {///                 // We found a new character for the first time.///                 single_entry.insert()///             Occupied(single_entry) => {///                 // We've already seen this once, "move" it to dupes.///                 single_entry.remove();///                 dupe_entry.insert();/// assert!(!singles.contains(&'t') && dupes.contains(&'t'));/// assert!(singles.contains(&'u') && !dupes.contains(&'u'));/// assert!(!singles.contains(&'v') && !dupes.contains(&'v'));/// Insert a value the set without checking if the value already exists in the set./// Returns a reference to the value just inserted./// This operation is safe if a value does not exist in the set./// However, if a value exists in the set already, the behavior is unspecified:/// this operation may panic, loop forever, or any following operation with the set/// This operation is useful during initial population of the set./// For example, when constructing a set from another set, we know/// that values are unique./// let set1 = HashSet::from([1, 2, 3, 4]);/// let set2: HashSet<_> = [1, 2, 3, 4].into();/// use hashbrown::hash_set::{Entry, HashSet};/// let mut set: HashSet<_> = ["a", "b"].into();/// match set.entry("a") {/// let mut set: HashSet<&str> = HashSet::new();/// A view into a single entry in a set, which may either be vacant or occupied./// This `enum` is constructed from the [`entry`] method on [`HashSet`]./// [`entry`]: struct.HashSet.html#method.entry/// use hashbrown::hash_set::{Entry, HashSet, OccupiedEntry};/// set.extend(["a", "b", "c"]);/// // Existing value (insert)/// let entry: Entry<_, _> = set.entry("a");/// let _raw_o: OccupiedEntry<_, _> = entry.insert();/// // Nonexistent value (insert)/// set.entry("d").insert();/// // Existing value (or_insert)/// set.entry("b").or_insert();/// // Nonexistent value (or_insert)/// set.entry("e").or_insert();/// println!("Our HashSet: {:?}", set);/// let mut vec: Vec<_> = set.iter().copied().collect();/// assert_eq!(vec, ["a", "b", "c", "d", "e"]);/// A view into an occupied entry in a `HashSet`./// let _entry_o: OccupiedEntry<_, _> = set.entry("a").insert();///         assert_eq!(view.get(), &"a");/// match set.entry("c") {///         assert_eq!(view.remove(), "c");/// assert_eq!(set.get(&"c"), None);/// assert_eq!(set.len(), 2);/// A view into a vacant entry in a `HashSet`./// use hashbrown::hash_set::{Entry, HashSet, VacantEntry};/// let mut set = HashSet::<&str>::new();/// let entry_v: VacantEntry<_, _> = match set.entry("a") {/// entry_v.insert();/// assert!(set.contains("a") && set.len() == 1);/// match set.entry("b") {///     Entry::Vacant(view) => view.insert(),/// assert!(set.contains("b") && set.len() == 2);/// let entry = set.entry("horseyland").insert();/// assert_eq!(entry.get(), &"horseyland");/// Ensures a value is in the entry by inserting if it was vacant./// set.entry("poneyland").or_insert();/// assert!(set.contains("poneyland"));/// Returns a reference to this entry's value./// assert_eq!(set.entry("poneyland").get(), &"poneyland");/// assert_eq!(set.entry("horseland").get(), &"horseland");/// match set.entry("poneyland") {///     Entry::Occupied(entry) => assert_eq!(entry.get(), &"poneyland"),/// use hashbrown::hash_set::Entry;/// // The set is empty/// assert!(set.is_empty() && set.capacity() == 0);/// let capacity_before_remove = set.capacity();/// if let Entry::Occupied(o) = set.entry("poneyland") {///     assert_eq!(o.remove(), "poneyland");/// assert_eq!(set.contains("poneyland"), false);/// // Now set hold none elements but capacity is equal to the old one/// assert!(set.len() == 0 && set.capacity() == capacity_before_remove);/// Replaces the entry, returning the old value. The new value in the hash map will be/// the value used to create this entry.///  use hashbrown::hash_set::{Entry, HashSet};///  let mut set: HashSet<Rc<String>> = HashSet::new();///  set.insert(key_one.clone());///  match set.entry(key_two.clone()) {///          let old_key: Rc<String> = entry.replace();///          assert!(Rc::ptr_eq(&key_one, &old_key));///  assert!(set.contains(&"Stringthing".to_owned()));/// Gets a reference to the value that would be used when inserting/// Take ownership of the value.///     Entry::Vacant(v) => assert_eq!(v.into_value(), "poneyland"),/// Sets the value of the entry with the VacantEntry's value./// if let Entry::Vacant(o) = set.entry("poneyland") {///     o.insert();NonZeroBitMaskWordBITMASK_ITER_MASK/// For implementation reasons, the bits in the set may be sparsely packed with/// groups of 8 bits representing one element. If any of these bits are non-zero/// then this element is considered to true in the mask. If this is the/// To iterate over a bit mask, it must be converted to a form where only 1 bit/// is set per element. This is done by applying `BITMASK_ITER_MASK` on the/// mask bits.nonzero_trailing_zeros/// Same as above but takes a `NonZeroBitMaskWord`.NonZeroGroupWord// We only care about the highest bit of each tag for the mask./// Helper function to replicate a tag across a `GroupWord`./// Abstraction over a group of control tags which can be scanned in/// Returns a full group of empty tags, suitable for use as the initial/// Loads a group of tags starting at the given address./// Loads a group of tags starting at the given address, which must be/// Stores the group of tags to the given address, which must bematch_tag/// Returns a `BitMask` indicating all tags in the group which *may*/// the tag in the group differs from the searched value only in its/// Returns a `BitMask` indicating all tags in the group which are/// Returns a `BitMask` indicating all tags in the group which are full./// Performs the following transformation on all tags in the group:loongarch64v16i8/// This implementation uses a 128-bit LSX value./// Returns a `BitMask` indicating all tags in the group which haveuint8x8_t/// This implementation uses a 64-bit NEON value.TagSliceExt/// Single tag in a control group./// Control tag value for an empty bucket./// Control tag value for a deleted bucket./// Checks whether a control tag represents a full bucket (top bit is clear)./// Checks whether a control tag represents a special value (top bit is set).full/// Creates a control tag representing a full bucket with the given hash.fill_tag/// Fills the control with the given tag.fill_empty/// Clears out the control./// Extension trait for slices of tags.hash_tableHashTable/// This iterator is created by the [`par_iter`] method on [`HashTable`]/// [`par_iter`]: /hashbrown/struct.HashTable.html#method.par_iter/// [`HashTable`]: /hashbrown/struct.HashTable.html/// This iterator is created by the [`par_iter_mut`] method on [`HashTable`]/// [`par_iter_mut`]: /hashbrown/struct.HashTable.html#method.par_iter_mut/// This iterator is created by the [`into_par_iter`] method on [`HashTable`]/// [`into_par_iter`]: /hashbrown/struct.HashTable.html#method.into_par_iter/// This iterator is created by the [`par_drain`] method on [`HashTable`]./// [`par_drain`]: /hashbrown/struct.HashTable.html#method.par_draintest_par_table//! Rayon extensions for `HashTable`./// Dummy default hasher for [`HashMap`] and [`HashSet`].control//! A hash table implemented with quadratic probing and SIMD lookup.// This is only used as a fallback when building as part of `std`.// Helper macro for specialization. This also helps avoid parse errors if the// default fn syntax for specialization changes in the future.RawExtractIf/// The default hashing algorithm is currently [`foldhash`], though this is/// [`foldhash`]: https://crates.io/crates/foldhash///     .into_iter().collect();/// instances of any functions like `RawTable::reserve` from being generated/// [`std::collections::hash_map::RandomState`]/// the `HashMap` to be useful, see its documentation for details./// use hashbrown::DefaultHashBuilder;extract_ifExtractIf/// Note that `extract_if` lets you mutate every value in the filter closure, regardless of/// If the returned `ExtractIf` is not exhausted, e.g. because it is dropped without iterating/// or the iteration short-circuits, then the remaining elements will be retained./// Use [`retain()`] with a negated predicate if you do not need the returned iterator./// [`retain()`]: HashMap::retain/// let drained: HashMap<i32, i32> = map.extract_if(|k, _v| k % 2 == 0).collect();///     let d = map.extract_if(|k, _v| k % 2 != 0);/// // ExtractIf was not exhausted, therefore no elements were drained./// mutable reference will be returned to any value. `None` will be used if the key is missing./// Panics if any keys are overlapping./// // Get Athenæum and Bodleian Library/// let [Some(a), Some(b)] = libraries.get_many_mut([/// ]) else { panic!() };/// // Assert values of Athenæum and Library of Congress///     [///         Some(&mut 1807),///         Some(&mut 1800),///     ]/// // Duplicate keys panic!/// Returns an array of length `N` with the results of each query. `None` will be used if/// the key is missing./// // SAFETY: The keys do not overlap./// let [Some(a), Some(b)] = (unsafe { libraries.get_many_unchecked_mut([/// ]) }) else { panic!() };/// let got = unsafe { libraries.get_many_unchecked_mut([/// ]) };/// assert_eq!(got, [Some(&mut 1807), None]);///         Some((&"Bodleian Library".to_string(), &mut 1602)),///         Some((&"Herzogin-Anna-Amalia-Bibliothek".to_string(), &mut 1691)),/// assert_eq!(got, [Some((&"Bodleian Library".to_string(), &mut 1602)), None]);/// // Duplicate keys result in panic!///         None,find_or_find_insert_slotInsertSlot/// However this operation is still unsafe because the resulting `HashMap`/// may be passed to unsafe code which does expect the map to behave/// correctly, and would cause unsoundness as a result.///         map2.insert_unique_unchecked(key, value);/// let (key, value) = unsafe { map2.insert_unique_unchecked(4, "d") };allocation_size/// Returns the total amount of memory allocated internally by the hash/// set, in bytes./// The returned number is informational only. It is intended to be/// primarily used for memory profiling."Iterators are lazy unless consumed"/// This `struct` is created by the [`extract_if`] method on [`HashMap`]. See its/// [`extract_if`]: struct.HashMap.html#method.extract_if/// let mut extract_if = map.extract_if(|k, _v| k % 2 != 0);/// let mut vec = vec![extract_if.next(), extract_if.next()];/// // The `ExtractIf` iterator produces items in arbitrary order, so the/// assert_eq!(extract_if.next(), None);/// drop(extract_if);/// A view into an occupied entry in a [`HashMap`]./// It is part of the [`Entry`] and [`EntryRef`] enums./// use hashbrown::hash_map::{EntryRef, HashMap, OccupiedEntry};/// let _raw_o: OccupiedEntry<_, _, _, _> = entry.insert(1);///     map_two.insert(*key, *value);/// Sets the value of the entry, and returns an `OccupiedEntry`./// Converts the `OccupiedEntry` into a mutable reference to the value in the entry/// Sets the value of the entry with the [`VacantEntry`]'s key,/// and returns an [`OccupiedEntry`]./// Sets the value of the entry with the `VacantEntryRef`'s key,/// Sets the value of the entry with the [`VacantEntryRef`]'s key,/// if let EntryRef::Vacant(v) = map.entry_ref("poneyland") {extend_oneextend_reserve// Nightly-case.// Use unstable `allocator_api` feature.// This is compatible with `allocator-api2` which can be enabled or not.// This is used when building for `std`.invalid_mutIS_ZERO_SIZEDNEEDS_DROPSizedTypeProperties/// Helper which allows the max calculation for `ctrl_align` to be statically computed for each `T`/// A reference to an empty bucket into which an can be inserted./// Creates a [`Bucket`] that contain pointer to the data./// The pointer calculation is performed by calculating the/// offset from given `base` pointer (convenience for/// `base.as_ptr().sub(index)`)./// `index` is in units of `T`; e.g., an `index` of 3 represents a pointer/// offset of `3 * size_of::<T>()` bytes./// If the `T` is a ZST, then we instead track the index of the element/// in the table so that `erase` works properly (return/// `NonNull::new_unchecked((index + 1) as *mut T)`)/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived/// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and the safety/// rules of [`NonNull::new_unchecked`] function./// Thus, in order to uphold the safety contracts for the [`<*mut T>::sub`] method/// and [`NonNull::new_unchecked`] function, as well as for the correct/// logic of the work of this crate, the following rules are necessary and/// sufficient:/// * the `base` pointer must not be `dangling` and must points to the///   end of the first `value element` from the `data part` of the table, i.e.///   must be the pointer that returned by [`RawTable::data_end`] or by///   [`RawTableInner::data_end<T>`];/// * `index` must not be greater than `RawTableInner.bucket_mask`, i.e.///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`///   must be no greater than the number returned by the function///   [`RawTable::buckets`] or [`RawTableInner::buckets`]./// If `mem::size_of::<T>() == 0`, then the only requirement is that the/// `index` must not be greater than `RawTableInner.bucket_mask`, i.e./// `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)`/// must be no greater than the number returned by the function/// [`RawTable::buckets`] or [`RawTableInner::buckets`]./// [`Bucket`]: crate::raw::Bucket/// [`<*mut T>::sub`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.sub-1/// [`NonNull::new_unchecked`]: https://doc.rust-lang.org/stable/std/ptr/struct.NonNull.html#method.new_unchecked/// [`RawTable::data_end`]: crate::raw::RawTable::data_end/// [`RawTableInner::data_end<T>`]: RawTableInner::data_end<T>/// [`RawTable::buckets`]: crate::raw::RawTable::buckets/// [`RawTableInner::buckets`]: RawTableInner::buckets/// Calculates the index of a [`Bucket`] as distance between two pointers/// (convenience for `base.as_ptr().offset_from(self.ptr.as_ptr()) as usize`)./// The returned value is in units of T: the distance in bytes divided by/// [`core::mem::size_of::<T>()`]./// If the `T` is a ZST, then we return the index of the element in/// the table so that `erase` works properly (return `self.ptr.as_ptr() as usize - 1`)./// This function is the inverse of [`from_base_index`]./// from the safety rules for [`<*const T>::offset_from`] method of `*const T`./// Thus, in order to uphold the safety contracts for [`<*const T>::offset_from`]/// method, as well as for the correct logic of the work of this crate, the/// following rules are necessary and sufficient:/// * `base` contained pointer must not be `dangling` and must point to the///   end of the first `element` from the `data part` of the table, i.e.///   must be a pointer that returns by [`RawTable::data_end`] or by/// * `self` also must not contain dangling pointer;/// * both `self` and `base` must be created from the same [`RawTable`]///   (or [`RawTableInner`])./// If `mem::size_of::<T>() == 0`, this function is always safe./// [`from_base_index`]: crate::raw::Bucket::from_base_index/// [`RawTable`]: crate::raw::RawTable/// [`RawTableInner`]: RawTableInner/// [`<*const T>::offset_from`]: https://doc.rust-lang.org/nightly/core/primitive.pointer.html#method.offset_from/// Acquires the underlying raw pointer `*mut T` to `data`./// If `T` is not [`Copy`], do not use `*mut T` methods that can cause calling the/// destructor of `T` (for example the [`<*mut T>::drop_in_place`] method), because/// for properly dropping the data we also need to clear `data` control bytes. If we/// drop data, but do not clear `data control byte` it leads to double drop when/// [`RawTable`] goes out of scope./// If you modify an already initialized `value`, so [`Hash`] and [`Eq`] on the new/// `T` value and its borrowed form *must* match those for the old `T` value, as the map/// will not re-evaluate where the new value should go, meaning the value may become/// "lost" if their location does not reflect their state./// [`<*mut T>::drop_in_place`]: https://doc.rust-lang.org/core/primitive.pointer.html#method.drop_in_place/// [`Hash`]: https://doc.rust-lang.org/core/hash/trait.Hash.html/// [`Eq`]: https://doc.rust-lang.org/core/cmp/trait.Eq.htmlas_non_null/// Acquires the underlying non-null pointer `*mut T` to `data`./// Create a new [`Bucket`] that is offset from the `self` by the given/// `offset`. The pointer calculation is performed by calculating the/// offset from `self` pointer (convenience for `self.ptr.as_ptr().sub(offset)`)./// This function is used for iterators./// `offset` is in units of `T`; e.g., a `offset` of 3 represents a pointer/// from the safety rules for [`<*mut T>::sub`] method of `*mut T` and safety/// Thus, in order to uphold the safety contracts for [`<*mut T>::sub`] method/// * `self` contained pointer must not be `dangling`;/// * `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,///   i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other///   words, `self.to_base_index() + offset + 1` must be no greater than the number returned///   by the function [`RawTable::buckets`] or [`RawTableInner::buckets`]./// `self.to_base_index() + offset` must not be greater than `RawTableInner.bucket_mask`,/// i.e. `(self.to_base_index() + offset) <= RawTableInner.bucket_mask` or, in other words,/// `self.to_base_index() + offset + 1` must be no greater than the number returned by the/// function [`RawTable::buckets`] or [`RawTableInner::buckets`]./// Executes the destructor (if any) of the pointed-to `data`./// See [`ptr::drop_in_place`] for safety concerns./// You should use [`RawTable::erase`] instead of this function,/// or be careful with calling this function directly, because for/// properly dropping the data we need also clear `data` control bytes./// If we drop data, but do not erase `data control byte` it leads to/// double drop when [`RawTable`] goes out of scope./// [`ptr::drop_in_place`]: https://doc.rust-lang.org/core/ptr/fn.drop_in_place.html/// [`RawTable::erase`]: crate::raw::RawTable::erase/// Reads the `value` from `self` without moving it. This leaves the/// memory in `self` unchanged./// See [`ptr::read`] for safety concerns./// You should use [`RawTable::remove`] instead of this function,/// or be careful with calling this function directly, because compiler/// calls its destructor when the read `value` goes out of scope. It/// can cause double dropping when [`RawTable`] goes out of scope,/// because of not erased `data control byte`./// [`ptr::read`]: https://doc.rust-lang.org/core/ptr/fn.read.html/// [`RawTable::remove`]: crate::raw::RawTable::remove/// Overwrites a memory location with the given `value` without reading/// or dropping the old value (like [`ptr::write`] function)./// See [`ptr::write`] for safety concerns./// [`Hash`] and [`Eq`] on the new `T` value and its borrowed form *must* match/// those for the old `T` value, as the map will not re-evaluate where the new/// value should go, meaning the value may become "lost" if their location/// does not reflect their state./// [`ptr::write`]: https://doc.rust-lang.org/core/ptr/fn.write.html/// Returns a shared immutable reference to the `value`./// See [`NonNull::as_ref`] for safety concerns./// [`NonNull::as_ref`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.as_ref/// Returns a unique mutable reference to the `value`./// See [`NonNull::as_mut`] for safety concerns./// [`NonNull::as_mut`]: https://doc.rust-lang.org/core/ptr/struct.NonNull.html#method.as_mut// [Padding], T_n, ..., T1, T0, C0, C1, ...//                              ^ points here/// Returns pointer to one past last `data` element in the table as viewed from/// the start point of the allocation./// The caller must ensure that the `RawTable` outlives the returned [`NonNull<T>`],/// otherwise using it may result in [`undefined behavior`]./// [`undefined behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.htmldata_start/// Returns pointer to start of data table./// table, in bytes./// The caller must ensure that the `RawTable` outlives the returned [`Bucket<T>`],/// If `mem::size_of::<T>() != 0`, then the caller of this function must observe the/// following safety rules:/// * The table must already be allocated;/// * The `index` must not be greater than the number returned by the [`RawTable::buckets`]///   function, i.e. `(index + 1) <= self.buckets()`./// It is safe to call this function with index of zero (`index == 0`) on a table that has/// not been allocated, but using the returned [`Bucket`] results in [`undefined behavior`]./// If `mem::size_of::<T>() == 0`, then the only requirement is that the `index` must/// not be greater than the number returned by the [`RawTable::buckets`] function, i.e./// `(index + 1) <= self.buckets()`./// [`RawTable::buckets`]: RawTable::buckets/// This also returns an `InsertSlot` pointing to the newly free bucket./// The [`RawTableInner`] must have properly initialized control bytes,/// otherwise calling this function results in [`undefined behavior`]/// The caller of this function must ensure that `capacity >= self.table.items`/// otherwise:/// * If `self.table.items != 0`, calling of this function with `capacity`///   equal to 0 (`capacity == 0`) results in [`undefined behavior`]./// * If `self.table.items > capacity_to_buckets(capacity, Self::TABLE_LAYOUT)`///   calling this function are never return (will loop infinitely)./// See [`RawTableInner::find_insert_slot`] for more information./// [`RawTableInner::find_insert_slot`]: RawTableInner::find_insert_slotinsert_no_grow/// Inserts a new element into the table, without growing the table./// There must be enough space in the table to insert the new element./// Searches for an element in the table. If the element is not found,/// returns `Err` with the position of a slot where an element with the/// same hash could be inserted./// This function may resize the table if additional space is required for/// inserting an element.insert_in_slot/// Inserts a new element into the table in the given slot, and returns its/// raw bucket./// `slot` must point to a slot previously returned by/// `find_or_find_insert_slot`, and no mutation of the table must have/// occurred since that call./// `RawTable` only stores 7 bits of the hash value, so this iterator may/// return items that have a hash value different than the one provided. You/// should always validate the returned values before using them.NEW/// leave the data pointer dangling since that bucket is never accessed/// Allocates a new [`RawTableInner`] with the given number of buckets./// The control bytes and buckets are left uninitialized./// The caller of this function must ensure that the `buckets` is power of two/// and also initialize all control bytes of the length `self.bucket_mask + 1 +/// Group::WIDTH` with the [`Tag::EMPTY`] bytes./// See also [`Allocator`] API for other safety concerns./// [`Allocator`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html/// Attempts to allocate a new [`RawTableInner`] with at least enough/// capacity for inserting the given number of elements without reallocating./// All the control bytes are initialized with the [`Tag::EMPTY`] bytes./// Allocates a new [`RawTableInner`] with at least enough capacity for inserting/// in case of allocation error. Use [`fallible_with_capacity`] instead if you want to/// handle memory allocation failure./// [`fallible_with_capacity`]: RawTableInner::fallible_with_capacityfix_insert_slot/// Fixes up an insertion slot returned by the [`RawTableInner::find_insert_slot_in_group`] method./// In tables smaller than the group width (`self.buckets() < Group::WIDTH`), trailing control/// bytes outside the range of the table are filled with [`Tag::EMPTY`] entries. These will unfortunately/// trigger a match of [`RawTableInner::find_insert_slot_in_group`] function. This is because/// the `Some(bit)` returned by `group.match_empty_or_deleted().lowest_set_bit()` after masking/// (`(probe_seq.pos + bit) & self.bucket_mask`) may point to a full bucket that is already occupied./// We detect this situation here and perform a second scan starting at the beginning of the table./// This second scan is guaranteed to find an empty slot (due to the load factor) before hitting the/// trailing control bytes (containing [`Tag::EMPTY`] bytes)./// If this function is called correctly, it is guaranteed to return [`InsertSlot`] with an/// index of an empty or deleted bucket in the range `0..self.buckets()` (see `Warning` and/// `Safety`)./// The table must have at least 1 empty or deleted `bucket`, otherwise if the table is less than/// the group width (`self.buckets() < Group::WIDTH`) this function returns an index outside of the/// table indices range `0..self.buckets()` (`0..=self.bucket_mask`). Attempt to write data at that/// index will cause immediate [`undefined behavior`]./// The safety rules are directly derived from the safety rules for [`RawTableInner::ctrl`] method./// Thus, in order to uphold those safety contracts, as well as for the correct logic of the work/// of this crate, the following rules are necessary and sufficient:/// * The [`RawTableInner`] must have properly initialized control bytes otherwise calling this///   function results in [`undefined behavior`]./// * This function must only be used on insertion slots found by [`RawTableInner::find_insert_slot_in_group`]///   (after the `find_insert_slot_in_group` function, but before insertion into the table)./// * The `index` must not be greater than the `self.bucket_mask`, i.e. `(index + 1) <= self.buckets()`///   (this one is provided by the [`RawTableInner::find_insert_slot_in_group`] function)./// Calling this function with an index not provided by [`RawTableInner::find_insert_slot_in_group`]/// may result in [`undefined behavior`] even if the index satisfies the safety rules of the/// [`RawTableInner::ctrl`] function (`index < self.bucket_mask + 1 + Group::WIDTH`)./// [`RawTableInner::ctrl`]: RawTableInner::ctrl/// [`RawTableInner::find_insert_slot_in_group`]: RawTableInner::find_insert_slot_in_groupfind_insert_slot_in_group/// Finds the position to insert something in a group./// **This may have false positives and must be fixed up with `fix_insert_slot`/// before it's used.**/// The function is guaranteed to return the index of an empty or deleted [`Bucket`]/// in the range `0..self.buckets()` (`0..=self.bucket_mask`).find_or_find_insert_slot_inner/// Searches for an element in the table, or a potential slot where that element could/// be inserted (an empty or deleted [`Bucket`] index)./// This uses dynamic dispatch to reduce the amount of code generated, but that is/// eliminated by LLVM optimizations./// This function does not make any changes to the `data` part of the table, or any/// changes to the `items` or `growth_left` field of the table./// The table must have at least 1 empty or deleted `bucket`, otherwise, if the/// `eq: &mut dyn FnMut(usize) -> bool` function does not return `true`, this function/// will never return (will go into an infinite loop) for tables larger than the group/// width, or return an index outside of the table indices range if the table is less/// than the group width./// This function is guaranteed to provide the `eq: &mut dyn FnMut(usize) -> bool`/// function with only `FULL` buckets' indices and return the `index` of the found/// element (as `Ok(index)`). If the element is not found and there is at least 1/// empty or deleted [`Bucket`] in the table, the function is guaranteed to return/// [`InsertSlot`] with an index in the range `0..self.buckets()`, but in any case,/// if this function returns [`InsertSlot`], it will contain an index in the range/// `0..=self.buckets()`./// The [`RawTableInner`] must have properly initialized control bytes otherwise calling/// this function results in [`undefined behavior`]./// Attempt to write data at the [`InsertSlot`] returned by this function when the table is/// less than the group width and if there was not at least one empty or deleted bucket in/// the table will cause immediate [`undefined behavior`]. This is because in this case the/// function will return `self.bucket_mask + 1` as an index due to the trailing [`Tag::EMPTY`]/// control bytes outside the table range./// Searches for an empty or deleted bucket which is suitable for inserting a new/// element and sets the hash for that slot. Returns an index of that slot and the/// old control byte stored in the found index./// This function does not check if the given element exists in the table. Also,/// this function does not check if there is enough space in the table to insert/// a new element. The caller of the function must make sure that the table has at/// least 1 empty or deleted `bucket`, otherwise this function will never return/// (will go into an infinite loop) for tables larger than the group width, or/// return an index outside of the table indices range if the table is less than/// the group width./// If there is at least 1 empty or deleted `bucket` in the table, the function is/// guaranteed to return an `index` in the range `0..self.buckets()`, but in any case,/// if this function returns an `index` it will be in the range `0..=self.buckets()`./// This function does not make any changes to the `data` parts of the table,/// or any changes to the `items` or `growth_left` field of the table./// The safety rules are directly derived from the safety rules for the/// [`RawTableInner::set_ctrl_hash`] and [`RawTableInner::find_insert_slot`] methods./// Thus, in order to uphold the safety contracts for that methods, as well as for/// the correct logic of the work of this crate, you must observe the following rules/// when calling this function:/// * The [`RawTableInner`] has already been allocated and has properly initialized///   control bytes otherwise calling this function results in [`undefined behavior`]./// * The caller of this function must ensure that the "data" parts of the table///   will have an entry in the returned index (matching the given hash) right///   after calling this function./// Attempt to write data at the `index` returned by this function when the table is/// The caller must independently increase the `items` field of the table, and also,/// if the old control byte was [`Tag::EMPTY`], then decrease the table's `growth_left`/// field, and do not change it if the old control byte was [`Tag::DELETED`]./// See also [`Bucket::as_ptr`] method, for more information about of properly removing/// or saving `element` from / into the [`RawTable`] / [`RawTableInner`]./// [`Bucket::as_ptr`]: Bucket::as_ptr/// [`RawTableInner::set_ctrl_hash`]: RawTableInner::set_ctrl_hash/// a new element, returning the `index` for the new [`Bucket`]./// The table must have at least 1 empty or deleted `bucket`, otherwise this function/// guaranteed to return [`InsertSlot`] with an index in the range `0..self.buckets()`,/// but in any case, if this function returns [`InsertSlot`], it will contain an index/// in the range `0..=self.buckets()`./// Searches for an element in a table, returning the `index` of the found element./// This uses dynamic dispatch to reduce the amount of code generated, but it is/// The table must have at least 1 empty `bucket`, otherwise, if the/// `eq: &mut dyn FnMut(usize) -> bool` function does not return `true`,/// this function will also never return (will go into an infinite loop)./// element as `Some(index)`, so the index will always be in the range/// `0..self.buckets()`./// Prepares for rehashing data in place (that is, without allocating new memory)./// Converts all full index `control bytes` to `Tag::DELETED` and all `Tag::DELETED` control/// bytes to `Tag::EMPTY`, i.e. performs the following conversion:/// - `Tag::EMPTY` control bytes   -> `Tag::EMPTY`;/// - `Tag::DELETED` control bytes -> `Tag::EMPTY`;/// - `FULL` control bytes    -> `Tag::DELETED`./// You must observe the following safety rules when calling this function:/// * The [`RawTableInner`] has already been allocated;/// * The caller of this function must convert the `Tag::DELETED` bytes back to `FULL`///   bytes when re-inserting them into their ideal position (which was impossible///   to do during the first insert due to tombstones). If the caller does not do///   this, then calling this function may result in a memory leak./// * The [`RawTableInner`] must have properly initialized control bytes otherwise///   calling this function results in [`undefined behavior`]./// Calling this function on a table that has not been allocated results in/// [`undefined behavior`]./// or saving `data element` from / into the [`RawTable`] / [`RawTableInner`]./// Returns an iterator over every element in the table./// If any of the following conditions are violated, the result/// is [`undefined behavior`]:/// * The caller has to ensure that the `RawTableInner` outlives the///   `RawIter`. Because we cannot make the `next` method unsafe on///   the `RawIter` struct, we have to make the `iter` method unsafe./// * The [`RawTableInner`] must have properly initialized control bytes./// The type `T` must be the actual type of the elements stored in the table,/// otherwise using the returned [`RawIter`] results in [`undefined behavior`]./// Executes the destructors (if any) of the values stored in the table./// This function does not erase the control bytes of the table and does/// not make any changes to the `items` or `growth_left` fields of the/// table. If necessary, the caller of this function must manually set/// up these table fields, for example using the [`clear_no_drop`] function./// Be careful during calling this function, because drop function of/// the elements can panic, and this can leave table in an inconsistent/// otherwise calling this function may result in [`undefined behavior`]./// If `T` is a type that should be dropped and **the table is not empty**,/// calling this function more than once results in [`undefined behavior`]./// If `T` is not [`Copy`], attempting to use values stored in the table after/// calling this function may result in [`undefined behavior`]./// It is safe to call this function on a table that has not been allocated,/// on a table with uninitialized control bytes, and on a table with no actual/// data but with `Full` control bytes if `self.items == 0`./// See also [`Bucket::drop`] / [`Bucket::as_ptr`] methods, for more information/// about of properly removing or saving `element` from / into the [`RawTable`] //// [`RawTableInner`]./// [`Bucket::drop`]: Bucket::drop/// [`clear_no_drop`]: RawTableInner::clear_no_dropdrop_inner_table/// Executes the destructors (if any) of the values stored in the table and than/// deallocates the table./// Calling this function automatically makes invalid (dangling) all instances of/// buckets ([`Bucket`]) and makes invalid (dangling) the `ctrl` field of the table./// This function does not make any changes to the `bucket_mask`, `items` or `growth_left`/// fields of the table. If necessary, the caller of this function must manually set/// up these table fields./// If any of the following conditions are violated, the result is [`undefined behavior`]:/// * Calling this function more than once;/// * The type `T` must be the actual type of the elements stored in the table./// * The `alloc` must be the same [`Allocator`] as the `Allocator` that was used///   to allocate this table./// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout` that///   was used to allocate this table./// The caller of this function should pay attention to the possibility of the/// elements' drop function panicking, because this:///    * May leave the table in an inconsistent state;///    * Memory is never deallocated, so a memory leak may occur./// Attempt to use the `ctrl` field of the table (dereference) after calling this/// function results in [`undefined behavior`]./// See also [`RawTableInner::drop_elements`] or [`RawTableInner::free_buckets`]/// for more  information./// [`RawTableInner::drop_elements`]: RawTableInner::drop_elements/// [`RawTableInner::free_buckets`]: RawTableInner::free_buckets/// Returns a pointer to an element in the table (convenience for/// `Bucket::from_base_index(self.data_end::<T>(), index)`)./// The caller must ensure that the `RawTableInner` outlives the returned [`Bucket<T>`],/// If `mem::size_of::<T>() != 0`, then the safety rules are directly derived from the/// safety rules of the [`Bucket::from_base_index`] function. Therefore, when calling/// this function, the following safety rules must be observed:/// * The `index` must not be greater than the number returned by the [`RawTableInner::buckets`]/// * The type `T` must be the actual type of the elements stored in the table, otherwise///   using the returned [`Bucket`] may result in [`undefined behavior`]./// ```none/// If mem::size_of::<T>() != 0 then return a pointer to the `element` in the `data part` of the table/// (we start counting from "0", so that in the expression T[n], the "n" index actually one less than/// the "buckets" number of our `RawTableInner`, i.e. "n = RawTableInner::buckets() - 1"):///           `table.bucket(3).as_ptr()` returns a pointer that points here in the `data`///           part of the `RawTableInner`, i.e. to the start of T3 (see [`Bucket::as_ptr`])///                  |///                  |               `base = table.data_end::<T>()` points here///                  |               (to the start of CT0 or to the end of T0)///                  v                 v/// [Pad], T_n, ..., |T3|, T2, T1, T0, |CT0, CT1, CT2, CT3, ..., CT_n, CTa_0, CTa_1, ..., CTa_m///                     ^                                              \__________  __________////        `table.bucket(3)` returns a pointer that points                        \////         here in the `data` part of the `RawTableInner`             additional control bytes///         (to the end of T3)                                          `m = Group::WIDTH - 1`/// where: T0...T_n  - our stored data;///        CT0...CT_n - control bytes or metadata for `data`;///        CTa_0...CTa_m - additional control bytes (so that the search with loading `Group` bytes from///                        the heap works properly, even if the result of `h1(hash) & self.bucket_mask`///                        is equal to `self.bucket_mask`). See also `RawTableInner::set_ctrl` function./// P.S. `h1(hash) & self.bucket_mask` is the same as `hash as usize % self.buckets()` because the number/// of buckets is a power of two, and `self.bucket_mask = self.buckets() - 1`./// [`Bucket::from_base_index`]: Bucket::from_base_index/// Returns a raw `*mut u8` pointer to the start of the `data` element in the table/// (convenience for `self.data_end::<u8>().as_ptr().sub((index + 1) * size_of)`)./// The caller must ensure that the `RawTableInner` outlives the returned `*mut u8`,///   function, i.e. `(index + 1) <= self.buckets()`;/// * The `size_of` must be equal to the size of the elements stored in the table;///           `table.bucket_ptr(3, mem::size_of::<T>())` returns a pointer that points here in the///           `data` part of the `RawTableInner`, i.e. to the start of T3///                  |               `base = table.data_end::<u8>()` points here///                                                                    \__________  __________////                                                                               \////                                                                    additional control bytes///                                                                     `m = Group::WIDTH - 1`/// the start point of the allocation (convenience for `self.ctrl.cast()`)./// This function actually returns a pointer to the end of the `data element` at/// index "0" (zero)./// The caller must ensure that the `RawTableInner` outlives the returned [`NonNull<T>`],/// The type `T` must be the actual type of the elements stored in the table, otherwise/// using the returned [`NonNull<T>`] may result in [`undefined behavior`].///                        `table.data_end::<T>()` returns pointer that points here///                        (to the end of `T0`)///                          ∨/// [Pad], T_n, ..., T1, T0, |CT0, CT1, ..., CT_n|, CTa_0, CTa_1, ..., CTa_m///                           \________  ________////                                    \////       `n = buckets - 1`, i.e. `RawTableInner::buckets() - 1`///        CT0...CT_n - control bytes or metadata for `data`.///        CTa_0...CTa_m - additional control bytes, where `m = Group::WIDTH - 1` (so that the search///                        with loading `Group` bytes from the heap works properly, even if the result///                        of `h1(hash) & self.bucket_mask` is equal to `self.bucket_mask`). See also///                        `RawTableInner::set_ctrl` function.set_ctrl_hash/// The safety rules are directly derived from the safety rules for [`RawTableInner::set_ctrl`]/// method. Thus, in order to uphold the safety contracts for the method, you must observe the/// following rules when calling this function:/// * The `index` must not be greater than the `RawTableInner.bucket_mask`, i.e.///   `index <= RawTableInner.bucket_mask` or, in other words, `(index + 1)` must///   be no greater than the number returned by the function [`RawTableInner::buckets`]./// Calling this function on a table that has not been allocated results in [`undefined behavior`]./// [`RawTableInner::set_ctrl`]: RawTableInner::set_ctrlreplace_ctrl_hash/// Replaces the hash in the control byte at the given index with the provided one,/// and possibly also replicates the new control byte at the end of the array of control/// bytes, returning the old control byte./// The safety rules are directly derived from the safety rules for [`RawTableInner::set_ctrl_hash`]/// and [`RawTableInner::ctrl`] methods. Thus, in order to uphold the safety contracts for both/// methods, you must observe the following rules when calling this function:/// For the allocated [`RawTableInner`], the result is [`Undefined Behavior`],/// if the `index` is greater than the `self.bucket_mask + 1 + Group::WIDTH`./// In that case, calling this function with `index == self.bucket_mask + 1 + Group::WIDTH`/// will return a pointer to the end of the allocated table and it is useless on its own./// Calling this function with `index >= self.bucket_mask + 1 + Group::WIDTH` on a/// table that has not been allocated results in [`Undefined Behavior`]./// So to satisfy both requirements you should always follow the rule that/// `index < self.bucket_mask + 1 + Group::WIDTH`/// Calling this function on [`RawTableInner`] that are not already allocated is safe/// for read-only purpose./// See also [`Bucket::as_ptr()`] method, for more information about of properly removing/// [`Bucket::as_ptr()`]: Bucket::as_ptr()/// [`Undefined Behavior`]: https://doc.rust-lang.org/reference/behavior-considered-undefined.htmlctrl_slice/// Gets the slice of all control bytes./// for inserting the given number of elements without reallocating,/// and return it inside `ScopeGuard` to protect against panic in the hash/// It is recommended (but not required):/// * That the new table's `capacity` be greater than or equal to `self.items`./// * The `alloc` is the same [`Allocator`] as the `Allocator` used/// * The `table_layout` is the same [`TableLayout`] as the `TableLayout` used/// If `table_layout` does not match the `TableLayout` that was used to allocate/// this table, then using `mem::swap` with the `self` and the new table returned/// by this function results in [`undefined behavior`]./// If any of the following conditions are violated, the result is/// [`undefined behavior`]:/// * The `alloc` must be the same [`Allocator`] as the `Allocator` used/// * The `layout` must be the same [`TableLayout`] as the `TableLayout`///   used to allocate this table./// * The `drop` function (`fn(*mut u8)`) must be the actual drop function of///   the elements stored in the table.full_buckets_indicesFullBucketsIndices/// Returns an iterator over full buckets indices in the table./// Behavior is undefined if any of the following conditions are violated:///   `FullBucketsIndices`. Because we cannot make the `next` method///   unsafe on the `FullBucketsIndices` struct, we have to make the///   `full_buckets_indices` method unsafe.///   to allocate this table;///   used to allocate this table;/// The caller of this function must ensure that `capacity >= self.items`/// * If `self.items != 0`, calling of this function with `capacity == 0`///   results in [`undefined behavior`]./// * If `capacity_to_buckets(capacity) < Group::WIDTH` and///   `self.items > capacity_to_buckets(capacity)` calling this function/// * If `capacity_to_buckets(capacity) >= Group::WIDTH` and///   are never return (will go into an infinite loop)./// Note: It is recommended (but not required) that the new table's `capacity`/// be greater than or equal to `self.items`. In case if `capacity <= self.items`/// this function can never return. See [`RawTableInner::find_insert_slot`] for/// more information./// This function must be called only after [`drop_elements`](RawTableInner::drop_elements),/// else it can lead to leaking of memory. Also calling this function automatically/// makes invalid (dangling) all instances of buckets ([`Bucket`]) and makes invalid/// (dangling) the `ctrl` field of the table./// If any of the following conditions are violated, the result is [`Undefined Behavior`]:/// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout` that was used/// See also [`GlobalAlloc::dealloc`] or [`Allocator::deallocate`] for more  information./// [`GlobalAlloc::dealloc`]: https://doc.rust-lang.org/alloc/alloc/trait.GlobalAlloc.html#tymethod.dealloc/// [`Allocator::deallocate`]: https://doc.rust-lang.org/alloc/alloc/trait.Allocator.html#tymethod.deallocate/// Returns a pointer to the allocated memory and the layout that was used to/// allocate the table./// Caller of this function must observe the following safety rules:/// * The [`RawTableInner`] has already been allocated, otherwise///   calling this function results in [`undefined behavior`]/// * The `table_layout` must be the same [`TableLayout`] as the `TableLayout`///   that was used to allocate this table. Failure to comply with this condition///   may result in [`undefined behavior`].allocation_size_or_zero/// The `table_layout` must be the same [`TableLayout`] as the `TableLayout`/// that was used to allocate this table. Failure to comply with this condition/// may result in [`undefined behavior`]./// Erases the [`Bucket`]'s control byte at the given index so that it does not/// triggered as full, decreases the `items` of the table and, if it can be done,/// increases `self.growth_left`./// This function does not actually erase / drop the [`Bucket`] itself, i.e. it/// does not make any changes to the `data` parts of the table. The caller of this/// function must take care to properly drop the `data`, otherwise calling this/// function may result in a memory leak./// * It must be the full control byte at the given position;/// Calling this function on a table with no elements is unspecified, but calling subsequent/// functions is likely to result in [`undefined behavior`] due to overflow subtraction/// (`self.items -= 1 cause overflow when self.items == 0`)./// Common code for `clone` and `clone_from`. Assumes:may_dangle/// * `ctrl` must be [valid] for reads, i.e. table outlives the `RawIterRange`;/// * `ctrl` must be properly aligned to the group size (`Group::WIDTH`);/// * `ctrl` must point to the array of properly initialized control bytes;/// * `data` must be the [`Bucket`] at the `ctrl` index in the table;/// * the value of `len` must be less than or equal to the number of table buckets,///   and the returned value of `ctrl.as_ptr().add(len).offset_from(ctrl.as_ptr())`///   must be positive./// * The `ctrl.add(len)` pointer must be either in bounds or one///   byte past the end of the same [allocated table]./// * The `len` must be a power of two./// [valid]: https://doc.rust-lang.org/std/ptr/index.html#safety/// If `DO_CHECK_PTR_RANGE` is false, caller must ensure that we never try to iteratefold_impl/// Folds every element into an accumulator by applying an operation,/// returning the final result./// `fold_impl()` takes three arguments: the number of items remaining in/// the iterator, an initial value, and a closure with two arguments: an/// 'accumulator', and an element. The closure returns the value that the/// accumulator should have for the next iteration./// The initial value is the value the accumulator will have on the first call./// After applying this closure to every element of the iterator, `fold_impl()`/// returns the accumulator./// [`Undefined Behavior`]:/// * The [`RawTableInner`] / [`RawTable`] must be alive and not moved,///   i.e. table outlives the `RawIterRange`;/// * The provided `n` value must match the actual number of items///   in the table.group_first_index// Initial value of the bytes' indices of the current group (relative// to the start of the control bytes).// Pointer to the current group of control bytes,// Must be aligned to the group size (Group::WIDTH).// Number of elements in the table./// Iterator which returns an index of every full bucket in the table.///   result in the iterator yielding index of that bucket.///   created will be yielded by that iterator./// - The order in which the iterator yields indices of the buckets is unspecified///   and may change in the future./// Advances the iterator and returns the next value.///   i.e. table outlives the `FullBucketsIndices`;/// * It never tries to iterate after getting all elements./// Advances the iterator and returns the next value. It is up to/// the caller to ensure that the `RawTable` outlives the `FullBucketsIndices`,/// because we cannot make the `next` method unsafe.///   result in the iterator yielding that bucket./// - The order in which the iterator yields buckets is unspecified and may// See `RawTableInner`'s corresponding fields for details.// We can't store a `*const RawTableInner` as it would get// invalidated by the user calling `&mut` methods on `RawTable`.tag_hash// The elements within the group with a matching tag-hash./// Creates a raw entry builder for the `HashMap`./// to put the `HashMap` into an inconsistent state which, while memory-safe,/// This is because implementations of `HashMap` may need to recompute hashes/// Creates a raw immutable entry builder for the `HashMap`./// Sets the value of the entry, and returns a `RawOccupiedEntryMut`./// Converts the `OccupiedEntry` into a mutable reference to the key and value in the entry/// Sets the value of the entry with the `VacantEntry`'s key,///     [ "Einar", "Olaf", "Harald" ].into_iter().collect();/// let mut set: HashSet<_> = [1, 2, 3].into_iter().collect();/// let mut set: HashSet<i32> = xs.into_iter().collect();/// [`retain()`]: HashSet::retain/// let drained: HashSet<i32> = set.extract_if(|v| v % 2 == 0).collect();/// the `HashSet` to be useful, see its documentation for details./// let a: HashSet<_> = [1, 2, 3].into_iter().collect();/// let b: HashSet<_> = [4, 2, 3, 4].into_iter().collect();/// let set: HashSet<_> = [1, 2, 3].into_iter().collect();/// The following example will panic because the new value doesn't match./// let mut set = hashbrown::HashSet::new();/// set.get_or_insert_with("rust", |_| String::new());///                 single_entry.insert();/// let sup: HashSet<_> = [1, 2, 3].into_iter().collect();/// let sub: HashSet<_> = [1, 2].into_iter().collect();/// However this operation is still unsafe because the resulting `HashSet`/// may be passed to unsafe code which does expect the set to behave/// Modifies this set to contain the union of `self` and `rhs`./// let mut a: HashSet<_> = vec![1, 2, 3].into_iter().collect();/// a |= &b;/// for x in &a {/// Modifies this set to contain the intersection of `self` and `rhs`./// a &= &b;/// Modifies this set to contain the symmetric difference of `self` and `rhs`./// a ^= &b;/// Modifies this set to contain the difference of `self` and `rhs`./// a -= &b;/// This `struct` is created by the [`extract_if`] method on [`HashSet`]. See its/// [`extract_if`]: struct.HashSet.html#method.extract_if///     Entry::Vacant(view) => { view.insert(); },/// Sets the value of the entry with the `VacantEntry`'s value./// Low-level hash table with explicit hashing./// The primary use case for this type over [`HashMap`] or [`HashSet`] is to/// support types that do not implement the [`Hash`] and [`Eq`] traits, but/// instead require additional data not contained in the key itself to compute a/// hash and compare two elements for equality./// Examples of when this can be useful include:/// - An `IndexMap` implementation where indices into a `Vec` are stored as///   elements in a `HashTable<usize>`. Hashing and comparing the elements///   requires indexing the associated `Vec` to get the actual value referred to///   by the index./// - Avoiding re-computing a hash when it is already known./// - Mutating the key of an element in a way that doesn't affect its hash./// To achieve this, `HashTable` methods that search for an element in the table/// require a hash value and equality function to be explicitly passed in as/// arguments. The method will then iterate over the elements with the given/// hash and call the equality function on each of them, until a match is found./// In most cases, a `HashTable` will not be exposed directly in an API. It will/// instead be wrapped in a helper type which handles the work of calculating/// hash values and comparing elements./// Due to its low-level nature, this type provides fewer guarantees than/// [`HashMap`] and [`HashSet`]. Specifically, the API allows you to shoot/// yourself in the foot by having multiple elements with identical keys in the/// table. The table itself will still function correctly and lookups will/// arbitrarily return one of the matching elements. However you should avoid/// doing this because it changes the runtime of hash table operations from/// `O(1)` to `O(k)` where `k` is the number of duplicate entries./// [`HashMap`]: super::HashMap/// [`HashSet`]: super::HashSet/// Creates an empty `HashTable`./// The hash table is initially created with a capacity of 0, so it will not allocate until it/// use hashbrown::HashTable;/// let mut table: HashTable<&str> = HashTable::new();/// assert_eq!(table.len(), 0);/// assert_eq!(table.capacity(), 0);/// Creates an empty `HashTable` with the specified capacity./// The hash table will be able to hold at least `capacity` elements without/// reallocating. If `capacity` is 0, the hash table will not allocate./// let mut table: HashTable<&str> = HashTable::with_capacity(10);/// assert!(table.capacity() >= 10);/// Creates an empty `HashTable` using the given allocator./// # #[cfg(feature = "nightly")]/// use hashbrown::{HashTable, DefaultHashBuilder};/// let mut table = HashTable::new_in(&bump);/// let hasher = |val: &_| hasher.hash_one(val);/// // The created HashTable holds none elements/// // The created HashTable also doesn't allocate memory/// // Now we insert element inside created HashTable/// table.insert_unique(hasher(&"One"), "One", hasher);/// // We can see that the HashTable holds 1 element/// assert_eq!(table.len(), 1);/// assert!(table.capacity() > 1);/// #     #[cfg(feature = "nightly")]/// Creates an empty `HashTable` with the specified capacity using the given allocator./// let mut table = HashTable::with_capacity_in(5, &bump);/// let empty_map_capacity = table.capacity();/// // Now we insert some 5 elements inside created HashTable/// table.insert_unique(hasher(&"Two"), "Two", hasher);/// table.insert_unique(hasher(&"Three"), "Three", hasher);/// table.insert_unique(hasher(&"Four"), "Four", hasher);/// table.insert_unique(hasher(&"Five"), "Five", hasher);/// // We can see that the HashTable holds 5 elements/// assert_eq!(table.len(), 5);/// assert_eq!(table.capacity(), empty_map_capacity)/// Returns a reference to an entry in the table with the given hash and/// which satisfies the equality function passed./// This method will call `eq` for all entries with the given hash, but may/// also call it for entries with a different hash. `eq` should only return/// true for the desired entry, at which point the search is stopped./// let mut table = HashTable::new();/// table.insert_unique(hasher(&1), 1, hasher);/// table.insert_unique(hasher(&2), 2, hasher);/// table.insert_unique(hasher(&3), 3, hasher);/// assert_eq!(table.find(hasher(&2), |&val| val == 2), Some(&2));/// assert_eq!(table.find(hasher(&4), |&val| val == 4), None);find_mut/// Returns a mutable reference to an entry in the table with the given hash/// and which satisfies the equality function passed./// When mutating an entry, you should ensure that it still retains the same/// hash value as when it was inserted, otherwise lookups of that entry may/// fail to find it./// table.insert_unique(hasher(&1), (1, "a"), |val| hasher(&val.0));/// if let Some(val) = table.find_mut(hasher(&1), |val| val.0 == 1) {///     val.1 = "b";/// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), Some(&(1, "b")));/// assert_eq!(table.find(hasher(&2), |val| val.0 == 2), None);find_entryAbsentEntry/// Returns an `OccupiedEntry` for an entry in the table with the given hash/// This can be used to remove the entry from the table. Call/// [`HashTable::entry`] instead if you wish to insert an entry if the/// lookup fails./// if let Ok(entry) = table.find_entry(hasher(&1), |val| val.0 == 1) {///     entry.remove();/// assert_eq!(table.find(hasher(&1), |val| val.0 == 1), None);/// Returns an `Entry` for an entry in the table with the given hash/// This can be used to remove the entry from the table, or insert a new/// entry with the given hash if one doesn't already exist./// This method may grow the table in preparation for an insertion. Call/// [`HashTable::find_entry`] if this is undesirable./// `hasher` is called if entries need to be moved or copied to a new table./// This must return the same hash value that each entry was inserted with./// use hashbrown::hash_table::Entry;/// if let Entry::Occupied(entry) = table.entry(hasher(&1), |val| val.0 == 1, |val| hasher(&val.0))/// if let Entry::Vacant(entry) = table.entry(hasher(&2), |val| val.0 == 2, |val| hasher(&val.0)) {///     entry.insert((2, "b"));/// assert_eq!(table.find(hasher(&2), |val| val.0 == 2), Some(&(2, "b")));insert_unique/// Inserts an element into the `HashTable` with the given hash value, but/// without checking whether an equivalent element already exists within the/// table./// let mut v = HashTable::new();/// v.insert_unique(hasher(&1), 1, hasher);/// Clears the table, removing all values./// Shrinks the capacity of the table as much as possible. It will drop/// let mut table = HashTable::with_capacity(100);/// assert!(table.capacity() >= 100);/// table.shrink_to_fit(hasher);/// assert!(table.capacity() >= 2);/// Shrinks the capacity of the table with a lower limit. It will drop/// table.shrink_to(10, hasher);/// table.shrink_to(0, hasher);/// in the `HashTable`. The collection may reserve more space to avoid/// in case of allocation error. Use [`try_reserve`](HashTable::try_reserve) instead/// let mut table: HashTable<i32> = HashTable::new();/// table.reserve(10, hasher);/// in the given `HashTable`. The collection may reserve more space to avoid/// table///     .try_reserve(10, hasher)///     .expect("why is the test harness OOMing on 10 bytes?");/// Returns the number of elements the table can hold without reallocating./// let table: HashTable<i32> = HashTable::with_capacity(100);/// table.insert_unique(hasher(&"a"), "b", hasher);/// table.insert_unique(hasher(&"b"), "b", hasher);/// for x in table.iter() {/// An iterator visiting all elements in arbitrary order,/// with mutable references to the elements./// The iterator element type is `&'a mut T`./// for val in table.iter_mut() {/// assert_eq!(table.len(), 3);/// for val in &table {///     println!("val: {}", val);/// assert_eq!(vec, [2, 4, 6]);IterHash/// An iterator visiting all elements which may match a hash./// This iterator may return elements from the table that have a hash value/// different than the one provided. You should always validate the returned/// values before using them./// table.insert_unique(hasher(&"a"), "a", hasher);/// table.insert_unique(hasher(&"b"), "c", hasher);/// // Will print "a" and "b" (and possibly "c") in an arbitrary order./// for x in table.iter_hash(hasher(&"a")) {iter_hash_mutIterHashMut/// A mutable iterator visiting all elements which may match a hash./// table.insert_unique(hasher(&1), 2, hasher);/// table.insert_unique(hasher(&1), 3, hasher);/// table.insert_unique(hasher(&2), 5, hasher);/// // Update matching values/// for val in table.iter_hash_mut(hasher(&1)) {/// // The values will contain 4 and 6 and may contain either 5 or 10./// assert!(vec.contains(&4));/// assert!(vec.contains(&6));/// for x in 1..=6 {///     table.insert_unique(hasher(&x), x, hasher);/// table.retain(|&mut x| x % 2 == 0);/// for x in 1..=3 {/// assert!(!table.is_empty());/// for i in table.drain() {/// assert!(table.is_empty());/// [`retain()`]: HashTable::retain/// for x in 0..8 {/// let drained: Vec<i32> = table.extract_if(|&mut v| v % 2 == 0).collect();/// let mut odds = table.into_iter().collect::<Vec<_>>();/// let mut libraries: HashTable<(&str, u32)> = HashTable::new();/// for (k, v) in [///     ("Bodleian Library", 1602),///     ("Athenæum", 1807),///     ("Herzogin-Anna-Amalia-Bibliothek", 1691),///     ("Library of Congress", 1800),/// ] {///     libraries.insert_unique(hasher(&k), (k, v), |(k, _)| hasher(&k));/// let keys = ["Athenæum", "Library of Congress"];/// let got = libraries.get_many_mut(keys.map(|k| hasher(&k)), |i, val| keys[i] == val.0);///     [Some(&mut ("Athenæum", 1807)), Some(&mut ("Library of Congress", 1800))],/// let keys = ["Athenæum", "New York Public Library"];/// assert_eq!(got, [Some(&mut ("Athenæum", 1807)), None]);/// # use hashbrown::{HashTable, DefaultHashBuilder};/// # use std::hash::BuildHasher;/// // Duplicate keys result in a panic!/// let keys = ["Athenæum", "Athenæum"];/// #     test();/// #     #[cfg(not(feature = "nightly"))]/// #     panic!();/// For a safe alternative see [`get_many_mut`](`HashTable::get_many_mut`)./// use hashbrown::hash_table::{Entry, OccupiedEntry};/// for x in ["a", "b"] {/// match table.entry(hasher(&"a"), |&x| x == "a", hasher) {///     Entry::Occupied(_) => {}/// let mut table = HashTable::<&str>::new();///     Entry::Vacant(_) => {}/// A view into a single entry in a table, which may either be vacant or occupied./// This `enum` is constructed from the [`entry`] method on [`HashTable`]./// [`HashTable`]: struct.HashTable.html/// [`entry`]: struct.HashTable.html#method.entry/// for x in ["a", "b", "c"] {/// let entry: Entry<_> = table.entry(hasher(&"a"), |&x| x == "a", hasher);/// let _raw_o: OccupiedEntry<_, _> = entry.insert("a");/// table.entry(hasher(&"d"), |&x| x == "d", hasher).insert("d");///     .entry(hasher(&"b"), |&x| x == "b", hasher)///     .or_insert("b");///     .entry(hasher(&"e"), |&x| x == "e", hasher)///     .or_insert("e");/// println!("Our HashTable: {:?}", table);/// let mut vec: Vec<_> = table.iter().copied().collect();/// Sets the value of the entry, replacing any existing value if there is/// one, and returns an [`OccupiedEntry`]./// let entry = table///     .entry(hasher(&"horseyland"), |&x| x == "horseyland", hasher)///     .insert("horseyland");/// Returns an [`OccupiedEntry`] pointing to the now-occupied entry.///     .entry(hasher(&"poneyland"), |&x| x == "poneyland", hasher)///     .or_insert("poneyland");/// assert!(table///     .find(hasher(&"poneyland"), |&x| x == "poneyland")///     .is_some());/// Ensures a value is in the entry by inserting the result of the default function if empty../// let mut table: HashTable<String> = HashTable::new();///     .entry(hasher("poneyland"), |x| x == "poneyland", |val| hasher(val))///     .or_insert_with(|| "poneyland".to_string());///     .find(hasher(&"poneyland"), |x| x == "poneyland")/// potential inserts into the table./// let mut table: HashTable<(&str, u32)> = HashTable::new();///     .entry(///         hasher(&"poneyland"),///         |&(x, _)| x == "poneyland",///         |(k, _)| hasher(&k),///     .and_modify(|(_, v)| *v += 1)///     .or_insert(("poneyland", 42));///     table.find(hasher(&"poneyland"), |&(k, _)| k == "poneyland"),///     Some(&("poneyland", 42))///     Some(&("poneyland", 43))/// A view into an occupied entry in a `HashTable`./// let _entry_o: OccupiedEntry<_, _> = table.find_entry(hasher(&"a"), |&x| x == "a").unwrap();/// match table.entry(hasher(&"c"), |&x| x == "c", hasher) {///         assert_eq!(view.remove().0, "c");/// assert_eq!(table.find(hasher(&"c"), |&x| x == "c"), None);/// assert_eq!(table.len(), 2);/// Takes the value out of the entry, and returns it along with a/// `VacantEntry` that can be used to insert another value with the same/// hash as the one that was just removed./// // The table is empty/// assert!(table.is_empty() && table.capacity() == 0);/// table.insert_unique(hasher(&"poneyland"), "poneyland", hasher);/// let capacity_before_remove = table.capacity();/// if let Entry::Occupied(o) = table.entry(hasher(&"poneyland"), |&x| x == "poneyland", hasher) {///     assert_eq!(o.remove().0, "poneyland");///     .is_none());/// // Now table hold none elements but capacity is equal to the old one/// assert!(table.len() == 0 && table.capacity() == capacity_before_remove);/// match table.entry(hasher(&"poneyland"), |&x| x == "poneyland", hasher) {/// table.insert_unique(hasher(&"poneyland"), ("poneyland", 12), |(k, _)| hasher(&k));///     table.find(hasher(&"poneyland"), |&(x, _)| x == "poneyland",),///     Some(&("poneyland", 12))/// if let Entry::Occupied(mut o) = table.entry(///     hasher(&"poneyland"),///     |&(x, _)| x == "poneyland",///     |(k, _)| hasher(&k),/// ) {///     o.get_mut().1 += 10;///     assert_eq!(o.get().1, 22);///     o.get_mut().1 += 2;///     Some(&("poneyland", 24))/// with a lifetime bound to the table itself./// let value: &mut (&str, u32);/// match table.entry(/// value.1 += 10;///     Some(&("poneyland", 22))into_table/// Converts the `OccupiedEntry` into a mutable reference to the underlyinginsert_slot/// A view into a vacant entry in a `HashTable`./// use hashbrown::hash_table::{Entry, VacantEntry};/// let entry_v: VacantEntry<_, _> = match table.entry(hasher(&"a"), |&x| x == "a", hasher) {/// entry_v.insert("a");/// assert!(table.find(hasher(&"a"), |&x| x == "a").is_some() && table.len() == 1);/// match table.entry(hasher(&"b"), |&x| x == "b", hasher) {///         view.insert("b");/// assert!(table.find(hasher(&"b"), |&x| x == "b").is_some() && table.len() == 2);/// Inserts a new element into the table with the hash that was used to/// obtain the `VacantEntry`./// An `OccupiedEntry` is returned for the newly inserted element./// if let Entry::Vacant(o) = table.entry(hasher(&"poneyland"), |&x| x == "poneyland", hasher) {///     o.insert("poneyland");///     table.find(hasher(&"poneyland"), |&x| x == "poneyland"),///     Some(&"poneyland")/// Converts the `VacantEntry` into a mutable reference to the underlying/// Type representing the absence of an entry, as returned by [`HashTable::find_entry`]./// This type only exists due to [limitations] in Rust's NLL borrow checker. In/// the future, `find_entry` will return an `Option<OccupiedEntry>` and this/// type will be removed./// [limitations]: https://smallcultfollowing.com/babysteps/blog/2018/06/15/mir-based-borrow-check-nll-status-update/#polonius/// use hashbrown::hash_table::{AbsentEntry, Entry};/// let entry_v: AbsentEntry<_, _> = table.find_entry(hasher(&"a"), |&x| x == "a").unwrap_err();/// entry_v///     .into_table()///     .insert_unique(hasher(&"a"), "a", hasher);/// Converts the `AbsentEntry` into a mutable reference to the underlying/// An iterator over the entries of a `HashTable` in arbitrary order./// This `struct` is created by the [`iter`] method on [`HashTable`]. See its/// [`iter`]: struct.HashTable.html#method.iter/// A mutable iterator over the entries of a `HashTable` in arbitrary order./// This `struct` is created by the [`iter_mut`] method on [`HashTable`]. See its/// [`iter_mut`]: struct.HashTable.html#method.iter_mut/// An iterator over the entries of a `HashTable` that could match a given hash./// This `struct` is created by the [`iter_hash`] method on [`HashTable`]. See its/// [`iter_hash`]: struct.HashTable.html#method.iter_hash/// A mutable iterator over the entries of a `HashTable` that could match a given hash./// This `struct` is created by the [`iter_hash_mut`] method on [`HashTable`]. See its/// [`iter_hash_mut`]: struct.HashTable.html#method.iter_hash_mut/// An owning iterator over the entries of a `HashTable` in arbitrary order./// The iterator element type is `T`./// This `struct` is created by the [`into_iter`] method on [`HashTable`]/// The table cannot be used after calling that method./// [`into_iter`]: struct.HashTable.html#method.into_iter/// A draining iterator over the items of a `HashTable`./// This `struct` is created by the [`drain`] method on [`HashTable`]./// [`drain`]: struct.HashTable.html#method.drain/// A draining iterator over entries of a `HashTable` which don't satisfy the predicate `f`./// This `struct` is created by [`HashTable::extract_if`]. See its// FIXME: use strict provenance functions once they are stable.// Implement it with a transmute for now.// clippy is wrong, cast and transmute are different hereor_insert_entry/// Ensures a value is in the entry by inserting the default if empty,/// let entry = map.entry("poneyland").or_insert_entry(3);/// assert_eq!(entry.key(), &"poneyland");/// assert_eq!(entry.get(), &3);/// let mut entry = map.entry("poneyland").or_insert_entry(10);or_default_entry/// let entry = map.entry_ref("poneyland").or_default_entry();/// assert_eq!(entry.get(), &None);/// let entry = map.entry_ref("horseland").or_default_entry();/// assert_eq!(entry.key(), &"horseland");/// assert_eq!(entry.get(), &Some(3));test_extract_iftest_get_many_mut"duplicate keys found"test_get_many_mut_duplicate"panic in clone"test_clone_from_memory_leaksdrop_countMyAllocInner_innerMyAlloctest_hashmap_into_iter_bugpanic_in_clonepanic_in_dropdroppedCheckedCloneDropget_test_map/// Return hashmap with predefined distribution of elements./// All elements will be located in the same order as elements/// returned by iterator./// This function does not panic, but returns an error as a `String`/// to distinguish between a test panic and an error in the input data.DISARMEDARMEDARMED_FLAGSDISARMED_FLAGStest_clone_memory_leaks_and_double_drop_onetest_clone_memory_leaks_and_double_drop_twotest_catch_panic_clone_from_when_len_is_equal/// We check that we have a working table if the clone operation from another/// thread ended in a panic (when buckets of maps are equal to each other).test_catch_panic_clone_from_when_len_is_not_equal/// thread ended in a panic (when buckets of maps are not equal to each other).test_allocation_info// No-defaults case.// When building with default-features turned off and// neither `nightly` nor `allocator-api2` is enabled,// this will be used.// Making it impossible to use any custom allocator with collections defined// in this crate.// Any crate in build-tree can enable `allocator-api2`,// or `nightly` without disturbing users that don't want to use it.test_minimum_capacity_for_small_typestest_drop_uninitialized/// CHECKING THAT WE ARE NOT TRYING TO READ THE MEMORY OF/// AN UNINITIALIZED TABLE DURING THE DROPtest_drop_zero_items/// CHECKING THAT WE DON'T TRY TO DROP DATA IF THE `ITEMS`/// ARE ZERO, EVEN IF WE HAVE `FULL` CONTROL BYTES.test_catch_panic_clone_fromtest_sub_assignduplicate_insertsome_invalid_equivalentcold_pathcapitalizetransformto_camel_case/// Convert this type to camel case./// This trait defines a camel case conversion./// In CamelCase, word boundaries are indicated by capital letters, including/// the first word./// ## Example:/// use heck::CamelCase;/// let sentence = "We are not in the least afraid of ruins.";/// assert_eq!(sentence.to_camel_case(), "WeAreNotInTheLeastAfraidOfRuins");test1test2test3test4test5test6test7test8test9test10lowercaseto_kebab_case/// Convert this type to kebab case.KebabCase/// This trait defines a kebab case conversion./// In kebab-case, word boundaries are indicated by hyphens./// use heck::KebabCase;/// let sentence = "We are going to inherit the earth.";/// assert_eq!(sentence.to_kebab_case(), "we-are-going-to-inherit-the-earth");camelkebabmixedshouty_kebabshouty_snakesnaketitleMixedCaseShoutyKebabCaseShoutySnakeCaseShoutySnekCaseSnekCaseTitleCaseUnicodeSegmentationuppercase//! **heck** is a case conversion library.//! This library exists to provide case conversion between common cases like//! CamelCase and snake_case. It is intended to be unicode aware, internally,//! consistent, and reasonably well performing.//! ## Definition of a word boundary//! Word boundaries are defined as the "unicode words" defined in the//! `unicode_segmentation` library, as well as within those words in this//! manner://! 1. All underscore characters are considered word boundaries.//! 2. If an uppercase character is followed by lowercase letters, a word//! boundary is considered to be just prior to that uppercase character.//! 3. If multiple uppercase characters are consecutive, they are considered to//! be within a single word, except that the last will be part of the next word//! if it is followed by lowercase characters (see rule 2).//! That is, "HelloWorld" is segmented `Hello|World` whereas "XMLHttpRequest" is//! segmented `XML|Http|Request`.//! Characters not within words (such as spaces, punctuations, and underscores)//! are not included in the output string except as they are a part of the case//! being converted to. Multiple adjacent word boundaries (such as a series of//! underscores) are folded into one. ("hello__world" in snake case is therefore//! "hello_world", not the exact same string). Leading or trailing word boundary//! indicators are dropped, except insofar as CamelCase capitalizes the first//! word.//! ### Cases contained in this library://! 1. CamelCase//! 2. snake_case//! 3. kebab-case//! 4. SHOUTY_SNAKE_CASE//! 5. mixedCase//! 6. Title Case//! 7. SHOUTY-KEBAB-CASEto_mixed_case/// Convert this type to mixed case./// This trait defines a mixed case conversion./// In mixedCase, word boundaries are indicated by capital letters, excepting/// use heck::MixedCase;/// let sentence = "It is we who built these palaces and cities.";/// assert_eq!(sentence.to_mixed_case(), "itIsWeWhoBuiltThesePalacesAndCities");// TODO unicode teststo_shouty_kebab_case/// Convert this type to shouty kebab case./// This trait defines a shouty kebab case conversion./// In SHOUTY-KEBAB-CASE, word boundaries are indicated by hyphens and all/// words are in uppercase./// use heck::ShoutyKebabCase;/// assert_eq!(sentence.to_shouty_kebab_case(), "WE-ARE-GOING-TO-INHERIT-THE-EARTH");test11to_shouty_snake_case/// Convert this type to shouty snake case./// This trait defines a shouty snake case conversion./// In SHOUTY_SNAKE_CASE, word boundaries are indicated by underscores and all/// use heck::ShoutySnakeCase;///     /// let sentence = "That world is growing in this minute.";/// assert_eq!(sentence.to_shouty_snake_case(), "THAT_WORLD_IS_GROWING_IN_THIS_MINUTE");TO_SHOUTY_SNEK_CASE/// CONVERT THIS TYPE TO SNEK CASE./// Oh heck, ShoutySnekCase is an alias for ShoutySnakeCase. See ShoutySnakeCase/// for more documentation.to_snake_case/// Convert this type to snake case./// This trait defines a snake case conversion./// In snake_case, word boundaries are indicated by underscores./// use heck::SnakeCase;/// let sentence = "We carry a new world here, in our hearts.";/// assert_eq!(sentence.to_snake_case(), "we_carry_a_new_world_here_in_our_hearts");to_snek_case/// Convert this type to snek case./// Oh heck, SnekCase is an alias for SnakeCase. See SnakeCase for/// more documentation.test12test13test14test16test17test18test19test20test21test22test23test24test25to_title_case/// Convert this type to title case./// This trait defines a title case conversion./// In Title Case, word boundaries are indicated by spaces, and every word is/// capitalized./// use heck::TitleCase;/// let sentence = "We have always lived in slums and holes in the wall.";/// assert_eq!(sentence.to_title_case(), "We Have Always Lived In Slums And Holes In The Wall");optimHmacCoreSimpleHmacIPADOPADget_der_key//! Generic implementation of Hash-based Message Authentication Code (HMAC).//! To use it you will need a cryptographic hash function implementation which//! implements the [`digest`] crate traits. You can find compatible crates//! (e.g. [`sha2`]) in the [`RustCrypto/hashes`] repository.//! This crate provides two HMAC implementation [`Hmac`] and [`SimpleHmac`].//! The first one is a buffered wrapper around block-level [`HmacCore`].//! Internally it uses efficient state representation, but works only with//! hash functions which expose block-level API and consume blocks eagerly//! (e.g. it will not work with the BLAKE2 family of  hash functions).//! On the other hand, [`SimpleHmac`] is a bit less efficient memory-wise,//! but works with all hash functions which implement the [`Digest`] trait.//! Let us demonstrate how to use HMAC using the SHA-256 hash function.//! In the following examples [`Hmac`] is interchangeable with [`SimpleHmac`].//! To get authentication code://! use sha2::Sha256;//! use hmac::{Hmac, Mac};//! use hex_literal::hex;//! // Create alias for HMAC-SHA256//! type HmacSha256 = Hmac<Sha256>;//! let mut mac = HmacSha256::new_from_slice(b"my secret and secure key")//!     .expect("HMAC can take key of any size");//! mac.update(b"input message");//! // `result` has type `CtOutput` which is a thin wrapper around array of//! // bytes for providing constant time equality check//! let result = mac.finalize();//! // To get underlying array use `into_bytes`, but be careful, since//! // incorrect use of the code value may permit timing attacks which defeats//! // the security provided by the `CtOutput`//! let code_bytes = result.into_bytes();//! let expected = hex!("//!     97d2a569059bbcd8ead4444ff99071f4//!     c01d005bcefe0d3567e1be628e5fdcd9//! ");//! assert_eq!(code_bytes[..], expected[..]);//! To verify the message://! # use sha2::Sha256;//! # use hmac::{Hmac, Mac};//! # use hex_literal::hex;//! # type HmacSha256 = Hmac<Sha256>;//! let code_bytes = hex!("//! // `verify_slice` will return `Ok(())` if code is correct, `Err(MacError)` otherwise//! mac.verify_slice(&code_bytes[..]).unwrap();//! # Block and input sizes//! Usually it is assumed that block size is larger than output size. Due to the//! generic nature of the implementation, this edge case must be handled as well//! to remove potential panic. This is done by truncating hash output to the hash//! block size if needed.//! [`digest`]: https://docs.rs/digest//! [`sha2`]: https://docs.rs/sha2//! [`RustCrypto/hashes`]: https://github.com/RustCrypto/hashes/// Generic HMAC instance.opad_digest/// Generic core HMAC instance, which operates over blocks.opad_key/// Simplified HMAC instance able to operate over hash functions/// which do not expose block-level API and hash functions which/// process blocks lazily (e.g. BLAKE2).i_key_pad/// The `Hmac` struct represents an HMAC using a given hash function `D`.//! To use it you'll need a cryptographic hash function implementation from//! RustCrypto project. You can either import specific crate (e.g. `sha2`), or//! meta-crate `crypto-hashes` which reexport all related crates.//! Let us demonstrate how to use HMAC using SHA256 as an example.//! To get the authentication code://! use hmac::{Hmac, Mac, NewMac};//! // Create HMAC-SHA256 instance which implements `Mac` trait//! let mut mac = HmacSha256::new_varkey(b"my secret and secure key")//! // `result` has type `Output` which is a thin wrapper around array of//! // To get underlying array use `into_bytes` method, but be careful, since//! // incorrect use of the code value may permit timing attacks which defeat//! // the security provided by the `Output`//! # use hmac::{Hmac, Mac, NewMac};//! # let code_bytes = mac.clone().finalize().into_bytes();//! // `verify` will return `Ok(())` if code is correct, `Err(MacError)` otherwise//! mac.verify(&code_bytes).unwrap();//! Usually it is assumed that block size is larger than output size, due to the//! generic nature of the implementation this edge case must be handled as well//! to remove potential panic scenario. This is done by truncating hash output//! to the hash block size if needed.HmacDRBGreseedgenerate_to_sliceSECONDSTIMESTAMP// last second of year 9999/// Numeric component is out of rangeInvalidDigit/// Bad character where digit is expectedInvalidFormat/// Other formatting errors/// Error parsing datetime (timestamp)PrecisionSmartRfc3339Timestamp/// A wrapper type that allows you to Display a SystemTime/// Converts two digits given in ASCII to its proper decimal representation./// Parse RFC3339 timestamp `2018-02-14T00:28:07Z`/// Supported feature: any precision of fractional/// digits `2018-02-14T00:28:07.133Z`./// Unsupported feature: localized timestamps. Only UTC is supported.parse_rfc3339_weak/// Parse RFC3339-like timestamp `2018-02-14 00:28:07`/// Supported features:/// 1. Any precision of fractional digits `2018-02-14 00:28:07.133`./// 2. Supports timestamp with or without either of `T` or `Z`/// 3. Anything valid for [`parse_rfc3339`](parse_rfc3339) is valid for this function/// Unsupported feature: localized timestamps. Only UTC is supported, even if/// `Z` is not specified./// This function is intended to use for parsing human input. Whereas/// `parse_rfc3339` is for strings generated programmatically.format_rfc3339/// Format an RFC3339 timestamp `2018-02-14T00:28:07Z`/// This function formats timestamp with smart precision: i.e. if it has no/// fractional seconds, they aren't written at all. And up to nine digits if/// they are./// The value is always UTC and ignores system timezone./// This format always shows timestamp without fractional seconds./// Format an RFC3339 timestamp `2018-02-14T00:28:07.000Z`/// This format always shows milliseconds even if millisecond value is zero./// Format an RFC3339 timestamp `2018-02-14T00:28:07.000000Z`/// This format always shows microseconds even if microsecond value is zero./// Format an RFC3339 timestamp `2018-02-14T00:28:07.000000000Z`/// This format always shows nanoseconds even if nanosecond value is zero./// Returns a reference to the [`SystemTime`][] that is being formatted.format_descriptionwell_knownRfc3339from_secsmoke_tests_parsesmoke_tests_formatsmoke_tests_format_millissmoke_tests_format_microssmoke_tests_format_nanosupper_boundleap_secondfirst_731_daysthe_731_consecutive_daysall_86400_secondsrandom_pastrandom_wide_rangezero_monthbig_monthzero_daybig_daybig_day2big_secondbig_minutebig_hourbreak_dataweak_smoke_tests/// Invalid character during parsing/// More specifically anything that is not alphanumeric is prohibited/// The field is an byte offset of the character in the string.NumberExpected/// Non-numeric value where number is expected/// This usually means that either time unit is broken into words,/// e.g. `m sec` instead of `msec`, or just number is omitted,/// for example `2 hours min` instead of `2 hours 1 min`/// The field is an byte offset of the errorneous character/// in the string./// Start of the invalid unit inside the original string/// End of the invalid unit inside the original string/// The unit verbatim/// A number associated with the unitUnknownUnit/// Unit in the number is not one of allowed units/// See documentation of `parse_duration` for the list of supported/// time units./// The two fields are start and end (exclusive) of the slice from/// the original string, containing errorneous valueNumberOverflow/// The numeric value is too large/// Usually this means value is too large to be useful. If user writes/// data in subsecond units, then the maximum is about 3k years. When/// using seconds, or larger units, the limit is even larger./// The value was an empty string (or consists only whitespace)/// Error parsing human-friendly durationFormattedDuration/// A wrapper type that allows you to Display a DurationOverflowOpparse_first_charparse_unitparse_duration/// Parse duration object `1hour 12min 5s`/// The duration object is a concatenation of time spans. Where each time/// span is an integer number and a suffix. Supported suffixes:/// * `nsec`, `ns` -- nanoseconds/// * `usec`, `us` -- microseconds/// * `msec`, `ms` -- milliseconds/// * `seconds`, `second`, `sec`, `s`/// * `minutes`, `minute`, `min`, `m`/// * `hours`, `hour`, `hr`, `h`/// * `days`, `day`, `d`/// * `weeks`, `week`, `w`/// * `months`, `month`, `M` -- defined as 30.44 days/// * `years`, `year`, `y` -- defined as 365.25 days/// use humantime::parse_duration;/// assert_eq!(parse_duration("2h 37min"), Ok(Duration::new(9420, 0)));/// assert_eq!(parse_duration("32ms"), Ok(Duration::new(0, 32_000_000)));format_duration/// Formats duration into a human-readable string/// Note: this format is guaranteed to have same value when using/// parse_duration, but we can change some details of the exact composition/// of the value./// use humantime::format_duration;/// let val1 = Duration::new(9420, 0);/// assert_eq!(format_duration(val1).to_string(), "2h 37m");/// let val2 = Duration::new(0, 32_000_000);/// assert_eq!(format_duration(val2).to_string(), "32ms");item_plural/// Returns a reference to the [`Duration`][] that is being formatted.test_unitstest_comborandom_secondrandom_anytest_overlowtest_nice_error_messagetest_error_casesdurationTimestampErrorDurationError//! Human-friendly time parser and formatter//! Features://! * Parses durations in free form like `15days 2min 2s`//! * Formats durations in similar form `2years 2min 12us`//! * Parses and formats timestamp in `rfc3339` format: `2018-01-01T12:53:00Z`//! * Parses timestamps in a weaker format: `2018-01-01 12:53:00`//! Timestamp parsing/formatting is super-fast because format is basically//! fixed.//! See [humantime-serde] for serde integration (previous crate [serde-humantime] looks unmaintained).//! [serde-humantime]: https://docs.rs/serde-humantime/0.1.1/serde_humantime///! [humantime-serde]: https://docs.rs/humantime-serdeStdDuration/// A wrapper for duration that has `FromStr` implementation/// This is useful if you want to use it somewhere where `FromStr` is/// See `parse_duration` for the description of the format./// let x: Duration;/// x = "12h 5min 2ns".parse::<humantime::Duration>().unwrap().into();/// assert_eq!(x, Duration::new(12*3600 + 5*60, 2))/// A wrapper for SystemTime that has `FromStr` implementation/// See `parse_rfc3339_weak` for the description of the format. The "weak"/// format is used as it's more pemissive for human input as this is the/// expected use of the type (e.g. command-line parsing)./// use std::time::SystemTime;/// let x: SystemTime;/// x = "2018-02-16T00:31:37Z".parse::<humantime::Timestamp>().unwrap().into();/// assert_eq!(humantime::format_rfc3339(x).to_string(), "2018-02-16T00:31:37Z");asciiAsciiExt/// No-op rename rule.LowerCase/// Rename direct children to "lowercase" style.PascalCase/// Rename direct children to "PascalCase" style, as typically used for enum variants./// Rename direct children to "camelCase" style./// Rename direct children to "snake_case" style, as commonly used for fields.ScreamingSnakeCase/// Rename direct children to "SCREAMING_SNAKE_CASE" style, as commonly used for constants./// Rename direct children to "kebab-case" style./// A casing rule for renaming Rust identifiers.apply_to_variant/// Change case of a `PascalCase` variant.apply_to_field/// Change case of a `snake_case` field.rename_variantsrename_fields//! Crate for changing case of Rust identifiers.//! * Supports `snake_case`, `lowercase`, `camelCase`, //!   `PascalCase`, `SCREAMING_SNAKE_CASE`, and `kebab-case`//! * Rename variants, and fields//! //! use ident_case::RenameRule;//! assert_eq!("helloWorld", RenameRule::CamelCase.apply_to_field("hello_world"));//! assert_eq!("i_love_serde", RenameRule::SnakeCase.apply_to_variant("ILoveSerde"));// Copyright 2017 Serde DevelopersOrdMapOrdSetarbitrary_take_restVectorChunkSize/// The branching factor of RRB-treesOrdChunkSize/// The branching factor of B-treesHashLevelSize/// The level size of HAMTs, in bits/// Branching factor is 2 ^ HashLevelSize.POOL_SIZE/// The size of per-instance memory pools if the `pool` feature is enabled./// This is set to 0, meaning you have to opt in to using a pool by constructing/// with eg. `Vector::with_pool(pool)` even if the `pool` feature is enabled.// Must be an even number!RRcRArcnodeschunkChunkPoolDefaultPoolClonePoolget_pool_sizemake_mutptr_equnwrap_or_clone// Rc// Archamthash_keyNodeDrainHashBitsHashValueNodeIterNodeIterMutPoolRefhashmap/// Construct a hash map from a sequence of key/value pairs./// # Examples/// # #[macro_use] extern crate im;/// # use im::hashmap::HashMap;/// assert_eq!(///   hashmap!{///     1 => 11,///     2 => 22,///     3 => 33///   },///   HashMap::from(vec![(1, 11), (2, 22), (3, 33)])/// );def_poolr" A memory pool for the appropriate node type."HashMapPoolr" Create a new pool with the given size."r" Fill the pool with preallocated chunks."r"Get the current size of the pool."pool_sizepool/// An unordered map./// An immutable hash map using [hash array mapped tries] [1]./// Most operations on this map are O(log<sub>x</sub> n) for a/// suitably high *x* that it should be nearly O(1) for most maps./// Because of this, it's a great choice for a generic map as long as/// you don't mind that keys will need to implement/// [`Hash`][std::hash::Hash] and [`Eq`][std::cmp::Eq]./// Map entries will have a predictable order based on the hasher/// being used. Unless otherwise specified, this will be the standard/// [`RandomState`][std::collections::hash_map::RandomState] hasher./// [1]: https://en.wikipedia.org/wiki/Hash_array_mapped_trie/// [std::cmp::Eq]: https://doc.rust-lang.org/std/cmp/trait.Eq.html/// [std::hash::Hash]: https://doc.rust-lang.org/std/hash/trait.Hash.html/// [std::collections::hash_map::RandomState]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.htmlextract_key/// Construct an empty hash map./// Construct a hash map with a single mapping./// let map = HashMap::unit(123, "onetwothree");///   map.get(&123),///   Some(&"onetwothree")/// Test whether a hash map is empty./// Time: O(1)/// assert!(///   !hashmap!{1 => 2}.is_empty()///   HashMap::<i32, i32>::new().is_empty()/// Get the size of a hash map./// assert_eq!(3, hashmap!{///   1 => 11,///   2 => 22,///   3 => 33/// }.len());/// Test whether two maps refer to the same content in memory./// This is true if the two sides are references to the same map,/// or if the two maps refer to the same root node./// This would return true if you're comparing a map to itself, or/// if you're comparing a map to a fresh clone of itself.RS/// Construct an empty hash map using the provided hasher./// Get a reference to the map's [`BuildHasher`][BuildHasher]./// [BuildHasher]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.htmlK1new_from/// Construct an empty hash map using the same hasher as the/// current hash map./// Get an iterator over the key/value pairs of a hash map./// Please note that the order is consistent between maps using/// the same hasher, but no other ordering guarantee is offered./// Items will not come out in insertion order or sort order./// They will, however, come out in the same order every time for/// the same map./// Get an iterator over a hash map's keys./// Get an iterator over a hash map's values./// Discard all elements from the map./// This leaves you with an empty map, and all elements that/// were previously inside it are dropped./// Time: O(n)/// # use im::HashMap;/// let mut map = hashmap![1=>1, 2=>2, 3=>3];/// map.clear();/// assert!(map.is_empty());BK/// Get the value for a key from a hash map./// Time: O(log n)/// let map = hashmap!{123 => "lol"};///   Some(&"lol")/// Get the key/value pair for a key from a hash map.///   map.get_key_value(&123),///   Some((&123, &"lol"))/// Test for the presence of a key in a hash map.///   map.contains_key(&123)///   !map.contains_key(&321)RMis_submap_by/// Test whether a map is a submap of another map, meaning that/// all keys in our map must also be in the other map, with the/// same values./// Use the provided function to decide whether values are equal./// Time: O(n log n)is_proper_submap_by/// Test whether a map is a proper submap of another map, meaning/// that all keys in our map must also be in the other map, with/// the same values. To be a proper submap, ours must also contain/// fewer keys than the other map.is_submap/// let map1 = hashmap!{1 => 1, 2 => 2};/// let map2 = hashmap!{1 => 1, 2 => 2, 3 => 3};/// assert!(map1.is_submap(map2));is_proper_submap/// assert!(map1.is_proper_submap(map2));/// let map3 = hashmap!{1 => 1, 2 => 2};/// let map4 = hashmap!{1 => 1, 2 => 2};/// assert!(!map3.is_proper_submap(map4));/// Get a mutable iterator over the values of a hash map./// Get a mutable reference to the value for a key from a hash/// map./// let mut map = hashmap!{123 => "lol"};/// if let Some(value) = map.get_mut(&123) {///     *value = "omg";///   Some(&"omg")/// Insert a key/value mapping into a map./// If the map already has a mapping for the given key, the/// previous value is overwritten./// let mut map = hashmap!{};/// map.insert(123, "123");/// map.insert(456, "456");///   map,///   hashmap!{123 => "123", 456 => "456"}/// Remove a key/value pair from a map, if it exists, and return/// the removed value./// This is a copy-on-write operation, so that the parts of the/// set's structure which are shared with other sets will be/// safely copied before mutating./// let mut map = hashmap!{123 => "123", 456 => "456"};/// assert_eq!(Some("123"), map.remove(&123));/// assert_eq!(Some("456"), map.remove(&456));/// assert_eq!(None, map.remove(&789));remove_with_key/// the removed key and value./// assert_eq!(Some((123, "123")), map.remove_with_key(&123));/// assert_eq!(Some((456, "456")), map.remove_with_key(&456));/// assert_eq!(None, map.remove_with_key(&789));/// Get the [`Entry`][Entry] for a key in the map for in-place manipulation./// [Entry]: enum.Entry.html/// Construct a new hash map by inserting a key/value mapping into a map./// If the map already has a mapping for the given key, the previous value/// is overwritten./// let map = hashmap!{};///   map.update(123, "123"),///   hashmap!{123 => "123"}update_with/// Construct a new hash map by inserting a key/value mapping into/// a map./// If the map already has a mapping for the given key, we call/// the provided function with the old value and the new value,/// and insert the result as the new value.update_with_key/// Construct a new map by inserting a key/value mapping into a/// the provided function with the key, the old value and the new/// value, and insert the result as the new value.update_lookup_with_key/// map, returning the old value for the key as well as the newalter/// Update the value for a given key by calling a function with/// the current value and overwriting it with the function's/// return value./// The function gets an [`Option<V>`][std::option::Option] and/// returns the same, so that it can decide to delete a mapping/// instead of updating the value, and decide what to do if the/// key isn't in the map./// [std::option::Option]: https://doc.rust-lang.org/std/option/enum.Option.htmlwithout/// Construct a new map without the given key./// Construct a map that's a copy of the current map, absent the/// mapping for `key` if it's present./// Filter out values from a map which don't satisfy a predicate./// This is slightly more efficient than filtering using an/// iterator, in that it doesn't need to rehash the retained/// values, but it still needs to reconstruct the entire tree/// structure of the map./// let mut map = hashmap!{1 => 1, 2 => 2, 3 => 3};/// map.retain(|k, v| *k > 1);/// let expected = hashmap!{2 => 2, 3 => 3};/// assert_eq!(expected, map);extract/// the removed value as well as the updated map.extract_with_key/// the removed key and value as well as the updated list./// Construct the union of two maps, keeping the values in the/// current map when keys exist in both maps./// let map1 = hashmap!{1 => 1, 3 => 3};/// let map2 = hashmap!{2 => 2, 3 => 4};/// let expected = hashmap!{1 => 1, 2 => 2, 3 => 3};/// assert_eq!(expected, map1.union(map2));union_with/// Construct the union of two maps, using a function to decide/// what to do with the value when a key is in both maps./// The function is called when a value exists in both maps, and/// receives the value from the current map as its first argument,/// and the value from the other map as the second. It should/// return the value to be inserted in the resulting map.union_with_key/// receives a reference to the key as its first argument, the/// value from the current map as the second argument, and the/// value from the other map as the third argument. It should/// let map1 = hashmap!{1 => 1, 3 => 4};/// let map2 = hashmap!{2 => 2, 3 => 5};/// let expected = hashmap!{1 => 1, 2 => 2, 3 => 9};/// assert_eq!(expected, map1.union_with_key(///     map2,///     |key, left, right| left + right/// ));union_with_key_inner/// Construct the union of a sequence of maps, selecting the value/// of the leftmost when a key appears in more than one map./// let map2 = hashmap!{2 => 2};/// assert_eq!(expected, HashMap::unions(vec![map1, map2]));unions_with/// Construct the union of a sequence of maps, using a function to/// decide what to do with the value when a key is in more than/// one map./// The function is called when a value exists in multiple maps,/// and receives the value from the current map as its first/// argument, and the value from the next map as the second. It/// should return the value to be inserted in the resulting map.unions_with_key/// and receives a reference to the key as its first argument, the/// value from the next map as the third argument. It should/// Construct the symmetric difference between two maps by discarding keys/// which occur in both maps./// This is an alias for the/// [`symmetric_difference`][symmetric_difference] method./// let expected = hashmap!{1 => 1, 2 => 2};/// assert_eq!(expected, map1.difference(map2));/// [symmetric_difference]: #method.symmetric_difference/// assert_eq!(expected, map1.symmetric_difference(map2));difference_with/// Construct the symmetric difference between two maps by using a function/// to decide what to do if a key occurs in both./// [`symmetric_difference_with`][symmetric_difference_with] method./// [symmetric_difference_with]: #method.symmetric_difference_withsymmetric_difference_withdifference_with_key/// to decide what to do if a key occurs in both. The function/// receives the key as well as both values./// [`symmetric_difference_with`_key][symmetric_difference_with_key]/// method./// assert_eq!(expected, map1.difference_with_key(///     |key, left, right| Some(left + right)/// [symmetric_difference_with_key]: #method.symmetric_difference_with_keysymmetric_difference_with_key/// assert_eq!(expected, map1.symmetric_difference_with_key(relative_complement/// Construct the relative complement between two maps by discarding keys/// which occur in `other`./// Time: O(m log n) where m is the size of the other map/// # use im::ordmap::OrdMap;/// let map1 = ordmap!{1 => 1, 3 => 4};/// let map2 = ordmap!{2 => 2, 3 => 5};/// let expected = ordmap!{1 => 1};/// assert_eq!(expected, map1.relative_complement(map2));/// Construct the intersection of two maps, keeping the values/// from the current map./// let map2 = hashmap!{2 => 3, 3 => 4};/// let expected = hashmap!{2 => 2};/// assert_eq!(expected, map1.intersection(map2));intersection_with/// Construct the intersection of two maps, calling a function/// with both values for each key and using the result as the/// value for the key.intersection_with_key/// with the key and both values for each key and using the result/// as the value for the key./// let expected = hashmap!{2 => 5};/// assert_eq!(expected, map1.intersection_with_key(/// An entry which exists in the map./// An entry which doesn't exist in the map.// Entries/// A handle for a key and its associated value./// ## Performance Note/// When using an `Entry`, the key is only ever hashed once, when you/// create the `Entry`. Operations on an `Entry` will never trigger a/// rehash, where eg. a `contains_key(key)` followed by an/// `insert(key, default_value)` (the equivalent of/// `Entry::or_insert()`) would need to hash the key once for the/// `contains_key` and again for the `insert`. The operations/// generally perform similarly otherwise./// Insert the default value provided if there was no value/// already, and return a mutable reference to the value./// Insert the default value from the provided function if there/// was no value already, and return a mutable reference to the/// value./// Insert a default value if there was no value already, and/// return a mutable reference to the value./// Get the key for this entry./// Call the provided function to modify the value if the value/// exists./// An entry for a mapping that already exists in the map./// Remove this entry from the map and return the removed mapping./// Get the current value./// Get a mutable reference to the current value./// Convert this entry into a mutable reference./// Overwrite the current value./// Remove this entry from the map and return the removed value./// An entry for a mapping that does not already exist in the map./// Convert this entry into its key./// Insert a value into this entry./// Clone a map.// Core traitsRKRV// // Iterators/// An iterator over the elements of a map./// A mutable iterator over the elements of a map.ConsumingIter/// A consuming iterator over the elements of a map./// An iterator over the keys of a map./// An iterator over the values of a map.// ConversionsSA'm'k'vOKOVSB// impl<K: Ord + Hash + Eq, V, S> From<OrdMap<K, V>> for HashMap<K, V, S>// where//     S: BuildHasher + Default,// {//     fn from(m: OrdMap<K, V>) -> Self {//         m.into_iter().collect()//     }// }// impl<'a, K: Ord + Hash + Eq, V, S> From<&'a OrdMap<K, V>> for HashMap<K, V, S>//     fn from(m: &'a OrdMap<K, V>) -> Self {// ProptestLolHashersafe_mutationindex_operatorproper_formattingremove_failingmatch_string_keys_with_string_slicesmacro_allows_trailing_commaremove_top_level_collisionsentry_apirefpool_crashlarge_map// Tests// This Source Code Form is subject to the terms of the Mozilla Public// License, v. 2.0. If a copy of the MPL was not distributed with this// file, You can obtain one at http://mozilla.org/MPL/2.0/.//! An unordered map.//! An immutable hash map using [hash array mapped tries][1].//! Most operations on this map are O(log<sub>x</sub> n) for a//! suitably high *x* that it should be nearly O(1) for most maps.//! Because of this, it's a great choice for a generic map as long as//! you don't mind that keys will need to implement//! [`Hash`][std::hash::Hash] and [`Eq`][std::cmp::Eq].//! Map entries will have a predictable order based on the hasher//! being used. Unless otherwise specified, this will be the standard//! [`RandomState`][std::collections::hash_map::RandomState] hasher.//! [1]: https://en.wikipedia.org/wiki/Hash_array_mapped_trie//! [std::cmp::Eq]: https://doc.rust-lang.org/std/cmp/trait.Eq.html//! [std::hash::Hash]: https://doc.rust-lang.org/std/hash/trait.Hash.html//! [std::collections::hash_map::RandomState]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.htmlordsethashset/// Construct a set from a sequence of values./// # #[macro_use] extern crate im;/// # use im::hashset::HashSet;///   hashset![1, 2, 3],///   HashSet::from(vec![1, 2, 3])HashSetPool/// An unordered set./// An immutable hash set using [hash array mapped tries] [1]./// Most operations on this set are O(log<sub>x</sub> n) for a/// suitably high *x* that it should be nearly O(1) for most sets./// Because of this, it's a great choice for a generic set as long as/// you don't mind that values will need to implement/// [`Hash`][std::hash::Hash] and [`Eq`][std::cmp::Eq]./// Values will have a predictable order based on the hasher/// being used. Unless otherwise specified, this will be the standard/// [`RandomState`][std::collections::hash_map::RandomState] hasher./// [1]: https://en.wikipedia.org/wiki/Hash_array_mapped_trie/// [std::cmp::Eq]: https://doc.rust-lang.org/std/cmp/trait.Eq.html/// [std::hash::Hash]: https://doc.rust-lang.org/std/hash/trait.Hash.html/// [std::collections::hash_map::RandomState]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html// FIXME lacking specialisation, we can't simply implement `HashValue`// for `A`, we have to use the `Value<A>` indirection./// Construct an empty set./// Construct a set with a single value./// # use std::sync::Arc;/// let set = HashSet::unit(123);/// assert!(set.contains(&123));/// Test whether a set is empty./// Time: O(1)///   !hashset![1, 2, 3].is_empty()///   HashSet::<i32>::new().is_empty()/// Get the size of a set./// assert_eq!(3, hashset![1, 2, 3].len());/// Test whether two sets refer to the same content in memory./// This is true if the two sides are references to the same set,/// or if the two sets refer to the same root node./// This would return true if you're comparing a set to itself, or/// if you're comparing a set to a fresh clone of itself./// Construct an empty hash set using the provided hasher./// Get a reference to the set's [`BuildHasher`][BuildHasher]./// [BuildHasher]: https://doc.rust-lang.org/std/hash/trait.BuildHasher.htmlA1/// Construct an empty hash set using the same hasher as the current hash set./// Discard all elements from the set./// This leaves you with an empty set, and all elements that/// were previously inside it are dropped./// Time: O(n)/// # use im::HashSet;/// let mut set = hashset![1, 2, 3];/// set.clear();/// Get an iterator over the values in a hash set./// Please note that the order is consistent between sets using/// the same hasher, but no other ordering guarantee is offered./// Items will not come out in insertion order or sort order./// They will, however, come out in the same order every time for/// the same set./// Test if a value is part of a set./// Time: O(log n)/// Test whether a set is a subset of another set, meaning that/// all values in our set must also be in the other set./// Time: O(n log n)is_proper_subset/// Test whether a set is a proper subset of another set, meaning/// that all values in our set must also be in the other set. A/// proper subset must also be smaller than the other set./// Insert a value into a set./// Remove a value from a set if it exists./// Construct a new set from the current set with the given value/// added./// let set = hashset![123];///   set.update(456),///   hashset![123, 456]/// Construct a new set with the given value removed if it's in/// the set./// Filter out values from a set which don't satisfy a predicate./// This is slightly more efficient than filtering using an/// iterator, in that it doesn't need to rehash the retained/// values, but it still needs to reconstruct the entire tree/// structure of the set./// set.retain(|v| *v > 1);/// let expected = hashset![2, 3];/// assert_eq!(expected, set);/// Construct the union of two sets./// let set1 = hashset!{1, 2};/// let set2 = hashset!{2, 3};/// let expected = hashset!{1, 2, 3};/// assert_eq!(expected, set1.union(set2));/// Construct the union of multiple sets./// Construct the symmetric difference between two sets./// This is an alias for the/// [`symmetric_difference`][symmetric_difference] method./// let expected = hashset!{1, 3};/// assert_eq!(expected, set1.difference(set2));/// [symmetric_difference]: #method.symmetric_difference/// assert_eq!(expected, set1.symmetric_difference(set2));/// Construct the relative complement between two sets, that is the set/// of values in `self` that do not occur in `other`./// Time: O(m log n) where m is the size of the other set/// # use im::ordset::OrdSet;/// let set1 = ordset!{1, 2};/// let set2 = ordset!{2, 3};/// let expected = ordset!{1};/// assert_eq!(expected, set1.relative_complement(set2));/// Construct the intersection of two sets./// let expected = hashset!{2};/// assert_eq!(expected, set1.intersection(set2));/// Clone a set./// An iterator over the elements of a set./// A consuming iterator over the elements of a set.OA// Proptestinsert_failingmatch_strings_with_string_slicesissue_60_drain_iterator_memory_corruption//! An unordered set.//! An immutable hash set using [hash array mapped tries] [1].//! Most operations on this set are O(log<sub>x</sub> n) for a//! suitably high *x* that it should be nearly O(1) for most sets.//! Because of this, it's a great choice for a generic set as long as//! you don't mind that values will need to implement//! [`Hash`][std::hash::Hash] and [`Eq`][std::cmp::Eq].//! Values will have a predictable order based on the hasher//! being used. Unless otherwise specified, this will be the standard//! [`RandomState`][std::collections::hash_map::RandomState] hasher.//! [1]: https://en.wikipedia.org/wiki/Hash_array_mapped_trie//! [std::cmp::Eq]: https://doc.rust-lang.org/std/cmp/trait.Eq.html//! [std::hash::Hash]: https://doc.rust-lang.org/std/hash/trait.Hash.html//! [std::collections::hash_map::RandomState]: https://doc.rust-lang.org/std/collections/hash_map/struct.RandomState.html// Core traits// Iterator conversions// Conversionsunfold/// Create an iterator of values using a function to update an owned state/// The function is called with the current state as its argument, and should/// return an [`Option`][std::option::Option] of a tuple of the next value to/// yield from the iterator and the updated state. If the function returns/// [`None`][std::option::Option::None], the iterator ends./// # use im::iter::unfold;/// # use im::vector::Vector;/// # use std::iter::FromIterator;/// // Create an infinite stream of numbers, starting at 0./// let mut it = unfold(0, |i| Some((i, i + 1)));/// // Make a list out of its first five elements./// let numbers = Vector::from_iter(it.take(5));/// assert_eq!(numbers, vector![0, 1, 2, 3, 4]);/// [std::option::Option]: https://doc.rust-lang.org/std/option/enum.Option.html/// [std::option::Option::None]: https://doc.rust-lang.org/std/option/enum.Option.html#variant.None//! Iterators over immutable data.pretty_assertionsordmapfakepoolupdate_in/// Update a value inside multiple levels of data structures./// This macro takes a [`Vector`][Vector], [`OrdMap`][OrdMap] or [`HashMap`][HashMap],/// a key or a series of keys, and a value, and returns the data structure with the/// new value at the location described by the keys./// If one of the keys in the path doesn't exist, the macro will panic./// let vec_inside_vec = vector![vector![1, 2, 3], vector![4, 5, 6]];/// let expected = vector![vector![1, 2, 3], vector![4, 5, 1337]];/// assert_eq!(expected, update_in![vec_inside_vec, 1 => 2, 1337]);/// [Vector]: ../vector/enum.Vector.html/// [HashMap]: ../hashmap/struct.HashMap.html/// [OrdMap]: ../ordmap/struct.OrdMap.htmlget_in/// Get a value inside multiple levels of data structures./// along with a key or a series of keys, and returns the value at the location inside/// the data structure described by the key sequence, or `None` if any of the keys didn't/// exist./// assert_eq!(Some(&6), get_in![vec_inside_vec, 1 => 2]);lib_test//! # Immutable Data Structures for Rust//! This library implements several of the more commonly useful immutable data//! structures for Rust.//! ## What are immutable data structures?//! Immutable data structures are data structures which can be copied and//! modified efficiently without altering the original. The most uncomplicated//! example of this is the venerable [cons list][cons-list]. This crate offers a//! selection of more modern and flexible data structures with similar//! properties, tuned for the needs of Rust developers.//! Briefly, the following data structures are provided://! * [Vectors][vector::Vector] based on [RRB trees][rrb-tree]//! * [Hash maps][hashmap::HashMap]/[sets][hashset::HashSet] based on [hash//!   array mapped tries][hamt]//! * [Ordered maps][ordmap::OrdMap]/[sets][ordset::OrdSet] based on//!   [B-trees][b-tree]//! ## Why Would I Want This?//! While immutable data structures can be a game changer for other//! programming languages, the most obvious benefit - avoiding the//! accidental mutation of data - is already handled so well by Rust's//! type system that it's just not something a Rust programmer needs//! to worry about even when using data structures that would send a//! conscientious Clojure programmer into a panic.//! Immutable data structures offer other benefits, though, some of//! which are useful even in a language like Rust. The most prominent//! is *structural sharing*, which means that if two data structures//! are mostly copies of each other, most of the memory they take up//! will be shared between them. This implies that making copies of an//! immutable data structure is cheap: it's really only a matter of//! copying a pointer and increasing a reference counter, where in the//! case of [`Vec`][std::vec::Vec] you have to allocate the same//! amount of memory all over again and make a copy of every element//! it contains. For immutable data structures, extra memory isn't//! allocated until you modify either the copy or the original, and//! then only the memory needed to record the difference.//! Another goal of this library has been the idea that you shouldn't//! even have to think about what data structure to use in any given//! situation, until the point where you need to start worrying about//! optimisation - which, in practice, often never comes. Beyond the//! shape of your data (ie. whether to use a list or a map), it should//! be fine not to think too carefully about data structures - you can//! just pick the one that has the right shape and it should have//! acceptable performance characteristics for every operation you//! might need. Specialised data structures will always be faster at//! what they've been specialised for, but `im` aims to provide the//! data structures which deliver the least chance of accidentally//! using them for the wrong thing.//! For instance, [`Vec`][std::vec::Vec] beats everything at memory//! usage, indexing and operations that happen at the back of the//! list, but is terrible at insertion and removal, and gets worse the//! closer to the front of the list you get.//! [`VecDeque`][std::collections::VecDeque] adds a little bit of//! complexity in order to make operations at the front as efficient//! as operations at the back, but is still bad at insertion and//! especially concatenation. [`Vector`][vector::Vector] adds another//! bit of complexity, and could never match [`Vec`][std::vec::Vec] at//! what it's best at, but in return every operation you can throw at//! it can be completed in a reasonable amount of time - even normally//! expensive operations like copying and especially concatenation are//! reasonably cheap when using a [`Vector`][vector::Vector].//! It should be noted, however, that because of its simplicity,//! [`Vec`][std::vec::Vec] actually beats [`Vector`][vector::Vector] even at its//! strongest operations at small sizes, just because modern CPUs are//! hyperoptimised for things like copying small chunks of contiguous memory -//! you actually need to go past a certain size (usually in the vicinity of//! several hundred elements) before you get to the point where//! [`Vec`][std::vec::Vec] isn't always going to be the fastest choice.//! [`Vector`][vector::Vector] attempts to overcome this by actually just being//! an array at very small sizes, and being able to switch efficiently to the//! full data structure when it grows large enough. Thus,//! [`Vector`][vector::Vector] will actually be equivalent to//! [Vec][std::vec::Vec] until it grows past the size of a single chunk.//! The maps - [`HashMap`][hashmap::HashMap] and//! [`OrdMap`][ordmap::OrdMap] - generally perform similarly to their//! equivalents in the standard library, but tend to run a bit slower//! on the basic operations ([`HashMap`][hashmap::HashMap] is almost//! neck and neck with its counterpart, while//! [`OrdMap`][ordmap::OrdMap] currently tends to run 2-3x slower). On//! the other hand, they offer the cheap copy and structural sharing//! between copies that you'd expect from immutable data structures.//! In conclusion, the aim of this library is to provide a safe//! default choice for the most common kinds of data structures,//! allowing you to defer careful thinking about the right data//! structure for the job until you need to start looking for//! optimisations - and you may find, especially for larger data sets,//! that immutable data structures are still the right choice.//! ## Values//! Because we need to make copies of shared nodes in these data structures//! before updating them, the values you store in them must implement//! [`Clone`][std::clone::Clone].  For primitive values that implement//! [`Copy`][std::marker::Copy], such as numbers, everything is fine: this is//! the case for which the data structures are optimised, and performance is//! going to be great.//! On the other hand, if you want to store values for which cloning is//! expensive, or values that don't implement [`Clone`][std::clone::Clone], you//! need to wrap them in [`Rc`][std::rc::Rc] or [`Arc`][std::sync::Arc]. Thus,//! if you have a complex structure `BigBlobOfData` and you want to store a list//! of them as a `Vector<BigBlobOfData>`, you should instead use a//! `Vector<Rc<BigBlobOfData>>`, which is going to save you not only the time//! spent cloning the big blobs of data, but also the memory spent keeping//! multiple copies of it around, as [`Rc`][std::rc::Rc] keeps a single//! reference counted copy around instead.//! If you're storing smaller values that aren't//! [`Copy`][std::marker::Copy]able, you'll need to exercise judgement: if your//! values are going to be very cheap to clone, as would be the case for short//! [`String`][std::string::String]s or small [`Vec`][std::vec::Vec]s, you're//! probably better off storing them directly without wrapping them in an//! [`Rc`][std::rc::Rc], because, like the [`Rc`][std::rc::Rc], they're just//! pointers to some data on the heap, and that data isn't expensive to clone -//! you might actually lose more performance from the extra redirection of//! wrapping them in an [`Rc`][std::rc::Rc] than you would from occasionally//! cloning them.//! ### When does cloning happen?//! So when will your values actually be cloned? The easy answer is only if you//! [`clone`][std::clone::Clone::clone] the data structure itself, and then only//! lazily as you change it. Values are stored in tree nodes inside the data//! structure, each node of which contains up to 64 values. When you//! [`clone`][std::clone::Clone::clone] a data structure, nothing is actually//! copied - it's just the reference count on the root node that's incremented,//! to indicate that it's shared between two data structures. It's only when you//! actually modify one of the shared data structures that nodes are cloned://! when you make a change somewhere in the tree, the node containing the change//! needs to be cloned, and then its parent nodes need to be updated to contain//! the new child node instead of the old version, and so they're cloned as//! well.//! We can call this "lazy" cloning - if you make two copies of a data structure//! and you never change either of them, there's never any need to clone the//! data they contain. It's only when you start making changes that cloning//! starts to happen, and then only on the specific tree nodes that are part of//! the change. Note that the implications of lazily cloning the data structure//! extend to memory usage as well as the CPU workload of copying the data//! around - cloning an immutable data structure means both copies share the//! same allocated memory, until you start making changes.//! Most crucially, if you never clone the data structure, the data inside it is//! also never cloned, and in this case it acts just like a mutable data//! structure, with minimal performance differences (but still non-zero, as we//! still have to check for shared nodes).//! ## Data Structures//! We'll attempt to provide a comprehensive guide to the available//! data structures below.//! ### Performance Notes//! "Big O notation" is the standard way of talking about the time//! complexity of data structure operations. If you're not familiar//! with big O notation, here's a quick cheat sheet://! *O(1)* means an operation runs in constant time: it will take the//! same time to complete regardless of the size of the data//! structure.//! *O(n)* means an operation runs in linear time: if you double the//! size of your data structure, the operation will take twice as long//! to complete; if you quadruple the size, it will take four times as//! long, etc.//! *O(log n)* means an operation runs in logarithmic time: for//! *log<sub>2</sub>*, if you double the size of your data structure,//! the operation will take one step longer to complete; if you//! quadruple the size, it will need two steps more; and so on.//! However, the data structures in this library generally run in//! *log<sub>64</sub>* time, meaning you have to make your data//! structure 64 times bigger to need one extra step, and 4096 times//! bigger to need two steps. This means that, while they still count//! as O(log n), operations on all but really large data sets will run//! at near enough to O(1) that you won't usually notice.//! *O(n log n)* is the most expensive operation you'll see in this//! library: it means that for every one of the *n* elements in your//! data structure, you have to perform *log n* operations. In our//! case, as noted above, this is often close enough to O(n) that it's//! not usually as bad as it sounds, but even O(n) isn't cheap and the//! cost still increases logarithmically, if slowly, as the size of//! your data increases. O(n log n) basically means "are you sure you//! need to do this?"//! *O(1)** means 'amortised O(1),' which means that an operation//! usually runs in constant time but will occasionally be more//! expensive: for instance,//! [`Vector::push_back`][vector::Vector::push_back], if called in//! sequence, will be O(1) most of the time but every 64th time it//! will be O(log n), as it fills up its tail chunk and needs to//! insert it into the tree. Please note that the O(1) with the//! asterisk attached is not a common notation; it's just a convention//! I've used in these docs to save myself from having to type//! 'amortised' everywhere.//! ### Lists//! Lists are sequences of single elements which maintain the order in//! which you inserted them. The only list in this library is//! [`Vector`][vector::Vector], which offers the best all round//! performance characteristics: it's pretty good at everything, even//! if there's always another kind of list that's better at something.//! | Type | Algorithm | Constraints | Order | Push | Pop | Split | Append | Lookup |//! | --- | --- | --- | --- | --- | --- | --- | --- | --- |//! | [`Vector<A>`][vector::Vector] | [RRB tree][rrb-tree] | [`Clone`][std::clone::Clone] | insertion | O(1)\* | O(1)\* | O(log n) | O(log n) | O(log n) |//! ### Maps//! Maps are mappings of keys to values, where the most common read//! operation is to find the value associated with a given key. Maps//! may or may not have a defined order. Any given key can only occur//! once inside a map, and setting a key to a different value will//! overwrite the previous value.//! | Type | Algorithm | Key Constraints | Order | Insert | Remove | Lookup |//! | --- | --- | --- | --- | --- | --- | --- |//! | [`HashMap<K, V>`][hashmap::HashMap] | [HAMT][hamt] | [`Clone`][std::clone::Clone] + [`Hash`][std::hash::Hash] + [`Eq`][std::cmp::Eq] | undefined | O(log n) | O(log n) | O(log n) |//! | [`OrdMap<K, V>`][ordmap::OrdMap] | [B-tree][b-tree] | [`Clone`][std::clone::Clone] + [`Ord`][std::cmp::Ord] | sorted | O(log n) | O(log n) | O(log n) |//! ### Sets//! Sets are collections of unique values, and may or may not have a//! defined order. Their crucial property is that any given value can//! only exist once in a given set.//! | Type | Algorithm | Constraints | Order | Insert | Remove | Lookup |//! | [`HashSet<A>`][hashset::HashSet] | [HAMT][hamt] | [`Clone`][std::clone::Clone] + [`Hash`][std::hash::Hash] + [`Eq`][std::cmp::Eq] | undefined | O(log n) | O(log n) | O(log n) |//! | [`OrdSet<A>`][ordset::OrdSet] | [B-tree][b-tree] | [`Clone`][std::clone::Clone] + [`Ord`][std::cmp::Ord] | sorted | O(log n) | O(log n) | O(log n) |//! ## In-place Mutation//! All of these data structures support in-place copy-on-write//! mutation, which means that if you're the sole user of a data//! structure, you can update it in place without taking the//! performance hit of making a copy of the data structure before//! modifying it (this is about an order of magnitude faster than//! immutable operations, almost as fast as//! [`std::collections`][std::collections]'s mutable data structures).//! Thanks to [`Rc`][std::rc::Rc]'s reference counting, we are able to//! determine whether a node in a data structure is being shared with//! other data structures, or whether it's safe to mutate it in place.//! When it's shared, we'll automatically make a copy of the node//! before modifying it. The consequence of this is that cloning a//! data structure becomes a lazy operation: the initial clone is//! instant, and as you modify the cloned data structure it will clone//! chunks only where you change them, so that if you change the//! entire thing you will eventually have performed a full clone.//! This also gives us a couple of other optimisations for free://! implementations of immutable data structures in other languages//! often have the idea of local mutation, like Clojure's transients//! or Haskell's `ST` monad - a managed scope where you can treat an//! immutable data structure like a mutable one, gaining a//! considerable amount of performance because you no longer need to//! copy your changed nodes for every operation, just the first time//! you hit a node that's sharing structure. In Rust, we don't need to//! think about this kind of managed scope, it's all taken care of//! behind the scenes because of our low level access to the garbage//! collector (which, in our case, is just a simple//! [`Rc`][std::rc::Rc]).//! ## Thread Safety//! The data structures in the `im` crate are thread safe, through//! [`Arc`][std::sync::Arc]. This comes with a slight performance impact, so//! that if you prioritise speed over thread safety, you may want to use the//! `im-rc` crate instead, which is identical to `im` except that it uses//! [`Rc`][std::rc::Rc] instead of [`Arc`][std::sync::Arc], implying that the//! data structures in `im-rc` do not implement [`Send`][std::marker::Send] and//! [`Sync`][std::marker::Sync]. This yields approximately a 20-25% increase in//! general performance.//! ## Feature Flags//! `im` comes with optional support for the following crates through Cargo//! feature flags. You can enable them in your `Cargo.toml` file like this://! im = { version = "*", features = ["proptest", "serde"] }//! | Feature | Description |//! | ------- | ----------- |//! | [`pool`](https://crates.io/crates/refpool) | Constructors and pool types for [`refpool`](https://crates.io/crates/refpool) memory pools (only available in `im-rc`) |//! | [`proptest`](https://crates.io/crates/proptest) | Strategies for all `im` datatypes under a `proptest` namespace, eg. `im::vector::proptest::vector()` |//! | [`quickcheck`](https://crates.io/crates/quickcheck) | [`quickcheck::Arbitrary`](https://docs.rs/quickcheck/latest/quickcheck/trait.Arbitrary.html) implementations for all `im` datatypes (not available in `im-rc`) |//! | [`rayon`](https://crates.io/crates/rayon) | parallel iterator implementations for [`Vector`][vector::Vector] (not available in `im-rc`) |//! | [`serde`](https://crates.io/crates/serde) | [`Serialize`](https://docs.rs/serde/latest/serde/trait.Serialize.html) and [`Deserialize`](https://docs.rs/serde/latest/serde/trait.Deserialize.html) implementations for all `im` datatypes |//! | [`arbitrary`](https://crates.io/crates/arbitrary/) | [`arbitrary::Arbitrary`](https://docs.rs/arbitrary/latest/arbitrary/trait.Arbitrary.html) implementations for all `im` datatypes |//! [std::collections]: https://doc.rust-lang.org/std/collections/index.html//! [std::collections::VecDeque]: https://doc.rust-lang.org/std/collections/struct.VecDeque.html//! [std::vec::Vec]: https://doc.rust-lang.org/std/vec/struct.Vec.html//! [std::string::String]: https://doc.rust-lang.org/std/string/struct.String.html//! [std::rc::Rc]: https://doc.rust-lang.org/std/rc/struct.Rc.html//! [std::sync::Arc]: https://doc.rust-lang.org/std/sync/struct.Arc.html//! [std::cmp::Ord]: https://doc.rust-lang.org/std/cmp/trait.Ord.html//! [std::clone::Clone]: https://doc.rust-lang.org/std/clone/trait.Clone.html//! [std::clone::Clone::clone]: https://doc.rust-lang.org/std/clone/trait.Clone.html#tymethod.clone//! [std::marker::Copy]: https://doc.rust-lang.org/std/marker/trait.Copy.html//! [std::marker::Send]: https://doc.rust-lang.org/std/marker/trait.Send.html//! [std::marker::Sync]: https://doc.rust-lang.org/std/marker/trait.Sync.html//! [hashmap::HashMap]: ./struct.HashMap.html//! [hashset::HashSet]: ./struct.HashSet.html//! [ordmap::OrdMap]: ./struct.OrdMap.html//! [ordset::OrdSet]: ./struct.OrdSet.html//! [vector::Vector]: ./struct.Vector.html//! [vector::Vector::push_back]: ./vector/enum.Vector.html#method.push_back//! [rrb-tree]: https://infoscience.epfl.ch/record/213452/files/rrbvector.pdf//! [hamt]: https://en.wikipedia.org/wiki/Hash_array_mapped_trie//! [b-tree]: https://en.wikipedia.org/wiki/B-tree//! [cons-list]: https://en.wikipedia.org/wiki/Cons#ListsNodeSizeInsertInsertActionNODE_SIZEMEDIANsearch_keysearch_valuecmp_keyscmp_valuesBTreeValuechildrenAddedReplacedAddedActionReplacedActionInsertAtInsertSplitRemoveNoChangeRemovedBoundaryLowestHighestRemoveActionDeleteAtPullUpMergeStealFromLeftStealFromRightMergeFirstContinueDownhas_roomnew_from_splitchild_containslookuplookup_mutlookup_prevlookup_nextlookup_prev_mutlookup_next_mutpath_firstpath_lastpath_nextpath_prevmergepop_minpop_maxpush_minpush_maxremove_targetremove_indexfwd_pathback_path/// An iterator over an ordered set.step_forwardstep_backConsumingIterItemConsiderYieldfwd_lastfwd_stackback_lastback_stack/// A consuming iterator over an ordered set.push_nodepush_fwdpush_node_backpush_backold_stackIterItemnew_stackDiffIter/// An iterator over the differences between two ordered sets.DiffItem/// This value has been added to the new set.old/// The old value./// The new value./// This value has been changed between the two sets./// This value has been removed from the new set./// A description of a difference between two ordered sets.// Iterator// Consuming iterator// DiffIterSliceIterSliceIterMutsparse_chunkChunkIterMutSparseChunkPowclone_refHashWidthHASH_SHIFT// a uint of HASH_SIZE bitsHASH_WIDTHHASH_MASKCollisionNodeCollisionis_valueunwrap_valuefrom_nodepairsingle_childmerge_valuesstackcollision// Ref iterator// Mut ref iteratorbtreerrbscsized_chunkRRBPoolTableis_sizetable_from_sizePushResultFullDonePopResultDrainedSplitResultDroppedOutOfBoundsNodes// Invariants: Nodes only at level > 0, Values/Empty only at level = 0unwrap_valuesunwrap_nodesunwrap_values_mutunwrap_nodes_mutis_empty_nodeparentclear_nodefrom_chunksingle_parentjoin_denseelevatejoin_branchesis_singlenumber_of_children// this is only used by testsfirst_childis_dense/// True if the node is dense and so doesn't have a size tableis_completely_dense/// True if the node and its children are dense and at capacity// TODO can use this technique to quickly test if a Size::Table// should be converted back to a Size::Sizepush_sizepop_sizeupdate_sizesize_up_toindex_inlookup_chunklookup_chunk_mutpush_child_nodepop_child_nodepush_chunkpop_chunkmerge_leavesmerge_rebalanceassert_invariants// pub fn print<W>(&self, f: &mut W, indent: usize, level: usize) -> Result<(), fmt::Error>//     W: fmt::Write,//     A: fmt::Debug,// {//     print_indent(f, indent)?;//     if level == 0 {//         if self.children.is_empty_node() {//             writeln!(f, "Leaf: EMPTY")//         } else {//             writeln!(f, "Leaf: {:?}", self.children.unwrap_values())//     } else {//         match &self.children {//             Entry::Nodes(size, children) => {//                 writeln!(f, "Node level {} size_table {:?}", level, size)?;//                 for child in children.iter() {//                     child.print(f, indent + 4, level - 1)?;//                 }//                 Ok(())//             }//             _ => unreachable!(),// Node// fn print_indent<W>(f: &mut W, indent: usize) -> Result<(), fmt::Error>//     for _i in 0..indent {//         write!(f, " ")?;//     Ok(())linear_search_byNodeDiffItemNodeDiffIterRangedIter/// Construct a map from a sequence of key/value pairs./// # use im::ordmap::OrdMap;///   ordmap!{///     1 => 11,///     2 => 22,///     3 => 33///   },///   OrdMap::from(vec![(1, 11), (2, 22), (3, 33)])OrdMapPool/// An ordered map./// An immutable ordered map implemented as a B-tree./// Most operations on this type of map are O(log n). A/// [`HashMap`][hashmap::HashMap] is usually a better choice for/// performance, but the `OrdMap` has the advantage of only requiring/// an [`Ord`][std::cmp::Ord] constraint on the key, and of being/// ordered, so that keys always come out from lowest to highest,/// where a [`HashMap`][hashmap::HashMap] has no guaranteed ordering./// [hashmap::HashMap]: ../hashmap/struct.HashMap.html/// [std::cmp::Ord]: https://doc.rust-lang.org/std/cmp/trait.Ord.html/// Construct an empty map./// Construct a map with a single mapping./// let map = OrdMap::unit(123, "onetwothree");///   map.get(&123),///   Some(&"onetwothree")/// Test whether a map is empty.///   !ordmap!{1 => 2}.is_empty()///   OrdMap::<i32, i32>::new().is_empty()/// Test whether two maps refer to the same content in memory./// This is true if the two sides are references to the same map,/// or if the two maps refer to the same root node./// This would return true if you're comparing a map to itself, or/// if you're comparing a map to a fresh clone of itself./// Get the size of a map./// assert_eq!(3, ordmap!{///   1 => 11,///   2 => 22,///   3 => 33/// }.len());/// Discard all elements from the map./// This leaves you with an empty map, and all elements that/// # use im::OrdMap;/// let mut map = ordmap![1=>1, 2=>2, 3=>3];/// map.clear();get_max/// Get the largest key in a map, along with its value. If the map/// is empty, return `None`./// assert_eq!(Some(&(3, 33)), ordmap!{/// }.get_max());get_min/// Get the smallest key in a map, along with its value. If the/// map is empty, return `None`./// assert_eq!(Some(&(1, 11)), ordmap!{/// }.get_min());/// Get an iterator over the key/value pairs of a map./// Create an iterator over a range of key/value pairs./// Get an iterator over a map's keys./// Get an iterator over a map's values.diff/// Get an iterator over the differences between this map and/// another, i.e. the set of entries to add, update, or remove to/// this map in order to make it equal to the other map./// This function will avoid visiting nodes which are shared/// between the two maps, meaning that even very large maps can be/// compared quickly if most of their structure is shared./// Time: O(n) (where n is the number of unique elements across/// the two maps, minus the number of elements belonging to nodes/// shared between them)/// Get the value for a key from a map./// let map = ordmap!{123 => "lol"};///   Some(&"lol")/// Get the key/value pair for a key from a map.///   map.get_key_value(&123),///   Some((&123, &"lol"))get_prev/// Get the closest smaller entry in a map to a given key/// as a mutable reference./// If the map contains the given key, this is returned./// Otherwise, the closest key in the map smaller than the/// given value is returned. If the smallest key in the map/// is larger than the given key, `None` is returned./// let map = ordmap![1 => 1, 3 => 3, 5 => 5];/// assert_eq!(Some((&3, &3)), map.get_prev(&4));get_next/// Get the closest larger entry in a map to a given key/// If the set contains the given value, this is returned./// Otherwise, the closest value in the set larger than the/// given value is returned. If the largest value in the set/// is smaller than the given value, `None` is returned./// assert_eq!(Some((&5, &5)), map.get_next(&4));/// Test for the presence of a key in a map.///   map.contains_key(&123)///   !map.contains_key(&321)/// Test whether a map is a submap of another map, meaning that/// all keys in our map must also be in the other map, with the/// same values./// Use the provided function to decide whether values are equal./// Test whether a map is a proper submap of another map, meaning/// that all keys in our map must also be in the other map, with/// the same values. To be a proper submap, ours must also contain/// fewer keys than the other map./// let map1 = ordmap!{1 => 1, 2 => 2};/// let map2 = ordmap!{1 => 1, 2 => 2, 3 => 3};/// assert!(map1.is_submap(map2));/// assert!(map1.is_proper_submap(map2));/// let map3 = ordmap!{1 => 1, 2 => 2};/// let map4 = ordmap!{1 => 1, 2 => 2};/// assert!(!map3.is_proper_submap(map4));/// Get a mutable reference to the value for a key from a map./// let mut map = ordmap!{123 => "lol"};/// if let Some(value) = map.get_mut(&123) {///     *value = "omg";///   Some(&"omg")get_prev_mut/// let mut map = ordmap![1 => 1, 3 => 3, 5 => 5];/// if let Some((key, value)) = map.get_prev_mut(&4) {///     *value = 4;/// assert_eq!(ordmap![1 => 1, 3 => 4, 5 => 5], map);get_next_mut/// if let Some((key, value)) = map.get_next_mut(&4) {/// assert_eq!(ordmap![1 => 1, 3 => 3, 5 => 4], map);/// Insert a key/value mapping into a map./// This is a copy-on-write operation, so that the parts of the/// map's structure which are shared with other maps will be/// safely copied before mutating./// If the map already has a mapping for the given key, the/// previous value is overwritten./// let mut map = ordmap!{};/// map.insert(123, "123");/// map.insert(456, "456");///   map,///   ordmap!{123 => "123", 456 => "456"}/// [insert]: #method.insert/// Remove a key/value mapping from a map if it exists./// let mut map = ordmap!{123 => "123", 456 => "456"};/// map.remove(&123);/// map.remove(&456);/// [remove]: #method.remove/// Remove a key/value pair from a map, if it exists, and return/// the removed key and value./// Construct a new map by inserting a key/value mapping into a/// map./// let map = ordmap!{};///   map.update(123, "123"),///   ordmap!{123 => "123"}/// If the map already has a mapping for the given key, we call/// the provided function with the old value and the new value,/// and insert the result as the new value./// the provided function with the key, the old value and the new/// value, and insert the result as the new value./// map, returning the old value for the key as well as the new/// Update the value for a given key by calling a function with/// the current value and overwriting it with the function's/// return value./// The function gets an [`Option<V>`][std::option::Option] and/// returns the same, so that it can decide to delete a mapping/// instead of updating the value, and decide what to do if the/// key isn't in the map./// Remove a key/value pair from a map, if it exists./// the removed value as well as the updated list./// the removed key and value as well as the updated list./// Construct the union of two maps, keeping the values in the/// current map when keys exist in both maps./// let map1 = ordmap!{1 => 1, 3 => 3};/// let map2 = ordmap!{2 => 2, 3 => 4};/// let expected = ordmap!{1 => 1, 2 => 2, 3 => 3};/// assert_eq!(expected, map1.union(map2));/// Construct the union of two maps, using a function to decide/// what to do with the value when a key is in both maps./// The function is called when a value exists in both maps, and/// receives the value from the current map as its first argument,/// and the value from the other map as the second. It should/// return the value to be inserted in the resulting map./// receives a reference to the key as its first argument, the/// value from the current map as the second argument, and the/// value from the other map as the third argument. It should/// let map1 = ordmap!{1 => 1, 3 => 4};/// let map2 = ordmap!{2 => 2, 3 => 5};/// let expected = ordmap!{1 => 1, 2 => 2, 3 => 9};/// assert_eq!(expected, map1.union_with_key(///     map2,///     |key, left, right| left + right/// ));/// Construct the union of a sequence of maps, selecting the value/// of the leftmost when a key appears in more than one map./// let map2 = ordmap!{2 => 2};/// assert_eq!(expected, OrdMap::unions(vec![map1, map2]));/// Construct the union of a sequence of maps, using a function to/// decide what to do with the value when a key is in more than/// one map./// The function is called when a value exists in multiple maps,/// and receives the value from the current map as its first/// argument, and the value from the next map as the second. It/// should return the value to be inserted in the resulting map./// and receives a reference to the key as its first argument, the/// value from the next map as the third argument. It should/// Construct the symmetric difference between two maps by discarding keys/// which occur in both maps./// let expected = ordmap!{1 => 1, 2 => 2};/// assert_eq!(expected, map1.difference(map2));/// assert_eq!(expected, map1.symmetric_difference(map2));/// Construct the symmetric difference between two maps by using a function/// to decide what to do if a key occurs in both./// [`symmetric_difference_with`][symmetric_difference_with] method./// [symmetric_difference_with]: #method.symmetric_difference_with/// to decide what to do if a key occurs in both. The function/// receives the key as well as both values./// [`symmetric_difference_with_key`][symmetric_difference_with_key]/// assert_eq!(expected, map1.difference_with_key(///     |key, left, right| Some(left + right)/// [symmetric_difference_with_key]: #method.symmetric_difference_with_key/// assert_eq!(expected, map1.symmetric_difference_with_key(/// Construct the relative complement between two maps by discarding keys/// which occur in `other`./// Time: O(m log n) where m is the size of the other map/// let expected = ordmap!{1 => 1};/// assert_eq!(expected, map1.relative_complement(map2));/// Construct the intersection of two maps, keeping the values/// from the current map./// let map2 = ordmap!{2 => 3, 3 => 4};/// let expected = ordmap!{2 => 2};/// assert_eq!(expected, map1.intersection(map2));/// Construct the intersection of two maps, calling a function/// with both values for each key and using the result as the/// value for the key./// with the key and both values for each key and using the result/// as the value for the key./// let expected = ordmap!{2 => 5};/// assert_eq!(expected, map1.intersection_with_key(/// Split a map into two, with the left hand map containing keys/// which are smaller than `split`, and the right hand map/// containing keys which are larger than `split`./// The `split` mapping is discarded.split_lookup/// Returns both the two maps and the value of `split`./// Construct a map with only the `n` smallest keys from a given/// Construct a map with the `n` smallest keys removed from a/// given map.without_min/// Remove the smallest key from a map, and return its value as/// well as the updated map.without_min_with_key/// Remove the smallest key from a map, and return that key, its/// value as well as the updated map.without_max/// Remove the largest key from a map, and return its value aswithout_max_with_key/// Remove the largest key from a map, and return that key, its/// Get the [`Entry`][Entry] for a key in the map for in-place manipulation./// [Entry]: enum.Entry.html/// An entry which exists in the map./// An entry which doesn't exist in the map./// A handle for a key and its associated value./// Insert the default value provided if there was no value/// already, and return a mutable reference to the value./// Insert the default value from the provided function if there/// was no value already, and return a mutable reference to the/// Insert a default value if there was no value already, and/// return a mutable reference to the value./// Get the key for this entry./// Call the provided function to modify the value if the value/// exists./// An entry for a mapping that already exists in the map./// Remove this entry from the map and return the removed mapping./// Get the current value./// Get a mutable reference to the current value./// Convert this entry into a mutable reference./// Overwrite the current value./// Remove this entry from the map and return the removed value./// An entry for a mapping that does not already exist in the map./// Convert this entry into its key./// Insert a value into this entry./// Clone a map./// An iterator over the key/value pairs of a map./// An iterator over the differences between two maps./// This value has been added to the new map./// This value has been changed between the two maps./// This value has been removed from the new map./// A description of a difference between two ordered maps./// An iterator ove the keys of a map./// An iterator over the values of a map.ord_mapis_sortediterates_in_orderdeletes_correctlydebug_outputequality2insert_remove_single_mutdouble_ended_iterator_1double_ended_iterator_2ranged_iterrange_iter_bigissue_124//! An ordered map.//! An immutable ordered map implemented as a [B-tree] [1].//! Most operations on this type of map are O(log n). A//! [`HashMap`][hashmap::HashMap] is usually a better choice for//! performance, but the `OrdMap` has the advantage of only requiring//! an [`Ord`][std::cmp::Ord] constraint on the key, and of being//! ordered, so that keys always come out from lowest to highest,//! where a [`HashMap`][hashmap::HashMap] has no guaranteed ordering.//! [1]: https://en.wikipedia.org/wiki/B-tree//! [hashmap::HashMap]: ../hashmap/struct.HashMap.html// EntriesConsumingNodeIter///   ordset![1, 2, 3],///   OrdSet::from(vec![1, 2, 3])OrdSetPool/// An ordered set./// An immutable ordered set implemented as a [B-tree] [1]./// Most operations on this type of set are O(log n). A/// [`HashSet`][hashset::HashSet] is usually a better choice for/// performance, but the `OrdSet` has the advantage of only requiring/// an [`Ord`][std::cmp::Ord] constraint on its values, and of being/// ordered, so values always come out from lowest to highest, where a/// [`HashSet`][hashset::HashSet] has no guaranteed ordering./// [1]: https://en.wikipedia.org/wiki/B-tree/// [hashset::HashSet]: ./struct.HashSet.html/// let set = OrdSet::unit(123);///   !ordset![1, 2, 3].is_empty()///   OrdSet::<i32>::new().is_empty()/// assert_eq!(3, ordset![1, 2, 3].len());/// # use im::OrdSet;/// let mut set = ordset![1, 2, 3];/// Get the smallest value in a set./// If the set is empty, returns `None`./// Get the largest value in a set./// Create an iterator over the contents of the set./// Create an iterator over a range inside the set./// Get an iterator over the differences between this set and/// another, i.e. the set of entries to add or remove to this set/// in order to make it equal to the other set./// between the two sets, meaning that even very large sets can be/// the two sets, minus the number of elements belonging to nodes/// let mut set = ordset!{1, 2, 3};/// assert!(set.contains(&1));/// assert!(!set.contains(&4));/// Get the closest smaller value in a set to a given value./// Otherwise, the closest value in the set smaller than the/// given value is returned. If the smallest value in the set/// is larger than the given value, `None` is returned./// let set = ordset![1, 3, 5, 7, 9];/// assert_eq!(Some(&5), set.get_prev(&6));/// Get the closest larger value in a set to a given value./// assert_eq!(Some(&5), set.get_next(&4));/// Time: O(n log m) where m is the size of the other set/// let mut set = ordset!{};/// set.insert(123);/// set.insert(456);///   set,///   ordset![123, 456]/// Remove a value from a set.remove_min/// Remove the smallest value from a set.remove_max/// Remove the largest value from a set./// let set = ordset![456];///   set.update(123),/// Remove the smallest value from a set, and return that value as/// well as the updated set./// Remove the largest value from a set, and return that value as/// let expected = ordset!{1, 2, 3};/// let expected = ordset!{1, 3};/// let expected = ordset!{2};/// Split a set into two, with the left hand set containing values/// which are smaller than `split`, and the right hand set/// containing values which are larger than `split`./// The `split` value itself is discarded.split_member/// Returns a tuple of the two sets and a boolean which is true if/// the `split` value existed in the original set, and false/// Construct a set with only the `n` smallest values from a given/// Construct a set with the `n` smallest values removed from a/// given set./// Advance the iterator and return the next value./// Time: O(1)*/// A ranged iterator over the elements of a set./// The only difference from `Iter` is that this one doesn't implement/// `ExactSizeIterator` because we can't know the size of the range without first/// iterating over it to count./// An iterator over the difference between two sets.ord_set//! An ordered set.//! An immutable ordered set implemented as a [B-tree] [1].//! Most operations on this type of set are O(log n). A//! [`HashSet`][hashset::HashSet] is usually a better choice for//! performance, but the `OrdSet` has the advantage of only requiring//! an [`Ord`][std::cmp::Ord] constraint on its values, and of being//! ordered, so values always come out from lowest to highest, where a//! [`HashSet`][hashset::HashSet] has no guaranteed ordering.strategyBoxedStrategyStrategyValueTreeTree/// A strategy for generating a [`Vector`][Vector] of a certain size./// ```rust,no_run/// # use ::proptest::proptest;/// proptest! {///     #[test]///     fn proptest_a_vector(ref l in vector(".*", 10..100)) {///         assert!(l.len() < 100);///         assert!(l.len() >= 10);/// [Vector]: ../struct.Vector.html/// A strategy for an [`OrdMap`][OrdMap] of a given size.///     fn proptest_works(ref m in ord_map(0..9999, ".*", 10..100)) {///         assert!(m.len() < 100);///         assert!(m.len() >= 10);/// [OrdMap]: ../struct.OrdMap.html/// A strategy for an [`OrdSet`][OrdSet] of a given size.///     fn proptest_a_set(ref s in ord_set(".*", 10..100)) {///         assert!(s.len() < 100);///         assert!(s.len() >= 10);/// [OrdSet]: ../struct.OrdSet.html/// A strategy for a [`HashMap`][HashMap] of a given size.///     fn proptest_works(ref m in hash_map(0..9999, ".*", 10..100)) {/// [HashMap]: ../struct.HashMap.html/// A strategy for a [`HashSet`][HashSet] of a given size.///     fn proptest_a_set(ref s in hash_set(".*", 10..100)) {/// [HashSet]: ../struct.HashSet.html//! Proptest strategies.//! These are only available when using the `proptest` feature flag.phantom_sphantom_aphantom_lifetimeSeqVisitorAccessphantom_kphantom_vMapVisitorvisit_mapSer// Set// Map// HashMap// HashSet// VectorFocusMutgen_rangedo_quicksort// Ported from the Java version at://    http://www.cs.princeton.edu/~rs/talks/QuicksortIsOptimal.pdf// There are a couple of modifications made here to make it more performant on the tree structure of// the Vector. Instead of moving of handling equal and nonequal items in a single pass we make two// additional passes to find the exact partition places. This allows us to split the focus into// three correctly sized parts for less than, equal to and greater than items. As a bonus this// doesn't need to reorder the equal items to the center of the vector.quicksortLock/// Thread safe lock: just wraps a `Mutex`.metrohashMetroHash64shiftfeed_meMetroHashBuilderNatSetproptest_deriveActionActionscode_fmtPushFrontPushBackPopFrontPopBackJoinLeftJoinRightSplitLeftSplitRightcap_indextest_inserts// `Arc` without refpool// `Ref` == `Arc` when threadsafeswap_indices/// Swap two values of anything implementing `IndexMut`./// Like `slice::swap`, but more generic.to_range// Every codebase needs a `util` module.// The `Ref` type is an alias for either `Rc` or `Arc`, user's choice.RrbVectorInnerInlineFocusTreeFocus/// Focused indexing over a [`Vector`][Vector]./// By remembering the last tree node accessed through an index lookup and the/// path we took to get there, we can speed up lookups for adjacent indices/// tremendously. Lookups on indices in the same node are instantaneous, and/// lookups on sibling nodes are also very fast./// A `Focus` can also be used as a restricted view into a vector, using the/// [`narrow`][narrow] and [`split_at`][split_at] methods./// # When should I use a `Focus` for better performance?/// `Focus` is useful when you need to perform a large number of index lookups/// that are more likely than not to be close to each other. It's usually worth/// using a `Focus` in any situation where you're batching a lot of index/// lookups together, even if they're not obviously adjacent - there's likely/// to be some performance gain for even completely random access./// If you're just iterating forwards or backwards over the [`Vector`][Vector]/// in order, you're better off with a regular iterator, which, in fact, is/// implemented using a `Focus`, but provides a simpler interface./// If you're just doing a very small number of index lookups, the setup cost/// for the `Focus` is probably not worth it./// A `Focus` is never faster than an index lookup on a small [`Vector`][Vector]/// with a length below the internal RRB tree's branching factor of 64./// This example is contrived, as the better way to iterate forwards or/// backwards over a vector is with an actual iterator. Even so, the version/// using a `Focus` should run nearly an order of magnitude faster than the/// version using index lookups at a length of 1000. It should also be noted/// that [`vector::Iter`][Iter] is actually implemented using a `Focus` behind/// the scenes, so the performance of the two should be identical./// let mut vec: Vector<i64> = Vector::from_iter(0..1000);/// // Summing a vector, the slow way:/// for i in 0..1000 {///     sum += *vec.get(i).unwrap();/// assert_eq!(499500, sum);/// // Summing a vector faster using a Focus:/// let mut focus = vec.focus();///     sum += *focus.get(i).unwrap();/// // And the easy way, for completeness:/// let sum: i64 = vec.iter().sum();/// [Vector]: enum.Vector.html/// [Iter]: struct.Iter.html/// [narrow]: #method.narrow/// [split_at]: #method.split_at/// Construct a `Focus` for a [`Vector`][Vector]./// Get the length of the focused [`Vector`][Vector]./// Test if the focused [`Vector`][Vector] is empty./// Get a reference to the value at a given index./// Panics if the index is out of bounds.chunk_at/// Get the chunk for the given index./// This gives you a reference to the leaf node that contains the index,/// along with its start and end indices.narrow/// Narrow the focus onto a subslice of the vector./// `Focus::narrow(range)` has the same effect as `&slice[range]`, without/// actually modifying the underlying vector./// Panics if the range isn't fully inside the current focus./// let vec = Vector::from_iter(0..1000);/// let narrowed = vec.focus().narrow(100..200);/// let narrowed_vec = narrowed.into_iter().cloned().collect();/// assert_eq!(Vector::from_iter(100..200), narrowed_vec);/// [slice::split_at]: https://doc.rust-lang.org/std/primitive.slice.html#method.split_at/// [Vector::split_at]: enum.Vector.html#method.split_at/// Split the focus into two./// Given an index `index`, consume the focus and produce two new foci, the/// left onto indices `0..index`, and the right onto indices `index..N`/// where `N` is the length of the current focus./// This is the moral equivalent of [`slice::split_at`][slice::split_at], in/// that it leaves the underlying data structure unchanged, unlike/// [`Vector::split_at`][Vector::split_at]./// let (left, right) = vec.focus().split_at(500);/// let left_vec = left.into_iter().cloned().collect();/// let right_vec = right.into_iter().cloned().collect();/// assert_eq!(Vector::from_iter(0..500), left_vec);/// assert_eq!(Vector::from_iter(500..1000), right_vec);treeviewmiddle_rangetarget_rangetarget_ptrphysical_indexlogical_rangeset_focusget_focusget_chunkTreeFocusMut/// A mutable version of [`Focus`][Focus]./// See [`Focus`][Focus] for more details./// You can only build one `FocusMut` at a time for a vector, effectively/// keeping a lock on the vector until you're done with the focus, which relies/// on the structure of the vector not changing while it exists./// let mut vec = Vector::from_iter(0..1000);/// let focus1 = vec.focus_mut();/// // Fails here in 2015 edition because you're creating/// // two mutable references to the same thing./// let focus2 = vec.focus_mut();/// // Fails here in 2018 edition because creating focus2/// // made focus1's lifetime go out of scope./// assert_eq!(Some(&0), focus1.get(0));/// On the other hand, you can split that one focus into multiple sub-focuses,/// which is safe because they can't overlap:/// let focus = vec.focus_mut();/// let (mut left, mut right) = focus.split_at(500);/// assert_eq!(Some(&0), left.get(0));/// assert_eq!(Some(&500), right.get(0));/// These sub-foci also work as a lock on the vector, even if the focus they/// were created from goes out of scope./// let (left, right) = {///     let focus = vec.focus_mut();///     focus.split_at(500)/// // `left` and `right` are still in scope even if `focus` isn't, so we can't/// // create another focus:/// [Focus]: enum.Focus.html/// Construct a `FocusMut` for a `Vector`./// Get the length of the focused `Vector`./// Test if the focused `Vector` is empty./// Get a mutable reference to the value at a given index.// would if I could/// Update the value at a given index./// Returns `None` if the index is out of bounds, or the replaced value/// Swap the values at two given indices./// Panics if either index is out of bounds./// If the indices are equal, this function returns without doing anything./// Lookup two indices simultaneously and run a function over them./// Useful because the borrow checker won't let you have more than one/// mutable reference into the same data structure at any given time./// Panics if either index is out of bounds, or if they are the same index./// let mut vec = vector![1, 2, 3, 4, 5];/// vec.focus_mut().pair(1, 3, |a, b| *a += *b);/// assert_eq!(vector![1, 6, 3, 4, 5], vec);triplet/// Lookup three indices simultaneously and run a function over them./// Panics if any index is out of bounds, or if any indices are equal./// vec.focus_mut().triplet(0, 2, 4, |a, b, c| *a += *b + *c);/// assert_eq!(vector![9, 2, 3, 4, 5], vec);/// `FocusMut::narrow(range)` has the same effect as `&slice[range]`, without/// let narrowed = vec.focus_mut().narrow(100..200);/// let narrowed_vec = narrowed.unmut().into_iter().cloned().collect();///     let (left, right) = vec.focus_mut().split_at(500);///     for ptr in left {///         *ptr += 100;///     for ptr in right {///         *ptr -= 100;/// let expected = Vector::from_iter(100..600)///              + Vector::from_iter(400..900);/// assert_eq!(expected, vec);unmut/// Convert a `FocusMut` into a `Focus`.InlineArrayfocus/// Construct a vector from a sequence of elements.///   vector![1, 2, 3],///   Vector::from(vec![1, 2, 3])/// A persistent vector./// This is a sequence of elements in insertion order - if you need a list of/// things, any kind of list of things, this is what you're looking for./// It's implemented as an [RRB vector][rrbpaper] with [smart head/tail/// chunking][chunkedseq]. In performance terms, this means that practically/// every operation is O(log n), except push/pop on both sides, which will be/// O(1) amortised, and O(log n) in the worst case. In practice, the push/pop/// operations will be blindingly fast, nearly on par with the native/// [`VecDeque`][VecDeque], and other operations will have decent, if not high,/// performance, but they all have more or less the same O(log n) complexity, so/// you don't need to keep their performance characteristics in mind -/// everything, even splitting and merging, is safe to use and never too slow./// ## Performance Notes/// Because of the head/tail chunking technique, until you push a number of/// items above double the tree's branching factor (that's `self.len()` = 2 ×/// *k* (where *k* = 64) = 128) on either side, the data structure is still just/// a handful of arrays, not yet an RRB tree, so you'll see performance and/// memory characteristics similar to [`Vec`][Vec] or [`VecDeque`][VecDeque]./// This means that the structure always preallocates four chunks of size *k*/// (*k* being the tree's branching factor), equivalent to a [`Vec`][Vec] with/// an initial capacity of 256. Beyond that, it will allocate tree nodes of/// capacity *k* as needed./// In addition, vectors start out as single chunks, and only expand into the/// full data structure once you go past the chunk size. This makes them/// perform identically to [`Vec`][Vec] at small sizes./// [rrbpaper]: https://infoscience.epfl.ch/record/213452/files/rrbvector.pdf/// [chunkedseq]: http://deepsea.inria.fr/pasl/chunkedseq.pdf/// [Vec]: https://doc.rust-lang.org/std/vec/struct.Vec.html/// [VecDeque]: https://doc.rust-lang.org/std/collections/struct.VecDeque.htmlmiddle_levelouter_finner_fmiddleinner_bouter_b/// Get a reference to the memory pool this `Vector` is using./// Note that if you didn't specifically construct it with a pool, you'll/// get back a reference to a pool of size 0.needs_promotion/// True if a vector is a full inline or single chunk, ie. must be promoted/// to grow further.promote_inline/// Promote an inline to a single.promote_front/// Promote a single to a full, with the single chunk becoming inner_f, or/// promote an inline to a single.promote_back/// Promote a single to a full, with the single chunk becoming inner_b, or/// Construct an empty vector./// Get the length of a vector./// assert_eq!(5, vector![1, 2, 3, 4, 5].len());/// Test whether a vector is empty./// # use im::Vector;/// let vec = vector!["Joe", "Mike", "Robert"];/// assert_eq!(false, vec.is_empty());/// assert_eq!(true, Vector::<i32>::new().is_empty());is_inline/// Test whether a vector is currently inlined./// Vectors small enough that their contents could be stored entirely inside/// the space of `std::mem::size_of::<Vector<A>>()` bytes are stored inline on/// the stack instead of allocating any chunks. This method returns `true` if/// this vector is currently inlined, or `false` if it currently has chunks allocated/// on the heap./// This may be useful in conjunction with [`ptr_eq()`][ptr_eq], which checks if/// two vectors' heap allocations are the same, and thus will never return `true`/// for inlined vectors./// [ptr_eq]: #method.ptr_eq/// Test whether two vectors refer to the same content in memory./// This uses the following rules to determine equality:/// * If the two sides are references to the same vector, return true./// * If the two sides are single chunk vectors pointing to the same chunk, return true./// * If the two sides are full trees pointing to the same chunks, return true./// This would return true if you're comparing a vector to itself, or/// if you're comparing a vector to a fresh clone of itself. The exception to this is/// if you've cloned an inline array (ie. an array with so few elements they can fit/// inside the space a `Vector` allocates for its pointers, so there are no heap allocations/// to compare)./// Get an iterator over a vector./// Get a mutable iterator over a vector.leaves/// Get an iterator over the leaf nodes of a vector./// This returns an iterator over the [`Chunk`s][Chunk] at the leaves of the/// RRB tree. These are useful for efficient parallelisation of work on/// the vector, but should not be used for basic iteration./// [Chunk]: ../chunk/struct.Chunk.htmlleaves_mutChunksMut/// Get a mutable iterator over the leaf nodes of a vector./// Construct a [`Focus`][Focus] for a vector.focus_mut/// Construct a [`FocusMut`][FocusMut] for a vector./// [FocusMut]: enum.FocusMut.html/// Get a reference to the value at index `index` in a vector./// Returns `None` if the index is out of bounds./// assert_eq!(Some(&"Robert"), vec.get(2));/// assert_eq!(None, vec.get(5));/// Get a mutable reference to the value at index `index` in a/// let mut vec = vector!["Joe", "Mike", "Robert"];///     let robert = vec.get_mut(2).unwrap();///     assert_eq!(&mut "Robert", robert);///     *robert = "Bjarne";/// assert_eq!(vector!["Joe", "Mike", "Bjarne"], vec);/// Get the first element of a vector./// If the vector is empty, `None` is returned.front_mut/// Get a mutable reference to the first element of a vector./// This is an alias for the [`front`][front] method./// [front]: #method.front/// Get the last element of a vector.back_mut/// Get a mutable reference to the last element of a vector./// This is an alias for the [`back`][back] method./// [back]: #method.backindex_of/// Get the index of a given element in the vector./// Searches the vector for the first occurrence of a given value,/// and returns the index of the value if it's there. Otherwise,/// it returns `None`./// assert_eq!(Some(2), vec.index_of(&3));/// assert_eq!(None, vec.index_of(&31337));/// Test if a given element is in the vector./// and returns `true` if it's there. If it's nowhere to be found/// in the vector, it returns `false`./// assert_eq!(true, vec.contains(&3));/// assert_eq!(false, vec.contains(&31337));/// Discard all elements from the vector./// This leaves you with an empty vector, and all elements thatbinary_search_by/// Binary search a sorted vector for a given element using a comparator/// Assumes the vector has already been sorted using the same comparator/// function, eg. by using [`sort_by`][sort_by]./// If the value is found, it returns `Ok(index)` where `index` is the index/// of the element. If the value isn't found, it returns `Err(index)` where/// `index` is the index at which the element would need to be inserted to/// maintain sorted order./// [sort_by]: #method.sort_bybinary_search/// Binary search a sorted vector for a given element.binary_search_by_key/// Binary search a sorted vector for a given element with a key extract/// Assumes the vector has already been sorted using the same key extract/// function, eg. by using [`sort_by_key`][sort_by_key]./// [sort_by_key]: #method.sort_by_key/// Construct a vector with a single value./// let vec = Vector::unit(1337);/// assert_eq!(1, vec.len());///   vec.get(0),///   Some(&1337)/// Create a new vector with the value at index `index` updated./// let mut vec = vector![1, 2, 3];/// assert_eq!(vector![1, 5, 3], vec.update(1, 5));/// Update the value at index `index` in a vector./// Returns the previous value at the index./// Swap the elements at indices `i` and `j`.push_front/// Push a value to the front of a vector./// let mut vec = vector![5, 6, 7];/// vec.push_front(4);/// assert_eq!(vector![4, 5, 6, 7], vec);/// Push a value to the back of a vector./// vec.push_back(4);/// assert_eq!(vector![1, 2, 3, 4], vec);/// Remove the first element from a vector and return it./// assert_eq!(Some(1), vec.pop_front());/// assert_eq!(vector![2, 3], vec);/// Remove the last element from a vector and return it./// assert_eq!(Some(3), vec.pop_back());/// assert_eq!(vector![1, 2], vec);/// Append the vector `other` to the end of the current vector./// vec.append(vector![7, 8, 9]);/// assert_eq!(vector![1, 2, 3, 7, 8, 9], vec);/// Retain only the elements specified by the predicate./// Remove all elements for which the provided function `f`/// returns false from the vector./// Split a vector at a given index./// Split a vector at a given index, consuming the vector and/// returning a pair of the left hand side and the right hand side/// of the split./// let mut vec = vector![1, 2, 3, 7, 8, 9];/// let (left, right) = vec.split_at(3);/// assert_eq!(vector![1, 2, 3], left);/// assert_eq!(vector![7, 8, 9], right);/// Split a vector at a given index, leaving the left hand side in/// the current vector and returning a new vector containing the/// right hand side./// let mut left = vector![1, 2, 3, 7, 8, 9];/// let right = left.split_off(3);/// Construct a vector with `count` elements removed from the/// start of the current vector./// Construct a vector of the first `count` elements from the/// current vector./// Truncate a vector to the given size./// Discards all elements in the vector beyond the given length./// Panics if the new length is greater than the current length./// Extract a slice from a vector./// Remove the elements from `start_index` until `end_index` in/// the current vector and return the removed slice as a new/// Insert an element into a vector./// Insert an element at position `index`, shifting all elements/// after it to the right./// ## Performance Note/// While `push_front` and `push_back` are heavily optimised/// operations, `insert` in the middle of a vector requires a/// split, a push, and an append. Thus, if you want to insert/// many elements at the same location, instead of `insert`ing/// them one by one, you should rather create a new vector/// containing the elements to insert, split the vector at the/// insertion point, and append the left hand, the new vector and/// the right hand in order./// Remove an element from a vector./// Remove the element from position 'index', shifting all/// elements after it to the left, and return the removed element./// While `pop_front` and `pop_back` are heavily optimised/// operations, `remove` in the middle of a vector requires a/// split, a pop, and an append. Thus, if you want to remove many/// elements from the same location, instead of `remove`ing them/// one by one, it is much better to use [`slice`][slice]./// [slice]: #method.sliceinsert_ord/// Insert an element into a sorted vector./// Insert an element into a vector in sorted order, assuming the vector is/// already in sorted order./// vec.insert_ord(5);/// assert_eq!(vector![1, 2, 3, 5, 7, 8, 9], vec);/// Sort a vector./// let mut vec = vector![3, 2, 5, 4, 1];/// vec.sort();/// assert_eq!(vector![1, 2, 3, 4, 5], vec);sort_by/// Sort a vector using a comparator function./// vec.sort_by(|left, right| left.cmp(right));/// Verify the internal consistency of a vector./// This method walks the RRB tree making up the current `Vector`/// (if it has one) and verifies that all the invariants hold./// If something is wrong, it will panic./// This method requires the `debug` feature flag.prunepush_middlepop_middlereplace_pool_def/// Clone a vector./// Time: O(1), or O(n) with a very small, bounded *n* for an inline vector./// Concatenate two vectors./// Add values to the end of a vector by consuming an iterator./// Get a reference to the value at index `index` in the vector./// Get a mutable reference to the value at index `index` in the/// Create a vector from an iterator./// Create a vector from a [`std::vec::Vec`][vec]./// [vec]: https://doc.rust-lang.org/std/vec/struct.Vec.htmlfront_indexback_index/// An iterator over vectors with values of type `A`./// To obtain one, use [`Vector::iter()`][iter]./// [iter]: enum.Vector.html#method.iterfrom_focus/// A mutable iterator over vectors with values of type `A`./// To obtain one, use [`Vector::iter_mut()`][iter_mut]./// [iter_mut]: enum.Vector.html#method.iter_mut/// Remove and return an element from the back of the iterator./// A consuming iterator over vectors with values of type `A`./// An iterator over the leaf nodes of a vector./// To obtain one, use [`Vector::chunks()`][chunks]./// [chunks]: enum.Vector.html#method.chunks/// A mutable iterator over the leaf nodes of a vector./// To obtain one, use [`Vector::chunks_mut()`][chunks_mut]./// [chunks_mut]: enum.Vector.html#method.chunks_mutindexinglarge_vector_focuslarge_vector_focus_mutissue_55_fwdissue_55_backissue_55_appendissue_70issue_67issue_74_simple_sizeissue_77issue_105issue_107_split_off_causes_overflowcollect_crashissue_116issue_131//! A persistent vector.//! This is a sequence of elements in insertion order - if you need a//! list of things, any kind of list of things, this is what you're//! looking for.//! It's implemented as an [RRB vector][rrbpaper] with [smart//! head/tail chunking][chunkedseq]. In performance terms, this means//! that practically every operation is O(log n), except push/pop on//! both sides, which will be O(1) amortised, and O(log n) in the//! worst case. In practice, the push/pop operations will be//! blindingly fast, nearly on par with the native//! [`VecDeque`][VecDeque], and other operations will have decent, if//! not high, performance, but they all have more or less the same//! O(log n) complexity, so you don't need to keep their performance//! characteristics in mind - everything, even splitting and merging,//! is safe to use and never too slow.//! Because of the head/tail chunking technique, until you push a//! number of items above double the tree's branching factor (that's//! `self.len()` = 2 × *k* (where *k* = 64) = 128) on either side, the//! data structure is still just a handful of arrays, not yet an RRB//! tree, so you'll see performance and memory characteristics fairly//! close to [`Vec`][Vec] or [`VecDeque`][VecDeque].//! This means that the structure always preallocates four chunks of//! size *k* (*k* being the tree's branching factor), equivalent to a//! [`Vec`][Vec] with an initial capacity of 256. Beyond that, it will//! allocate tree nodes of capacity *k* as needed.//! In addition, vectors start out as single chunks, and only expand into the//! full data structure once you go past the chunk size. This makes them//! perform identically to [`Vec`][Vec] at small sizes.//! [rrbpaper]: https://infoscience.epfl.ch/record/213452/files/rrbvector.pdf//! [chunkedseq]: http://deepsea.inria.fr/pasl/chunkedseq.pdf//! [Vec]: https://doc.rust-lang.org/std/vec/struct.Vec.html//! [VecDeque]: https://doc.rust-lang.org/std/collections/struct.VecDeque.html// Implementation detailsnode_poolvalue_poolsize_pool/// A memory pool for `Vector`./// Create a new memory pool with the given size.with_sizes/// Create a new memory pool with the given sizes for each subpool./// Fill the memory pool with preallocated chunks.node_pool_size/// Get the size of the node subpool.leaf_pool_size/// Get the size of the leaf node subpool.size_table_pool_size/// Get the size of the size table subpool./// Construct a pool with a reasonable default pool size.bridgeConsumerProducerProducerCallbackIndexedParallelIteratorIntoParallelRefIteratorIntoParallelRefMutIteratorpar_iter_mut/// A parallel iterator for [`Vector`][Vector].drivewith_producer/// A mutable parallel iterator for [`Vector`][Vector].VectorProducerVectorMutProducer//! Parallel iterators.//! These are only available when using the `rayon` feature flag.IndexMapIndexSet// NOTE: the real `#[deprecated]` attribute doesn't work for trait implementations,// but we can get close by mimicking the message style for documentation./// <div class="stab deprecated"><span class="emoji">👎</span><span>Deprecated: use borsh's <code>indexmap</code> feature instead.</span></div>map_borsh_roundtripset_borsh_roundtripborsh_tests/// Hash value newtype. Not larger than usize, since anything larger/// isn't used for selecting position anyway.key_ref// field accessors -- used for `f` instead of closures in `.map(f)`value_refvalue_mutkey_valuerefsref_mutmutsTryReserveErrorKind/// The error type for [`try_reserve`][IndexMap::try_reserve] methods.Std// The standard library's kind is currently opaque to us, otherwise we could unify this.from_allocfrom_hashbrown// These are not `From` so we don't expose them in our public API.GetDisjointMutErrorIndexOutOfBounds/// An index provided was out-of-bounds for the slice.OverlappingIndices/// Two indices provided were overlapping.// NOTE: This is copied from the slice module in the std lib./// The error type returned by [`get_disjoint_indices_mut`][`IndexMap::get_disjoint_indices_mut`]./// It indicates one of two possible errors:/// - An index is out-of-bounds./// - The same index appeared multiple times in the array.//    (or different but overlapping indices when ranges are provided)// We *mostly* avoid unsafe code, but `Slice` allows it for DST casting.//! [`IndexMap`] is a hash table where the iteration order of the key-value//! pairs is independent of the hash values of the keys.//! [`IndexSet`] is a corresponding hash set using the same implementation and//! with similar properties.//! ### Highlights//! [`IndexMap`] and [`IndexSet`] are drop-in compatible with the std `HashMap`//! and `HashSet`, but they also have some features of note://! - The ordering semantics (see their documentation for details)//! - Sorting methods and the [`.pop()`][IndexMap::pop] methods.//! - The [`Equivalent`] trait, which offers more flexible equality definitions//!   between borrowed and owned versions of keys.//! - The [`MutableKeys`][map::MutableKeys] trait, which gives opt-in mutable//!   access to map keys, and [`MutableValues`][set::MutableValues] for sets.//! ### Feature Flags//! To reduce the amount of compiled code in the crate by default, certain//! features are gated behind [feature flags]. These allow you to opt in to (or//! out of) functionality. Below is a list of the features available in this//! crate.//! * `std`: Enables features which require the Rust standard library. For more//!   information see the section on [`no_std`].//! * `rayon`: Enables parallel iteration and other parallel methods.//! * `serde`: Adds implementations for [`Serialize`] and [`Deserialize`]//!   to [`IndexMap`] and [`IndexSet`]. Alternative implementations for//!   (de)serializing [`IndexMap`] as an ordered sequence are available in the//!   [`map::serde_seq`] module.//! * `arbitrary`: Adds implementations for the [`arbitrary::Arbitrary`] trait//!   to [`IndexMap`] and [`IndexSet`].//! * `quickcheck`: Adds implementations for the [`quickcheck::Arbitrary`] trait//! * `borsh` (**deprecated**): Adds implementations for [`BorshSerialize`] and//!   [`BorshDeserialize`] to [`IndexMap`] and [`IndexSet`]. Due to a cyclic//!   dependency that arose between [`borsh`] and `indexmap`, `borsh v1.5.6`//!   added an `indexmap` feature that should be used instead of enabling the//!   feature here.//! _Note: only the `std` feature is enabled by default._//! [feature flags]: https://doc.rust-lang.org/cargo/reference/manifest.html#the-features-section//! [`no_std`]: #no-standard-library-targets//! [`Serialize`]: `::serde::Serialize`//! [`Deserialize`]: `::serde::Deserialize`//! [`BorshSerialize`]: `::borsh::BorshSerialize`//! [`BorshDeserialize`]: `::borsh::BorshDeserialize`//! [`borsh`]: `::borsh`//! [`arbitrary::Arbitrary`]: `::arbitrary::Arbitrary`//! [`quickcheck::Arbitrary`]: `::quickcheck::Arbitrary`//! ### Alternate Hashers//! [`IndexMap`] and [`IndexSet`] have a default hasher type//! [`S = RandomState`][std::collections::hash_map::RandomState],//! just like the standard `HashMap` and `HashSet`, which is resistant to//! HashDoS attacks but not the most performant. Type aliases can make it easier//! to use alternate hashers://! use fnv::FnvBuildHasher;//! use indexmap::{IndexMap, IndexSet};//! type FnvIndexMap<K, V> = IndexMap<K, V, FnvBuildHasher>;//! type FnvIndexSet<T> = IndexSet<T, FnvBuildHasher>;//! let std: IndexSet<i32> = (0..100).collect();//! let fnv: FnvIndexSet<i32> = (0..100).collect();//! assert_eq!(std, fnv);//! ### Rust Version//! This version of indexmap requires Rust 1.63 or later.//! The indexmap 2.x release series will use a carefully considered version//! upgrade policy, where in a later 2.x version, we will raise the minimum//! required Rust version.//! ## No Standard Library Targets//! This crate supports being built without `std`, requiring `alloc` instead.//! This is chosen by disabling the default "std" cargo feature, by adding//! `default-features = false` to your dependency specification.//! - Creating maps and sets using [`new`][IndexMap::new] and//!   [`with_capacity`][IndexMap::with_capacity] is unavailable without `std`.//!   Use methods [`IndexMap::default`], [`with_hasher`][IndexMap::with_hasher],//!   [`with_capacity_and_hasher`][IndexMap::with_capacity_and_hasher] instead.//!   A no-std compatible hasher will be needed as well, for example//!   from the crate `twox-hash`.//! - Macros [`indexmap!`] and [`indexset!`] are unavailable without `std`. Use//!   the macros [`indexmap_with_default!`] and [`indexset_with_default!`] instead.// shared private itemsindexmap_with_default/// Create an [`IndexMap`][crate::IndexMap] from a list of key-value pairs/// and a [`BuildHasherDefault`][core::hash::BuildHasherDefault]-wrapped custom hasher./// use indexmap::indexmap_with_default;/// use fnv::FnvHasher;/// let map = indexmap_with_default!{///     FnvHasher;///     "a" => 1,///     "b" => 2,/// assert_eq!(map["a"], 1);/// assert_eq!(map["b"], 2);/// // "a" is the first key/// assert_eq!(map.keys().next(), Some(&"a"));/// use indexmap::indexmap;/// let map = indexmap!{indexset_with_default/// Create an [`IndexSet`][crate::IndexSet] from a list of values/// use indexmap::indexset_with_default;/// let set = indexset_with_default!{///     "a",///     "b",/// assert!(set.contains("a"));/// assert!(set.contains("b"));/// assert!(!set.contains("c"));/// // "a" is the first value/// assert_eq!(set.iter().next(), Some(&"a"));indexset/// use indexmap::indexset;/// let set = indexset!{iterator_methods// $map_elt is the mapping function from the underlying iterator's element// same mapping function for both options and iterators// generate all the Iterator methods by just forwarding to the underlying// self.iter and mapping its element.double_ended_iterator_methodsEntriesIndexMapCore/// Existing slot with equivalent key./// Vacant slot (no equivalent key in the map)./// Entry for an existing key-value pair in an [`IndexMap`][crate::IndexMap]/// or a vacant location to insert one./// Return the index where the key-value pair exists or will be inserted./// Sets the value of the entry (after inserting if vacant), and returns an `OccupiedEntry`./// Computes in **O(1)** time (amortized average)./// Inserts the given default value in the entry if it is vacant and returns a mutable/// reference to it. Otherwise a mutable reference to an already existent value is returned./// Inserts the result of the `call` function in the entry if it is vacant and returns a mutable/// Inserts the result of the `call` function with a reference to the entry's key if it is/// vacant, and returns a mutable reference to the new value. Otherwise a mutable reference to/// an already existent value is returned./// Gets a reference to the entry's key, either within the map if occupied,/// or else the new key that was used to find the entry./// Modifies the entry if it is occupied./// Inserts a default-constructed value in the entry if it is vacant and returns a mutableentries/// A view into an occupied entry in an [`IndexMap`][crate::IndexMap]./// Return the index of the key-value pairinto_ref_mut/// Gets a reference to the entry's key in the map./// Note that this is not the key that was used to find the entry. There may be an observable/// difference if the key type has any distinguishing features outside of `Hash` and `Eq`, like/// extra fields or the memory address of an allocation./// Gets a reference to the entry's value in the map./// Gets a mutable reference to the entry's value in the map./// If you need a reference which may outlive the destruction of the/// [`Entry`] value, see [`into_mut`][Self::into_mut]./// Converts into a mutable reference to the entry's value in the map,into_muts/// Sets the value of the entry to `value`, and returns the entry's old value./// Remove the key, value pair stored in the map for this entry, and return the value./// **NOTE:** This is equivalent to [`.swap_remove()`][Self::swap_remove], replacing this/// entry's position with the last element, and it is deprecated in favor of calling that/// explicitly. If you need to preserve the relative order of the keys in the map, use/// [`.shift_remove()`][Self::shift_remove] instead./// Like [`Vec::swap_remove`][crate::Vec::swap_remove], the pair is removed by swapping it with/// the last element of the map and popping it off./// **This perturbs the position of what used to be the last element!**/// Computes in **O(1)** time (average).shift_remove/// Like [`Vec::remove`][crate::Vec::remove], the pair is removed by shifting all of the/// elements that follow it, preserving their relative order./// **This perturbs the index of all of those elements!**/// Computes in **O(n)** time (average)./// Remove and return the key, value pair stored in the map for this entry/// **NOTE:** This is equivalent to [`.swap_remove_entry()`][Self::swap_remove_entry],/// replacing this entry's position with the last element, and it is deprecated in favor of/// calling that explicitly. If you need to preserve the relative order of the keys in the map,/// use [`.shift_remove_entry()`][Self::shift_remove_entry] instead.swap_remove_entryshift_remove_entrymove_index/// Moves the position of the entry to a new index/// by shifting all other entries in-between./// This is equivalent to [`IndexMap::move_index`][`crate::IndexMap::move_index`]/// coming `from` the current [`.index()`][Self::index]./// * If `self.index() < to`, the other pairs will shift down while the targeted pair moves up./// * If `self.index() > to`, the other pairs will shift up while the targeted pair moves down./// ***Panics*** if `to` is out of bounds./// Swaps the position of entry with another./// This is equivalent to [`IndexMap::swap_indices`][`crate::IndexMap::swap_indices`]/// with the current [`.index()`][Self::index] as one of the two being swapped./// ***Panics*** if the `other` index is out of bounds.IndexedEntry/// A view into a vacant entry in an [`IndexMap`][crate::IndexMap]./// Return the index where a key-value pair may be inserted./// Gets a reference to the key that was used to find the entry./// Takes ownership of the key, leaving the entry vacant./// Inserts the entry's key and the given value into the map, and returns a mutable reference/// to the value./// Inserts the entry's key and the given value into the map, and returns an `OccupiedEntry`.insert_sorted/// Inserts the entry's key and the given value into the map at its ordered/// position among sorted keys, and returns the new index and a mutable/// reference to the value./// If the existing keys are **not** already sorted, then the insertion/// index is unspecified (like [`slice::binary_search`]), but the key-value/// pair is inserted at that position regardless.shift_insert/// Inserts the entry's key and the given value into the map at the given index,/// shifting others to the right, and returns a mutable reference to the value./// ***Panics*** if `index` is out of bounds.// We have a mutable reference to the map, which keeps the index// valid and pointing to the correct entry./// A view into an occupied entry in an [`IndexMap`][crate::IndexMap] obtained by index./// This `struct` is created from the [`get_index_entry`][crate::IndexMap::get_index_entry] method./// `IndexedEntry` value, see [`into_mut`][Self::into_mut].simplify_rangeExtractCorenew_lenraw_entry_v1/// Creates a raw immutable entry builder for the [`IndexMap`]./// * Using a search key that doesn't work with the [`Equivalent`] trait/// [`get`][IndexMap::get] should be preferred./// Immutable raw entries have very limited use; you might instead want/// [`raw_entry_mut_v1`][Self::raw_entry_mut_v1]./// use indexmap::map::{IndexMap, RawEntryApiV1};/// let mut map = IndexMap::new();///     let i = map.get_index_of(k);///     let v = map.get(k);///     let kv = map.get_key_value(k);///     let ikv = map.get_full(k);///     assert_eq!(map.raw_entry_v1().from_key(k), kv);///     assert_eq!(map.raw_entry_v1().from_hash(hash, |q| *q == k), kv);///     assert_eq!(map.raw_entry_v1().from_key_hashed_nocheck(hash, k), kv);///     assert_eq!(map.raw_entry_v1().from_hash_full(hash, |q| *q == k), ikv);///     assert_eq!(map.raw_entry_v1().index_from_hash(hash, |q| *q == k), i);raw_entry_mut_v1/// Creates a raw entry builder for the [`IndexMap`]./// to put the `IndexMap` into an inconsistent state which, while memory-safe,/// will cause the map to produce seemingly random results. Higher-level and more/// foolproof APIs like [`entry`][IndexMap::entry] should be preferred when possible./// use indexmap::map::raw_entry_v1::RawEntryMut;/// match map.raw_entry_mut_v1().from_key("a") {///         assert_eq!(view.index(), 0);/// let hash = compute_hash(map.hasher(), "c");/// match map.raw_entry_mut_v1().from_key_hashed_nocheck(hash, "c") {///         assert_eq!(view.index(), 2);///         assert_eq!(view.shift_remove_entry(), ("c", 300));/// assert_eq!(map.raw_entry_v1().from_key("c"), None);/// let hash = compute_hash(map.hasher(), key);/// match map.raw_entry_mut_v1().from_hash(hash, |q| *q == key) {/// assert_eq!(map["d"], 40000);///         assert_eq!(view.swap_remove_entry(), ("d", 40000));/// assert_eq!(map.get("d"), None);RawEntryApiV1/// Opt-in access to the experimental raw entry API./// See the [`raw_entry_v1`][self] module documentation for more information./// A builder for computing where in an [`IndexMap`] a key-value pair would be stored./// This `struct` is created by the [`IndexMap::raw_entry_v1`] method, provided by the/// [`RawEntryApiV1`] trait. See its documentation for more.from_hash_full/// Access an entry by hash, including its index.index_from_hash/// Access the index of an entry by hash./// This `struct` is created by the [`IndexMap::raw_entry_mut_v1`] method, provided by the/// Raw entry for an existing key-value pair or a vacant location to/// insert one./// Return the index where the key-value pair exists or may be inserted./// Inserts the given default key and value in the entry if it is vacant and returns mutable/// references to them. Otherwise mutable references to an already existent pair are returned./// Inserts the result of the `call` function in the entry if it is vacant and returns mutable/// A raw view into an occupied entry in an [`IndexMap`]./// Gets a mutable reference to the entry's key in the map./// Converts into a mutable reference to the entry's key in the map,/// [`RawEntryMut`] value, see [`into_mut`][Self::into_mut]./// Gets a reference to the entry's key and value in the map.into_key_value_mut/// Converts into a mutable reference to the entry's key and value in the map,/// Sets the key of the entry, and returns the entry's old key./// This is equivalent to [`IndexMap::move_index`]/// This is equivalent to [`IndexMap::swap_indices`]/// A view into a vacant raw entry in an [`IndexMap`]./// Inserts the given key and value into the map,/// and returns mutable references to them./// Inserts the given key and value into the map with the provided hash,/// Inserts the given key and value into the map at the given index,/// shifting others to the right, and returns mutable references to them.shift_insert_hashed_nocheck/// Inserts the given key and value into the map with the provided hash/// at the given index, and returns mutable references to them.//! Opt-in access to the experimental raw entry API.//! This module is designed to mimic the raw entry API of [`HashMap`][std::collections::hash_map],//! matching its unstable state as of Rust 1.75. See the tracking issue//! [rust#56167](https://github.com/rust-lang/rust/issues/56167) for more details.//! The trait [`RawEntryApiV1`] and the `_v1` suffix on its methods are meant to insulate this for//! the future, in case later breaking changes are needed. If the standard library stabilizes its//! `hash_raw_entry` feature (or some replacement), matching *inherent* methods will be added to//! `IndexMap` without such an opt-in trait.Indicesindices/// indices mapping from the entry hash to its index./// entries is a dense vec maintaining entry order./// Core of the map that does not depend on S/// Mutable references to the parts of an `IndexMapCore`./// When using `HashTable::find_entry`, that takes hold of `&mut indices`, so we have to borrow our/// `&mut entries` separately, and there's no way to go back to a `&mut IndexMapCore`. So this type/// is used to implement methods on the split references, and `IndexMapCore` can also call those to/// avoid duplication.erase_indexupdate_indexinsert_bulk_no_grow/// Inserts many entries into the indices table without reallocating,/// and without regard for duplication./// ***Panics*** if there is not sufficient capacity already.MAX_ENTRIES_CAPACITY/// The maximum capacity before the `entries` allocation would exceed `isize::MAX`.into_entriesas_entriesas_entries_mutwith_entriessplit_spliceappend_unchecked/// Append from another map without checking whether items already exist./// Reserve capacity for `additional` more key-value pairs./// Reserve capacity for `additional` more key-value pairs, without over-allocating./// Try to reserve capacity for `additional` more key-value pairs.try_reserve_entries/// Try to reserve entries capacity, rounded up to match the indices/// Try to reserve capacity for `additional` more key-value pairs, without over-allocating./// Shrink the capacity of the map with a lower bound/// Remove the last key-value pairget_index_of/// Return the index in `entries` where an equivalent key can be foundpush_entry/// Append a key-value pair to `entries`,/// *without* checking whether it already exists.insert_fullreplace_full/// Same as `insert_full`, except it also replaces the keyshift_remove_full/// Remove an entry by shifting all entries that follow itshift_remove_indexswap_remove_full/// Remove an entry by swapping it with the lastswap_remove_indexerase_indices/// Erase `start..end` from `indices`, and shift `end..` indices down to `start..`/// All of these items should still be at their original location in `entries`./// This is used by `drain`, which will let `Vec::drain` do the work on `entries`.retain_in_orderrebuild_hash_tablereversereserve_entries/// Reserve entries capacity, rounded up to match the indices (via `try_capacity`)./// Reserve entries capacity, rounded up to match the indices/// Insert a key-value pair in `entries`,shift_insert_unique/// Insert a key-value pair in `entries` at a particular index,shift_remove_finish/// The index should already be removed from `self.indices`.swap_remove_finish/// Finish removing an entry by swapping it with the lastdecrement_indices/// Decrement all indices in the range `start..end`./// The index `start - 1` should not exist in `self.indices`./// All entries should still be in their original positions.increment_indices/// Increment all indices in the range `start..end`./// The index `end` should not exist in `self.indices`.assert_send_sync//! This is the core implementation that doesn't depend on the hasher at all.//! The methods of `IndexMapCore` don't use any Hash properties of K.//! It's cleaner to separate them out, then the compiler checks that we are not//! using Hash at all in these methods.//! However, we should probably not let this show in the public API or docs./// An iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::iter`] method./// Returns a slice of the remaining entries in the iterator./// A mutable iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::iter_mut`] method.into_slice/// Returns a mutable slice of the remaining entries in the iterator./// To avoid creating `&mut` references that alias, this is forced to consume the iterator.IterMut2/// This `struct` is created by the [`MutableKeys::iter_mut2`][super::MutableKeys::iter_mut2] method./// An owning iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::into_iter`] method/// A draining iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::drain`] method./// An iterator over the keys of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::keys`] method./// Returns a reference to the key at the supplied `index`./// Access [`IndexMap`] keys at indexed positions./// While [`Index<usize> for IndexMap`][values] accesses a map's values,/// indexing through [`IndexMap::keys`] offers an alternative to access a map's/// keys instead./// [values]: IndexMap#impl-Index<usize>-for-IndexMap<K,+V,+S>/// Since `Keys` is also an iterator, consuming items from the iterator will/// offset the effective indices. Similarly, if `Keys` is obtained from/// [`Slice::keys`], indices will be interpreted relative to the position of/// that slice./// use indexmap::IndexMap;/// for word in "Lorem ipsum dolor sit amet".split_whitespace() {///     map.insert(word.to_lowercase(), word.to_uppercase());/// assert_eq!(map[0], "LOREM");/// assert_eq!(map.keys()[0], "lorem");/// assert_eq!(map[1], "IPSUM");/// assert_eq!(map.keys()[1], "ipsum");/// map.reverse();/// assert_eq!(map.keys()[0], "amet");/// assert_eq!(map.keys()[1], "sit");/// map.sort_keys();/// assert_eq!(map.keys()[1], "dolor");/// // Advancing the iterator will offset the indexing/// assert_eq!(keys[0], "amet");/// assert_eq!(keys.next().map(|s| &**s), Some("amet"));/// assert_eq!(keys[0], "dolor");/// assert_eq!(keys[1], "ipsum");/// // Slices may have an offset as well/// let slice = &map[2..];/// assert_eq!(slice[0], "IPSUM");/// assert_eq!(slice.keys()[0], "ipsum");/// map.insert("foo", 1);/// println!("{:?}", map.keys()[10]); // panics!/// An owning iterator over the keys of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::into_keys`] method./// An iterator over the values of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::values`] method./// A mutable iterator over the values of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::values_mut`] method./// An owning iterator over the values of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::into_values`] method./// A splicing iterator for `IndexMap`./// This `struct` is created by [`IndexMap::splice()`]./// An extracting iterator for `IndexMap`./// This `struct` is created by [`IndexMap::extract_if()`].get_full_mut2/// Return item index, mutable reference to key and valueget_index_mut2/// Return mutable reference to key and value at an index./// Valid indices are `0 <= index < self.len()`./// Computes in **O(1)** time.iter_mut2/// Return an iterator over the key-value pairs of the map, in their orderretain2/// Scan through each key-value pair in the map and keep those where the/// closure `keep` returns `true`./// The elements are visited in order, and remaining elements keep their/// order.MutableKeys/// Opt-in mutable access to [`IndexMap`] keys./// These methods expose `&mut K`, mutable references to the key as it is stored/// in the map./// You are allowed to modify the keys in the map **if the modification/// does not change the key’s hash and equality**./// If keys are modified erroneously, you can no longer look them up./// This is sound (memory safe) but a logical error hazard (just like/// implementing `PartialEq`, `Eq`, or `Hash` incorrectly would be)./// `use` this trait to enable its methods for `IndexMap`./// This trait is sealed and cannot be implemented for types outside this crate./// See [`MutableKeys`] for more information./// Gets a mutable reference to the entry's key, either within the map if occupied,MutableEntryKey/// Opt-in mutable access to [`Entry`] keys./// `use` this trait to enable its methods for `Entry`./// See [`MutableEntryKey`] for more information./// Opt-in mutable access to [`OccupiedEntry`] keys./// Opt-in mutable access to [`VacantEntry`] keys./// Opt-in mutable access to [`IndexedEntry`] keys.MapSlicecautious_capacitySetSlice/// Serializes a [`map::Slice`][MapSlice] as an ordered sequence./// This behaves like [`crate::map::serde_seq`] for `IndexMap`, serializing a sequence/// of `(key, value)` pairs, rather than as a map that might not preserve order.Se/// Serializes a [`set::Slice`][SetSlice] as an ordered sequence./// Serializes an [`IndexMap`] as an ordered sequence./// This function may be used in a field attribute for deriving [`Serialize`]:/// # use indexmap::IndexMap;/// struct Data {///     #[serde(serialize_with = "indexmap::map::serde_seq::serialize")]///     map: IndexMap<i32, u64>,/// Visitor to deserialize a *sequenced* `IndexMap`/// Deserializes an [`IndexMap`] from an ordered sequence./// This function may be used in a field attribute for deriving [`Deserialize`]:/// #[derive(Deserialize)]///     #[serde(deserialize_with = "indexmap::map::serde_seq::deserialize")]//! Functions to serialize and deserialize an [`IndexMap`] as an ordered sequence.//! The default `serde` implementation serializes `IndexMap` as a normal map,//! but there is no guarantee that serialization formats will preserve the order//! of the key-value pairs. This module serializes `IndexMap` as a sequence of//! `(key, value)` elements instead, in order.//! This module may be used in a field attribute for derived implementations://! # use indexmap::IndexMap;//! # use serde_derive::{Deserialize, Serialize};//! #[derive(Deserialize, Serialize)]//! struct Data {//!     #[serde(with = "indexmap::map::serde_seq")]//!     map: IndexMap<i32, u64>,//!     // ...slice_eqtry_simplify_range/// A dynamically-sized slice of key-value pairs in an [`IndexMap`]./// This supports indexed operations much like a `[(K, V)]` slice,/// but not any hashed operations on the map keys./// Unlike `IndexMap`, `Slice` does consider the order for [`PartialEq`]/// and [`Eq`], and it also implements [`PartialOrd`], [`Ord`], and [`Hash`].into_boxed// SAFETY: `Slice<K, V>` is a transparent wrapper around `[Bucket<K, V>]`,// and reference lifetimes are bound together in function signatures./// Returns an empty slice.new_mut/// Returns an empty mutable slice./// Return the number of key-value pairs in the map slice./// Returns true if the map slice contains no elements.get_index/// Get a key-value pair by index.get_index_mut/// Get a key-value pair by index, with mutable access to the value./// Returns a slice of key-value pairs in the given range of indices.get_range_mut/// Returns a mutable slice of key-value pairs in the given range of indices./// Get the first key-value pair.first_mut/// Get the first key-value pair, with mutable access to the value./// Get the last key-value pair.last_mut/// Get the last key-value pair, with mutable access to the value./// Divides one slice into two at an index./// ***Panics*** if `index > len`.split_at_mut/// Divides one mutable slice into two at an index.split_first/// Returns the first key-value pair and the rest of the slice,/// or `None` if it is empty.split_first_mut/// with mutable access to the value, or `None` if it is empty.split_last/// Returns the last key-value pair and the rest of the slice,split_last_mut/// Return an iterator over the key-value pairs of the map slice./// Return an iterator over the keys of the map slice./// Return an owning iterator over the keys of the map slice./// Return an iterator over the values of the map slice./// Return an iterator over mutable references to the the values of the map slice./// Return an owning iterator over the values of the map slice.binary_search_keys/// Search over a sorted map for a key./// Returns the position where that key is present, or the position where it can be inserted to/// maintain the sort. See [`slice::binary_search`] for more details./// Computes in **O(log(n))** time, which is notably less scalable than looking the key up in/// the map this is a slice from using [`IndexMap::get_index_of`], but this can also position/// missing keys./// Search over a sorted map with a comparator function./// Returns the position where that value is present, or the position where it can be inserted/// to maintain the sort. See [`slice::binary_search_by`] for more details./// Computes in **O(log(n))** time./// Search over a sorted map with an extraction function./// to maintain the sort. See [`slice::binary_search_by_key`] for more details.partition_point/// Returns the index of the partition point of a sorted map according to the given predicate/// (the index of the first element of the second partition)./// See [`slice::partition_point`] for more details.get_disjoint_mut/// Get an array of `N` key-value pairs by `N` indices/// Valid indices are *0 <= index < self.len()* and each index needs to be unique.get_disjoint_opt_mutK2impl_index// We can't have `impl<I: RangeBounds<usize>> Index<I>` because that conflicts// both upstream with `Index<usize>` and downstream with `Index<&Q>`.// Instead, we repeat the implementations for all the core range types.slice_indexslice_index_mutslice_newslice_new_mutslice_get_index_mutslice_split_firstslice_split_first_mutslice_split_lastslice_split_last_mutslice_get_rangeit_worksinsert_2insert_orderinsert_sorted_badremove_to_emptypartial_eq_and_eqentry_and_modifyentry_or_defaultoccupied_entry_keyget_index_entryfrom_entriesiter_defaultshift_shift_remove_indexsorted_unstable_by"index out of bounds"insert_before_oobshift_insert_oobtest_binary_search_bytest_binary_search_by_keytest_partition_pointmove_index_oobtest_move_index_out_of_bounds_0_10test_move_index_out_of_bounds_0_maxtest_move_index_out_of_bounds_10_0test_move_index_out_of_bounds_max_0disjoint_mut_empty_mapdisjoint_mut_empty_paramdisjoint_mut_single_faildisjoint_mut_single_successdisjoint_mut_multi_successdisjoint_mut_multi_success_unsized_keydisjoint_mut_multi_success_borrow_keydisjoint_mut_multi_fail_missingdisjoint_mut_multi_fail_duplicate_panicdisjoint_indices_mut_fail_oobdisjoint_indices_mut_emptydisjoint_indices_mut_successdisjoint_indices_mut_fail_duplicatethird/// A hash table where the iteration order of the key-value pairs is independent/// of the hash values of the keys./// The interface is closely compatible with the standard/// [`HashMap`][std::collections::HashMap],/// but also has additional features./// # Order/// The key-value pairs have a consistent order that is determined by/// the sequence of insertion and removal calls on the map. The order does/// not depend on the keys or the hash function at all./// All iterators traverse the map in *the order*./// The insertion order is preserved, with **notable exceptions** like the/// [`.remove()`][Self::remove] or [`.swap_remove()`][Self::swap_remove] methods./// Methods such as [`.sort_by()`][Self::sort_by] of/// course result in a new order, depending on the sorting order./// # Indices/// The key-value pairs are indexed in a compact range without holes in the/// range `0..self.len()`. For example, the method `.get_full` looks up the/// index for a key, and the method `.get_index` looks up the key-value pair by/// // count the frequency of each letter in a sentence./// let mut letters = IndexMap::new();///     *letters.entry(ch).or_insert(0) += 1;/// Create a new map. (Does not allocate.)/// Create a new map with capacity for `n` key-value pairs. (Does not/// allocate if `n` is zero.)/// Computes in **O(n)** time./// Create a new map with `hash_builder`./// This function is `const`, so it/// can be called in `static` contexts./// Return the number of elements the map can hold without reallocating./// This number is a lower bound; the map might be able to hold more,/// but is guaranteed to be able to hold at least this many./// Return a reference to the map's `BuildHasher`./// Return the number of key-value pairs in the map./// Returns true if the map contains no elements./// Return an iterator over the keys of the map, in their order/// Return an owning iterator over the keys of the map, in their order/// Return an iterator over the values of the map, in their order/// Return an iterator over mutable references to the values of the map,/// in their order/// Return an owning iterator over the values of the map, in their order/// Remove all key-value pairs in the map, while preserving its capacity./// Shortens the map, keeping the first `len` elements and dropping the rest./// If `len` is greater than the map's current length, this has no effect./// Clears the `IndexMap` in the given index range, returning those/// key-value pairs as a drain iterator./// The range may be any type that implements [`RangeBounds<usize>`],/// including all of the `std::ops::Range*` types, or even a tuple pair of/// `Bound` start and end values. To drain the map entirely, use `RangeFull`/// like `map.drain(..)`./// This shifts down all entries following the drained range to fill the/// gap, and keeps the allocated memory for reuse./// ***Panics*** if the starting point is greater than the end point or if/// the end point is greater than the length of the map./// Creates an iterator which uses a closure to determine if an element should be removed,/// for all elements in the given range./// If the closure returns true, the element is removed from the map and yielded./// If the closure returns false, or panics, the element remains in the map and will not be/// yielded./// `Bound` start and end values. To check the entire map, use `RangeFull`/// like `map.extract_if(.., predicate)`./// Use [`retain`] with a negated predicate if you do not need the returned iterator./// [`retain`]: IndexMap::retain/// Splitting a map into even and odd keys, reusing the original map:/// let mut map: IndexMap<i32, i32> = (0..8).map(|x| (x, x)).collect();/// let extracted: IndexMap<i32, i32> = map.extract_if(.., |k, _v| k % 2 == 0).collect();/// let evens = extracted.keys().copied().collect::<Vec<_>>();/// let odds = map.keys().copied().collect::<Vec<_>>();/// Returns a newly allocated map containing the elements in the range/// `[at, len)`. After the call, the original map will be left containing/// the elements `[0, at)` with its previous capacity unchanged./// ***Panics*** if `at > len`./// Unlike `reserve`, this does not deliberately over-allocate the entry capacity to avoid/// frequent re-allocations. However, the underlying data structures may still have internal/// capacity requirements, and the allocator itself may give more space than requested, so this/// cannot be relied upon to be precisely minimal./// Unlike `try_reserve`, this does not deliberately over-allocate the entry capacity to avoid/// Shrink the capacity of the map as much as possible./// Shrink the capacity of the map with a lower limit./// Insert a key-value pair in the map./// If an equivalent key already exists in the map: the key remains and/// retains in its place in the order, its corresponding value is updated/// with `value`, and the older value is returned inside `Some(_)`./// If no equivalent key existed in the map: the new key-value pair is/// inserted, last in order, and `None` is returned./// See also [`entry`][Self::entry] if you want to insert *or* modify,/// or [`insert_full`][Self::insert_full] if you need to get the index of/// the corresponding key-value pair./// Insert a key-value pair in the map, and get their index./// with `value`, and the older value is returned inside `(index, Some(_))`./// inserted, last in order, and `(index, None)` is returned./// See also [`entry`][Self::entry] if you want to insert *or* modify./// Insert a key-value pair in the map at its ordered position among sorted keys./// This is equivalent to finding the position with/// [`binary_search_keys`][Self::binary_search_keys], then either updating/// it or calling [`insert_before`][Self::insert_before] for a new key./// If the sorted key is found in the map, its corresponding value is/// updated with `value`, and the older value is returned inside/// `(index, Some(_))`. Otherwise, the new key-value pair is inserted at/// the sorted position, and `(index, None)` is returned./// pair is moved to or inserted at that position regardless./// Computes in **O(n)** time (average). Instead of repeating calls to/// `insert_sorted`, it may be faster to call batched [`insert`][Self::insert]/// or [`extend`][Self::extend] and only call [`sort_keys`][Self::sort_keys]/// or [`sort_unstable_keys`][Self::sort_unstable_keys] once.insert_before/// Insert a key-value pair in the map before the entry at the given index, or at the end./// is moved to the new position in the map, its corresponding value is updated/// with `value`, and the older value is returned inside `Some(_)`. The returned index/// will either be the given index or one less, depending on how the entry moved./// (See [`shift_insert`](Self::shift_insert) for different behavior here.)/// inserted exactly at the given index, and `None` is returned./// Valid indices are `0..=map.len()` (inclusive)./// perhaps only using the index for new entries with [`VacantEntry::shift_insert`]./// let mut map: IndexMap<char, ()> = ('a'..='z').map(|c| (c, ())).collect();/// // The new key '*' goes exactly at the given index./// assert_eq!(map.get_index_of(&'*'), None);/// assert_eq!(map.insert_before(10, '*', ()), (10, None));/// assert_eq!(map.get_index_of(&'*'), Some(10));/// // Moving the key 'a' up will shift others down, so this moves *before* 10 to index 9./// assert_eq!(map.insert_before(10, 'a', ()), (9, Some(())));/// assert_eq!(map.get_index_of(&'a'), Some(9));/// // Moving the key 'z' down will shift others up, so this moves to exactly 10./// assert_eq!(map.insert_before(10, 'z', ()), (10, Some(())));/// assert_eq!(map.get_index_of(&'z'), Some(10));/// assert_eq!(map.get_index_of(&'*'), Some(11));/// // Moving or inserting before the endpoint is also valid./// assert_eq!(map.len(), 27);/// assert_eq!(map.insert_before(map.len(), '*', ()), (26, Some(())));/// assert_eq!(map.get_index_of(&'*'), Some(26));/// assert_eq!(map.insert_before(map.len(), '+', ()), (27, None));/// assert_eq!(map.get_index_of(&'+'), Some(27));/// assert_eq!(map.len(), 28);/// Insert a key-value pair in the map at the given index./// is moved to the given index in the map, its corresponding value is updated/// Note that existing entries **cannot** be moved to `index == map.len()`!/// (See [`insert_before`](Self::insert_before) for different behavior here.)/// inserted at the given index, and `None` is returned./// Valid indices are `0..map.len()` (exclusive) when moving an existing entry, or/// `0..=map.len()` (inclusive) when inserting a new key./// assert_eq!(map.shift_insert(10, '*', ()), None);/// // Moving the key 'a' up to 10 will shift others down, including the '*' that was at 10./// assert_eq!(map.shift_insert(10, 'a', ()), Some(()));/// assert_eq!(map.get_index_of(&'a'), Some(10));/// assert_eq!(map.get_index_of(&'*'), Some(9));/// // Moving the key 'z' down to 9 will shift others up, including the '*' that was at 9./// assert_eq!(map.shift_insert(9, 'z', ()), Some(()));/// assert_eq!(map.get_index_of(&'z'), Some(9));/// // Existing keys can move to len-1 at most, but new keys can insert at the endpoint./// assert_eq!(map.shift_insert(map.len() - 1, '*', ()), Some(()));/// assert_eq!(map.shift_insert(map.len(), '+', ()), None);/// // This is an invalid index for moving an existing key!/// map.shift_insert(map.len(), 'a', ());/// Get the given key’s corresponding entry in the map for insertion and/or/// in-place manipulation./// Creates a splicing iterator that replaces the specified range in the map/// with the given `replace_with` key-value iterator and yields the removed/// items. `replace_with` does not need to be the same length as `range`./// The `range` is removed even if the iterator is not consumed until the/// end. It is unspecified how many elements are removed from the map if the/// `Splice` value is leaked./// The input iterator `replace_with` is only consumed when the `Splice`/// value is dropped. If a key from the iterator matches an existing entry/// in the map (outside of `range`), then the value will be updated in that/// position. Otherwise, the new key-value pair will be inserted in the/// replaced `range`./// let mut map = IndexMap::from([(0, '_'), (1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]);/// let new = [(5, 'E'), (4, 'D'), (3, 'C'), (2, 'B'), (1, 'A')];/// let removed: Vec<_> = map.splice(2..4, new).collect();/// // 1 and 4 got new values, while 5, 3, and 2 were newly inserted./// assert!(map.into_iter().eq([(0, '_'), (1, 'A'), (5, 'E'), (3, 'C'), (2, 'B'), (4, 'D')]));/// assert_eq!(removed, &[(2, 'b'), (3, 'c')]);S2/// Moves all key-value pairs from `other` into `self`, leaving `other` empty./// This is equivalent to calling [`insert`][Self::insert] for each/// key-value pair from `other` in order, which means that for keys that/// already exist in `self`, their value is updated in the current position./// // Note: Key (3) is present in both maps./// let mut a = IndexMap::from([(3, "c"), (2, "b"), (1, "a")]);/// let mut b = IndexMap::from([(3, "d"), (4, "e"), (5, "f")]);/// let old_capacity = b.capacity();/// a.append(&mut b);/// assert_eq!(a.len(), 5);/// assert_eq!(b.len(), 0);/// assert_eq!(b.capacity(), old_capacity);/// assert!(a.keys().eq(&[3, 2, 1, 4, 5]));/// assert_eq!(a[&3], "d"); // "c" was overwritten./// Return `true` if an equivalent to `key` exists in the map./// Return a reference to the value stored for `key`, if it is present,/// else `None`./// Return references to the key-value pair stored for `key`,/// if it is present, else `None`.get_full/// Return item index, key and value/// Return item index, if it exists in the mapget_full_mut/// Return the values for `N` keys. If any key is duplicated, this function will panic./// let mut map = indexmap::IndexMap::from([(1, 'a'), (3, 'b'), (2, 'c')]);/// assert_eq!(map.get_disjoint_mut([&2, &1]), [Some(&mut 'c'), Some(&mut 'a')]);/// Remove the key-value pair equivalent to `key` and return/// its value./// **NOTE:** This is equivalent to [`.swap_remove(key)`][Self::swap_remove], replacing this/// [`.shift_remove(key)`][Self::shift_remove] instead./// Remove and return the key-value pair equivalent to `key`./// **NOTE:** This is equivalent to [`.swap_remove_entry(key)`][Self::swap_remove_entry],/// use [`.shift_remove_entry(key)`][Self::shift_remove_entry] instead./// Like [`Vec::swap_remove`], the pair is removed by swapping it with the/// last element of the map and popping it off. **This perturbs/// the position of what used to be the last element!**/// Return `None` if `key` is not in map./// Remove the key-value pair equivalent to `key` and return it and/// the index it had./// Like [`Vec::remove`], the pair is removed by shifting all of the/// This preserves the order of the remaining elements.// like `BTreeMap`sort_keys/// Sort the map’s key-value pairs by the default ordering of the keys./// This is a stable sort -- but equivalent keys should not normally coexist in/// a map at all, so [`sort_unstable_keys`][Self::sort_unstable_keys] is preferred/// because it is generally faster and doesn't allocate auxiliary memory./// See [`sort_by`](Self::sort_by) for details./// Sort the map’s key-value pairs in place using the comparison/// function `cmp`./// The comparison function receives two key and value pairs to compare (you/// can sort by keys or values or their combination as needed)./// Computes in **O(n log n + c)** time and **O(n)** space where *n* is/// the length of the map and *c* the capacity. The sort is stable.sorted_by/// Sort the key-value pairs of the map and return a by-value iterator of/// the key-value pairs with the result./// The sort is stable.sort_unstable_keys/// Sort the map's key-value pairs by the default ordering of the keys, but/// may not preserve the order of equal elements./// See [`sort_unstable_by`](Self::sort_unstable_by) for details.sort_unstable_by/// Sort the map's key-value pairs in place using the comparison function `cmp`, but/// Computes in **O(n log n + c)** time where *n* is/// the length of the map and *c* is the capacity. The sort is unstable./// The sort is unstable.sort_by_cached_key/// Sort the map’s key-value pairs in place using a sort-key extraction function./// During sorting, the function is called at most once per entry, by using temporary storage/// to remember the results of its evaluation. The order of calls to the function is/// unspecified and may change between versions of `indexmap` or the standard library./// Computes in **O(m n + n log n + c)** time () and **O(n)** space, where the function is/// **O(m)**, *n* is the length of the map, and *c* the capacity. The sort is stable./// Computes in **O(log(n))** time, which is notably less scalable than looking the key up/// using [`get_index_of`][IndexMap::get_index_of], but this can also position missing keys./// Reverses the order of the map’s key-value pairs in place./// Computes in **O(n)** time and **O(1)** space./// Returns a slice of all the key-value pairs in the map./// Returns a mutable slice of all the key-value pairs in the map./// Converts into a boxed slice of all the key-value pairs in the map./// Note that this will drop the inner hash table and any excess capacity./// Get a key-value pair by index/// Get an entry in the map by index for in-place manipulation.get_disjoint_indices_mut/// assert_eq!(map.get_disjoint_indices_mut([2, 0]), Ok([(&2, &mut 'c'), (&1, &mut 'a')]));/// Get the first key-value pair/// Get the first key-value pair, with mutable access to the valuefirst_entry/// Get the first entry in the map for in-place manipulation./// Get the last key-value pair/// Get the last key-value pair, with mutable access to the valuelast_entry/// Get the last entry in the map for in-place manipulation./// Remove the key-value pair by index/// Moves the position of a key-value pair from one index to another/// by shifting all other pairs in-between./// * If `from < to`, the other pairs will shift down while the targeted pair moves up./// * If `from > to`, the other pairs will shift up while the targeted pair moves down./// ***Panics*** if `from` or `to` are out of bounds./// Swaps the position of two key-value pairs in the map./// ***Panics*** if `a` or `b` are out of bounds./// Returns a reference to the value corresponding to the supplied `key`./// ***Panics*** if `key` is not present in the map./// Access [`IndexMap`] values corresponding to a key./// assert_eq!(map["lorem"], "LOREM");/// assert_eq!(map["ipsum"], "IPSUM");/// println!("{:?}", map["bar"]); // panics!/// Returns a mutable reference to the value corresponding to the supplied `key`./// Mutable indexing allows changing / updating values of key-value/// pairs that are already present./// You can **not** insert new pairs with index syntax, use `.insert()`.///     map.insert(word.to_lowercase(), word.to_string());/// let lorem = &mut map["lorem"];/// assert_eq!(lorem, "Lorem");/// lorem.retain(char::is_lowercase);/// assert_eq!(map["lorem"], "orem");/// map["bar"] = 1; // panics!/// Returns a reference to the value at the supplied `index`./// Access [`IndexMap`] values at indexed positions./// See [`Index<usize> for Keys`][keys] to access a map's keys instead./// [keys]: Keys#impl-Index<usize>-for-Keys<'a,+K,+V>/// assert_eq!(map[0], "AMET");/// assert_eq!(map[1], "SIT");/// assert_eq!(map[1], "DOLOR");/// println!("{:?}", map[10]); // panics!/// Returns a mutable reference to the value at the supplied `index`./// Mutable indexing allows changing / updating indexed values/// that are already present./// You can **not** insert new values with index syntax -- use [`.insert()`][IndexMap::insert]./// let lorem = &mut map[0];/// map[10] = 1; // panics!/// Create an `IndexMap` from the sequence of key-value pairs in the/// iterable./// `from_iter` uses the same logic as `extend`. See/// [`extend`][IndexMap::extend] for more details./// let map1 = IndexMap::from([(1, 2), (3, 4)]);/// let map2: IndexMap<_, _> = [(1, 2), (3, 4)].into();/// Extend the map with all key-value pairs in the iterable./// This is equivalent to calling [`insert`][IndexMap::insert] for each of/// them in order, which means that for keys that already existed/// in the map, their value is updated but it keeps the existing order./// New keys are inserted in the order they appear in the sequence. If/// equivalents of a key occur more than once, the last corresponding value/// prevails./// See the first extend method for more details./// Return an empty [`IndexMap`]S1/// A parallel owning iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::into_par_iter`] method/// (provided by rayon's [`IntoParallelIterator`] trait). See its documentation for more.parallel_iterator_methodsindexed_parallel_iterator_methods/// A parallel iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::par_iter`] method/// (provided by rayon's [`IntoParallelRefIterator`] trait). See its documentation for more./// [`IndexMap::par_iter`]: ../struct.IndexMap.html#method.par_iter/// A parallel mutable iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::par_iter_mut`] method/// (provided by rayon's [`IntoParallelRefMutIterator`] trait). See its documentation for more./// [`IndexMap::par_iter_mut`]: ../struct.IndexMap.html#method.par_iter_mutParallelDrainRange/// A parallel draining iterator over the entries of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::par_drain`] method/// (provided by rayon's [`ParallelDrainRange`] trait). See its documentation for more./// [`IndexMap::par_drain`]: ../struct.IndexMap.html#method.par_drain/// Return a parallel iterator over the keys of the map./// While parallel iterators can process items in any order, their relative order/// in the map is still preserved for operations like `reduce` and `collect`./// Return a parallel iterator over the values of the map./// Parallel iterator methods and other parallel methods./// The following methods **require crate feature `"rayon"`**./// See also the `IntoParallelIterator` implementations./// Return a parallel iterator over the keys of the map slice./// in the slice is still preserved for operations like `reduce` and `collect`./// Return a parallel iterator over the values of the map slice./// Returns `true` if `self` contains all of the same key-value pairs as `other`,/// regardless of each map's indexed order, determined in parallel./// A parallel iterator over the keys of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::par_keys`] method./// A parallel iterator over the values of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::par_values`] method./// Return a parallel iterator over mutable references to the values of the map/// Return a parallel iterator over mutable references to the the values of the map slice.par_sort_keys/// Sort the map’s key-value pairs in parallel, by the default ordering of the keys.par_sort_by/// Sort the map’s key-value pairs in place and in parallel, using the comparisonpar_sorted_by/// Sort the key-value pairs of the map in parallel and return a by-value parallel/// iterator of the key-value pairs with the result.par_sort_unstable_keys/// Sort the map's key-value pairs in parallel, by the default ordering of the keys.par_sort_unstable_by/// Sort the map's key-value pairs in place and in parallel, using the comparisonpar_sorted_unstable_bypar_sort_by_cached_key/// Sort the map’s key-value pairs in place and in parallel, using a sort-key extraction/// A parallel mutable iterator over the values of an [`IndexMap`]./// This `struct` is created by the [`IndexMap::par_values_mut`] method.//! Parallel iterator types for [`IndexMap`] with [`rayon`][::rayon].//! You will rarely need to interact with this module directly unless you need to name one of the//! iterator types.// This form of intermediate collection is also how Rayon collects `HashMap`.// Note that the order will also be preserved!/// A parallel owning iterator over the items of an [`IndexSet`]./// This `struct` is created by the [`IndexSet::into_par_iter`] method/// A parallel iterator over the items of an [`IndexSet`]./// This `struct` is created by the [`IndexSet::par_iter`] method/// [`IndexSet::par_iter`]: ../struct.IndexSet.html#method.par_iter/// A parallel draining iterator over the items of an [`IndexSet`]./// This `struct` is created by the [`IndexSet::par_drain`] method/// [`IndexSet::par_drain`]: ../struct.IndexSet.html#method.par_drain/// Return a parallel iterator over the values that are in `self` but not `other`./// in the `self` set is still preserved for operations like `reduce` and `collect`./// Return a parallel iterator over the values that are in `self` or `other`,/// but not in both./// in the sets is still preserved for operations like `reduce` and `collect`./// Values from `self` are produced in their original order, followed by/// values from `other` in their original order./// Return a parallel iterator over the values that are in both `self` and `other`./// Return a parallel iterator over all values that are in `self` or `other`./// values that are unique to `other` in their original order./// Returns `true` if `self` contains all of the same values as `other`,/// regardless of each set's indexed order, determined in parallel./// Returns `true` if `self` has no elements in common with `other`,/// determined in parallel./// Returns `true` if all elements of `other` are contained in `self`,/// Returns `true` if all elements of `self` are contained in `other`,set2/// A parallel iterator producing elements in the difference of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::par_difference`] method./// A parallel iterator producing elements in the intersection of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::par_intersection`] method./// A parallel iterator producing elements in the symmetric difference of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::par_symmetric_difference`] method./// A parallel iterator producing elements in the union of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::par_union`] method.par_sort/// Sort the set’s values in parallel by their default ordering./// Sort the set’s values in place and in parallel, using the comparison function `cmp`./// Sort the values of the set in parallel and return a by-value parallel iterator of/// the values with the result.par_sort_unstable/// Sort the set's values in parallel by their default ordering./// Sort the set’s values in place and in parallel, using a key extraction function./// Parallel sorting methods.comparisonsiter_comparisons//! Parallel iterator types for [`IndexSet`] with [rayon][::rayon].MapDeserializerSeqDeserializer/// Limit our preallocated capacity from a deserializer `size_hint()`./// We do account for the `Bucket` overhead from its saved `hash` field, but we don't count the/// `RawTable` allocation or the fact that its raw capacity will be rounded up to a power of two./// The "max" is an arbitrary choice anyway, not something that needs precise adherence./// This is based on the internal `serde::de::size_hint::cautious(hint)` function.IndexMapVisitorinto_deserializerIndexSetVisitor/// An iterator over the items of an [`IndexSet`]./// This `struct` is created by the [`IndexSet::iter`] method./// An owning iterator over the items of an [`IndexSet`]./// This `struct` is created by the [`IndexSet::into_iter`] method/// A draining iterator over the items of an [`IndexSet`]./// This `struct` is created by the [`IndexSet::drain`] method./// A lazy iterator producing elements in the difference of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::difference`] method./// A lazy iterator producing elements in the intersection of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::intersection`] method./// A lazy iterator producing elements in the symmetric difference of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::symmetric_difference`] method./// A lazy iterator producing elements in the union of [`IndexSet`]s./// This `struct` is created by the [`IndexSet::union`] method.UnitValue/// A splicing iterator for `IndexSet`./// This `struct` is created by [`IndexSet::splice()`]./// An extracting iterator for `IndexSet`./// This `struct` is created by [`IndexSet::extract_if()`]./// Return item index and mutable reference to the value/// Return mutable reference to the value at an index./// Scan through each value in the set and keep those where the/// The values are visited in order, and remaining values keep their order.MutableValues/// Opt-in mutable access to [`IndexSet`] values./// These methods expose `&mut T`, mutable references to the value as it is stored/// in the set./// You are allowed to modify the values in the set **if the modification/// does not change the value’s hash and equality**./// If values are modified erroneously, you can no longer look them up./// `use` this trait to enable its methods for `IndexSet`./// See [`MutableValues`] for more information./// A dynamically-sized slice of values in an [`IndexSet`]./// This supports indexed operations much like a `[T]` slice,/// but not any hashed operations on the values./// Unlike `IndexSet`, `Slice` does consider the order for [`PartialEq`]// SAFETY: `Slice<T>` is a transparent wrapper around `[Bucket<T>]`,/// Return the number of elements in the set slice./// Returns true if the set slice contains no elements./// Get a value by index./// Returns a slice of values in the given range of indices./// Get the first value./// Get the last value./// Returns the first value and the rest of the slice,/// Returns the last value and the rest of the slice,/// Return an iterator over the values of the set slice./// Search over a sorted set for a value./// to maintain the sort. See [`slice::binary_search`] for more details./// Computes in **O(log(n))** time, which is notably less scalable than looking the value up in/// the set this is a slice from using [`IndexSet::get_index_of`], but this can also position/// missing values./// Search over a sorted set with a comparator function./// Search over a sorted set with an extraction function./// Returns the index of the partition point of a sorted set according to the given predicate// We can't have `impl<I: RangeBounds<usize>> Index<I>` because that conflicts with `Index<usize>`.insert_dupreplace_2replace_dupreplace_orderreplace_changeswap_takesort_unstableshift_take/// A hash set where the iteration order of the values is independent of their/// hash values./// [`HashSet`][std::collections::HashSet],/// The values have a consistent order that is determined by the sequence of/// insertion and removal calls on the set. The order does not depend on the/// values or the hash function at all. Note that insertion order and value/// are not affected if a re-insertion is attempted once an element is/// already present./// All iterators traverse the set *in order*.  Set operation iterators like/// [`IndexSet::union`] produce a concatenated order, as do their matching "bitwise"/// operators.  See their documentation for specifics./// The values are indexed in a compact range without holes in the range/// `0..self.len()`. For example, the method `.get_full` looks up the index for/// a value, and the method `.get_index` looks up the value by index./// # Complexity/// Internally, `IndexSet<T, S>` just holds an [`IndexMap<T, (), S>`](IndexMap). Thus the complexity/// of the two are the same for most methods./// use indexmap::IndexSet;/// // Collects which letters appear in a sentence./// let letters: IndexSet<_> = "a short treatise on fungi".chars().collect();/// assert!(letters.contains(&'s'));/// assert!(letters.contains(&'t'));/// assert!(letters.contains(&'u'));/// assert!(!letters.contains(&'y'));/// Create a new set. (Does not allocate.)/// Create a new set with capacity for `n` elements./// (Does not allocate if `n` is zero.)/// Create a new set with `hash_builder`./// Return the number of elements the set can hold without reallocating./// This number is a lower bound; the set might be able to hold more,/// Return a reference to the set's `BuildHasher`./// Return the number of elements in the set./// Returns true if the set contains no elements./// Return an iterator over the values of the set, in their order/// Remove all elements in the set, while preserving its capacity./// Shortens the set, keeping the first `len` elements and dropping the rest./// If `len` is greater than the set's current length, this has no effect./// Clears the `IndexSet` in the given index range, returning those values/// as a drain iterator./// `Bound` start and end values. To drain the set entirely, use `RangeFull`/// like `set.drain(..)`./// the end point is greater than the length of the set./// Creates an iterator which uses a closure to determine if a value should be removed,/// for all values in the given range./// If the closure returns true, then the value is removed and yielded./// If the closure returns false, the value will remain in the list and will not be yielded/// by the iterator./// `Bound` start and end values. To check the entire set, use `RangeFull`/// like `set.extract_if(.., predicate)`./// [`retain`]: IndexSet::retain/// Splitting a set into even and odd values, reusing the original set:/// let mut set: IndexSet<i32> = (0..8).collect();/// let extracted: IndexSet<i32> = set.extract_if(.., |v| v % 2 == 0).collect();/// let evens = extracted.into_iter().collect::<Vec<_>>();/// let odds = set.into_iter().collect::<Vec<_>>();/// Returns a newly allocated set containing the elements in the range/// `[at, len)`. After the call, the original set will be left containing/// Reserve capacity for `additional` more values./// Reserve capacity for `additional` more values, without over-allocating./// Try to reserve capacity for `additional` more values./// Try to reserve capacity for `additional` more values, without over-allocating./// Shrink the capacity of the set as much as possible./// Shrink the capacity of the set with a lower limit./// Insert the value into the set./// If an equivalent item already exists in the set, it returns/// `false` leaving the original value in the set and without/// altering its insertion order. Otherwise, it inserts the new/// item and returns `true`./// Insert the value into the set, and get its index./// the index of the existing item and `false`, leaving the/// original value in the set and without altering its insertion/// order. Otherwise, it inserts the new item and returns the index/// of the inserted item and `true`./// Insert the value into the set at its ordered position among sorted values./// [`binary_search`][Self::binary_search], and if needed calling/// [`insert_before`][Self::insert_before] for a new value./// If the sorted item is found in the set, it returns the index of that/// existing item and `false`, without any change. Otherwise, it inserts the/// new item and returns its sorted index and `true`./// If the existing items are **not** already sorted, then the insertion/// index is unspecified (like [`slice::binary_search`]), but the value/// is moved to or inserted at that position regardless./// or [`extend`][Self::extend] and only call [`sort`][Self::sort] or/// [`sort_unstable`][Self::sort_unstable] once./// Insert the value into the set before the value at the given index, or at the end./// If an equivalent item already exists in the set, it returns `false` leaving the/// original value in the set, but moved to the new position. The returned index/// will either be the given index or one less, depending on how the value moved./// Otherwise, it inserts the new value exactly at the given index and returns `true`./// Valid indices are `0..=set.len()` (inclusive)./// let mut set: IndexSet<char> = ('a'..='z').collect();/// // The new value '*' goes exactly at the given index./// assert_eq!(set.get_index_of(&'*'), None);/// assert_eq!(set.insert_before(10, '*'), (10, true));/// assert_eq!(set.get_index_of(&'*'), Some(10));/// // Moving the value 'a' up will shift others down, so this moves *before* 10 to index 9./// assert_eq!(set.insert_before(10, 'a'), (9, false));/// assert_eq!(set.get_index_of(&'a'), Some(9));/// // Moving the value 'z' down will shift others up, so this moves to exactly 10./// assert_eq!(set.insert_before(10, 'z'), (10, false));/// assert_eq!(set.get_index_of(&'z'), Some(10));/// assert_eq!(set.get_index_of(&'*'), Some(11));/// assert_eq!(set.len(), 27);/// assert_eq!(set.insert_before(set.len(), '*'), (26, false));/// assert_eq!(set.get_index_of(&'*'), Some(26));/// assert_eq!(set.insert_before(set.len(), '+'), (27, true));/// assert_eq!(set.get_index_of(&'+'), Some(27));/// assert_eq!(set.len(), 28);/// Insert the value into the set at the given index./// If an equivalent item already exists in the set, it returns `false` leaving/// the original value in the set, but moved to the given index./// Note that existing values **cannot** be moved to `index == set.len()`!/// Otherwise, it inserts the new value at the given index and returns `true`./// Valid indices are `0..set.len()` (exclusive) when moving an existing value, or/// `0..=set.len()` (inclusive) when inserting a new value./// assert_eq!(set.shift_insert(10, '*'), true);/// // Moving the value 'a' up to 10 will shift others down, including the '*' that was at 10./// assert_eq!(set.shift_insert(10, 'a'), false);/// assert_eq!(set.get_index_of(&'a'), Some(10));/// assert_eq!(set.get_index_of(&'*'), Some(9));/// // Moving the value 'z' down to 9 will shift others up, including the '*' that was at 9./// assert_eq!(set.shift_insert(9, 'z'), false);/// assert_eq!(set.get_index_of(&'z'), Some(9));/// // Existing values can move to len-1 at most, but new values can insert at the endpoint./// assert_eq!(set.shift_insert(set.len() - 1, '*'), false);/// assert_eq!(set.shift_insert(set.len(), '+'), true);/// // This is an invalid index for moving an existing value!/// set.shift_insert(set.len(), 'a');/// Adds a value to the set, replacing the existing value, if any, that is/// equal to the given one, without altering its insertion order. Returns/// the replaced value./// the index of the item and its replaced value./// Return an iterator over the values that are in `self` but not `other`./// Values are produced in the same order that they appear in `self`./// Return an iterator over the values that are in `self` or `other`,/// Return an iterator over the values that are in both `self` and `other`./// Return an iterator over all values that are in `self` or `other`./// Creates a splicing iterator that replaces the specified range in the set/// end. It is unspecified how many elements are removed from the set if the/// value is dropped. If a value from the iterator matches an existing entry/// in the set (outside of `range`), then the original will be unchanged./// Otherwise, the new value will be inserted in the replaced `range`./// let mut set = IndexSet::from([0, 1, 2, 3, 4]);/// let new = [5, 4, 3, 2, 1];/// let removed: Vec<_> = set.splice(2..4, new).collect();/// // 1 and 4 kept their positions, while 5, 3, and 2 were newly inserted./// assert!(set.into_iter().eq([0, 1, 5, 3, 2, 4]));/// assert_eq!(removed, &[2, 3]);/// Moves all values from `other` into `self`, leaving `other` empty./// This is equivalent to calling [`insert`][Self::insert] for each value/// from `other` in order, which means that values that already exist/// in `self` are unchanged in their current position./// See also [`union`][Self::union] to iterate the combined values by/// reference, without modifying `self` or `other`./// let mut a = IndexSet::from([3, 2, 1]);/// let mut b = IndexSet::from([3, 4, 5]);/// assert!(a.iter().eq(&[3, 2, 1, 4, 5]));/// Return `true` if an equivalent to `value` exists in the set./// Return a reference to the value stored in the set, if it is present,/// Return item index and value/// Return item index, if it exists in the set/// Remove the value from the set, and return `true` if it was present./// **NOTE:** This is equivalent to [`.swap_remove(value)`][Self::swap_remove], replacing this/// value's position with the last element, and it is deprecated in favor of calling that/// explicitly. If you need to preserve the relative order of the values in the set, use/// [`.shift_remove(value)`][Self::shift_remove] instead./// Like [`Vec::swap_remove`], the value is removed by swapping it with the/// last element of the set and popping it off. **This perturbs/// Return `false` if `value` was not in the set./// Like [`Vec::remove`], the value is removed by shifting all of the/// Removes and returns the value in the set, if any, that is equal to the/// given one./// **NOTE:** This is equivalent to [`.swap_take(value)`][Self::swap_take], replacing this/// [`.shift_take(value)`][Self::shift_take] instead./// Return `None` if `value` was not in the set./// Remove the value from the set return it and the index it had./// Remove the last value// like `BTreeSet`/// Sort the set’s values by their default ordering./// This is a stable sort -- but equivalent values should not normally coexist in/// a set at all, so [`sort_unstable`][Self::sort_unstable] is preferred/// Sort the set’s values in place using the comparison function `cmp`./// Computes in **O(n log n)** time and **O(n)** space. The sort is stable./// Sort the values of the set and return a by-value iterator of/// Sort the set's values by their default ordering./// Sort the set's values in place using the comparison function `cmp`./// Computes in **O(n log n)** time. The sort is unstable./// Sort the set’s values in place using a key extraction function./// Computes in **O(log(n))** time, which is notably less scalable than looking the value up/// using [`get_index_of`][IndexSet::get_index_of], but this can also position missing values./// Reverses the order of the set’s values in place./// Returns a slice of all the values in the set./// Converts into a boxed slice of all the values in the set./// Get a value by index/// Get the first value/// Get the last value/// Remove the value by index/// Moves the position of a value from one index to another/// by shifting all other values in-between./// * If `from < to`, the other values will shift down while the targeted value moves up./// * If `from > to`, the other values will shift up while the targeted value moves down./// Swaps the position of two values in the set./// Access [`IndexSet`] values at indexed positions./// let mut set = IndexSet::new();///     set.insert(word.to_string());/// assert_eq!(set[0], "Lorem");/// assert_eq!(set[1], "ipsum");/// set.reverse();/// assert_eq!(set[0], "amet");/// assert_eq!(set[1], "sit");/// set.sort();/// assert_eq!(set[1], "amet");/// set.insert("foo");/// println!("{:?}", set[10]); // panics!/// let set1 = IndexSet::from([1, 2, 3, 4]);/// let set2: IndexSet<_> = [1, 2, 3, 4].into();/// Return an empty [`IndexSet`]/// Returns `true` if all elements of `self` are contained in `other`./// Returns `true` if all elements of `other` are contained in `self`./// Returns the set intersection, cloned into a new set./// Values are collected in the same order that they appear in `self`./// Returns the set union, cloned into a new set./// Values from `self` are collected in their original order, followed by/// Returns the set symmetric-difference, cloned into a new set./// Returns the set difference, cloned into a new set.//! A hash set implemented using [`IndexMap`]// Generic slice equality -- copied from the standard library but adding a custom comparator,// allowing for our `Bucket` wrapper on either or both sides."iterator adaptors are lazy and do nothing unless consumed"CoalesceByclone_fieldsdebug_fmt_fieldscoalesce_pairCoalescePredicateFnAccCoalesce/// An iterator adaptor that may join together adjacent elements./// See [`.coalesce()`](crate::Itertools::coalesce) for more information.coalesce/// Create a new `Coalesce`.PredDedupByDedupPred2CoalescePred/// An iterator adaptor that removes repeated duplicates, determining equality using a comparison function./// See [`.dedup_by()`](crate::Itertools::dedup_by) or [`.dedup()`](crate::Itertools::dedup) for more information.DPdedup_pair// TODO replace by Fn(&T, &T)->bool once Rust supports itDedupPredicateDedupEq/// Create a new `DedupBy`.Dedup/// An iterator adaptor that removes repeated duplicates./// See [`.dedup()`](crate::Itertools::dedup) for more information./// Create a new `Dedup`.DedupByWithCountDedupPredWithCount2CoalescePred/// An iterator adaptor that removes repeated duplicates, while keeping a count of how many/// repeated elements were present. This will determine equality using a comparison function./// See [`.dedup_by_with_count()`](crate::Itertools::dedup_by_with_count) or/// [`.dedup_with_count()`](crate::Itertools::dedup_with_count) for more information.DedupWithCount/// repeated elements were present./// See [`.dedup_with_count()`](crate::Itertools::dedup_with_count) for more information.dedup_by_with_count/// Create a new `DedupByWithCount`.dedup_with_count/// Create a new `DedupWithCount`.MapSpecialCaseOutMapSpecialCaseFnFoldMapOkMapSpecialCaseFnOk/// An iterator adapter to apply a transformation within a nested `Result::Ok`./// See [`.map_ok()`](crate::Itertools::map_ok) for more information.MapResults/// See [`MapOk`].map_ok/// Create a new `MapOk` iterator.MapIntoMapSpecialCaseFnInto/// An iterator adapter to apply `Into` conversion to each element./// See [`.map_into()`](crate::Itertools::map_into) for more information.map_into/// Create a new [`MapInto`] iterator.multi_productFusePeekableInterleave/// An iterator adaptor that alternates elements from two iterators until both/// run out./// This iterator is *fused*./// See [`.interleave()`](crate::Itertools::interleave) for more information.interleave/// Create an iterator that interleaves elements in `i` and `j`./// [`IntoIterator`] enabled version of `[Itertools::interleave]`.it0it1phase// false ==> it0, true ==> it1InterleaveShortest/// An iterator adaptor that alternates elements from the two iterators until/// one of them runs out./// See [`.interleave_shortest()`](crate::Itertools::interleave_shortest)interleave_shortest/// Create a new `InterleaveShortest` iterator.topPutBack/// An iterator adaptor that allows putting back a single/// item to the front of the iterator./// Iterator element type is `I::Item`.put_back/// Create an iterator where you can put back a single itemwith_value/// put back value `value` (builder method)into_parts/// Split the `PutBack` into its parts./// Put back a single value to the front of the iterator./// If a value is already in the put back slot, it is overwritten.a_curb_orig/// An iterator adaptor that iterates over the cartesian product of/// the element sets of two iterators `I` and `J`./// Iterator element type is `(I::Item, J::Item)`./// See [`.cartesian_product()`](crate::Itertools::cartesian_product) for more information.cartesian_product/// Create a new cartesian product iteratorBatching/// A “meta iterator adaptor”. Its closure receives a reference to the iterator/// and may pick off as many elements as it likes, to produce the next iterator element./// Iterator element type is *X*, if the return type of `F` is *Option\<X\>*./// See [`.batching()`](crate::Itertools::batching) for more information.batching/// Create a new Batching iterator.Step/// An iterator adaptor that steps a number elements in the base iterator/// for each iteration./// The iterator steps by yielding the next element from the base iterator,/// then skipping forward *n-1* elements./// See [`.step()`](crate::Itertools::step) for more information./// Create a `Step` iterator./// **Panics** if the step is 0.// known sizemerge_predMergePredicateMergeLteMergeBy/// An iterator adaptor that merges the two base iterators in ascending order./// If both base iterators are sorted (ascending), the result is sorted./// See [`.merge()`](crate::Itertools::merge_by) for more information./// Create an iterator that merges elements in `i` and `j`./// [`IntoIterator`] enabled version of [`Itertools::merge`](crate::Itertools::merge)./// use itertools::merge;/// for elt in merge(&[1, 2, 3], &[2, 3, 4]) {///     /* loop body */fused/// See [`.merge_by()`](crate::Itertools::merge_by) for more information.merge_by_new/// Create a `MergeBy` iterator.TakeWhileRef/// An iterator adaptor that borrows from a `Clone`-able iterator/// to only pick off elements while the predicate returns `true`./// See [`.take_while_ref()`](crate::Itertools::take_while_ref) for more information.take_while_ref/// Create a new `TakeWhileRef` from a reference to clonable iterator.WhileSome/// An iterator adaptor that filters `Option<A>` iterator elements/// and produces `A`. Stops on the first `None` encountered./// See [`.while_some()`](crate::Itertools::while_some) for more information.while_some/// Create a new `WhileSome<I>`.Combination_miTupleCombinationsHasCombination/// An iterator to iterate through all combinations in a `Clone`-able iterator that produces tuples/// of a specific size./// See [`.tuple_combinations()`](crate::Itertools::tuple_combinations) for moretuple_combinations/// Create a new `TupleCombinations` from a clonable iterator.Tuple1Combinationimpl_tuple_combinationcTuple2Combinationignore_ident// This snippet generates the twelve `impl_tuple_combination!` invocations://    use core::iter;//    use itertools::Itertools;//    for i in 2..=12 {//        println!("impl_tuple_combination!(Tuple{arity}Combination Tuple{prev}Combination; {idents});",//            arity = i,//            prev = i - 1,//            idents = ('a'..'z').take(i - 1).join(" "),//        );// It could probably be replaced by a bit more macro cleverness.Tuple3CombinationTuple4CombinationTuple5CombinationTuple6CombinationTuple7CombinationTuple8CombinationTuple9CombinationTuple10CombinationTuple11CombinationTuple12CombinationFilterOk/// An iterator adapter to filter values within a nested `Result::Ok`./// See [`.filter_ok()`](crate::Itertools::filter_ok) for more information.filter_ok/// Create a new `FilterOk` iterator.FilterMapOk/// An iterator adapter to filter and apply a transformation on values within a nested `Result::Ok`./// See [`.filter_map_ok()`](crate::Itertools::filter_map_ok) for more information.transpose_resultfilter_map_okPositions/// An iterator adapter to get the positions of each element that matches a predicate./// See [`.positions()`](crate::Itertools::positions) for more information.positions/// Create a new `Positions` iterator./// An iterator adapter to apply a mutating function to each element before yielding it./// See [`.update()`](crate::Itertools::update) for more information./// Create a new `Update` iterator.// if possible, re-use inner iterator specializations in collect//! Licensed under the Apache License, Version 2.0//! <https://www.apache.org/licenses/LICENSE-2.0> or the MIT license//! <https://opensource.org/licenses/MIT>, at your//! option. This file may not be copied, modified, or distributed//! except according to those terms.MultiProductIterMultiProduct/// multiple iterators of type `I`./// An iterator element type is `Vec<I>`./// See [`.multi_cartesian_product()`](crate::Itertools::multi_cartesian_product)multi_cartesian_product/// Create a new cartesian product iterator over an arbitrary number/// of iterators of the same type./// Iterator element is of type `Vec<H::Item::Item>`.curiter_orig/// Holds the state of a single iterator within a `MultiProduct`.MultiProductIterStateStartOfIteron_first_iterMidIter/// Holds the current state during an iteration of a `MultiProduct`.iterate_last/// Iterates the rightmost iterator, then recursively iterates iterators/// to the left if necessary./// Returns true if the iteration succeeded, else false.curr_iterator/// Returns the unwrapped value of the next iteration.in_progress/// Returns true if iteration has started and has not yet finished; falseiterate/// Iterate the managed iterator./// Reset the managed iterator./// Returns true if the current iterator has been started and has not yet/// finished; false otherwise.lazy_bufferCombinations/// An iterator to iterate through all the `k`-length combinations in an iterator./// See [`.combinations()`](crate::Itertools::combinations) for more information.combinations/// Create a new `Combinations` from a clonable iterator./// Returns the length of a combination produced by this iterator./// Returns the (current) length of the pool from which combination elements are/// selected. This value can change between invocations of [`next`](Combinations::next)./// Returns a reference to the source iterator./// Resets this `Combinations` back to an initial state for combinations of length/// `k` over the same pool data source. If `k` is larger than the current length/// of the data pool an attempt is made to prefill the pool so that it holds `k`CombinationsWithReplacement/// An iterator to iterate through all the `n`-length combinations in an iterator, with replacement./// See [`.combinations_with_replacement()`](crate::Itertools::combinations_with_replacement)/// Map the current mask over the pool to get an output combinationcombinations_with_replacement/// Create a new `CombinationsWithReplacement` from a clonable iterator./// Combine all an iterator's elements into one element by using [`Extend`]./// [`IntoIterator`]-enabled version of [`Itertools::concat`]./// This combinator will extend the first item with each of the rest of the/// items of the iterator. If the iterator is empty, the default value of/// `I::Item` is returned./// use itertools::concat;/// let input = vec![vec![1], vec![2, 3], vec![4, 5, 6]];/// assert_eq!(concat(input), vec![1, 2, 3, 4, 5, 6]);impl_cons_iter// stopConsTuples/// An iterator that maps an iterator of tuples like/// `((A, B), C)` to an iterator of `(A, B, C)`./// Used by the `iproduct!()` macro.cons_tuples/// Create an iterator that maps for example iterators of/// `((A, B), C)` to `(A, B, C)`.FirstMismatch/// The index of the first non-matching element along with both iterator's remaining elements/// starting with the first mis-match./// The total number of elements that were in `J` along with the remaining elements of `I`./// The total number of elements that were in `I` along with the remaining elements of `J`./// A type returned by the [`diff_with`] function./// `Diff` represents the way in which the elements yielded by the iterator `I` differ to some/// iterator `J`.diff_with/// Compares every element yielded by both `i` and `j` with the given function in lock-step and/// returns a [`Diff`] which describes how `j` differs from `i`./// If the number of elements yielded by `j` is less than the number of elements yielded by `i`,/// the number of `j` elements yielded will be returned along with `i`'s remaining elements as/// `Diff::Shorter`./// If the two elements of a step differ, the index of those elements along with the remaining/// elements of both `i` and `j` are returned as `Diff::FirstMismatch`./// If `i` becomes exhausted before `j` becomes exhausted, the number of elements in `i` along with/// the remaining `j` elements will be returned as `Diff::Longer`.//! "Diff"ing iterators for caching elements to sequential collections without requiring the new//! elements' iterator to be `Clone`.//! - [`Diff`] (produced by the [`diff_with`] function)//! describes the difference between two non-`Clone` iterators `I` and `J` after breaking ASAP from//! a lock-step comparison.DuplicatesByusedpendingkey_methodKeyMethod/// Takes an item and returns it back to the caller if it's the second time we see it./// Otherwise the item is consumed and None is returnedContainerKeyXorValuemake/// A keying method for use with `DuplicatesBy`ById/// Apply the identity function to elements before checking them for equality.JustValueByFn/// Apply a user-supplied function to elements before checking them for equality.KeyValue// Implementors of this trait can hold onto a key and a value but only give access to one of them// at a time. This allows the key and the value to be the same value internally/// An iterator adapter to filter for duplicate elements./// See [`.duplicates_by()`](crate::Itertools::duplicates_by) for more information.duplicates_by/// Create a new `DuplicatesBy` iterator.Duplicates/// An iterator adapter to filter out duplicate elements./// See [`.duplicates()`](crate::Itertools::duplicates) for more information.duplicates/// Create a new `Duplicates` iterator.EitherOrBoth/// Both values are present./// Only the left value of type `A` is present./// Only the right value of type `B` is present./// Value that either holds a single A or B, or both.has_left/// If `Left`, or `Both`, return true, otherwise, return false.has_right/// If `Right`, or `Both`, return true, otherwise, return false./// If Left, return true otherwise, return false./// Exclusive version of [`has_left`](EitherOrBoth::has_left)./// If Right, return true otherwise, return false./// Exclusive version of [`has_right`](EitherOrBoth::has_right).is_both/// Equivalent to `self.as_ref().both().is_some()`./// If `Left`, or `Both`, return `Some` with the left value, otherwise, return `None`./// If `Right`, or `Both`, return `Some` with the right value, otherwise, return `None`.both/// If Both, return `Some` tuple containing left and right./// Converts from `&EitherOrBoth<A, B>` to `EitherOrBoth<&A, &B>`./// Converts from `&mut EitherOrBoth<A, B>` to `EitherOrBoth<&mut A, &mut B>`./// Convert `EitherOrBoth<A, B>` to `EitherOrBoth<B, A>`./// Apply the function `f` on the value `a` in `Left(a)` or `Both(a, b)` variants. If it is/// present rewrapping the result in `self`'s original variant./// Apply the function `f` on the value `b` in `Right(b)` or `Both(a, b)` variants./// If it is present rewrapping the result in `self`'s original variant.map_any/// Apply the functions `f` and `g` on the value `a` and `b` respectively;/// found in `Left(a)`, `Right(b)`, or `Both(a, b)` variants./// The Result is rewrapped `self`'s original variant./// Apply the function `f` on the value `a` in `Left(a)` or `Both(a, _)` variants if it is/// present./// Apply the function `f` on the value `b`/// in `Right(b)` or `Both(_, b)` variants if it is present./// Returns a tuple consisting of the `l` and `r` in `Both(l, r)`, if present./// Otherwise, returns the wrapped value for the present element, and the supplied/// value for the other. The first (`l`) argument is used for a missing `Left`/// value. The second (`r`) argument is used for a missing `Right` value./// Arguments passed to `or` are eagerly evaluated; if you are passing/// the result of a function call, it is recommended to use [`or_else`],/// which is lazily evaluated./// [`or_else`]: EitherOrBoth::or_else/// # use itertools::EitherOrBoth;/// assert_eq!(EitherOrBoth::Both("tree", 1).or("stone", 5), ("tree", 1));/// assert_eq!(EitherOrBoth::Left("tree").or("stone", 5), ("tree", 5));/// assert_eq!(EitherOrBoth::Right(1).or("stone", 5), ("stone", 1));/// Otherwise, returns the wrapped value for the present element, and the [`default`](Default::default)/// for the other./// Otherwise, returns the wrapped value for the present element, and computes the/// missing value with the supplied closure. The first argument (`l`) is used for a/// missing `Left` value. The second argument (`r`) is used for a missing `Right` value./// let k = 10;/// assert_eq!(EitherOrBoth::Both("tree", 1).or_else(|| "stone", || 2 * k), ("tree", 1));/// assert_eq!(EitherOrBoth::Left("tree").or_else(|| "stone", || 2 * k), ("tree", 20));/// assert_eq!(EitherOrBoth::Right(1).or_else(|| "stone", || 2 * k), ("stone", 1));/// Return either value of left, right, or the product of `f` applied where `Both` are present.first_twoExactlyOneError/// Iterator returned for the error case of `IterTools::exactly_one()`/// This iterator yields exactly the same elements as the input iterator./// During the execution of `exactly_one` the iterator must be mutated.  This wrapper/// effectively "restores" the state of the input iterator when it's handed back./// This is very similar to `PutBackN` except this iterator only supports 0-2 elements and does not/// use a `Vec`./// Creates a new `ExactlyOneErr` iterator.additional_lenComparemin_set_impl/// Implementation guts for `min_set`, `min_set_by`, and `min_set_by_key`.max_set_impl/// Implementation guts for `ax_set`, `max_set_by`, and `max_set_by_key`.flatten_okFlattenOkinner_frontinner_back/// An iterator adaptor that flattens `Result::Ok` values and/// allows `Result::Err` values through unchanged./// See [`.flatten_ok()`](crate::Itertools::flatten_ok) for more information./// Only the iterator being flattened needs to implement [`FusedIterator`].sep/// FormatWith uses interior mutability because Display::fmt takes &self.FormatWith/// Format all iterator elements lazily, separated by `sep`./// The format value can only be formatted once, after that the iterator is/// exhausted./// See [`.format_with()`](crate::Itertools::format_with) for more information./// Format uses interior mutability because Display::fmt takes &self.Format/// See [`.format()`](crate::Itertools::format)new_formatnew_format_defaultimpl_formatZipVecIntoIterintersperseIntersperseIntersperseWithadaptorsput_back_n_implput_back_nmultipeek_implmultipeekpeek_nthkmerge_implkmergezip_eq_implzip_eqmerge_joinmerge_join_byrciter_implrciter/// Iterate `iterable` with a particular value inserted between each element./// [`IntoIterator`] enabled version of [`Iterator::intersperse`]./// use itertools::intersperse;/// itertools::assert_equal(intersperse((0..3), 8), vec![0, 8, 1, 8, 2]);intersperse_with/// Iterate `iterable` with a particular value created by a function inserted/// between each element./// [`IntoIterator`] enabled version of [`Iterator::intersperse_with`]./// use itertools::intersperse_with;/// let mut i = 10;/// itertools::assert_equal(intersperse_with((0..3), || { i -= 1; i }), vec![0, 9, 1, 8, 2]);/// assert_eq!(i, 8);enumerateEnumerate/// Iterate `iterable` with a running index./// [`IntoIterator`] enabled version of [`Iterator::enumerate`]./// use itertools::enumerate;/// for (i, elt) in enumerate(&[1, 2, 3]) {/// Iterate `iterable` in reverse./// [`IntoIterator`] enabled version of [`Iterator::rev`]./// use itertools::rev;/// for elt in rev(&[1, 2, 3]) {/// Converts the arguments to iterators and zips them./// [`IntoIterator`] enabled version of [`Iterator::zip`]./// use itertools::zip;/// let mut result: Vec<(i32, char)> = Vec::new();/// for (a, b) in zip(&[1, 2, 3, 4, 5], &['a', 'b', 'c']) {///     result.push((*a, *b));/// assert_eq!(result, vec![(1, 'a'),(2, 'b'),(3, 'c')]);/// Takes two iterables and creates a new iterator over both in sequence. /// [`IntoIterator`] enabled version of [`Iterator::chain`]./// use itertools::chain;/// let mut result:Vec<i32> = Vec::new();/// for element in chain(&[1, 2, 3], &[4]) {///     result.push(*element);/// assert_eq!(result, vec![1, 2, 3, 4]);Cloned/// Create an iterator that clones each element from &T to T/// [`IntoIterator`] enabled version of [`Iterator::cloned`]./// use itertools::cloned;/// assert_eq!(cloned(b"abc").next(), Some(b'a'));/// Perform a fold operation over the iterable./// [`IntoIterator`] enabled version of [`Iterator::fold`]./// use itertools::fold;/// assert_eq!(fold(&[1., 2., 3.], 0., |a, &b| f32::max(a, b)), 3.);/// Test whether the predicate holds for all elements in the iterable./// [`IntoIterator`] enabled version of [`Iterator::all`]./// use itertools::all;/// assert!(all(&[1, 2, 3], |elt| *elt > 0));/// Test whether the predicate holds for any elements in the iterable./// [`IntoIterator`] enabled version of [`Iterator::any`]./// use itertools::any;/// assert!(any(&[0, -1, 2], |elt| *elt > 0));/// Return the maximum value of the iterable./// [`IntoIterator`] enabled version of [`Iterator::max`]./// use itertools::max;/// assert_eq!(max(0..10), Some(9));/// Return the minimum value of the iterable./// [`IntoIterator`] enabled version of [`Iterator::min`]./// use itertools::min;/// assert_eq!(min(0..10), Some(0));/// Combine all iterator elements into one String, separated by `sep`./// [`IntoIterator`] enabled version of [`Itertools::join`]./// use itertools::join;/// assert_eq!(join(&[1, 2, 3], ", "), "1, 2, 3");sorted/// Sort all iterator elements into a new iterator in ascending order./// [`IntoIterator`] enabled version of [`Itertools::sorted`]./// use itertools::sorted;/// use itertools::assert_equal;/// assert_equal(sorted("rust".chars()), "rstu".chars());//! Free functions that create iterator adaptors or call iterator methods.//! The benefit of free functions is that they accept any [`IntoIterator`] as//! argument, so the resulting code may be easier to read.into_group_map/// Return a `HashMap` of keys mapped to a list of their corresponding values./// See [`.into_group_map()`](crate::Itertools::into_group_map)into_group_map_bycall_mutKeyFunction/// A trait to unify `FnMut` for `GroupBy` with the chunk key in `IntoChunks`ChunkIndex/// `ChunkIndex` acts like the grouping key function for `IntoChunks`current_keycurrent_elt/// flag set if iterator is exhaustedtop_group/// Index of group we are currently buffering or visitingoldest_buffered_group/// Least index for which we still have elements bufferedbottom_group/// Group index for `buffer[0]` -- the slots/// bottom_group..oldest_buffered_group are unused and will be erased when/// that range is large enough./// Buffered groups, from `bottom_group` (index 0) to `top_group`.dropped_group/// index of last group iter that was dropped, usize::MAX == noneGroupInner/// `client`: Index of group that requests next elementlookup_buffernext_element/// Take the next element from the iterator, and set the done/// flag if exhausted. Must not be called after done.step_bufferingpush_next_groupstep_current/// This is the immediate case, where we use no bufferinggroup_key/// Request the just started groups' key./// `client`: Index of group/// **Panics** if no group key is available.drop_group/// Called when a group is dropped// the group iterator's current index. Keep this in the main value// so that simultaneous iterators all use the same state.GroupBy/// `GroupBy` is the storage for the lazy grouping operation./// If the groups are consumed in their original order, or if each/// group is dropped without keeping it around, then `GroupBy` uses/// no allocations. It needs allocations only if several group iterators/// are alive at the same time./// This type implements [`IntoIterator`] (it is **not** an iterator/// itself), because the group iterators need to borrow from this/// value. It should be stored in a local variable or temporary and/// iterated./// See [`.group_by()`](crate::Itertools::group_by) for more information./// Create a newGroups/// An iterator that yields the Group iterators./// Iterator element type is `(K, Group)`:/// the group's key `K` and the group's iterator./// An iterator for the elements in a single group.new_chunksIntoChunks// the chunk iterator's current index. Keep this in the main value/// `ChunkLazy` is the storage for a lazy chunking operation./// `IntoChunks` behaves just like `GroupBy`: it is iterable, and/// it only buffers if several chunk iterators are alive at the same time./// itself), because the chunk iterators need to borrow from this/// Iterator element type is `Chunk`, each chunk's iterator./// See [`.chunks()`](crate::Itertools::chunks) for more information./// `client`: Index of chunk that requests next element/// `client`: Index of chunk/// An iterator that yields the Chunk iterators./// Iterator element type is `Chunk`./// An iterator for the elements in a single chunk.///// IntoChunks /////MinMaxResultMapForGrouping/// A wrapper to allow for an easy [`into_grouping_map_by`](crate::Itertools::into_grouping_map_by)GroupingMap/// Creates a new `GroupingMap` from `iter`GroupingMapBy/// `GroupingMapBy` is an intermediate struct for efficient group-and-fold operations./// See [`GroupingMap`] for more informations."GroupingMap is lazy and do nothing unless consumed"/// `GroupingMap` is an intermediate struct for efficient group-and-fold operations./// It groups elements by their key and at the same time fold each group/// using some aggregating operation./// No method on this struct performs temporary allocations.FOaggregate/// This is the generic way to perform any operation on a `GroupingMap`./// It's suggested to use this method only to implement custom operations/// when the already provided ones are not enough./// Groups elements from the `GroupingMap` source by key and applies `operation` to the elements/// of each group sequentially, passing the previously accumulated value, a reference to the key/// and the current element as arguments, and stores the results in an `HashMap`./// The `operation` function is invoked on each element with the following parameters:///  - the current value of the accumulator of the group if there is currently one;///  - a reference to the key of the group this element belongs to;///  - the element from the source being aggregated;/// If `operation` returns `Some(element)` then the accumulator is updated with `element`,/// otherwise the previous accumulation is discarded./// Return a `HashMap` associating the key of each group with the result of aggregation of/// that group's elements. If the aggregation of the last element of a group discards the/// accumulator then there won't be an entry associated to that group's key./// use itertools::Itertools;/// let data = vec![2, 8, 5, 7, 9, 0, 4, 10];/// let lookup = data.into_iter()///     .into_grouping_map_by(|&n| n % 4)///     .aggregate(|acc, _key, val| {///         if val == 0 || val == 10 {///             None///             Some(acc.unwrap_or(0) + val)/// assert_eq!(lookup[&0], 4);        // 0 resets the accumulator so only 4 is summed/// assert_eq!(lookup[&1], 5 + 9);/// assert_eq!(lookup.get(&2), None); // 10 resets the accumulator and nothing is summed afterward/// assert_eq!(lookup[&3], 7);/// assert_eq!(lookup.len(), 3);      // The final keys are only 0, 1 and 2/// and the current element as arguments, and stores the results in a new map./// `init` is the value from which will be cloned the initial value of each accumulator./// `operation` is a function that is invoked on each element with the following parameters:///  - the current value of the accumulator of the group;///  - the element from the source being accumulated./// Return a `HashMap` associating the key of each group with the result of folding that group's elements./// let lookup = (1..=7)///     .into_grouping_map_by(|&n| n % 3)///     .fold(0, |acc, _key, val| acc + val);/// assert_eq!(lookup[&0], 3 + 6);/// assert_eq!(lookup[&1], 1 + 4 + 7);/// assert_eq!(lookup[&2], 2 + 5);/// assert_eq!(lookup.len(), 3);fold_first/// This is similar to [`fold`] but the initial value of the accumulator is the first element of the group./// [`fold`]: GroupingMap::fold///     .fold_first(|acc, _key, val| acc + val);/// Groups elements from the `GroupingMap` source by key and collects the elements of each group in/// an instance of `C`. The iteration order is preserved when inserting elements. /// Return a `HashMap` associating the key of each group with the collection containing that group's elements./// use std::collections::HashSet;/// let lookup = vec![0, 1, 2, 3, 4, 5, 6, 2, 3, 6].into_iter()///     .collect::<HashSet<_>>();/// assert_eq!(lookup[&0], vec![0, 3, 6].into_iter().collect::<HashSet<_>>());/// assert_eq!(lookup[&1], vec![1, 4].into_iter().collect::<HashSet<_>>());/// assert_eq!(lookup[&2], vec![2, 5].into_iter().collect::<HashSet<_>>());/// Groups elements from the `GroupingMap` source by key and finds the maximum of each group./// If several elements are equally maximum, the last element is picked./// Returns a `HashMap` associating the key of each group with the maximum of that group's elements./// let lookup = vec![1, 3, 4, 5, 7, 8, 9, 12].into_iter()///     .max();/// assert_eq!(lookup[&0], 12);/// assert_eq!(lookup[&1], 7);/// assert_eq!(lookup[&2], 8);max_by/// Groups elements from the `GroupingMap` source by key and finds the maximum of each group/// with respect to the specified comparison function.///     .max_by(|_key, x, y| y.cmp(x));/// assert_eq!(lookup[&0], 3);/// assert_eq!(lookup[&1], 1);/// assert_eq!(lookup[&2], 5);CKmax_by_key/// Groups elements from the `GroupingMap` source by key and finds the element of each group/// that gives the maximum from the specified function.///     .max_by_key(|_key, &val| val % 4);/// Groups elements from the `GroupingMap` source by key and finds the minimum of each group./// If several elements are equally minimum, the first element is picked./// Returns a `HashMap` associating the key of each group with the minimum of that group's elements.///     .min();min_by/// Groups elements from the `GroupingMap` source by key and finds the minimum of each group///     .min_by(|_key, x, y| y.cmp(x));min_by_key/// that gives the minimum from the specified function.///     .min_by_key(|_key, &val| val % 4);/// assert_eq!(lookup[&1], 4);minmax/// Groups elements from the `GroupingMap` source by key and find the maximum and minimum of/// each group./// See [.minmax()](crate::Itertools::minmax) for the non-grouping version./// Differences from the non grouping version:/// - It never produces a `MinMaxResult::NoElements`/// - It doesn't have any speedup/// Returns a `HashMap` associating the key of each group with the minimum and maximum of that group's elements./// use itertools::MinMaxResult::{OneElement, MinMax};/// let lookup = vec![1, 3, 4, 5, 7, 9, 12].into_iter()///     .minmax();/// assert_eq!(lookup[&0], MinMax(3, 12));/// assert_eq!(lookup[&1], MinMax(1, 7));/// assert_eq!(lookup[&2], OneElement(5));minmax_by/// each group with respect to the specified comparison function./// It has the same differences from the non-grouping version as `minmax`.///     .minmax_by(|_key, x, y| y.cmp(x));/// assert_eq!(lookup[&0], MinMax(12, 3));/// assert_eq!(lookup[&1], MinMax(7, 1));minmax_by_key/// Groups elements from the `GroupingMap` source by key and find the elements of each group/// that gives the minimum and maximum from the specified function.///     .minmax_by_key(|_key, &val| val % 4);/// assert_eq!(lookup[&1], MinMax(4, 7));/// Groups elements from the `GroupingMap` source by key and sums them./// This is just a shorthand for `self.fold_first(|acc, _, val| acc + val)`./// It is more limited than `Iterator::sum` since it doesn't use the `Sum` trait./// Returns a `HashMap` associating the key of each group with the sum of that group's elements.///     .sum();/// assert_eq!(lookup[&0], 3 + 9 + 12);/// assert_eq!(lookup[&2], 5 + 8);/// Groups elements from the `GroupingMap` source by key and multiply them./// This is just a shorthand for `self.fold_first(|acc, _, val| acc * val)`./// It is more limited than `Iterator::product` since it doesn't use the `Product` trait./// Returns a `HashMap` associating the key of each group with the product of that group's elements.///     .product();/// assert_eq!(lookup[&0], 3 * 9 * 12);/// assert_eq!(lookup[&1], 1 * 4 * 7);/// assert_eq!(lookup[&2], 5 * 8);//! Implementation's internal macrosIntersperseElementIntersperseElementSimple/// An iterator adaptor to insert a particular value/// between each element of the adapted iterator./// Iterator element type is `I::Item`/// See [`.intersperse()`](crate::Itertools::intersperse) for more information./// Create a new Intersperse iteratorElemF/// An iterator adaptor to insert a particular value created by a function/// See [`.intersperse_with()`](crate::Itertools::intersperse_with) for more information./// Create a new `IntersperseWith` iteratork_smallestHeadTail/// Head element and Tail iterator pair/// `PartialEq`, `Eq`, `PartialOrd` and `Ord` are implemented by comparing sequences based on/// first items (which are guaranteed to exist)./// The meanings of `PartialOrd` and `Ord` are reversed so as to turn the heap used in/// `KMerge` into a min-heap./// Constructs a `HeadTail` from an `Iterator`. Returns `None` if the `Iterator` is empty./// Get the next element and update `head`, returning the old head in `Some`./// Returns `None` when the tail is exhausted (only `head` then remains)./// Hints at the size of the sequence, same as the `Iterator` method.heapify/// Make `data` a heap (min-heap w.r.t the sorting).sift_down/// Sift down element at `index` (`heap` is a min-heap wrt the ordering)KMergeKMergeByLtKMergeBy/// An iterator adaptor that merges an abitrary number of base iterators in ascending order./// If all base iterators are sorted (ascending), the result is sorted./// See [`.kmerge()`](crate::Itertools::kmerge) for more information.kmerge_predKMergePredicate/// Create an iterator that merges elements of the contained iterators using/// the ordering function./// [`IntoIterator`] enabled version of [`Itertools::kmerge`]./// use itertools::kmerge;/// for elt in kmerge(vec![vec![0, 2, 4], vec![1, 3, 5], vec![6, 7]]) {heapless_than/// An iterator adaptor that merges an abitrary number of base iterators/// according to an ordering function./// See [`.kmerge_by()`](crate::Itertools::kmerge_by) for morekmerge_by/// Create an iterator that merges elements of the contained iterators./// [`IntoIterator`] enabled version of [`Itertools::kmerge_by`].prefill"itertools"impl_macros__std_iter// for compatibility with no std and macroscons_tuples_implexactly_one_errgrouping_mapgroupbylazyMergeJoinByMultiPeekPeekNthpad_tailPadUsingpeeking_take_whilePeekingTakeWhilepermutationsPermutationsprocess_results_implProcessResultspowersetPowersetPutBackNRcIterrepeatnRepeatNsourcesRepeatCallUnfoldIterateteeTeetuple_implTupleBufferTupleWindowsCircularTupleWindowsTuplesduplicates_implunique_implUniqueUniqueBywith_positionWithPositionZipEqzip_longestZipLongestziptuple/// The concrete iterator types.HomogeneousTuple/// Traits helpful for using certain `Itertools` methods in generic contexts.concat_implPeekingNextprocess_resultsrepeat_nrepeat_callunziptuplemultiunzipMultiUnzipmultizipeither_or_bothextrema_setgroup_mapiproduct/// Create an iterator over the “cartesian product” of iterators./// Iterator element type is like `(A, B, ..., E)` if formed/// from iterators `(I, J, ..., M)` with element types `I::Item = A`, `J::Item = B`, etc./// # use itertools::iproduct;/// // Iterate over the coordinates of a 4 x 4 x 4 grid/// // from (0, 0, 0), (0, 0, 1), .., (0, 1, 0), (0, 1, 1), .. etc until (3, 3, 3)/// for (i, j, k) in iproduct!(0..4, 0..4, 0..4) {///    // ..izip// @closure creates a tuple-flattening closure for .map() call. usage:// @closure partial_pattern => partial_tuple , rest , of , iterators// eg. izip!( @closure ((a, b), c) => (a, b, c) , dd , ee )// The "b" identifier is a different identifier on each recursion level thanks to hygiene.// unary// binary// n-ary where n > 2/// Create an iterator running multiple iterators in lockstep./// The `izip!` iterator yields elements until any subiterator/// returns `None`./// This is a version of the standard ``.zip()`` that's supporting more than/// two iterators. The iterator element type is a tuple with one element/// from each of the input iterators. Just like ``.zip()``, the iteration stops/// when the shortest of the inputs reaches its end./// **Note:** The result of this macro is in the general case an iterator/// composed of repeated `.zip()` and a `.map()`; it has an anonymous type./// The special cases of one and two arguments produce the equivalent of/// `$a.into_iter()` and `$a.into_iter().zip($b)` respectively./// Prefer this macro `izip!()` over [`multizip`] for the performance benefits/// of using the standard library `.zip()`./// # use itertools::izip;/// // iterate over three sequences side-by-side/// let mut results = [0, 0, 0, 0];/// let inputs = [3, 7, 9, 6];/// for (r, index, input) in izip!(&mut results, 0..10, &inputs) {///     *r = index * 10 + input;/// assert_eq!(results, [0 + 3, 10 + 7, 29, 36]);/// [Chain][`chain`] zero or more iterators together into one sequence./// The comma-separated arguments must implement [`IntoIterator`]./// The final argument may be followed by a trailing comma./// [`chain`]: Iterator::chain/// Empty invocations of `chain!` expand to an invocation of [`std::iter::empty`]:/// let _: iter::Empty<()> = chain!();/// let _: iter::Empty<i8> = chain!();/// Invocations of `chain!` with one argument expand to [`arg.into_iter()`](IntoIterator):/// use std::{ops::Range, slice};/// let _: <Range<_> as IntoIterator>::IntoIter = chain!((2..6),); // trailing comma optional!/// let _:     <&[_] as IntoIterator>::IntoIter = chain!(&[2, 3, 4]);/// Invocations of `chain!` with multiple arguments [`.into_iter()`](IntoIterator) each/// argument, and then [`chain`] them together:/// use std::{iter::*, ops::Range, slice};/// use itertools::{assert_equal, chain};/// // e.g., this:/// let with_macro:  Chain<Chain<Once<_>, Take<Repeat<_>>>, slice::Iter<_>> =///     chain![once(&0), repeat(&1).take(2), &[2, 3, 5],];/// // ...is equivalent to this:/// let with_method: Chain<Chain<Once<_>, Take<Repeat<_>>>, slice::Iter<_>> =///     once(&0)///         .chain(repeat(&1).take(2))///         .chain(&[2, 3, 5]);/// assert_equal(with_macro, with_method);/// Alternate elements from two iterators until both have run out./// Iterator element type is `Self::Item`./// let it = (1..7).interleave(vec![-1, -2]);/// itertools::assert_equal(it, vec![1, -1, 2, -2, 3, 4, 5, 6]);/// Alternate elements from two iterators until at least one of them has run/// out./// let it = (1..7).interleave_shortest(vec![-1, -2]);/// itertools::assert_equal(it, vec![1, -1, 2, -2, 3]);/// itertools::assert_equal((0..3).intersperse(8), vec![0, 8, 1, 8, 2]);/// itertools::assert_equal((0..3).intersperse_with(|| { i -= 1; i }), vec![0, 9, 1, 8, 2]);/// Create an iterator which iterates over both this and the specified/// iterator simultaneously, yielding pairs of two optional elements./// As long as neither input iterator is exhausted yet, it yields two values/// via `EitherOrBoth::Both`./// When the parameter iterator is exhausted, it only yields a value from the/// `self` iterator via `EitherOrBoth::Left`./// When the `self` iterator is exhausted, it only yields a value from the/// parameter iterator via `EitherOrBoth::Right`./// When both iterators return `None`, all further invocations of `.next()`/// will return `None`./// Iterator element type is/// [`EitherOrBoth<Self::Item, J::Item>`](EitherOrBoth)./// use itertools::EitherOrBoth::{Both, Right};/// let it = (0..1).zip_longest(1..3);/// itertools::assert_equal(it, vec![Both(0, 1), Right(2)]);/// iterator simultaneously, yielding pairs of elements./// **Panics** if the iterators reach an end and they are not of equal/// lengths./// A “meta iterator adaptor”. Its closure receives a reference to the/// iterator and may pick off as many elements as it likes, to produce the/// next iterator element./// Iterator element type is `B`./// // An adaptor that gathers elements in pairs/// let pit = (0..4).batching(|it| {///            match it.next() {///                None => None,///                Some(x) => match it.next() {///                    None => None,///                    Some(y) => Some((x, y)),///                }///            }///        });/// itertools::assert_equal(pit, vec![(0, 1), (2, 3)]);group_by/// Return an *iterable* that can group iterator elements./// Consecutive elements that map to the same key (“runs”), are assigned/// to the same group./// If the groups are consumed in order, or if each group's iterator is/// dropped without keeping it around, then `GroupBy` uses no/// allocations.  It needs allocations only if several group iterators/// Iterator element type is `(K, Group)`: the group's key and the/// group iterator./// // group data into runs of larger than zero or not./// let data = vec![1, 3, -2, -2, 1, 0, 1, 2];/// // groups:     |---->|------>|--------->|/// // Note: The `&` is significant here, `GroupBy` is iterable/// // only by reference. You can also call `.into_iter()` explicitly./// let mut data_grouped = Vec::new();/// for (key, group) in &data.into_iter().group_by(|elt| *elt >= 0) {///     data_grouped.push((key, group.collect()));/// assert_eq!(data_grouped, vec![(true, vec![1, 3]), (false, vec![-2, -2]), (true, vec![1, 0, 1, 2])]);/// Return an *iterable* that can chunk the iterator./// Yield subiterators (chunks) that each yield a fixed number elements,/// determined by `size`. The last chunk will be shorter if there aren't/// enough elements./// `IntoChunks` is based on `GroupBy`: it is iterable (implements/// `IntoIterator`, **not** `Iterator`), and it only buffers if several/// chunk iterators are alive at the same time./// **Panics** if `size` is 0./// let data = vec![1, 1, 2, -2, 6, 0, 3, 1];/// //chunk size=3 |------->|-------->|--->|/// // Note: The `&` is significant here, `IntoChunks` is iterable/// for chunk in &data.into_iter().chunks(3) {///     // Check that the sum of each chunk is 4.///     assert_eq!(4, chunk.sum());tuple_windows/// Return an iterator over all contiguous windows producing tuples of/// a specific size (up to 12)./// `tuple_windows` clones the iterator elements so that they can be/// part of successive windows, this makes it most suited for iterators/// of references and other values that are cheap to copy./// let mut v = Vec::new();/// // pairwise iteration/// for (a, b) in (1..5).tuple_windows() {///     v.push((a, b));/// assert_eq!(v, vec![(1, 2), (2, 3), (3, 4)]);/// let mut it = (1..5).tuple_windows();/// assert_eq!(Some((1, 2, 3)), it.next());/// assert_eq!(Some((2, 3, 4)), it.next());/// assert_eq!(None, it.next());/// // this requires a type hint/// let it = (1..5).tuple_windows::<(_, _, _)>();/// itertools::assert_equal(it, vec![(1, 2, 3), (2, 3, 4)]);/// // you can also specify the complete type/// use itertools::TupleWindows;/// use std::ops::Range;/// let it: TupleWindows<Range<u32>, (u32, u32, u32)> = (1..5).tuple_windows();circular_tuple_windowsTupleCollect/// Return an iterator over all windows, wrapping back to the first/// elements when the window would otherwise exceed the length of the/// iterator, producing tuples of a specific size (up to 12)./// `circular_tuple_windows` clones the iterator elements so that they can be/// for (a, b) in (1..5).circular_tuple_windows() {/// assert_eq!(v, vec![(1, 2), (2, 3), (3, 4), (4, 1)]);/// let mut it = (1..5).circular_tuple_windows();/// assert_eq!(Some((3, 4, 1)), it.next());/// assert_eq!(Some((4, 1, 2)), it.next());/// let it = (1..5).circular_tuple_windows::<(_, _, _)>();/// itertools::assert_equal(it, vec![(1, 2, 3), (2, 3, 4), (3, 4, 1), (4, 1, 2)]);tuples/// Return an iterator that groups the items in tuples of a specific size/// (up to 12)./// See also the method [`.next_tuple()`](Itertools::next_tuple)./// for (a, b) in (1..5).tuples() {/// assert_eq!(v, vec![(1, 2), (3, 4)]);/// let mut it = (1..7).tuples();/// assert_eq!(Some((4, 5, 6)), it.next());/// let it = (1..7).tuples::<(_, _, _)>();/// itertools::assert_equal(it, vec![(1, 2, 3), (4, 5, 6)]);/// use itertools::Tuples;/// let it: Tuples<Range<u32>, (u32, u32, u32)> = (1..7).tuples();/// See also [`Tuples::into_buffer`]./// Split into an iterator pair that both yield all elements from/// the original iterator./// **Note:** If the iterator is clonable, prefer using that instead/// of using this method. Cloning is likely to be more efficient./// let xs = vec![0, 1, 2, 3];/// let (mut t1, t2) = xs.into_iter().tee();/// itertools::assert_equal(t1.next(), Some(0));/// itertools::assert_equal(t2, 0..4);/// itertools::assert_equal(t1, 1..4);/// Return an iterator adaptor that steps `n` elements in the base iterator/// then skipping forward `n - 1` elements./// let it = (0..8).step(3);/// itertools::assert_equal(it, vec![0, 3, 6]);/// Convert each item of the iterator using the [`Into`] trait./// (1i32..42i32).map_into::<f64>().collect_vec();map_results/// See [`.map_ok()`](Itertools::map_ok)./// Return an iterator adaptor that applies the provided closure/// to every `Result::Ok` value. `Result::Err` values are/// unchanged./// let input = vec![Ok(41), Err(false), Ok(11)];/// let it = input.into_iter().map_ok(|i| i + 1);/// itertools::assert_equal(it, vec![Ok(42), Err(false), Ok(12)]);/// Return an iterator adaptor that filters every `Result::Ok`/// value with the provided closure. `Result::Err` values are/// let input = vec![Ok(22), Err(false), Ok(11)];/// let it = input.into_iter().filter_ok(|&i| i > 20);/// itertools::assert_equal(it, vec![Ok(22), Err(false)]);/// Return an iterator adaptor that filters and transforms every/// `Result::Ok` value with the provided closure. `Result::Err`/// values are unchanged./// let it = input.into_iter().filter_map_ok(|i| if i > 20 { Some(i * 2) } else { None });/// itertools::assert_equal(it, vec![Ok(44), Err(false)]);/// Return an iterator adaptor that flattens every `Result::Ok` value into/// a series of `Result::Ok` values. `Result::Err` values are unchanged./// This is useful when you have some common error type for your crate and/// need to propagate it upwards, but the `Result::Ok` case needs to be flattened./// let input = vec![Ok(0..2), Err(false), Ok(2..4)];/// let it = input.iter().cloned().flatten_ok();/// itertools::assert_equal(it.clone(), vec![Ok(0), Ok(1), Err(false), Ok(2), Ok(3)]);/// // This can also be used to propagate errors when collecting./// let output_result: Result<Vec<i32>, bool> = it.collect();/// assert_eq!(output_result, Err(false));/// Return an iterator adaptor that merges the two base iterators in/// ascending order.  If both base iterators are sorted (ascending), the/// result is sorted./// let a = (0..11).step(3);/// let b = (0..11).step(5);/// let it = a.merge(b);/// itertools::assert_equal(it, vec![0, 0, 3, 5, 6, 9, 10]);merge_by/// Return an iterator adaptor that merges the two base iterators in order./// This is much like [`.merge()`](Itertools::merge) but allows for a custom ordering./// This can be especially useful for sequences of tuples./// let a = (0..).zip("bc".chars());/// let b = (0..).zip("ad".chars());/// let it = a.merge_by(b, |x, y| x.1 <= y.1);/// itertools::assert_equal(it, vec![(0, 'a'), (0, 'b'), (1, 'c'), (1, 'd')]);/// Create an iterator that merges items from both this and the specified/// iterator in ascending order./// It chooses whether to pair elements based on the `Ordering` returned by the/// specified compare function. At any point, inspecting the tip of the/// iterators `I` and `J` as items `i` of type `I::Item` and `j` of type/// `J::Item` respectively, the resulting iterator will:/// - Emit `EitherOrBoth::Left(i)` when `i < j`,///   and remove `i` from its source iterator/// - Emit `EitherOrBoth::Right(j)` when `i > j`,///   and remove `j` from its source iterator/// - Emit `EitherOrBoth::Both(i, j)` when  `i == j`,///   and remove both `i` and `j` from their respective source iterators/// use itertools::EitherOrBoth::{Left, Right, Both};/// let multiples_of_2 = (0..10).step(2);/// let multiples_of_3 = (0..10).step(3);/// itertools::assert_equal(///     multiples_of_2.merge_join_by(multiples_of_3, |i, j| i.cmp(j)),///     vec![Both(0, 0), Left(2), Right(3), Left(4), Both(6, 6), Left(8), Right(9)]/// Return an iterator adaptor that flattens an iterator of iterators by/// merging them in ascending order./// let a = (0..6).step(3);/// let b = (1..6).step(3);/// let c = (2..6).step(3);/// let it = vec![a, b, c].into_iter().kmerge();/// itertools::assert_equal(it, vec![0, 1, 2, 3, 4, 5]);/// merging them according to the given closure./// The closure `first` is called with two elements *a*, *b* and should/// return `true` if *a* is ordered before *b*./// If all base iterators are sorted according to `first`, the result is/// sorted./// let a = vec![-1f64, 2., 3., -5., 6., -7.];/// let b = vec![0., 2., -4.];/// let mut it = vec![a, b].into_iter().kmerge_by(|a, b| a.abs() < b.abs());/// assert_eq!(it.next(), Some(0.));/// assert_eq!(it.last(), Some(-7.));/// Return an iterator adaptor that iterates over the cartesian product of/// the element sets of two iterators `self` and `J`./// Iterator element type is `(Self::Item, J::Item)`./// let it = (0..2).cartesian_product("αβ".chars());/// itertools::assert_equal(it, vec![(0, 'α'), (0, 'β'), (1, 'α'), (1, 'β')]);/// all subiterators returned by meta-iterator `self`./// All provided iterators must yield the same `Item` type. To generate/// the product of iterators yielding multiple types, use the/// [`iproduct`] macro instead./// The iterator element type is `Vec<T>`, where `T` is the iterator element/// of the subiterators./// let mut multi_prod = (0..3).map(|i| (i * 2)..(i * 2 + 2))///     .multi_cartesian_product();/// assert_eq!(multi_prod.next(), Some(vec![0, 2, 4]));/// assert_eq!(multi_prod.next(), Some(vec![0, 2, 5]));/// assert_eq!(multi_prod.next(), Some(vec![0, 3, 4]));/// assert_eq!(multi_prod.next(), Some(vec![0, 3, 5]));/// assert_eq!(multi_prod.next(), Some(vec![1, 2, 4]));/// assert_eq!(multi_prod.next(), Some(vec![1, 2, 5]));/// assert_eq!(multi_prod.next(), Some(vec![1, 3, 4]));/// assert_eq!(multi_prod.next(), Some(vec![1, 3, 5]));/// assert_eq!(multi_prod.next(), None);/// Return an iterator adaptor that uses the passed-in closure to/// optionally merge together consecutive elements./// The closure `f` is passed two elements, `previous` and `current` and may/// return either (1) `Ok(combined)` to merge the two values or/// (2) `Err((previous', current'))` to indicate they can't be merged./// In (2), the value `previous'` is emitted by the iterator./// Either (1) `combined` or (2) `current'` becomes the previous value/// when coalesce continues with the next pair of elements to merge. The/// value that remains at the end is also emitted by the iterator./// // sum same-sign runs together/// let data = vec![-1., -2., -3., 3., 1., 0., -1.];/// itertools::assert_equal(data.into_iter().coalesce(|x, y|///         if (x >= 0.) == (y >= 0.) {///             Ok(x + y)///             Err((x, y))///         }),///         vec![-6., 4., -1.]);/// Remove duplicates from sections of consecutive identical elements./// If the iterator is sorted, all elements will be unique./// let data = vec![1., 1., 2., 3., 3., 2., 2.];/// itertools::assert_equal(data.into_iter().dedup(),///                         vec![1., 2., 3., 2.]);Cmp/// Remove duplicates from sections of consecutive identical elements,/// determining equality using a comparison function./// let data = vec![(0, 1.), (1, 1.), (0, 2.), (0, 3.), (1, 3.), (1, 2.), (2, 2.)];/// itertools::assert_equal(data.into_iter().dedup_by(|x, y| x.1 == y.1),///                         vec![(0, 1.), (0, 2.), (0, 3.), (1, 2.)]);/// Remove duplicates from sections of consecutive identical elements, while keeping a count of/// how many repeated elements were present./// Iterator element type is `(usize, Self::Item)`./// let data = vec!['a', 'a', 'b', 'c', 'c', 'b', 'b'];/// itertools::assert_equal(data.into_iter().dedup_with_count(),///                         vec![(2, 'a'), (1, 'b'), (2, 'c'), (2, 'b')]);/// This will determine equality using a comparison function./// let data = vec![(0, 'a'), (1, 'a'), (0, 'b'), (0, 'c'), (1, 'c'), (1, 'b'), (2, 'b')];/// itertools::assert_equal(data.into_iter().dedup_by_with_count(|x, y| x.1 == y.1),///                         vec![(2, (0, 'a')), (1, (0, 'b')), (2, (0, 'c')), (2, (1, 'b'))]);/// Return an iterator adaptor that produces elements that appear more than once during the/// iteration. Duplicates are detected using hash and equality./// The iterator is stable, returning the duplicate items in the order in which they occur in/// the adapted iterator. Each duplicate item is returned exactly once. If an item appears more/// than twice, the second item is the item retained and the rest are discarded./// let data = vec![10, 20, 30, 20, 40, 10, 50];/// itertools::assert_equal(data.into_iter().duplicates(),///                         vec![20, 10]);/// Duplicates are detected by comparing the key they map to with the keying function `f` by/// hash and equality. The keys are stored in a hash map in the iterator./// let data = vec!["a", "bb", "aa", "c", "ccc"];/// itertools::assert_equal(data.into_iter().duplicates_by(|s| s.len()),///                         vec!["aa", "c"]);unique/// Return an iterator adaptor that filters out elements that have/// already been produced once during the iteration. Duplicates/// are detected using hash and equality./// Clones of visited elements are stored in a hash set in the/// iterator./// The iterator is stable, returning the non-duplicate items in the order/// in which they occur in the adapted iterator. In a set of duplicate/// items, the first item encountered is the item retained./// itertools::assert_equal(data.into_iter().unique(),///                         vec![10, 20, 30, 40, 50]);unique_by/// already been produced once during the iteration./// Duplicates are detected by comparing the key they map to/// with the keying function `f` by hash and equality./// The keys are stored in a hash set in the iterator./// itertools::assert_equal(data.into_iter().unique_by(|s| s.len()),///                         vec!["a", "bb", "ccc"]);/// Return an iterator adaptor that borrows from this iterator and/// takes items while the closure `accept` returns `true`./// This adaptor can only be used on iterators that implement `PeekingNext`/// like `.peekable()`, `put_back` and a few other collection iterators./// The last and rejected element (first `false`) is still available when/// `peeking_take_while` is done./// See also [`.take_while_ref()`](Itertools::take_while_ref)/// which is a similar adaptor./// Return an iterator adaptor that borrows from a `Clone`-able iterator/// to only pick off elements while the predicate `accept` returns `true`./// It uses the `Clone` trait to restore the original iterator so that the/// last and rejected element (first `false`) is still available when/// `take_while_ref` is done./// let mut hexadecimals = "0123456789abcdef".chars();/// let decimals = hexadecimals.take_while_ref(|c| c.is_numeric())///                            .collect::<String>();/// assert_eq!(decimals, "0123456789");/// assert_eq!(hexadecimals.next(), Some('a'));/// Return an iterator adaptor that filters `Option<A>` iterator elements/// Iterator element type is `A`, the unwrapped element./// // List all hexadecimal digits///     (0..).map(|i| std::char::from_digit(i, 16)).while_some(),///     "0123456789abcdef".chars());/// Return an iterator adaptor that iterates over the combinations of the/// elements from an iterator./// Iterator element can be any homogeneous tuple of type `Self::Item` with/// size up to 12./// for (a, b) in (1..5).tuple_combinations() {/// assert_eq!(v, vec![(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]);/// let mut it = (1..5).tuple_combinations();/// assert_eq!(Some((1, 2, 4)), it.next());/// assert_eq!(Some((1, 3, 4)), it.next());/// let it = (1..5).tuple_combinations::<(_, _, _)>();/// itertools::assert_equal(it, vec![(1, 2, 3), (1, 2, 4), (1, 3, 4), (2, 3, 4)]);/// use itertools::TupleCombinations;/// let it: TupleCombinations<Range<u32>, (u32, u32, u32)> = (1..5).tuple_combinations();/// Return an iterator adaptor that iterates over the `k`-length combinations of/// the elements from an iterator./// Iterator element type is `Vec<Self::Item>`. The iterator produces a new Vec per iteration,/// and clones the iterator elements./// let it = (1..5).combinations(3);/// itertools::assert_equal(it, vec![///     vec![1, 2, 3],///     vec![1, 2, 4],///     vec![1, 3, 4],///     vec![2, 3, 4],/// Note: Combinations does not take into account the equality of the iterated values./// let it = vec![1, 2, 2].into_iter().combinations(2);///     vec![1, 2], // Note: these are the same///     vec![2, 2],/// Return an iterator that iterates over the `k`-length combinations of/// the elements from an iterator, with replacement./// let it = (1..4).combinations_with_replacement(2);///     vec![1, 1],///     vec![1, 2],///     vec![1, 3],///     vec![2, 3],///     vec![3, 3],/// Return an iterator adaptor that iterates over all k-permutations of the/// Iterator element type is `Vec<Self::Item>` with length `k`. The iterator/// produces a new Vec per iteration, and clones the iterator elements./// If `k` is greater than the length of the input iterator, the resultant/// iterator adaptor will be empty./// let perms = (5..8).permutations(2);/// itertools::assert_equal(perms, vec![///     vec![5, 6],///     vec![5, 7],///     vec![6, 5],///     vec![6, 7],///     vec![7, 5],///     vec![7, 6],/// Note: Permutations does not take into account the equality of the iterated values./// let it = vec![2, 2].into_iter().permutations(2);///     vec![2, 2], // Note: these are the same/// Note: The source iterator is collected lazily, and will not be/// re-iterated if the permutations adaptor is completed and re-iterated./// Return an iterator that iterates through the powerset of the elements from an/// Iterator element type is `Vec<Self::Item>`. The iterator produces a new `Vec`/// per iteration, and clones the iterator elements./// The powerset of a set contains all subsets including the empty set and the full/// input set. A powerset has length _2^n_ where _n_ is the length of the input/// Each `Vec` produced by this iterator represents a subset of the elements/// produced by the source iterator./// let sets = (1..4).powerset().collect::<Vec<_>>();/// itertools::assert_equal(sets, vec![///     vec![],///     vec![1],///     vec![2],///     vec![3],pad_using/// Return an iterator adaptor that pads the sequence to a minimum length of/// `min` by filling missing elements using a closure `f`./// let it = (0..5).pad_using(10, |i| 2*i);/// itertools::assert_equal(it, vec![0, 1, 2, 3, 4, 10, 12, 14, 16, 18]);/// let it = (0..10).pad_using(5, |i| 2*i);/// itertools::assert_equal(it, vec![0, 1, 2, 3, 4, 5, 6, 7, 8, 9]);/// let it = (0..5).pad_using(10, |i| 2*i).rev();/// itertools::assert_equal(it, vec![18, 16, 14, 12, 10, 4, 3, 2, 1, 0]);/// Return an iterator adaptor that wraps each element in a `Position` to/// ease special-case handling of the first or last elements./// [`Position<Self::Item>`](Position)/// use itertools::{Itertools, Position};/// let it = (0..4).with_position();/// itertools::assert_equal(it,///                         vec![Position::First(0),///                              Position::Middle(1),///                              Position::Middle(2),///                              Position::Last(3)]);/// let it = (0..1).with_position();/// itertools::assert_equal(it, vec![Position::Only(0)]);/// Return an iterator adaptor that yields the indices of all elements/// satisfying a predicate, counted from the start of the iterator./// Equivalent to `iter.enumerate().filter(|(_, v)| predicate(v)).map(|(i, _)| i)`./// let data = vec![1, 2, 3, 3, 4, 6, 7, 9];/// itertools::assert_equal(data.iter().positions(|v| v % 2 == 0), vec![1, 4, 5]);/// itertools::assert_equal(data.iter().positions(|v| v % 2 == 1).rev(), vec![7, 6, 3, 2, 0]);/// Return an iterator adaptor that applies a mutating function/// to each element before yielding it./// let input = vec![vec![1], vec![3, 2, 1]];/// let it = input.into_iter().update(|mut v| v.push(0));/// itertools::assert_equal(it, vec![vec![1, 0], vec![3, 2, 1, 0]]);next_tuple// non-adaptor methods/// Advances the iterator and returns the next items grouped in a tuple of/// If there are enough elements to be grouped in a tuple, then the tuple is/// returned inside `Some`, otherwise `None` is returned./// let mut iter = 1..5;/// assert_eq!(Some((1, 2)), iter.next_tuple());collect_tuple/// Collects all items from the iterator into a tuple of a specific size/// If the number of elements inside the iterator is **exactly** equal to/// the tuple size, then the tuple is returned inside `Some`, otherwise/// `None` is returned./// let iter = 1..3;/// if let Some((x, y)) = iter.collect_tuple() {///     assert_eq!((x, y), (1, 2))///     panic!("Expected two elements")find_position/// Find the position and value of the first element satisfying a predicate./// The iterator is not advanced past the first element found./// let text = "Hα";/// assert_eq!(text.chars().find_position(|ch| ch.is_lowercase()), Some((1, 'α')));find_or_last/// Find the value of the first element satisfying a predicate or return the last element, if any./// let numbers = [1, 2, 3, 4];/// assert_eq!(numbers.iter().find_or_last(|&&x| x > 5), Some(&4));/// assert_eq!(numbers.iter().find_or_last(|&&x| x > 2), Some(&3));/// assert_eq!(std::iter::empty::<i32>().find_or_last(|&x| x > 5), None);find_or_first/// Find the value of the first element satisfying a predicate or return the first element, if any./// assert_eq!(numbers.iter().find_or_first(|&&x| x > 5), Some(&1));/// assert_eq!(numbers.iter().find_or_first(|&&x| x > 2), Some(&3));/// assert_eq!(std::iter::empty::<i32>().find_or_first(|&x| x > 5), None);/// Returns `true` if the given item is present in this iterator./// This method is short-circuiting. If the given item is present in this/// iterator, this method will consume the iterator up-to-and-including/// the item. If the given item is not present in this iterator, the/// iterator will be exhausted./// #[derive(PartialEq, Debug)]/// enum Enum { A, B, C, D, E, }/// let mut iter = vec![Enum::A, Enum::B, Enum::C, Enum::D].into_iter();/// // search `iter` for `B`/// assert_eq!(iter.contains(&Enum::B), true);/// // `B` was found, so the iterator now rests at the item after `B` (i.e, `C`)./// assert_eq!(iter.next(), Some(Enum::C));/// // search `iter` for `E`/// assert_eq!(iter.contains(&Enum::E), false);/// // `E` wasn't found, so `iter` is now exhaustedall_equal/// Check whether all elements compare equal./// Empty iterators are considered to have equal elements:/// let data = vec![1, 1, 1, 2, 2, 3, 3, 3, 4, 5, 5];/// assert!(!data.iter().all_equal());/// assert!(data[0..3].iter().all_equal());/// assert!(data[3..5].iter().all_equal());/// assert!(data[5..8].iter().all_equal());/// let data : Option<usize> = None;/// assert!(data.into_iter().all_equal());all_unique/// Check whether all elements are unique (non equal)./// Empty iterators are considered to have unique elements:/// let data = vec![1, 2, 3, 4, 1, 5];/// assert!(!data.iter().all_unique());/// assert!(data[0..4].iter().all_unique());/// assert!(data[1..6].iter().all_unique());/// assert!(data.into_iter().all_unique());dropping/// Consume the first `n` elements from the iterator eagerly,/// and return the same iterator again./// It works similarly to *.skip(* `n` *)* except it is eager and/// preserves the iterator type./// let mut iter = "αβγ".chars().dropping(2);/// itertools::assert_equal(iter, "γ".chars());/// *Fusing notes: if the iterator is exhausted by dropping,/// the result of calling `.next()` again depends on the iterator implementation.*dropping_back/// Consume the last `n` elements from the iterator eagerly,/// This is only possible on double ended iterators. `n` may be/// larger than the number of elements./// Note: This method is eager, dropping the back elements immediately and/// let init = vec![0, 3, 6, 9].into_iter().dropping_back(1);/// itertools::assert_equal(init, vec![0, 3, 6]);foreach/// Run the closure `f` eagerly on each element of the iterator./// Consumes the iterator until its end./// use std::sync::mpsc::channel;/// let (tx, rx) = channel();/// // use .foreach() to apply a function to each value -- sending it/// (0..5).map(|x| x * 2 + 1).foreach(|x| { tx.send(x).unwrap(); } );/// drop(tx);/// itertools::assert_equal(rx.iter(), vec![1, 3, 5, 7, 9]);/// assert_eq!(input.into_iter().concat(),///            vec![1, 2, 3, 4, 5, 6]);collect_vec/// `.collect_vec()` is simply a type specialization of [`Iterator::collect`],/// for convenience.try_collect/// `.try_collect()` is more convenient way of writing/// `.collect::<Result<_, _>>()`/// use std::{fs, io};/// fn process_dir_entries(entries: &[fs::DirEntry]) {/// fn do_stuff() -> std::io::Result<()> {///     let entries: Vec<_> = fs::read_dir(".")?.try_collect()?;///     process_dir_entries(&entries);set_from/// Assign to each reference in `self` from the `from` iterator,/// stopping at the shortest of the two iterators./// The `from` iterator is queried for its next element before the `self`/// iterator, and if either is exhausted the method is done./// Return the number of elements written./// let mut xs = [0; 4];/// xs.iter_mut().set_from(1..);/// assert_eq!(xs, [1, 2, 3, 4]);/// Use the `Display` implementation of each element./// assert_eq!(["a", "b", "c"].iter().join(", "), "a, b, c");/// assert_eq!([1, 2, 3].iter().join(", "), "1, 2, 3");/// Format all iterator elements, separated by `sep`./// All elements are formatted (any formatting trait)/// with `sep` inserted between each element./// **Panics** if the formatter helper is formatted more than once./// let data = [1.1, 2.71828, -3.];///     format!("{:.2}", data.iter().format(", ")),///            "1.10, 2.72, -3.00");/// This is a customizable version of [`.format()`](Itertools::format)./// The supplied closure `format` is called once per iterator element,/// with two arguments: the element and a callback that takes a/// `&Display` value, i.e. any reference to type that implements `Display`./// Using `&format_args!(...)` is the most versatile way to apply custom/// element formatting. The callback can be called multiple times if needed./// let data_formatter = data.iter().format_with(", ", |elt, f| f(&format_args!("{:.2}", elt)));/// assert_eq!(format!("{}", data_formatter),/// // .format_with() is recursively composable/// let matrix = [[1., 2., 3.],///               [4., 5., 6.]];/// let matrix_formatter = matrix.iter().format_with("\n", |row, f| {///                                 f(&row.iter().format_with(", ", |elt, g| g(&elt)))///                              });/// assert_eq!(format!("{}", matrix_formatter),///            "1, 2, 3\n4, 5, 6");fold_results/// See [`.fold_ok()`](Itertools::fold_ok).fold_ok/// Fold `Result` values from an iterator./// Only `Ok` values are folded. If no error is encountered, the folded/// value is returned inside `Ok`. Otherwise, the operation terminates/// and returns the first `Err` value it encounters. No iterator elements are/// consumed after the first error./// The first accumulator value is the `start` parameter./// Each iteration passes the accumulator value and the next value inside `Ok`/// to the fold function `f` and its return value becomes the new accumulator value./// For example the sequence *Ok(1), Ok(2), Ok(3)* will result in a/// computation like this:/// let mut accum = start;/// accum = f(accum, 1);/// accum = f(accum, 2);/// accum = f(accum, 3);/// With a `start` value of 0 and an addition as folding function,/// this effectively results in *((0 + 1) + 2) + 3*/// use std::ops::Add;/// let values = [1, 2, -2, -1, 2, 1];///     values.iter()///           .map(Ok::<_, ()>)///           .fold_ok(0, Add::add),///     Ok(3)///           .map(|&x| if x >= 0 { Ok(x) } else { Err("Negative number") })///           .fold_ok(0, Add::add)///           .is_err()fold_options/// Fold `Option` values from an iterator./// Only `Some` values are folded. If no `None` is encountered, the folded/// value is returned inside `Some`. Otherwise, the operation terminates/// and returns `None`. No iterator elements are consumed after the `None`./// This is the `Option` equivalent to [`fold_ok`](Itertools::fold_ok)./// let mut values = vec![Some(1), Some(2), Some(-2)].into_iter();/// assert_eq!(values.fold_options(5, Add::add), Some(5 + 1 + 2 - 2));/// let mut more_values = vec![Some(2), None, Some(0)].into_iter();/// assert!(more_values.fold_options(0, Add::add).is_none());/// assert_eq!(more_values.next().unwrap(), Some(0));fold1/// Accumulator of the elements in the iterator./// Like `.fold()`, without a base case. If the iterator is/// empty, return `None`. With just one element, return it./// Otherwise elements are accumulated in sequence using the closure `f`./// assert_eq!((0..10).fold1(|x, y| x + y).unwrap_or(0), 45);/// assert_eq!((0..0).fold1(|x, y| x * y), None);tree_fold1/// Accumulate the elements in the iterator in a tree-like manner./// You can think of it as, while there's more than one item, repeatedly/// combining adjacent items.  It does so in bottom-up-merge-sort order,/// however, so that it needs only logarithmic stack space./// This produces a call tree like the following (where the calls under/// an item are done after reading that item):/// 1 2 3 4 5 6 7/// │ │ │ │ │ │ │/// └─f └─f └─f │///   │   │   │ │///   └───f   └─f///       │     │///       └─────f/// Which, for non-associative functions, will typically produce a different/// result than the linear call tree used by [`Iterator::reduce`]:/// └─f─f─f─f─f─f/// If `f` is associative, prefer the normal [`Iterator::reduce`] instead./// // The same tree as above/// let num_strings = (1..8).map(|x| x.to_string());/// assert_eq!(num_strings.tree_fold1(|x, y| format!("f({}, {})", x, y)),///     Some(String::from("f(f(f(1, 2), f(3, 4)), f(f(5, 6), 7))")));/// // Like fold1, an empty iterator produces None/// assert_eq!((0..0).tree_fold1(|x, y| x * y), None);/// // tree_fold1 matches fold1 for associative operations.../// assert_eq!((0..10).tree_fold1(|x, y| x + y),///     (0..10).fold1(|x, y| x + y));/// // ...but not for non-associative ones/// assert_ne!((0..10).tree_fold1(|x, y| x - y),///     (0..10).fold1(|x, y| x - y));fold_whileFoldWhile/// An iterator method that applies a function, producing a single, final value./// `fold_while()` is basically equivalent to [`Iterator::fold`] but with additional support for/// early exit via short-circuiting./// use itertools::FoldWhile::{Continue, Done};/// let numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];/// let mut result = 0;/// // for loop:/// for i in &numbers {///     if *i > 5 {///         break;///     result = result + i;/// // fold:/// let result2 = numbers.iter().fold(0, |acc, x| {///     if *x > 5 { acc } else { acc + x }/// // fold_while:/// let result3 = numbers.iter().fold_while(0, |acc, x| {///     if *x > 5 { Done(acc) } else { Continue(acc + x) }/// }).into_inner();/// // they're the same/// assert_eq!(result, result2);/// assert_eq!(result2, result3);/// The big difference between the computations of `result2` and `result3` is that while/// `fold()` called the provided closure for every item of the callee iterator,/// `fold_while()` actually stopped iterating as soon as it encountered `Fold::Done(_)`.sum1/// Iterate over the entire iterator and add all the elements./// An empty iterator returns `None`, otherwise `Some(sum)`./// When calling `sum1()` and a primitive integer type is being returned, this/// method will panic if the computation overflows and debug assertions are/// enabled./// let empty_sum = (1..1).sum1::<i32>();/// assert_eq!(empty_sum, None);/// let nonempty_sum = (1..11).sum1::<i32>();/// assert_eq!(nonempty_sum, Some(55));product1/// Iterate over the entire iterator and multiply all the elements./// An empty iterator returns `None`, otherwise `Some(product)`./// When calling `product1()` and a primitive integer type is being returned,/// let empty_product = (1..1).product1::<i32>();/// assert_eq!(empty_product, None);/// let nonempty_product = (1..11).product1::<i32>();/// assert_eq!(nonempty_product, Some(3628800));sorted_unstable/// **Note:** This consumes the entire iterator, uses the/// [`slice::sort_unstable`] method and returns the result as a new/// iterator that owns its elements./// The sorted iterator, if directly collected to a `Vec`, is converted/// without any extra copying or allocation cost./// // sort the letters of the text in ascending order/// let text = "bdacfe";/// itertools::assert_equal(text.chars().sorted_unstable(),///                         "abcdef".chars());/// [`slice::sort_unstable_by`] method and returns the result as a new/// // sort people in descending order by age/// let people = vec![("Jane", 20), ("John", 18), ("Jill", 30), ("Jack", 27)];/// let oldest_people_first = people///     .into_iter()///     .sorted_unstable_by(|a, b| Ord::cmp(&b.1, &a.1))///     .map(|(person, _age)| person);/// itertools::assert_equal(oldest_people_first,///                         vec!["Jill", "Jack", "Jane", "John"]);sorted_unstable_by_key/// [`slice::sort_unstable_by_key`] method and returns the result as a new///     .sorted_unstable_by_key(|x| -x.1)/// [`slice::sort`] method and returns the result as a new/// itertools::assert_equal(text.chars().sorted(),/// [`slice::sort_by`] method and returns the result as a new///     .sorted_by(|a, b| Ord::cmp(&b.1, &a.1))sorted_by_key/// [`slice::sort_by_key`] method and returns the result as a new///     .sorted_by_key(|x| -x.1)sorted_by_cached_key/// Sort all iterator elements into a new iterator in ascending order. The key function is/// called exactly once per key./// [`slice::sort_by_cached_key`] method and returns the result as a new///     .sorted_by_cached_key(|x| -x.1)/// Sort the k smallest elements into a new iterator, in ascending order./// **Note:** This consumes the entire iterator, and returns the result/// as a new iterator that owns its elements.  If the input contains/// less than k elements, the result is equivalent to `self.sorted()`./// This is guaranteed to use `k * sizeof(Self::Item) + O(1)` memory/// and `O(n log k)` time, with `n` the number of elements in the input./// **Note:** This is functionally-equivalent to `self.sorted().take(k)`/// but much more efficient./// // A random permutation of 0..15/// let numbers = vec![6, 9, 1, 14, 0, 4, 8, 7, 11, 2, 10, 3, 13, 12, 5];/// let five_smallest = numbers///     .k_smallest(5);/// itertools::assert_equal(five_smallest, 0..5);partition_map/// Collect all iterator elements into one of two/// partitions. Unlike [`Iterator::partition`], each partition may/// have a distinct type./// use itertools::{Itertools, Either};/// let successes_and_failures = vec![Ok(1), Err(false), Err(true), Ok(2)];/// let (successes, failures): (Vec<_>, Vec<_>) = successes_and_failures///     .partition_map(|r| {///         match r {///             Ok(v) => Either::Left(v),///             Err(v) => Either::Right(v),/// assert_eq!(successes, [1, 2]);/// assert_eq!(failures, [false, true]);partition_result/// Partition a sequence of `Result`s into one list of all the `Ok` elements/// and another list of all the `Err` elements.///     .partition_result();/// Return a `HashMap` of keys mapped to `Vec`s of values. Keys and values/// are taken from `(Key, Value)` tuple pairs yielded by the input iterator./// Essentially a shorthand for `.into_grouping_map().collect::<Vec<_>>()`./// let data = vec![(0, 10), (2, 12), (3, 13), (0, 20), (3, 33), (2, 42)];/// let lookup = data.into_iter().into_group_map();/// assert_eq!(lookup[&0], vec![10, 20]);/// assert_eq!(lookup.get(&1), None);/// assert_eq!(lookup[&2], vec![12, 42]);/// assert_eq!(lookup[&3], vec![13, 33]);/// Return an `Iterator` on a `HashMap`. Keys mapped to `Vec`s of values. The key is specified/// in the closure./// Essentially a shorthand for `.into_grouping_map_by(f).collect::<Vec<_>>()`./// let lookup: HashMap<u32,Vec<(u32, u32)>> =///     data.clone().into_iter().into_group_map_by(|a| a.0);/// assert_eq!(lookup[&0], vec![(0,10),(0,20)]);/// assert_eq!(lookup[&2], vec![(2,12), (2,42)]);/// assert_eq!(lookup[&3], vec![(3,13), (3,33)]);///     data.into_iter()///         .into_group_map_by(|x| x.0)///         .map(|(key, values)| (key, values.into_iter().fold(0,|acc, (_,v)| acc + v )))///         .collect::<HashMap<u32,u32>>()[&0],///     30,into_grouping_map/// Constructs a `GroupingMap` to be used later with one of the efficient /// group-and-fold operations it allows to perform./// The input iterator must yield item in the form of `(K, V)` where the/// value of type `K` will be used as key to identify the groups and the/// value of type `V` as value for the folding operation./// See [`GroupingMap`] for more informations/// on what operations are available.into_grouping_map_by/// The values from this iterator will be used as values for the folding operation/// while the keys will be obtained from the values by calling `key_mapper`.min_set/// Return all minimum elements of an iterator./// let a: [i32; 0] = [];/// assert_eq!(a.iter().min_set(), Vec::<&i32>::new());/// let a = [1];/// assert_eq!(a.iter().min_set(), vec![&1]);/// let a = [1, 2, 3, 4, 5];/// let a = [1, 1, 1, 1];/// assert_eq!(a.iter().min_set(), vec![&1, &1, &1, &1]);/// The elements can be floats but no particular result is guaranteed/// if an element is NaN.min_set_by/// Return all minimum elements of an iterator, as determined by/// the specified function./// # use std::cmp::Ordering;/// let a: [(i32, i32); 0] = [];/// assert_eq!(a.iter().min_set_by(|_, _| Ordering::Equal), Vec::<&(i32, i32)>::new());/// let a = [(1, 2)];/// assert_eq!(a.iter().min_set_by(|&&(k1,_), &&(k2, _)| k1.cmp(&k2)), vec![&(1, 2)]);/// let a = [(1, 2), (2, 2), (3, 9), (4, 8), (5, 9)];/// assert_eq!(a.iter().min_set_by(|&&(_,k1), &&(_,k2)| k1.cmp(&k2)), vec![&(1, 2), &(2, 2)]);/// let a = [(1, 2), (1, 3), (1, 4), (1, 5)];/// assert_eq!(a.iter().min_set_by(|&&(k1,_), &&(k2, _)| k1.cmp(&k2)), vec![&(1, 2), &(1, 3), &(1, 4), &(1, 5)]);min_set_by_key/// assert_eq!(a.iter().min_set_by_key(|_| ()), Vec::<&(i32, i32)>::new());/// assert_eq!(a.iter().min_set_by_key(|&&(k,_)| k), vec![&(1, 2)]);/// assert_eq!(a.iter().min_set_by_key(|&&(_, k)| k), vec![&(1, 2), &(2, 2)]);/// assert_eq!(a.iter().min_set_by_key(|&&(k, _)| k), vec![&(1, 2), &(1, 3), &(1, 4), &(1, 5)]);max_set/// Return all maximum elements of an iterator./// assert_eq!(a.iter().max_set(), Vec::<&i32>::new());/// assert_eq!(a.iter().max_set(), vec![&1]);/// assert_eq!(a.iter().max_set(), vec![&5]);/// assert_eq!(a.iter().max_set(), vec![&1, &1, &1, &1]);max_set_by/// Return all maximum elements of an iterator, as determined by/// assert_eq!(a.iter().max_set_by(|_, _| Ordering::Equal), Vec::<&(i32, i32)>::new());/// assert_eq!(a.iter().max_set_by(|&&(k1,_), &&(k2, _)| k1.cmp(&k2)), vec![&(1, 2)]);/// assert_eq!(a.iter().max_set_by(|&&(_,k1), &&(_,k2)| k1.cmp(&k2)), vec![&(3, 9), &(5, 9)]);/// assert_eq!(a.iter().max_set_by(|&&(k1,_), &&(k2, _)| k1.cmp(&k2)), vec![&(1, 2), &(1, 3), &(1, 4), &(1, 5)]);max_set_by_key/// assert_eq!(a.iter().max_set_by_key(|_| ()), Vec::<&(i32, i32)>::new());/// assert_eq!(a.iter().max_set_by_key(|&&(k,_)| k), vec![&(1, 2)]);/// assert_eq!(a.iter().max_set_by_key(|&&(_, k)| k), vec![&(3, 9), &(5, 9)]);/// assert_eq!(a.iter().max_set_by_key(|&&(k, _)| k), vec![&(1, 2), &(1, 3), &(1, 4), &(1, 5)]);/// Return the minimum and maximum elements in the iterator./// The return type `MinMaxResult` is an enum of three variants:/// - `NoElements` if the iterator is empty./// - `OneElement(x)` if the iterator has exactly one element./// - `MinMax(x, y)` is returned otherwise, where `x <= y`. Two///    values are equal if and only if there is more than one///    element in the iterator and all elements are equal./// On an iterator of length `n`, `minmax` does `1.5 * n` comparisons,/// and so is faster than calling `min` and `max` separately which does/// `2 * n` comparisons./// use itertools::MinMaxResult::{NoElements, OneElement, MinMax};/// assert_eq!(a.iter().minmax(), NoElements);/// assert_eq!(a.iter().minmax(), OneElement(&1));/// assert_eq!(a.iter().minmax(), MinMax(&1, &5));/// assert_eq!(a.iter().minmax(), MinMax(&1, &1));/// Return the minimum and maximum element of an iterator, as determined by/// The return value is a variant of [`MinMaxResult`] like for [`.minmax()`](Itertools::minmax)./// For the minimum, the first minimal element is returned.  For the maximum,/// the last maximal element wins.  This matches the behavior of the standard/// [`Iterator::min`] and [`Iterator::max`] methods./// The keys can be floats but no particular result is guaranteed/// if a key is NaN./// the specified comparison function.position_max/// Return the position of the maximum element in the iterator./// If several elements are equally maximum, the position of the/// last of them is returned./// assert_eq!(a.iter().position_max(), None);/// let a = [-3, 0, 1, 5, -10];/// assert_eq!(a.iter().position_max(), Some(3));/// let a = [1, 1, -1, -1];/// assert_eq!(a.iter().position_max(), Some(1));position_max_by_key/// Return the position of the maximum element in the iterator, as/// determined by the specified function./// assert_eq!(a.iter().position_max_by_key(|x| x.abs()), None);/// let a = [-3_i32, 0, 1, 5, -10];/// assert_eq!(a.iter().position_max_by_key(|x| x.abs()), Some(4));/// let a = [1_i32, 1, -1, -1];/// assert_eq!(a.iter().position_max_by_key(|x| x.abs()), Some(3));position_max_by/// determined by the specified comparison function./// assert_eq!(a.iter().position_max_by(|x, y| x.cmp(y)), None);/// assert_eq!(a.iter().position_max_by(|x, y| x.cmp(y)), Some(3));/// assert_eq!(a.iter().position_max_by(|x, y| x.cmp(y)), Some(1));position_min/// Return the position of the minimum element in the iterator./// If several elements are equally minimum, the position of the/// first of them is returned./// assert_eq!(a.iter().position_min(), None);/// assert_eq!(a.iter().position_min(), Some(4));/// assert_eq!(a.iter().position_min(), Some(2));position_min_by_key/// Return the position of the minimum element in the iterator, as/// assert_eq!(a.iter().position_min_by_key(|x| x.abs()), None);/// assert_eq!(a.iter().position_min_by_key(|x| x.abs()), Some(1));/// assert_eq!(a.iter().position_min_by_key(|x| x.abs()), Some(0));position_min_by/// assert_eq!(a.iter().position_min_by(|x, y| x.cmp(y)), None);/// assert_eq!(a.iter().position_min_by(|x, y| x.cmp(y)), Some(4));/// assert_eq!(a.iter().position_min_by(|x, y| x.cmp(y)), Some(2));position_minmax/// Return the positions of the minimum and maximum elements in/// the iterator./// The return type [`MinMaxResult`] is an enum of three variants:/// - `OneElement(xpos)` if the iterator has exactly one element./// - `MinMax(xpos, ypos)` is returned otherwise, where the///    element at `xpos` ≤ the element at `ypos`. While the///    referenced elements themselves may be equal, `xpos` cannot///    be equal to `ypos`./// On an iterator of length `n`, `position_minmax` does `1.5 * n`/// comparisons, and so is faster than calling `position_min` and/// `position_max` separately which does `2 * n` comparisons./// For the minimum, if several elements are equally minimum, the/// position of the first of them is returned. For the maximum, if/// several elements are equally maximum, the position of the last/// of them is returned./// The elements can be floats but no particular result is/// guaranteed if an element is NaN./// assert_eq!(a.iter().position_minmax(), NoElements);/// let a = [10];/// assert_eq!(a.iter().position_minmax(), OneElement(0));/// assert_eq!(a.iter().position_minmax(), MinMax(4, 3));/// assert_eq!(a.iter().position_minmax(), MinMax(2, 1));position_minmax_by_key/// Return the postions of the minimum and maximum elements of an/// iterator, as determined by the specified function./// The return value is a variant of [`MinMaxResult`] like for/// [`position_minmax`]./// assert_eq!(a.iter().position_minmax_by_key(|x| x.abs()), NoElements);/// let a = [10_i32];/// assert_eq!(a.iter().position_minmax_by_key(|x| x.abs()), OneElement(0));/// assert_eq!(a.iter().position_minmax_by_key(|x| x.abs()), MinMax(1, 4));/// assert_eq!(a.iter().position_minmax_by_key(|x| x.abs()), MinMax(0, 3));/// [`position_minmax`]: Self::position_minmaxposition_minmax_by/// iterator, as determined by the specified comparison function./// assert_eq!(a.iter().position_minmax_by(|x, y| x.cmp(y)), NoElements);/// assert_eq!(a.iter().position_minmax_by(|x, y| x.cmp(y)), OneElement(0));/// assert_eq!(a.iter().position_minmax_by(|x, y| x.cmp(y)), MinMax(4, 3));/// assert_eq!(a.iter().position_minmax_by(|x, y| x.cmp(y)), MinMax(2, 1));exactly_one/// If the iterator yields exactly one element, that element will be returned, otherwise/// an error will be returned containing an iterator that has the same output as the input/// This provides an additional layer of validation over just calling `Iterator::next()`./// If your assumption that there should only be one element yielded is false this provides/// the opportunity to detect and handle that, preventing errors at a distance./// assert_eq!((0..10).filter(|&x| x == 2).exactly_one().unwrap(), 2);/// assert!((0..10).filter(|&x| x > 1 && x < 4).exactly_one().unwrap_err().eq(2..4));/// assert!((0..10).filter(|&x| x > 1 && x < 5).exactly_one().unwrap_err().eq(2..5));/// assert!((0..10).filter(|&_| false).exactly_one().unwrap_err().eq(0..0));at_most_one/// If the iterator yields no elements, Ok(None) will be returned. If the iterator yields/// exactly one element, that element will be returned, otherwise an error will be returned/// containing an iterator that has the same output as the input iterator./// If your assumption that there should be at most one element yielded is false this provides/// assert_eq!((0..10).filter(|&x| x == 2).at_most_one().unwrap(), Some(2));/// assert!((0..10).filter(|&x| x > 1 && x < 4).at_most_one().unwrap_err().eq(2..4));/// assert!((0..10).filter(|&x| x > 1 && x < 5).at_most_one().unwrap_err().eq(2..5));/// assert_eq!((0..10).filter(|&_| false).at_most_one().unwrap(), None);/// An iterator adaptor that allows the user to peek at multiple `.next()`/// values without advancing the base iterator./// let mut iter = (0..10).multipeek();/// assert_eq!(iter.peek(), Some(&0));/// assert_eq!(iter.peek(), Some(&1));/// assert_eq!(iter.peek(), Some(&2));/// assert_eq!(iter.next(), Some(0));counts/// Collect the items in this iterator and return a `HashMap` which/// contains each item that appears in the iterator and the number/// of times it appears./// # use itertools::Itertools;/// let counts = [1, 1, 1, 3, 3, 5].into_iter().counts();/// assert_eq!(counts[&1], 3);/// assert_eq!(counts[&3], 2);/// assert_eq!(counts[&5], 1);/// assert_eq!(counts.get(&0), None);counts_by/// of times it appears,/// determining identity using a keying function./// struct Character {///   first_name: &'static str,///   last_name:  &'static str,/// let characters =///         Character { first_name: "Amy",   last_name: "Pond"      },///         Character { first_name: "Amy",   last_name: "Wong"      },///         Character { first_name: "Amy",   last_name: "Santiago"  },///         Character { first_name: "James", last_name: "Bond"      },///         Character { first_name: "James", last_name: "Sullivan"  },///         Character { first_name: "James", last_name: "Norington" },///         Character { first_name: "James", last_name: "Kirk"      },///     ];/// let first_name_frequency = ///     characters///         .counts_by(|c| c.first_name);/// assert_eq!(first_name_frequency["Amy"], 3);/// assert_eq!(first_name_frequency["James"], 4);/// assert_eq!(first_name_frequency.contains_key("Asha"), false);FromI/// Converts an iterator of tuples into a tuple of containers./// `unzip()` consumes an entire iterator of n-ary tuples, producing `n` collections, one for each/// column./// This function is, in some sense, the opposite of [`multizip`]./// let inputs = vec![(1, 2, 3), (4, 5, 6), (7, 8, 9)];/// let (a, b, c): (Vec<_>, Vec<_>, Vec<_>) = inputs///     .multiunzip();/// assert_eq!(a, vec![1, 4, 7]);/// assert_eq!(b, vec![2, 5, 8]);/// assert_eq!(c, vec![3, 6, 9]);// adaptors/// An [`Iterator`] blanket implementation that provides extra adaptors and/// This trait defines a number of methods. They are divided into two groups:/// * *Adaptors* take an iterator and parameter as input, and return/// a new iterator value. These are listed first in the trait. An example/// of an adaptor is [`.interleave()`](Itertools::interleave)/// * *Regular methods* are those that don't return iterators and instead/// return a regular value of some other kind./// [`.next_tuple()`](Itertools::next_tuple) is an example and the first regular/// method in the list./// Return `true` if both iterables produce equal sequences/// (elements pairwise equal and sequences of the same length),/// `false` otherwise./// [`IntoIterator`] enabled version of [`Iterator::eq`]./// assert!(itertools::equal(vec![1, 2, 3], 1..4));/// assert!(!itertools::equal(&[0, 0], &[0, 0, 0]));assert_equal/// Assert that two iterables produce equal sequences, with the same/// semantics as [`equal(a, b)`](equal)./// **Panics** on assertion failure with a message that shows the/// two iteration elements./// assert_equal("exceed".split('c'), "excess".split('c'));/// // ^PANIC: panicked at 'Failed assertion Some("eed") == Some("ess") for iteration 1',/// Partition a sequence using predicate `pred` so that elements/// that map to `true` are placed before elements which map to `false`./// The order within the partitions is arbitrary./// Return the index of the split point./// use itertools::partition;/// # // use repeated numbers to not promise any ordering/// let mut data = [7, 1, 1, 7, 1, 1, 7];/// let split_index = partition(&mut data, |elt| *elt >= 3);/// assert_eq!(data, [7, 7, 7, 1, 1, 1, 1]);/// assert_eq!(split_index, 3);Continue/// Continue folding with this value/// Fold is complete and will return this value/// An enum used for controlling the execution of `fold_while`./// See [`.fold_while()`](Itertools::fold_while) for more information./// Return the value in the continue or done./// Return true if `self` is `Done`, false if it is `Continue`.//! Extra iterator adaptors, functions and macros.//! To extend [`Iterator`] with methods in this crate, import//! the [`Itertools`] trait://! use itertools::Itertools;//! Now, new methods like [`interleave`](Itertools::interleave)//! are available on all iterators://! let it = (1..3).interleave(vec![-1, -2]);//! itertools::assert_equal(it, vec![1, -1, 2, -2]);//! Most iterator methods are also provided as functions (with the benefit//! that they convert parameters using [`IntoIterator`])://! use itertools::interleave;//! for elt in interleave(&[1, 2, 3], &[2, 3, 4]) {//!     /* loop body *///! ## Crate Features//! - `use_std`//!   - Enabled by default.//!   - Disable to compile itertools using `#![no_std]`. This disables//!     any items that depend on collections (like `group_by`, `unique`,//!     `kmerge`, `join` and many more).//! This version of itertools requires Rust 1.32 or later./// Return an iterator adaptor that merge-joins items from the two base iterators in ascending order./// [`IntoIterator`] enabled version of [`Itertools::merge_join_by`].cmp_fn/// An iterator adaptor that merge-joins items from the two base iterators in ascending order./// See [`.merge_join_by()`](crate::Itertools::merge_join_by) for more information.NoElements/// Empty iteratorOneElement/// Iterator with one element, so the minimum and maximum are the sameMinMax/// More than one element in the iterator, the first element is not larger/// than the second/// `MinMaxResult` is an enum returned by `minmax`./// See [`.minmax()`](crate::Itertools::minmax) for more detail./// `into_option` creates an `Option` of type `(T, T)`. The returned `Option`/// has variant `None` if and only if the `MinMaxResult` has variant/// `NoElements`. Otherwise `Some((x, y))` is returned where `x <= y`./// If the `MinMaxResult` has variant `OneElement(x)`, performing this/// operation will make one clone of `x`./// use itertools::MinMaxResult::{self, NoElements, OneElement, MinMax};/// let r: MinMaxResult<i32> = NoElements;/// assert_eq!(r.into_option(), None);/// let r = OneElement(1);/// assert_eq!(r.into_option(), Some((1, 1)));/// let r = MinMax(1, 2);/// assert_eq!(r.into_option(), Some((1, 2)));minmax_impl/// Implementation guts for `minmax` and `minmax_by_key`./// See [`multipeek()`] for more information./// [`IntoIterator`] enabled version of [`Itertools::multipeek`].reset_peek/// Reset the peeking “cursor”/// Works exactly like `.next()` with the only difference that it doesn't/// advance itself. `.peek()` can be called multiple times, to peek/// further ahead./// When `.next()` is called, reset the peeking “cursor”.peeking_next// Same sizefiller/// An iterator adaptor that pads a sequence to a minimum length by filling/// missing elements using a closure./// See [`.pad_using()`](crate::Itertools::pad_using) for more information./// Create a new `PadUsing` iterator./// See [`peek_nth()`] for more information./// A drop-in replacement for [`std::iter::Peekable`] which adds a `peek_nth`/// method allowing the user to `peek` at a value several iterations forward/// without advancing the base iterator./// This differs from `multipeek` in that subsequent calls to `peek` or/// `peek_nth` will always return the same value until `next` is called/// (making `reset_peek` unnecessary)./// Works exactly like the `peek` method in `std::iter::Peekable`/// Returns a reference to the `nth` value without advancing the iterator./// use itertools::peek_nth;/// let xs = vec![1,2,3];/// let mut iter = peek_nth(xs.iter());/// assert_eq!(iter.peek_nth(0), Some(&&1));/// assert_eq!(iter.next(), Some(&1));/// // The iterator does not advance even if we call `peek_nth` multiple times/// assert_eq!(iter.peek_nth(0), Some(&&2));/// assert_eq!(iter.peek_nth(1), Some(&&3));/// assert_eq!(iter.next(), Some(&2));/// // Calling `peek_nth` past the end of the iterator will return `None`/// assert_eq!(iter.peek_nth(1), None);/// Pass a reference to the next iterator element to the closure `accept`;/// if `accept` returns true, return it as the next element,/// else None./// An iterator that allows peeking at an element before deciding to accept it./// See [`.peeking_take_while()`](crate::Itertools::peeking_take_while)/// This is implemented by peeking adaptors like peekable and put back,/// but also by a few iterators that can be peeked natively, like the slice’s/// by reference iterator (`std::slice::Iter`)./// An iterator adaptor that takes items while a closure returns `true`./// Create a `PeekingTakeWhile`peeking_next_by_clone// Some iterators are so lightweight we can simply clone them to save their// state and use that for peeking.CharIndiceslinked_listvec_deque// cloning a Rev has no extra overhead; peekable and put backs are never DEI.PermutationState/// An iterator adaptor that iterates through all the `k`-permutations of the/// See [`.permutations()`](crate::Itertools::permutations) forStartUnknownLenmin_nOngoingUnknownLenCompleteStateCompletecyclesOngoingCompleteStateRemainingKnownadvancecombs// Iterator `position` (equal to count of yielded elements)./// An iterator to iterate through the powerset of the elements from an iterator./// See [`.powerset()`](crate::Itertools::powerset) for more/// Create a new `Powerset` from a clonable iterator./// An iterator that produces only the `T` values as long as the/// inner iterator produces `Ok(T)`./// Used by [`process_results`](crate::process_results), see its docs/// “Lift” a function of the values of an iterator so that it can process/// an iterator of `Result` values instead./// `iterable` is an iterator or iterable with `Result<T, E>` elements, where/// `T` is the value type and `E` the error type./// `processor` is a closure that receives an adapted version of the iterable/// as the only argument — the adapted iterator produces elements of type `T`,/// as long as the original iterator produces `Ok` values./// If the original iterable produces an error at any point, the adapted/// iterator ends and the `process_results` function will return the/// error iself./// Otherwise, the return value from the closure is returned wrapped/// inside `Ok`./// use itertools::process_results;/// type R = Result<i32, &'static str>;/// let first_values: Vec<R> = vec![Ok(1), Ok(0), Ok(3)];/// let second_values: Vec<R> = vec![Ok(2), Ok(1), Err("overflow")];/// // “Lift” the iterator .max() method to work on the values in Results using process_results/// let first_max = process_results(first_values, |iter| iter.max().unwrap_or(0));/// let second_max = process_results(second_values, |iter| iter.max().unwrap_or(0));/// assert_eq!(first_max, Ok(3));/// assert!(second_max.is_err());/// An iterator adaptor that allows putting multiple/// items in front of the iterator./// Create an iterator where you can put back multiple values to the front/// of the iteration./// Puts x in front of the iterator./// The values are yielded in order of the most recently put back/// values first./// use itertools::put_back_n;/// let mut it = put_back_n(1..5);/// it.next();/// it.put_back(1);/// it.put_back(0);/// assert!(itertools::equal(it, 0..5));/// The boxed iterator./// A wrapper for `Rc<RefCell<I>>`, that implements the `Iterator` trait./// Return an iterator inside a `Rc<RefCell<_>>` wrapper./// The returned `RcIter` can be cloned, and each clone will refer back to the/// same original iterator./// `RcIter` allows doing interesting things like using `.zip()` on an iterator with/// itself, at the cost of runtime borrow checking which may have a performance/// penalty./// use itertools::rciter;/// // In this example a range iterator is created and we iterate it using/// // three separate handles (two of them given to zip)./// // We also use the IntoIterator implementation for `&RcIter`./// let mut iter = rciter(0..9);/// let mut z = zip(&iter, &iter);/// assert_eq!(z.next(), Some((0, 1)));/// assert_eq!(z.next(), Some((2, 3)));/// assert_eq!(z.next(), Some((4, 5)));/// assert_eq!(iter.next(), Some(6));/// assert_eq!(z.next(), Some((7, 8)));/// assert_eq!(z.next(), None);/// **Panics** in iterator methods if a borrow error is encountered in the/// iterator methods. It can only happen if the `RcIter` is reentered in/// `.next()`, i.e. if it somehow participates in an “iterator knot”/// where it is an adaptor of itself./// Return an iterator from `&RcIter<I>` (by simply cloning it)."iterators are lazy and do nothing unless consumed"elt/// An iterator that produces *n* repetitions of an element./// See [`repeat_n()`](crate::repeat_n) for more information./// Create an iterator that produces `n` repetitions of `element`.SizeHint/// `SizeHint` is the return type of `Iterator::size_hint()`./// Add `SizeHint` correctly.add_scalar/// Add `x` correctly to a `SizeHint`.sub_scalar/// Subtract `x` correctly from a `SizeHint`./// Multiply `SizeHint` correctly/// use std::usize;/// use itertools::size_hint;/// assert_eq!(size_hint::mul((3, Some(4)), (3, Some(4))),///            (9, Some(16)));/// assert_eq!(size_hint::mul((3, Some(4)), (usize::MAX, None)),///            (usize::MAX, None));/// assert_eq!(size_hint::mul((3, None), (0, Some(0))),///            (0, Some(0)));mul_scalar/// Multiply `x` correctly with a `SizeHint`.pow_scalar_base/// Raise `base` correctly by a `SizeHint` exponent./// Return the maximum/// Return the minimum//! Arithmetic on `Iterator.size_hint()` values./// See [`repeat_call`](crate::repeat_call) for more information./// An iterator source that produces elements indefinitely by calling/// a given closure./// Iterator element type is the return type of the closure./// use itertools::repeat_call;/// use std::collections::BinaryHeap;/// let mut heap = BinaryHeap::from(vec![2, 5, 3, 7, 8]);/// // extract each element in sorted order/// for element in repeat_call(|| heap.pop()).while_some() {///     print!("{}", element);///     repeat_call(|| 1).take(5),///     vec![1, 1, 1, 1, 1]St/// Creates a new unfold source with the specified closure as the "iterator/// function" and an initial state to eventually pass to the closure/// `unfold` is a general iterator builder: it has a mutable state value,/// and a closure with access to the state that produces the next value./// This more or less equivalent to a regular struct with an [`Iterator`]/// implementation, and is useful for one-off iterators./// // an iterator that yields sequential Fibonacci numbers,/// // and stops at the maximum representable value./// use itertools::unfold;/// let mut fibonacci = unfold((1u32, 1u32), |(x1, x2)| {///     // Attempt to get the next Fibonacci number///     let next = x1.saturating_add(*x2);///     // Shift left: ret <- x1 <- x2 <- next///     let ret = *x1;///     *x1 = *x2;///     *x2 = next;///     // If addition has saturated at the maximum, we are finished///     if ret == *x1 && ret > 1 {///         Some(ret)/// itertools::assert_equal(fibonacci.by_ref().take(8),///                         vec![1, 1, 2, 3, 5, 8, 13, 21]);/// assert_eq!(fibonacci.last(), Some(2_971_215_073))/// Internal state that will be passed to the closure on the next iteration/// See [`unfold`](crate::unfold) for more information./// An iterator that infinitely applies function to value and yields results./// This `struct` is created by the [`iterate()`](crate::iterate) function./// Creates a new iterator that infinitely applies function to value and yields results./// use itertools::iterate;/// itertools::assert_equal(iterate(1, |&i| i * 3).take(5), vec![1, 3, 9, 27, 81]);//! Iterators that are sources (produce elements from parameters,//! not from another iterator).backlog/// The owner field indicates which id should read from the backlogTeeBuffer/// Common buffer object for the two tee halvesrcbuffer/// One half of an iterator pair where both return the same elements./// See [`.tee()`](crate::Itertools::tee) for more information.TakeCycle/// Implemented for homogeneous tuples of size up to 12./// An iterator over a incomplete tuple./// See [`.tuples()`](crate::Itertools::tuples) and/// [`Tuples::into_buffer()`]./// An iterator that groups the items in tuples of a specific size./// See [`.tuples()`](crate::Itertools::tuples) for more information./// Create a new tuples iterator.into_buffer/// Return a buffer with the produced items that was not enough to be grouped in a tuple./// let mut iter = (0..5).tuples();/// assert_eq!(Some((0, 1, 2)), iter.next());/// assert_eq!(None, iter.next());/// itertools::assert_equal(vec![3, 4], iter.into_buffer());/// An iterator over all contiguous windows that produces tuples of a specific size./// See [`.tuple_windows()`](crate::Itertools::tuple_windows) for more/// Create a new tuple windows iterator.phantom_data/// An iterator over all windows,wrapping back to the first elements when the/// window would otherwise exceed the length of the iterator, producing tuples/// See [`.circular_tuple_windows()`](crate::Itertools::circular_tuple_windows) for morecollect_from_itercollect_from_iter_no_bufnum_itemsleft_shift_pushcount_identrev_for_each_identimpl_tuple_collect//! Some iterator that produces tuples// `HomogeneousTuple` is a public facade for `TupleCollect`, allowing// tuple-related methods to be used by clients in generic contexts, while// hiding the implementation details of `TupleCollect`.// See https://github.com/rust-itertools/itertools/issues/387// Use a Hashmap for the Entry API in order to prevent hashing twice.// This can maybe be replaced with a HashSet once `get_or_insert_with`// or a proper Entry API for Hashset is stable and meets this msrv/// See [`.unique_by()`](crate::Itertools::unique) for more information./// Create a new `UniqueBy` iterator.count_new_keys// count the number of new unique keys in iterable (`used` is the set already seen)/// See [`.unique()`](crate::Itertools::unique) for more information./// use itertools::multiunzip;/// let (a, b, c): (Vec<_>, Vec<_>, Vec<_>) = multiunzip(inputs);/// [`multizip`]: crate::multizip/// Unzip this iterator into multiple collections./// An iterator that can be unzipped into multiple collections./// See [`.multiunzip()`](crate::Itertools::multiunzip) for more information.impl_unzip_iterITFromAFromBFromCFromDFromEFromFFromGFromHFromJFromKFromLhandled_firstpeekable/// An iterator adaptor that wraps each element in an [`Position`]./// Iterator element type is `Position<I::Item>`./// See [`.with_position()`](crate::Itertools::with_position) for more information./// Create a new `WithPosition` iterator./// This is the first element.Middle/// This is neither the first nor the last element.Last/// This is the last element./// This is the only element./// A value yielded by `WithPosition`./// Indicates the position of this element in the iterator results./// Return the inner value./// An iterator which iterates two other iterators simultaneously/// See [`.zip_eq()`](crate::Itertools::zip_eq) for more information./// Iterate `i` and `j` in lock step./// **Panics** if the iterators are not of the same length./// [`IntoIterator`] enabled version of [`Itertools::zip_eq`](crate::Itertools::zip_eq)./// use itertools::zip_eq;/// let data = [1, 2, 3, 4, 5];/// for (a, b) in zip_eq(&data[..data.len() - 1], &data[1..]) {EqualGreaterLess/// See [`.zip_longest()`](crate::Itertools::zip_longest) for more information./// Create a new `ZipLongest` iterator.// ZipLongest originally written by SimonSapin,// and dedicated to itertools https://github.com/rust-lang/rust/pull/19283/// See [`multizip`] for more information./// An iterator that generalizes *.zip()* and allows running multiple iterators in lockstep./// The iterator `Zip<(I, J, ..., M)>` is formed from a tuple of iterators (or values that/// implement [`IntoIterator`]) and yields elements/// until any of the subiterators yields `None`./// The iterator element type is a tuple like like `(A, B, ..., E)` where `A` to `E` are the/// element types of the subiterator./// **Note:** The result of this macro is a value of a named type (`Zip<(I, J,/// ..)>` of each component iterator `I, J, ...`) if each component iterator is/// nameable./// Prefer [`izip!()`] over `multizip` for the performance benefits of using the/// standard library `.zip()`. Prefer `multizip` if a nameable type is needed./// use itertools::multizip;/// for (r, index, input) in multizip((&mut results, 0..10, &inputs)) {/// [`izip!()`]: crate::izipimpl_zip_iterudiv128MAX_STR_LEN/// A correctly sized stack allocation for the formatted integer to be written/// let mut buffer = itoa::Buffer::new();/// let printed = buffer.format(1234);/// assert_eq!(printed, "1234");// false positive https://github.com/rust-lang/rust-clippy/issues/11072/// This is a cheap operation; you don't need to worry about reusing buffers/// for efficiency./// Print an integer into this buffer and return a reference to its string/// representation within the buffer./// The maximum length of string that formatting an integer of this type can/// produce on the current target platform./// An integer that can be written into an [`itoa::Buffer`][Buffer]./// This trait is sealed and cannot be implemented for types outside of itoa.// Seal to prevent downstream implementations of the Integer trait.DEC_DIGITS_LUTimpl_Integer// Adaptation of the original implementation at// https://github.com/rust-lang/rust/blob/b8214dc6c6fc20d0a660fb5700dca9ebf51ebe89/src/libcore/fmt/num.rs#L188-L266impl_Integer_sizeimpl_Integer128//! [![github]](https://github.com/dtolnay/itoa)&ensp;[![crates-io]](https://crates.io/crates/itoa)&ensp;[![docs-rs]](https://docs.rs/itoa)//! This crate provides a fast conversion of integer primitives to decimal//! strings. The implementation comes straight from [libcore] but avoids the//! performance penalty of going through [`core::fmt::Formatter`].//! See also [`ryu`] for printing floating point primitives.//! [libcore]: https://github.com/rust-lang/rust/blob/b8214dc6c6fc20d0a660fb5700dca9ebf51ebe89/src/libcore/fmt/num.rs#L201-L254//! [`ryu`]: https://github.com/dtolnay/ryu//!     let mut buffer = itoa::Buffer::new();//!     let printed = buffer.format(128u64);//!     assert_eq!(printed, "128");//! # Performance (lower is better)//! ![performance](https://raw.githubusercontent.com/dtolnay/itoa/master/performance.png)u128_mulhi/// Multiply unsigned 128 bit integers, return upper 128 bits of the resultudivmod_1e19/// Divide `n` by 1e19 and return quotient and remainder/// Integer division algorithm is based on the following paper:///   T. Granlund and P. Montgomery, “Division by Invariant Integers Using Multiplication”///   in Proc. of the SIGPLAN94 Conference on Programming Language Design and///   Implementation, 1994, pp. 61–72FromEnvErrorInnerFromEnvError/// Error type for [`Client::from_env_ext`] function./// [`Client::from_env_ext`]: crate::Client::from_env_extFromEnvErrorKindNoEnvVar/// There is no environment variable that describes jobserver to inherit.NoJobserver/// There is no jobserver in the environment variable./// Variables associated with Make can be used for passing data other than jobserver info.CannotParse/// Cannot parse jobserver environment variable value, incorrect format.CannotOpenPath/// Cannot open path or name from the jobserver environment variable value.CannotOpenFd/// Cannot open file descriptor from the jobserver environment variable value.NegativeFd/// The jobserver style is a simple pipe, but at least one of the file descriptors/// is negative, which means it is disabled for this process/// ([GNU `make` manual: POSIX Jobserver Interaction](https://www.gnu.org/software/make/manual/make.html#POSIX-Jobserver)).NotAPipe/// File descriptor from the jobserver environment variable value is not a pipe.Unsupported/// Jobserver inheritance is not supported on this platform./// Kind of an error returned from [`Client::from_env_ext`] function./// Get the error kind./// A client of a jobserver/// This structure is the main type exposed by this library, and is where/// interaction to a jobserver is configured through. Clients are either created/// from scratch in which case the internal semphore is initialied on the spot,/// or a client is created from the environment to connect to a jobserver/// already created./// Some usage examples can be found in the crate documentation for using a/// client./// Note that a [`Client`] implements the [`Clone`] trait, and all instances of/// a [`Client`] refer to the same jobserver instance.disabled/// An acquired token from a jobserver./// This token will be released back to the jobserver when it is dropped and/// otherwise represents the ability to spawn off another thread of work.drop_without_releasing/// This drops the [`Acquired`] token without releasing the associated token./// This is not generally useful, but can be helpful if you do not have the/// ability to store an Acquired token but need to not yet release it./// You'll typically want to follow this up with a call to/// [`Client::release_raw`] or similar to actually release the token later on.HelperInnerHelperStaterequestsproducer_doneconsumer_done/// Result of trying to get jobserver client from env./// Name and value of the environment variable./// `None` if no relevant environment variable is found.FromEnv/// Return type for [`Client::from_env_ext`] function.new_oknew_err/// Creates a new jobserver initialized with the given parallelism limit./// A client to the jobserver created will be returned. This client will/// allow at most `limit` tokens to be acquired from it in parallel. More/// calls to [`Client::acquire`] will cause the calling thread to block./// Note that the created [`Client`] is not automatically inherited into/// spawned child processes from this program. Manual usage of the/// [`Client::configure`] function is required for a child process to have/// access to a job server./// use jobserver::Client;/// let client = Client::new(4).expect("failed to create jobserver");/// Returns an error if any I/O error happens when attempting to create the/// jobserver client.from_env_ext/// Attempts to connect to the jobserver specified in this process's/// environment./// When the a `make` executable calls a child process it will configure the/// environment of the child to ensure that it has handles to the jobserver/// it's passing down. This function will attempt to look for these details/// and connect to the jobserver./// # Return value/// [`FromEnv`] contains result and relevant environment variable./// If a jobserver was found in the environment and it looks correct then/// result with the connected client will be returned. In other cases/// result will contain `Err(FromEnvErr)`./// Additionally on Unix this function will configure the file descriptors/// with `CLOEXEC` so they're not automatically inherited by spawned/// children./// On unix if `check_pipe` enabled this function will check if provided/// files are actually pipes./// This function is `unsafe` to call on Unix specifically as it/// transitively requires usage of the `from_raw_fd` function, which is/// itself unsafe in some circumstances./// It's recommended to call this function very early in the lifetime of a/// program before any other file descriptors are opened. That way you can/// make sure to take ownership properly of the file descriptors passed/// down, if any./// It is ok to call this function any number of times./// Wraps [`Client::from_env_ext`] and discards error details./// Acquires a token from this jobserver client./// This function will block the calling thread until a new token can be/// acquired from the jobserver./// On successful acquisition of a token an instance of [`Acquired`] is/// returned. This structure, when dropped, will release the token back to/// the jobserver. It's recommended to avoid leaking this value./// If an I/O error happens while acquiring a token then this function will/// return immediately with the error. If an error is returned then a token/// was not acquired.try_acquire/// Acquires a token from this jobserver client in a non-blocking way./// If non-blocking acquire is not supported, the return error will have its `kind()`/// set to [`io::ErrorKind::Unsupported`]./// Returns amount of tokens in the read-side pipe./// Number of bytes available to be read from the jobserver pipe/// Underlying errors from the ioctl will be passed up.configure/// Configures a child process to have access to this client's jobserver as/// well./// This function is required to be called to ensure that a jobserver is/// properly inherited to a child process. If this function is *not* called/// then this [`Client`] will not be accessible in the child process. In/// other words, if not called, then [`Client::from_env`] will return `None`/// in the child process (or the equivalent of [`Client::from_env`] that/// `make` uses)./// ## Platform-specific behavior/// On Unix and Windows this will clobber the `CARGO_MAKEFLAGS` environment/// variables for the child process, and on Unix this will also allow the/// two file descriptors for this client to be inherited to the child./// On platforms other than Unix and Windows this panics.configure_make/// On Unix and Windows this will clobber the `CARGO_MAKEFLAGS`,/// `MAKEFLAGS` and `MFLAGS` environment variables for the child process,/// and on Unix this will also allow the two file descriptors for/// this client to be inherited to the child.mflags_envinto_helper_thread/// Converts this [`Client`] into a helper thread to deal with a blocking/// [`Client::acquire`] function a little more easily./// The fact that the [`Client::acquire`] isn't always the easiest to work/// with. Typically you're using a jobserver to manage running other events/// in parallel! This means that you need to either (a) wait for an existing/// job to finish or (b) wait for a new token to become available./// Unfortunately the blocking in [`Client::acquire`] happens at the/// implementation layer of jobservers. On Unix this requires a blocking/// call to `read` and on Windows this requires one of the `WaitFor*`/// functions. Both of these situations aren't the easiest to deal with:/// * On Unix there's basically only one way to wake up a `read` early, and///   that's through a signal. This is what the `make` implementation///   itself uses, relying on `SIGCHLD` to wake up a blocking acquisition///   of a new job token. Unfortunately nonblocking I/O is not an option///   here, so it means that "waiting for one of two events" means that///   the latter event must generate a signal! This is not always the case///   on unix for all jobservers./// * On Windows you'd have to basically use the `WaitForMultipleObjects`///   which means that you've got to canonicalize all your event sources///   into a `HANDLE` which also isn't the easiest thing to do///   unfortunately./// This function essentially attempts to ease these limitations by/// converting this [`Client`] into a helper thread spawned into this/// process. The application can then request that the helper thread/// acquires tokens and the provided closure will be invoked for each token/// acquired./// The intention is that this function can be used to translate the event/// of a token acquisition into an arbitrary user-defined event./// This function will consume the [`Client`] provided to be transferred to/// the helper thread that is spawned. Additionally a closure `f` is/// provided to be invoked whenever a token is acquired./// This closure is only invoked after calls to/// [`HelperThread::request_token`] have been made and a token itself has/// been acquired. If an error happens while acquiring the token then/// an error will be yielded to the closure as well./// This function will return an instance of the [`HelperThread`] structure/// which is used to manage the helper thread associated with this client./// Through the [`HelperThread`] you'll request that tokens are acquired./// When acquired, the closure provided here is invoked./// When the [`HelperThread`] structure is returned it will be gracefully/// torn down, and the calling thread will be blocked until the thread is/// torn down (which should be prompt)./// This function may fail due to creation of the helper thread or/// auxiliary I/O objects to manage the helper thread. In any of these/// situations the error is propagated upwards./// # Platform-specific behavior/// On Windows this function behaves pretty normally as expected, but on/// Unix the implementation is... a little heinous. As mentioned above/// we're forced into blocking I/O for token acquisition, namely a blocking/// call to `read`. We must be able to unblock this, however, to tear down/// the helper thread gracefully!/// Essentially what happens is that we'll send a signal to the helper/// thread spawned and rely on `EINTR` being returned to wake up the helper/// thread. This involves installing a global `SIGUSR1` handler that does/// nothing along with sending signals to that thread. This may cause/// odd behavior in some applications, so it's recommended to review and/// test thoroughly before using this.acquire_raw/// Blocks the current thread until a token is acquired./// This is the same as [`Client::acquire`], except that it doesn't return/// an RAII helper. If successful the process will need to guarantee that/// [`Client::release_raw`] is called in the future.release_raw/// Releases a jobserver token back to the original jobserver./// This is intended to be paired with [`Client::acquire_raw`] if it was/// called, but in some situations it could also be called to relinquish a/// process's implicit token temporarily which is then re-acquired later.Helper/// Structure returned from [`Client::into_helper_thread`] to manage the lifetime/// of the helper thread returned, see those associated docs for more info.request_token/// Request that the helper thread acquires a token, eventually calling the/// original closure with a token when it's available./// For more information, see the docs on [`Client::into_helper_thread`].for_each_request/// Executes `f` for each request for a token, where `f` is expected to/// block and then provide the original closure with a token once it's/// This is an infinite loop until the helper thread is dropped, at which/// point everything should get interrupted.find_jobserver_auth/// Finds and returns the value of `--jobserver-auth=<VALUE>` in the given/// Precedence rules:/// * The last instance wins [^1]./// * `--jobserver-fds=` as a fallback when no `--jobserver-auth=` is present [^2]./// [^1]: See ["GNU `make` manual: Sharing Job Slots with GNU `make`"](https://www.gnu.org/software/make/manual/make.html#Job-Slots)/// _"Be aware that the `MAKEFLAGS` variable may contain multiple instances of/// the `--jobserver-auth=` option. Only the last instance is relevant."_/// [^2]: Refer to [the release announcement](https://git.savannah.gnu.org/cgit/make.git/tree/NEWS?h=4.2#n31)/// of GNU Make 4.2, which states that `--jobserver-fds` was initially an/// internal-only flag and was later renamed to `--jobserver-auth`.run_named_fifo_try_acquire_testsno_helper_deadlocktest_find_jobserver_auth//! An implementation of the GNU make jobserver.//! This crate is an implementation, in Rust, of the GNU `make` jobserver for//! CLI tools that are interoperating with make or otherwise require some form//! of parallelism limiting across process boundaries. This was originally//! written for usage in Cargo to both (a) work when `cargo` is invoked from//! `make` (using `make`'s jobserver) and (b) work when `cargo` invokes build//! scripts, exporting a jobserver implementation for `make` processes to//! transitively use.//! The jobserver implementation can be found in [detail online][docs] but//! basically boils down to a cross-process semaphore. On Unix this is//! implemented with the `pipe` syscall and read/write ends of a pipe and on//! Windows this is implemented literally with IPC semaphores. Starting from//! GNU `make` version 4.4, named pipe becomes the default way in communication//! on Unix. This crate also supports that feature in the sense of inheriting//! and forwarding the correct environment.//! The jobserver protocol in `make` also dictates when tokens are acquired to//! run child work, and clients using this crate should take care to implement//! such details to ensure correct interoperation with `make` itself.//! ## Examples//! Connect to a jobserver that was set up by `make` or a different process://! ```no_run//! use jobserver::Client;//! // See API documentation for why this is `unsafe`//! let client = match unsafe { Client::from_env() } {//!     Some(client) => client,//!     None => panic!("client not configured"),//! Acquire and release token from a jobserver://! let client = unsafe { Client::from_env().unwrap() };//! let token = client.acquire().unwrap(); // blocks until it is available//! drop(token); // releases the token when the work is done//! Create a new jobserver and configure a child process to have access://! use std::process::Command;//! let client = Client::new(4).expect("failed to create jobserver");//! let mut cmd = Command::new("make");//! client.configure(&mut cmd);//! ## Caveats//! This crate makes no attempt to release tokens back to a jobserver on//! abnormal exit of a process. If a process which acquires a token is killed//! with ctrl-c or some similar signal then tokens will not be released and the//! jobserver may be in a corrupt state.//! Note that this is typically ok as ctrl-c means that an entire build process//! is being torn down, but it's worth being aware of at least!//! ## Windows caveats//! There appear to be two implementations of `make` on Windows. On MSYS2 one//! typically comes as `mingw32-make` and the other as `make` itself. I'm not//! personally too familiar with what's going on here, but for jobserver-related//! information the `mingw32-make` implementation uses Windows semaphores//! whereas the `make` program does not. The `make` program appears to use file//! descriptors and I'm not really sure how it works, so this crate is not//! compatible with `make` on Windows. It is, however, compatible with//! `mingw32-make`.//! [docs]: https://make.mad-scientist.net/papers/jobserver-implementation/ClientCreationArgFds/// This preserves the `--jobserver-auth` type at creation time,/// so auth type will be passed down to and inherit from sub-Make processes correctly./// See <https://github.com/rust-lang/jobserver-rs/issues/99> for details.creation_arg/// It is set to `None` if the pipe is shared with other processes, so it/// cannot support non-blocking mode./// If it is set to `Some`, then it can only go from/// `Some(false)` -> `Some(true)` but not the other way around,/// since that could cause a race condition.mkfrom_fifo/// `--jobserver-auth=fifo:PATH`from_pipe/// `--jobserver-auth=R,W`from_fdsacquire_allow_interrupts/// Block waiting for a token, returning `None` if we're interrupted with/// EINTR.releasestring_argspawn_helperfcntl_checkfd_checkclone_fd_and_set_cloexecset_cloexecset_nonblockingcvtsigusr1_handlersiginfo_tClientImpfrom_imp_clientnew_client_from_fifonew_client_from_pipetest_try_acquire_named_fifotest_try_acquire_annoymous_pipe_linux_specific_optimizationtest_string_argCStringsemHandleLONGERROR_ALREADY_EXISTSINFINITESYNCHRONIZETRUECloseHandleSetEventWaitForMultipleObjectsCreateEventAReleaseSemaphoreCreateSemaphoreAOpenSemaphoreAWaitForSingleObject// HANDLE is a raw ptr, but we're send/syncp1600_armv8_sha3_asm/// Keccak-p1600 on ARMv8.4-A with FEAT_SHA3./// See p. K12.2.2  p. 11,749 of the ARM Reference manual./// Adapted from the Keccak-f1600 implementation in the XKCP/K12./// see <https://github.com/XKCP/K12/blob/df6a21e6d1f34c1aa36e8d702540899c97dba5a0/lib/ARMv8Asha3/KeccakP-1600-ARMv8Asha3.S#L69>test_keccak_f1600PLENRHORCKECCAK_F_ROUND_COUNT/// Number of rounds of the Keccak-f permutation.truncate_rc/// Truncate function.rotate_left/// Rotate left function.LaneSize/// Keccak is a permutation over an array of lanes which comprise the sponge/// construction.impl_lanesizeimpl_keccakr" Keccak-p sponge function"p200r" Keccak-f sponge function"f200p400f400p800f800p1600f1600keccak_p/// Generic Keccak-p sponge functionkeccak_fkeccak_f200keccak_f400keccak_f800keccak_f1600//! Keccak [sponge function](https://en.wikipedia.org/wiki/Sponge_function).//! If you are looking for SHA-3 hash functions take a look at [`sha3`][1] and//! [`tiny-keccak`][2] crates.//! To disable loop unrolling (e.g. for constraint targets) use `no_unroll`//! feature.//! // Test vectors are from KeccakCodePackage//! let mut data = [0u64; 25];//! keccak::f1600(&mut data);//! assert_eq!(data, [//!     0xF1258F7940E1DDE7, 0x84D5CCF933C0478A, 0xD598261EA65AA9EE, 0xBD1547306F80494D,//!     0x8B284E056253D057, 0xFF97A42D7F8E6FD4, 0x90FEE5A0A44647C4, 0x8C5BDA0CD6192E76,//!     0xAD30A6F71B19059C, 0x30935AB7D08FFC64, 0xEB5AA93F2317D635, 0xA9A6E6260D712103,//!     0x81A57C16DBCF555F, 0x43B831CD0347C826, 0x01F22F1A11A5569F, 0x05E5635A21D9AE61,//!     0x64BEFEF28CC970F2, 0x613670957BC46611, 0xB87C5A554FD00ECB, 0x8C3EE88A1CCF32C8,//!     0x940C7922AE3A2614, 0x1841F924A2C509E4, 0x16F53526E70465C2, 0x75F644E97F30A13B,//!     0xEAF1FF7B5CECA249,//! ]);//!     0x2D5C954DF96ECB3C, 0x6A332CD07057B56D, 0x093D8D1270D76B6C, 0x8A20D9B25569D094,//!     0x4F9C4F99E5E7F156, 0xF957B9A2DA65FB38, 0x85773DAE1275AF0D, 0xFAF4F247C3D810F7,//!     0x1F1B9EE6F79A8759, 0xE4FECC0FEE98B425, 0x68CE61B6B9CE68A1, 0xDEEA66C4BA8F974F,//!     0x33C43D836EAFB1F5, 0xE00654042719DBD9, 0x7CF8A9F009831265, 0xFD5449A6BF174743,//!     0x97DDAD33D8994B40, 0x48EAD5FC5D0BE774, 0xE3B8C8EE55B7B03C, 0x91A0226E649E42E9,//!     0x900E3129E7BADD7B, 0x202A9EC5FAA3CCE8, 0x5B3402464E1C3DB6, 0x609F4E62A44C1059,//!     0x20D06CD26A8FBF5C,//! [1]: https://docs.rs/sha3//! [2]: https://docs.rs/tiny-keccakunroll5/// unroll5unroll24/// unroll24__lazy_static_create// Copyright 2016 lazy-static.rs Developers// Licensed under the Apache License, Version 2.0, <LICENSE-APACHE or// https://apache.org/licenses/LICENSE-2.0> or the MIT license <LICENSE-MIT or// https://opensource.org/licenses/MIT>, at your option. This file may not be// copied, modified, or distributed except according to those terms.v1ONCE_INIT// Used in macros__Deref__lazy_static_internal// optional visibility restrictions are wrapped in `()` to allow for// explicitly passing otherwise implicit information about private items// `vis` is wrapped in `()` to prevent parsing ambiguityLazyStatic/// Support trait for enabling a few common operation on lazy static values./// This is implemented by each defined lazy static, and/// used by the free functions in this crate./// Takes a shared reference to a lazy static and initializes/// it if it has not been already./// This can be used to control the initialization point of a lazy static./// use lazy_static::lazy_static;/// lazy_static! {///     static ref BUFFER: Vec<u8> = (0..255).collect();///     lazy_static::initialize(&BUFFER);///     work_with_initialized_data(&BUFFER);/// # fn work_with_initialized_data(_: &[u8]) {}/*!
A macro for declaring lazily evaluated statics.

Using this macro, it is possible to have `static`s that require code to be
executed at runtime in order to be initialized.
This includes anything requiring heap allocations, like vectors or hash maps,
as well as anything that requires function calls to be computed.

# Syntax

```ignore
lazy_static! {
    [pub] static ref NAME_1: TYPE_1 = EXPR_1;
    [pub] static ref NAME_2: TYPE_2 = EXPR_2;
    ...
    [pub] static ref NAME_N: TYPE_N = EXPR_N;
}
```

Attributes (including doc comments) are supported as well:

```rust
use lazy_static::lazy_static;

# fn main() {
lazy_static! {
    /// This is an example for using doc comment attributes
    static ref EXAMPLE: u8 = 42;
}
# }
```

# Semantics

For a given `static ref NAME: TYPE = EXPR;`, the macro generates a unique type that
implements `Deref<TYPE>` and stores it in a static with name `NAME`. (Attributes end up
attaching to this type.)

On first deref, `EXPR` gets evaluated and stored internally, such that all further derefs
can return a reference to the same object. Note that this can lead to deadlocks
if you have multiple lazy statics that depend on each other in their initialization.

Apart from the lazy initialization, the resulting "static ref" variables
have generally the same properties as regular "static" variables:

- Any type in them needs to fulfill the `Sync` trait.
- If the type has a destructor, then it will not run when the process exits.

# Example

Using the macro:

```rust
use lazy_static::lazy_static;
use std::collections::HashMap;

lazy_static! {
    static ref HASHMAP: HashMap<u32, &'static str> = {
        let mut m = HashMap::new();
        m.insert(0, "foo");
        m.insert(1, "bar");
        m.insert(2, "baz");
        m
    };
    static ref COUNT: usize = HASHMAP.len();
    static ref NUMBER: u32 = times_two(21);
}

fn times_two(n: u32) -> u32 { n * 2 }

fn main() {
    println!("The map has {} entries.", *COUNT);
    println!("The entry for `0` is \"{}\".", HASHMAP.get(&0).unwrap());
    println!("A expensive calculation on a static results in: {}.", *NUMBER);
}
```

# Implementation details

The `Deref` implementation uses a hidden static variable that is guarded by an atomic check on each access.

# Cargo features

This crate provides one cargo feature:

- `spin_no_std`: This allows using this crate in a no-std environment, by depending on the standalone `spin` crate.

*/ALLOWED_CFGS// List of cfgs this build script is allowed to set. The list is needed to support check-cfg, as we// need to know all the possible cfgs that this script will set. If you need to set another cfg// make sure to add it to this list as well.CHECK_CFG_EXTRA// Extra values to allow for check-cfg.rustc_version_cmd/// Run `rustc --version` and capture the output, adjusting arguments as needed if `clippy-driver`/// is used instead.rustc_minor_nightly/// Return the minor version of `rustc`, as well as a bool indicating whether or not the version/// is a nightly.which_freebsdemcc_version_codeset_cfgoff_t__u64c_ulonglongnlink_tblksize_tc_longMINSIGSTKSZ// From https://cs.opensource.google/fuchsia/fuchsia/+/main:zircon/third_party/ulib/musl/include/bits/signal.h;l=20-21;drc=0827b18ab9540c46f8037f407d17ea15a79e9ba7SIGSTKSZintmax_tuintmax_tlocale_tptrdiff_tintptr_tuintptr_tpid_tuid_tgid_tin_addr_tin_port_tsighandler_tcc_tc_ucharsa_family_tpthread_key_tspeed_ttcflag_tclockid_tkey_tid_tuseconds_tdev_tsocklen_tpthread_tmode_tino64_toff64_tblkcnt64_trlim64_tmqd_tnfds_tnl_itemidtype_tloff_tc_longlong__u8__u16c_ushort__s16c_short__u32__s32Elf32_HalfElf32_WordElf32_OffElf32_AddrElf64_HalfElf64_WordElf64_OffElf64_AddrElf64_Xwordclock_ttime_tsuseconds_tino_tblkcnt_tshmatt_tmsgqnum_tmsglen_tfsblkcnt_tfsfilcnt_trlim_t// FIXME(fuchsia): why are these uninhabited types? that seems... wrong?// Presumably these should be `()` or an `extern type` (when that stabilizes).DIRfpos64_t// FIXME(fuchsia): fill this out with a structs_no_extra_traitsINT_MININT_MAXSIG_DFLSIG_IGNSIG_ERRDT_UNKNOWNDT_FIFODT_CHRDT_DIRDT_BLKDT_REGDT_LNKDT_SOCKFD_CLOEXECUSRQUOTAGRPQUOTASIGIOTS_ISUIDS_ISGIDS_ISVTXIF_NAMESIZEIFNAMSIZLOG_EMERGLOG_ALERTLOG_CRITLOG_ERRLOG_WARNINGLOG_NOTICELOG_INFOLOG_DEBUGLOG_KERNLOG_USERLOG_MAILLOG_DAEMONLOG_AUTHLOG_SYSLOGLOG_LPRLOG_NEWSLOG_UUCPLOG_LOCAL0LOG_LOCAL1LOG_LOCAL2LOG_LOCAL3LOG_LOCAL4LOG_LOCAL5LOG_LOCAL6LOG_LOCAL7LOG_PIDLOG_CONSLOG_ODELAYLOG_NDELAYLOG_NOWAITLOG_PRIMASKLOG_FACMASKPRIO_PROCESSPRIO_PGRPPRIO_USERPRIO_MINPRIO_MAXIPPROTO_ICMPIPPROTO_ICMPV6IPPROTO_TCPIPPROTO_UDPIPPROTO_IPIPPROTO_IPV6INADDR_LOOPBACKINADDR_ANYINADDR_BROADCASTINADDR_NONEEXIT_FAILUREEXIT_SUCCESSRAND_MAXEOFSEEK_SETSEEK_CURSEEK_END_IOFBF_IONBF_IOLBFF_DUPFDF_GETFDF_SETFDF_GETFLF_SETFLF_SETLEASE// Linux-specific fcntlsF_GETLEASEF_NOTIFYF_CANCELLKF_DUPFD_CLOEXECF_SETPIPE_SZF_GETPIPE_SZF_ADD_SEALSF_GET_SEALSF_SEAL_SEALF_SEAL_SHRINKF_SEAL_GROWF_SEAL_WRITESIGTRAPPTHREAD_CREATE_JOINABLEPTHREAD_CREATE_DETACHEDCLOCK_REALTIMECLOCK_MONOTONICCLOCK_PROCESS_CPUTIME_IDCLOCK_THREAD_CPUTIME_IDCLOCK_MONOTONIC_RAWCLOCK_REALTIME_COARSECLOCK_MONOTONIC_COARSECLOCK_BOOTTIMECLOCK_REALTIME_ALARMCLOCK_BOOTTIME_ALARMCLOCK_SGI_CYCLECLOCK_TAITIMER_ABSTIMERLIMIT_CPURLIMIT_FSIZERLIMIT_DATARLIMIT_STACKRLIMIT_CORERLIMIT_LOCKSRLIMIT_SIGPENDINGRLIMIT_MSGQUEUERLIMIT_NICERLIMIT_RTPRIORUSAGE_SELFO_RDONLYO_WRONLYO_RDWRS_IFIFOS_IFCHRS_IFBLKS_IFDIRS_IFREGS_IFLNKS_IFSOCKS_IFMTS_IRWXUS_IXUSRS_IWUSRS_IRUSRS_IRWXGS_IXGRPS_IWGRPS_IRGRPS_IRWXOS_IXOTHS_IWOTHS_IROTHF_OKR_OKW_OKX_OKSTDIN_FILENOSTDOUT_FILENOSTDERR_FILENOSIGHUPSIGINTSIGQUITSIGILLSIGABRTSIGFPESIGKILLSIGSEGVSIGPIPESIGALRMSIGTERMPROT_NONEPROT_READPROT_WRITEPROT_EXECLC_CTYPELC_NUMERICLC_TIMELC_COLLATELC_MONETARYLC_MESSAGESLC_ALLLC_CTYPE_MASKLC_NUMERIC_MASKLC_TIME_MASKLC_COLLATE_MASKLC_MONETARY_MASKLC_MESSAGES_MASKMAP_FILEMAP_SHAREDMAP_PRIVATEMAP_FIXEDMAP_FAILEDMS_ASYNC// MS_ flags for msync(2)MS_INVALIDATEMS_SYNCMS_RDONLY// MS_ flags for mount(2)MS_NOSUIDMS_NODEVMS_NOEXECMS_SYNCHRONOUSMS_REMOUNTMS_MANDLOCKMS_DIRSYNCMS_NOATIMEMS_NODIRATIMEMS_BINDMS_MOVEMS_RECMS_SILENTMS_POSIXACLMS_UNBINDABLEMS_PRIVATEMS_SLAVEMS_SHAREDMS_RELATIMEMS_KERNMOUNTMS_I_VERSIONMS_STRICTATIMEMS_ACTIVEMS_NOUSERMS_MGC_VALMS_MGC_MSKMS_RMT_MASKEPERMENOENTESRCHEINTREIOENXIOE2BIGENOEXECEBADFECHILDEAGAINENOMEMEACCESEFAULTENOTBLKEBUSYEEXISTEXDEVENODEVENOTDIREISDIREINVALENFILEEMFILEENOTTYETXTBSYEFBIGENOSPCESPIPEEROFSEMLINKEPIPEEDOMERANGEEWOULDBLOCKSCM_RIGHTSSCM_CREDENTIALSPROT_GROWSDOWNPROT_GROWSUPMAP_TYPEMADV_NORMALMADV_RANDOMMADV_SEQUENTIALMADV_WILLNEEDMADV_DONTNEEDMADV_FREEMADV_REMOVEMADV_DONTFORKMADV_DOFORKMADV_MERGEABLEMADV_UNMERGEABLEMADV_HUGEPAGEMADV_NOHUGEPAGEMADV_DONTDUMPMADV_DODUMPMADV_HWPOISONMADV_SOFT_OFFLINEIFF_UPIFF_BROADCASTIFF_DEBUGIFF_LOOPBACKIFF_POINTOPOINTIFF_NOTRAILERSIFF_RUNNINGIFF_NOARPIFF_PROMISCIFF_ALLMULTIIFF_MASTERIFF_SLAVEIFF_MULTICASTIFF_PORTSELIFF_AUTOMEDIAIFF_DYNAMICIFF_TUNIFF_TAPIFF_NO_PISOL_IPSOL_TCPSOL_UDPSOL_IPV6SOL_ICMPV6SOL_RAWSOL_DECNETSOL_X25SOL_PACKETSOL_ATMSOL_AALSOL_IRDASOL_NETBEUISOL_LLCSOL_DCCPSOL_NETLINKSOL_TIPCAF_UNSPECAF_UNIXAF_LOCALAF_INETAF_AX25AF_IPXAF_APPLETALKAF_NETROMAF_BRIDGEAF_ATMPVCAF_X25AF_INET6AF_ROSEAF_DECnetAF_NETBEUIAF_SECURITYAF_KEYAF_NETLINKAF_ROUTEAF_PACKETAF_ASHAF_ECONETAF_ATMSVCAF_RDSAF_SNAAF_IRDAAF_PPPOXAF_WANPIPEAF_LLCAF_CANAF_TIPCAF_BLUETOOTHAF_IUCVAF_RXRPCAF_ISDNAF_PHONETAF_IEEE802154AF_CAIFAF_ALGPF_UNSPECPF_UNIXPF_LOCALPF_INETPF_AX25PF_IPXPF_APPLETALKPF_NETROMPF_BRIDGEPF_ATMPVCPF_X25PF_INET6PF_ROSEPF_DECnetPF_NETBEUIPF_SECURITYPF_KEYPF_NETLINKPF_ROUTEPF_PACKETPF_ASHPF_ECONETPF_ATMSVCPF_RDSPF_SNAPF_IRDAPF_PPPOXPF_WANPIPEPF_LLCPF_CANPF_TIPCPF_BLUETOOTHPF_IUCVPF_RXRPCPF_ISDNPF_PHONETPF_IEEE802154PF_CAIFPF_ALGSOMAXCONNMSG_OOBMSG_PEEKMSG_DONTROUTEMSG_CTRUNCMSG_TRUNCMSG_DONTWAITMSG_EORMSG_WAITALLMSG_FINMSG_SYNMSG_CONFIRMMSG_RSTMSG_ERRQUEUEMSG_NOSIGNALMSG_MOREMSG_WAITFORONEMSG_FASTOPENMSG_CMSG_CLOEXECSCM_TIMESTAMPSOCK_RAWSOCK_RDMIP_TOSIP_TTLIP_HDRINCLIP_RECVTOSIP_FREEBINDIP_TRANSPARENTIP_MULTICAST_IFIP_MULTICAST_TTLIP_MULTICAST_LOOPIP_ADD_MEMBERSHIPIP_DROP_MEMBERSHIPIPV6_UNICAST_HOPSIPV6_MULTICAST_IFIPV6_MULTICAST_HOPSIPV6_MULTICAST_LOOPIPV6_ADD_MEMBERSHIPIPV6_DROP_MEMBERSHIPIPV6_V6ONLYIPV6_RECVPKTINFOIPV6_RECVTCLASSIPV6_TCLASSTCP_NODELAYTCP_MAXSEGTCP_CORKTCP_KEEPIDLETCP_KEEPINTVLTCP_KEEPCNTTCP_SYNCNTTCP_LINGER2TCP_DEFER_ACCEPTTCP_WINDOW_CLAMPTCP_INFOTCP_QUICKACKTCP_CONGESTIONSO_DEBUGSHUT_RDSHUT_WRSHUT_RDWRLOCK_SHLOCK_EXLOCK_NBLOCK_UNSS_ONSTACKSS_DISABLEPATH_MAXFD_SETSIZEEPOLLINEPOLLPRIEPOLLOUTEPOLLRDNORMEPOLLRDBANDEPOLLWRNORMEPOLLWRBANDEPOLLMSGEPOLLERREPOLLHUPEPOLLETEPOLL_CTL_ADDEPOLL_CTL_MODEPOLL_CTL_DELMNT_DETACHMNT_EXPIREQ_GETFMTQ_GETINFOQ_SETINFOQIF_BLIMITSQIF_SPACEQIF_ILIMITSQIF_INODESQIF_BTIMEQIF_ITIMEQIF_LIMITSQIF_USAGEQIF_TIMESQIF_ALLMNT_FORCEQ_SYNCQ_QUOTAONQ_QUOTAOFFQ_GETQUOTAQ_SETQUOTATCIOFFTCIONTCOOFFTCOONTCIFLUSHTCOFLUSHTCIOFLUSHNL0NL1TAB0CR0FF0BS0VT0VERASEVKILLVINTRVQUITVLNEXTIGNBRKBRKINTIGNPARPARMRKINPCKISTRIPINLCRIGNCRICRNLIXANYIMAXBELOPOSTCS5CRTSCTSECHOOCRNLONOCRONLRETOFILLOFDELCLONE_VMCLONE_FSCLONE_FILESCLONE_SIGHANDCLONE_PTRACECLONE_VFORKCLONE_PARENTCLONE_THREADCLONE_NEWNSCLONE_SYSVSEMCLONE_SETTLSCLONE_PARENT_SETTIDCLONE_CHILD_CLEARTIDCLONE_DETACHEDCLONE_UNTRACEDCLONE_CHILD_SETTIDCLONE_NEWUTSCLONE_NEWIPCCLONE_NEWUSERCLONE_NEWPIDCLONE_NEWNETCLONE_IOCLONE_NEWCGROUPWNOHANGWUNTRACEDWSTOPPEDWEXITEDWCONTINUEDWNOWAITPTRACE_O_TRACESYSGOOD// Options set using PTRACE_SETOPTIONS.PTRACE_O_TRACEFORKPTRACE_O_TRACEVFORKPTRACE_O_TRACECLONEPTRACE_O_TRACEEXECPTRACE_O_TRACEVFORKDONEPTRACE_O_TRACEEXITPTRACE_O_TRACESECCOMPPTRACE_O_EXITKILLPTRACE_O_SUSPEND_SECCOMPPTRACE_O_MASKPTRACE_EVENT_FORK// Wait extended result codes for the above trace options.PTRACE_EVENT_VFORKPTRACE_EVENT_CLONEPTRACE_EVENT_EXECPTRACE_EVENT_VFORK_DONEPTRACE_EVENT_EXITPTRACE_EVENT_SECCOMP__WNOTHREAD__WALL__WCLONESPLICE_F_MOVESPLICE_F_NONBLOCKSPLICE_F_MORESPLICE_F_GIFTRTLD_LOCALRTLD_LAZYPOSIX_FADV_NORMALPOSIX_FADV_RANDOMPOSIX_FADV_SEQUENTIALPOSIX_FADV_WILLNEEDAT_FDCWDAT_SYMLINK_NOFOLLOWAT_REMOVEDIRAT_EACCESSAT_SYMLINK_FOLLOWAT_NO_AUTOMOUNTAT_EMPTY_PATHLOG_CRONLOG_AUTHPRIVLOG_FTPLOG_PERRORPIPE_BUFSI_LOAD_SHIFTCLD_EXITEDCLD_KILLEDCLD_DUMPEDCLD_TRAPPEDCLD_STOPPEDCLD_CONTINUEDSIGEV_SIGNALSIGEV_NONESIGEV_THREADP_ALLP_PIDP_PGIDUTIME_OMITUTIME_NOWPOLLINPOLLPRIPOLLOUTPOLLERRPOLLHUPPOLLNVALPOLLRDNORMPOLLRDBANDABDAY_1ABDAY_2ABDAY_3ABDAY_4ABDAY_5ABDAY_6ABDAY_7DAY_1DAY_2DAY_3DAY_4DAY_5DAY_6DAY_7ABMON_1ABMON_2ABMON_3ABMON_4ABMON_5ABMON_6ABMON_7ABMON_8ABMON_9ABMON_10ABMON_11ABMON_12MON_1MON_2MON_3MON_4MON_5MON_6MON_7MON_8MON_9MON_10MON_11MON_12AM_STRPM_STRD_T_FMTD_FMTT_FMTT_FMT_AMPMERAERA_D_FMTALT_DIGITSERA_D_T_FMTERA_T_FMTCODESETCRNCYSTRRUSAGE_THREADRUSAGE_CHILDRENRADIXCHARTHOUSEPYESEXPRNOEXPRYESSTRNOSTRFILENAME_MAXL_tmpnam_PC_LINK_MAX_PC_MAX_CANON_PC_MAX_INPUT_PC_NAME_MAX_PC_PATH_MAX_PC_PIPE_BUF_PC_CHOWN_RESTRICTED_PC_NO_TRUNC_PC_VDISABLE_PC_SYNC_IO_PC_ASYNC_IO_PC_PRIO_IO_PC_SOCK_MAXBUF_PC_FILESIZEBITS_PC_REC_INCR_XFER_SIZE_PC_REC_MAX_XFER_SIZE_PC_REC_MIN_XFER_SIZE_PC_REC_XFER_ALIGN_PC_ALLOC_SIZE_MIN_PC_SYMLINK_MAX_PC_2_SYMLINKS_SC_ARG_MAX_SC_CHILD_MAX_SC_CLK_TCK_SC_NGROUPS_MAX_SC_OPEN_MAX_SC_STREAM_MAX_SC_TZNAME_MAX_SC_JOB_CONTROL_SC_SAVED_IDS_SC_REALTIME_SIGNALS_SC_PRIORITY_SCHEDULING_SC_TIMERS_SC_ASYNCHRONOUS_IO_SC_PRIORITIZED_IO_SC_SYNCHRONIZED_IO_SC_FSYNC_SC_MAPPED_FILES_SC_MEMLOCK_SC_MEMLOCK_RANGE_SC_MEMORY_PROTECTION_SC_MESSAGE_PASSING_SC_SEMAPHORES_SC_SHARED_MEMORY_OBJECTS_SC_AIO_LISTIO_MAX_SC_AIO_MAX_SC_AIO_PRIO_DELTA_MAX_SC_DELAYTIMER_MAX_SC_MQ_OPEN_MAX_SC_MQ_PRIO_MAX_SC_VERSION_SC_PAGESIZE_SC_PAGE_SIZE_SC_RTSIG_MAX_SC_SEM_NSEMS_MAX_SC_SEM_VALUE_MAX_SC_SIGQUEUE_MAX_SC_TIMER_MAX_SC_BC_BASE_MAX_SC_BC_DIM_MAX_SC_BC_SCALE_MAX_SC_BC_STRING_MAX_SC_COLL_WEIGHTS_MAX_SC_EXPR_NEST_MAX_SC_LINE_MAX_SC_RE_DUP_MAX_SC_2_VERSION_SC_2_C_BIND_SC_2_C_DEV_SC_2_FORT_DEV_SC_2_FORT_RUN_SC_2_SW_DEV_SC_2_LOCALEDEF_SC_UIO_MAXIOV_SC_IOV_MAX_SC_THREADS_SC_THREAD_SAFE_FUNCTIONS_SC_GETGR_R_SIZE_MAX_SC_GETPW_R_SIZE_MAX_SC_LOGIN_NAME_MAX_SC_TTY_NAME_MAX_SC_THREAD_DESTRUCTOR_ITERATIONS_SC_THREAD_KEYS_MAX_SC_THREAD_STACK_MIN_SC_THREAD_THREADS_MAX_SC_THREAD_ATTR_STACKADDR_SC_THREAD_ATTR_STACKSIZE_SC_THREAD_PRIORITY_SCHEDULING_SC_THREAD_PRIO_INHERIT_SC_THREAD_PRIO_PROTECT_SC_THREAD_PROCESS_SHARED_SC_NPROCESSORS_CONF_SC_NPROCESSORS_ONLN_SC_PHYS_PAGES_SC_AVPHYS_PAGES_SC_ATEXIT_MAX_SC_PASS_MAX_SC_XOPEN_VERSION_SC_XOPEN_XCU_VERSION_SC_XOPEN_UNIX_SC_XOPEN_CRYPT_SC_XOPEN_ENH_I18N_SC_XOPEN_SHM_SC_2_CHAR_TERM_SC_2_UPE_SC_XOPEN_XPG2_SC_XOPEN_XPG3_SC_XOPEN_XPG4_SC_NZERO_SC_XBS5_ILP32_OFF32_SC_XBS5_ILP32_OFFBIG_SC_XBS5_LP64_OFF64_SC_XBS5_LPBIG_OFFBIG_SC_XOPEN_LEGACY_SC_XOPEN_REALTIME_SC_XOPEN_REALTIME_THREADS_SC_ADVISORY_INFO_SC_BARRIERS_SC_CLOCK_SELECTION_SC_CPUTIME_SC_THREAD_CPUTIME_SC_MONOTONIC_CLOCK_SC_READER_WRITER_LOCKS_SC_SPIN_LOCKS_SC_REGEXP_SC_SHELL_SC_SPAWN_SC_SPORADIC_SERVER_SC_THREAD_SPORADIC_SERVER_SC_TIMEOUTS_SC_TYPED_MEMORY_OBJECTS_SC_2_PBS_SC_2_PBS_ACCOUNTING_SC_2_PBS_LOCATE_SC_2_PBS_MESSAGE_SC_2_PBS_TRACK_SC_SYMLOOP_MAX_SC_STREAMS_SC_2_PBS_CHECKPOINT_SC_V6_ILP32_OFF32_SC_V6_ILP32_OFFBIG_SC_V6_LP64_OFF64_SC_V6_LPBIG_OFFBIG_SC_HOST_NAME_MAX_SC_TRACE_SC_TRACE_EVENT_FILTER_SC_TRACE_INHERIT_SC_TRACE_LOG_SC_IPV6_SC_RAW_SOCKETS_SC_V7_ILP32_OFF32_SC_V7_ILP32_OFFBIG_SC_V7_LP64_OFF64_SC_V7_LPBIG_OFFBIG_SC_SS_REPL_MAX_SC_TRACE_EVENT_NAME_MAX_SC_TRACE_NAME_MAX_SC_TRACE_SYS_MAX_SC_TRACE_USER_EVENT_MAX_SC_XOPEN_STREAMS_SC_THREAD_ROBUST_PRIO_INHERIT_SC_THREAD_ROBUST_PRIO_PROTECTRLIM_SAVED_MAXRLIM_SAVED_CURGLOB_ERRGLOB_MARKGLOB_NOSORTGLOB_DOOFFSGLOB_NOCHECKGLOB_APPENDGLOB_NOESCAPEGLOB_NOSPACEGLOB_ABORTEDGLOB_NOMATCHPOSIX_MADV_NORMALPOSIX_MADV_RANDOMPOSIX_MADV_SEQUENTIALPOSIX_MADV_WILLNEEDS_IEXECS_IWRITES_IREADF_LOCKF_TESTF_TLOCKF_ULOCKIFF_LOWER_UPIFF_DORMANTIFF_ECHOST_RDONLYST_NOSUIDST_NODEVST_NOEXECST_SYNCHRONOUSST_MANDLOCKST_WRITEST_APPENDST_IMMUTABLEST_NOATIMEST_NODIRATIMERTLD_NEXTRTLD_DEFAULTRTLD_NODELETERTLD_NOWTCP_MD5SIGPTHREAD_MUTEX_INITIALIZERPTHREAD_COND_INITIALIZERpthread_cond_tPTHREAD_RWLOCK_INITIALIZERpthread_rwlock_tPTHREAD_MUTEX_NORMALPTHREAD_MUTEX_RECURSIVEPTHREAD_MUTEX_ERRORCHECKPTHREAD_MUTEX_DEFAULTPTHREAD_PROCESS_PRIVATEPTHREAD_PROCESS_SHARED__SIZEOF_PTHREAD_COND_TRENAME_NOREPLACERENAME_EXCHANGERENAME_WHITEOUTSCHED_OTHERSCHED_FIFOSCHED_RRSCHED_BATCHSCHED_IDLEIPPROTO_HOPOPTS// IPPROTO_IP defined in src/unix/mod.rs/// Hop-by-hop option headerIPPROTO_IGMP// IPPROTO_ICMP defined in src/unix/mod.rs/// group mgmt protocolIPPROTO_IPIP/// for compatibilityIPPROTO_EGP// IPPROTO_TCP defined in src/unix/mod.rs/// exterior gateway protocolIPPROTO_PUP/// pupIPPROTO_IDP// IPPROTO_UDP defined in src/unix/mod.rs/// xns idpIPPROTO_TP/// tp-4 w/ class negotiationIPPROTO_DCCP/// DCCPIPPROTO_ROUTING// IPPROTO_IPV6 defined in src/unix/mod.rs/// IP6 routing headerIPPROTO_FRAGMENT/// IP6 fragmentation headerIPPROTO_RSVP/// resource reservationIPPROTO_GRE/// General Routing Encap.IPPROTO_ESP/// IP6 Encap Sec. PayloadIPPROTO_AH/// IP6 Auth HeaderIPPROTO_NONE// IPPROTO_ICMPV6 defined in src/unix/mod.rs/// IP6 no next headerIPPROTO_DSTOPTS/// IP6 destination optionIPPROTO_MTPIPPROTO_BEETPHIPPROTO_ENCAP/// encapsulation headerIPPROTO_PIM/// Protocol indep. multicastIPPROTO_COMP/// IP Payload Comp. ProtocolIPPROTO_SCTP/// SCTPIPPROTO_MHIPPROTO_UDPLITEIPPROTO_MPLSIPPROTO_RAW/// raw IP packetIPPROTO_MAXAF_IBAF_MPLSAF_NFCAF_VSOCKPF_IBPF_MPLSPF_NFCPF_VSOCKIPC_PRIVATE// System V IPCIPC_CREATIPC_EXCLIPC_NOWAITIPC_RMIDIPC_SETIPC_STATIPC_INFOMSG_STATMSG_INFOMSG_NOERRORMSG_EXCEPTMSG_COPYSHM_RSHM_WSHM_RDONLYSHM_RNDSHM_REMAPSHM_EXECSHM_LOCKSHM_UNLOCKSHM_HUGETLBSHM_NORESERVEEPOLLRDHUPEPOLLEXCLUSIVEEPOLLONESHOTQFMT_VFS_OLDQFMT_VFS_V0QFMT_VFS_V1EFD_SEMAPHORELOG_NFACILITIESSEM_FAILEDsem_tRB_AUTOBOOTRB_HALT_SYSTEMRB_ENABLE_CADRB_DISABLE_CADRB_POWER_OFFRB_SW_SUSPENDRB_KEXECAI_PASSIVEAI_CANONNAMEAI_NUMERICHOSTAI_V4MAPPEDAI_ALLAI_ADDRCONFIGAI_NUMERICSERVEAI_BADFLAGSEAI_NONAMEEAI_AGAINEAI_FAILEAI_FAMILYEAI_SOCKTYPEEAI_SERVICEEAI_MEMORYEAI_OVERFLOWNI_NUMERICHOSTNI_NUMERICSERVNI_NOFQDNNI_NAMEREQDNI_DGRAMSYNC_FILE_RANGE_WAIT_BEFORESYNC_FILE_RANGE_WRITESYNC_FILE_RANGE_WAIT_AFTEREAI_SYSTEMAIO_CANCELEDAIO_NOTCANCELEDAIO_ALLDONELIO_READLIO_WRITELIO_NOPLIO_WAITLIO_NOWAITMREMAP_MAYMOVEMREMAP_FIXEDPR_SET_PDEATHSIGPR_GET_PDEATHSIGPR_GET_DUMPABLEPR_SET_DUMPABLEPR_GET_UNALIGNPR_SET_UNALIGNPR_UNALIGN_NOPRINTPR_UNALIGN_SIGBUSPR_GET_KEEPCAPSPR_SET_KEEPCAPSPR_GET_FPEMUPR_SET_FPEMUPR_FPEMU_NOPRINTPR_FPEMU_SIGFPEPR_GET_FPEXCPR_SET_FPEXCPR_FP_EXC_SW_ENABLEPR_FP_EXC_DIVPR_FP_EXC_OVFPR_FP_EXC_UNDPR_FP_EXC_RESPR_FP_EXC_INVPR_FP_EXC_DISABLEDPR_FP_EXC_NONRECOVPR_FP_EXC_ASYNCPR_FP_EXC_PRECISEPR_GET_TIMINGPR_SET_TIMINGPR_TIMING_STATISTICALPR_TIMING_TIMESTAMPPR_SET_NAMEPR_GET_NAMEPR_GET_ENDIANPR_SET_ENDIANPR_ENDIAN_BIGPR_ENDIAN_LITTLEPR_ENDIAN_PPC_LITTLEPR_GET_SECCOMPPR_SET_SECCOMPPR_CAPBSET_READPR_CAPBSET_DROPPR_GET_TSCPR_SET_TSCPR_TSC_ENABLEPR_TSC_SIGSEGVPR_GET_SECUREBITSPR_SET_SECUREBITSPR_SET_TIMERSLACKPR_GET_TIMERSLACKPR_TASK_PERF_EVENTS_DISABLEPR_TASK_PERF_EVENTS_ENABLEPR_MCE_KILLPR_MCE_KILL_CLEARPR_MCE_KILL_SETPR_MCE_KILL_LATEPR_MCE_KILL_EARLYPR_MCE_KILL_DEFAULTPR_MCE_KILL_GETPR_SET_MMPR_SET_MM_START_CODEPR_SET_MM_END_CODEPR_SET_MM_START_DATAPR_SET_MM_END_DATAPR_SET_MM_START_STACKPR_SET_MM_START_BRKPR_SET_MM_BRKPR_SET_MM_ARG_STARTPR_SET_MM_ARG_ENDPR_SET_MM_ENV_STARTPR_SET_MM_ENV_ENDPR_SET_MM_AUXVPR_SET_MM_EXE_FILEPR_SET_MM_MAPPR_SET_MM_MAP_SIZEPR_SET_PTRACERPR_SET_PTRACER_ANYPR_SET_CHILD_SUBREAPERPR_GET_CHILD_SUBREAPERPR_SET_NO_NEW_PRIVSPR_GET_NO_NEW_PRIVSPR_GET_TID_ADDRESSPR_SET_THP_DISABLEPR_GET_THP_DISABLEPR_MPX_ENABLE_MANAGEMENTPR_MPX_DISABLE_MANAGEMENTPR_SET_FP_MODEPR_GET_FP_MODEPR_FP_MODE_FRPR_FP_MODE_FREPR_CAP_AMBIENTPR_CAP_AMBIENT_IS_SETPR_CAP_AMBIENT_RAISEPR_CAP_AMBIENT_LOWERPR_CAP_AMBIENT_CLEAR_ALLITIMER_REALITIMER_VIRTUALITIMER_PROFTFD_CLOEXECTFD_NONBLOCKTFD_TIMER_ABSTIMEXATTR_CREATEXATTR_REPLACE_POSIX_VDISABLEFALLOC_FL_KEEP_SIZEFALLOC_FL_PUNCH_HOLEFALLOC_FL_COLLAPSE_RANGEFALLOC_FL_ZERO_RANGEFALLOC_FL_INSERT_RANGEFALLOC_FL_UNSHARE_RANGEENOATTR// On Linux, libc doesn't define this constant, libattr does instead.// We still define it for Linux as it's defined by libc on other platforms,// and it's mentioned in the man pages for getxattr and setxattr.SO_ORIGINAL_DSTIUTF8CMSPARMFD_CLOEXECMFD_ALLOW_SEALINGPT_NULL// these are used in the p_type field of Elf32_Phdr and Elf64_Phdr, which has// the type Elf32Word and Elf64Word respectively. Luckily, both of those are u32// so we can use that type here to avoid having to cast.PT_LOADPT_DYNAMICPT_INTERPPT_NOTEPT_SHLIBPT_PHDRPT_TLSPT_NUMPT_LOOSPT_GNU_EH_FRAMEPT_GNU_STACKPT_GNU_RELROETH_P_LOOP// Ethernet protocol IDs.ETH_P_PUPETH_P_PUPATETH_P_IPETH_P_X25ETH_P_ARPETH_P_BPQETH_P_IEEEPUPETH_P_IEEEPUPATETH_P_BATMANETH_P_DECETH_P_DNA_DLETH_P_DNA_RCETH_P_DNA_RTETH_P_LATETH_P_DIAGETH_P_CUSTETH_P_SCAETH_P_TEBETH_P_RARPETH_P_ATALKETH_P_AARPETH_P_8021QETH_P_IPXETH_P_IPV6ETH_P_PAUSEETH_P_SLOWETH_P_WCCPETH_P_MPLS_UCETH_P_MPLS_MCETH_P_ATMMPOAETH_P_PPP_DISCETH_P_PPP_SESETH_P_LINK_CTLETH_P_ATMFATEETH_P_PAEETH_P_AOEETH_P_8021ADETH_P_802_EX1ETH_P_TIPCETH_P_8021AHETH_P_MVRPETH_P_1588ETH_P_PRPETH_P_FCOEETH_P_TDLSETH_P_FIPETH_P_80221ETH_P_LOOPBACKETH_P_QINQ1ETH_P_QINQ2ETH_P_QINQ3ETH_P_EDSAETH_P_AF_IUCVETH_P_802_3_MINETH_P_802_3ETH_P_AX25ETH_P_ALLETH_P_802_2ETH_P_SNAPETH_P_DDCMPETH_P_WAN_PPPETH_P_PPP_MPETH_P_LOCALTALKETH_P_CANETH_P_CANFDETH_P_PPPTALKETH_P_TR_802_2ETH_P_MOBITEXETH_P_CONTROLETH_P_IRDAETH_P_ECONETETH_P_HDLCETH_P_ARCNETETH_P_DSAETH_P_TRAILERETH_P_PHONETETH_P_IEEE802154ETH_P_CAIFSFD_CLOEXECNCCSO_TRUNCO_NOATIMEO_CLOEXECO_TMPFILEEBFONTENOSTRENODATAETIMEENOSRENONETENOPKGEREMOTEENOLINKEADVESRMNTECOMMEPROTOEDOTDOTSA_NODEFERSA_RESETHANDSA_RESTARTSA_NOCLDSTOPEPOLL_CLOEXECEFD_CLOEXECBUFSIZTMP_MAXFOPEN_MAXO_PATHO_EXECO_SEARCHO_ACCMODEO_NDELAYNI_MAXHOSTPTHREAD_STACK_MINPOSIX_FADV_DONTNEEDPOSIX_FADV_NOREUSEPOSIX_MADV_DONTNEEDRLIM_INFINITYRLIMIT_RTTIMERLIMIT_NLIMITSRLIM_NLIMITSMAP_ANONYMOUSSOCK_DCCPSOCK_PACKETTCP_COOKIE_TRANSACTIONSTCP_THIN_LINEAR_TIMEOUTSTCP_THIN_DUPACKTCP_USER_TIMEOUTTCP_REPAIRTCP_REPAIR_QUEUETCP_QUEUE_SEQTCP_REPAIR_OPTIONSTCP_FASTOPENTCP_TIMESTAMPSIGUNUSED__SIZEOF_PTHREAD_CONDATTR_T__SIZEOF_PTHREAD_MUTEXATTR_T__SIZEOF_PTHREAD_RWLOCKATTR_TCPU_SETSIZEPTRACE_TRACEMEPTRACE_PEEKTEXTPTRACE_PEEKDATAPTRACE_PEEKUSERPTRACE_POKETEXTPTRACE_POKEDATAPTRACE_POKEUSERPTRACE_CONTPTRACE_KILLPTRACE_SINGLESTEPPTRACE_GETREGSPTRACE_SETREGSPTRACE_GETFPREGSPTRACE_SETFPREGSPTRACE_ATTACHPTRACE_DETACHPTRACE_GETFPXREGSPTRACE_SETFPXREGSPTRACE_SYSCALLPTRACE_SETOPTIONSPTRACE_GETEVENTMSGPTRACE_GETSIGINFOPTRACE_SETSIGINFOPTRACE_GETREGSETPTRACE_SETREGSETPTRACE_SEIZEPTRACE_INTERRUPTPTRACE_LISTENPTRACE_PEEKSIGINFOEPOLLWAKEUPEFD_NONBLOCKSFD_NONBLOCKTCSANOWTCSADRAINTCSAFLUSHTIOCINQRTLD_GLOBALRTLD_NOLOADMCL_CURRENTMCL_FUTURECBAUDTAB1TAB2TAB3CR1CR2CR3FF1BS1VT1VWERASEVREPRINTVSUSPVSTARTVSTOPVDISCARDVTIMEIXONIXOFFONLCRCSIZECS6CS7CS8CSTOPBCREADPARENBPARODDHUPCLCLOCALECHOKEECHOEECHOKECHONLECHOPRTECHOCTLISIGICANONPENDINNOFLSHCIBAUDCBAUDEXVSWTCOLCUCNLDLYCRDLYTABDLYBSDLYFFDLYVTDLYXTABSB50B75B110B134B150B200B300B600B1200B1800B2400B4800B9600B19200B38400EXTAEXTBB57600B115200B230400B460800B500000B576000B921600B1000000B1152000B1500000B2000000B2500000B3000000B3500000B4000000SO_BINDTODEVICESO_TIMESTAMPSO_MARKSO_RXQ_OVFLSO_PEEK_OFFSO_BUSY_POLLSO_BINDTOIFINDEX__SIZEOF_PTHREAD_RWLOCK_T__SIZEOF_PTHREAD_MUTEX_TO_ASYNCFIOCLEXFIONBIORLIMIT_RSSRLIMIT_NOFILERLIMIT_ASRLIMIT_NPROCRLIMIT_MEMLOCKO_APPENDO_CREATO_EXCLO_NOCTTYO_NONBLOCKO_SYNCO_RSYNCO_DSYNCSOCK_CLOEXECSOCK_NONBLOCKMAP_ANONMAP_GROWSDOWNMAP_DENYWRITEMAP_EXECUTABLEMAP_LOCKEDMAP_NORESERVEMAP_POPULATEMAP_NONBLOCKMAP_STACKSOCK_STREAMSOCK_DGRAMSOCK_SEQPACKETSOL_SOCKETEDEADLKENAMETOOLONGENOLCKENOSYSENOTEMPTYELOOPENOMSGEIDRMECHRNGEL2NSYNCEL3HLTEL3RSTELNRNGEUNATCHENOCSIEL2HLTEBADEEBADREXFULLENOANOEBADRQCEBADSLTEDEADLOCKEMULTIHOPEBADMSGEOVERFLOWENOTUNIQEBADFDEREMCHGELIBACCELIBBADELIBSCNELIBMAXELIBEXECEILSEQERESTARTESTRPIPEEUSERSENOTSOCKEDESTADDRREQEMSGSIZEEPROTOTYPEENOPROTOOPTEPROTONOSUPPORTESOCKTNOSUPPORTEOPNOTSUPPENOTSUPEPFNOSUPPORTEAFNOSUPPORTEADDRINUSEEADDRNOTAVAILENETDOWNENETUNREACHENETRESETECONNABORTEDECONNRESETENOBUFSEISCONNENOTCONNESHUTDOWNETOOMANYREFSETIMEDOUTECONNREFUSEDEHOSTDOWNEHOSTUNREACHEALREADYEINPROGRESSESTALEEUCLEANENOTNAMENAVAILEISNAMEREMOTEIOEDQUOTENOMEDIUMEMEDIUMTYPEECANCELEDENOKEYEKEYEXPIREDEKEYREVOKEDEKEYREJECTEDEOWNERDEADENOTRECOVERABLEERFKILLEHWPOISONSO_REUSEADDRSO_TYPESO_ERRORSO_DONTROUTESO_BROADCASTSO_SNDBUFSO_RCVBUFSO_KEEPALIVESO_OOBINLINESO_NO_CHECKSO_PRIORITYSO_LINGERSO_BSDCOMPATSO_REUSEPORTSO_PASSCREDSO_PEERCREDSO_RCVLOWATSO_SNDLOWATSO_RCVTIMEOSO_SNDTIMEOSO_ACCEPTCONNSO_SNDBUFFORCESO_RCVBUFFORCESO_PROTOCOLSO_DOMAINSA_ONSTACKSA_SIGINFOSA_NOCLDWAITSIGCHLDSIGBUSSIGTTINSIGTTOUSIGXCPUSIGXFSZSIGVTALRMSIGPROFSIGWINCHSIGUSR1SIGUSR2SIGCONTSIGSTOPSIGTSTPSIGURGSIGIOSIGSYSSIGSTKFLTSIGPOLLSIGPWRSIG_SETMASKSIG_BLOCKSIG_UNBLOCKEXTPROCMAP_HUGETLBF_GETLKF_GETOWNF_SETLKF_SETLKWF_SETOWNVEOFVEOLVEOL2VMINIEXTENTOSTOPFLUSHOTCGETSTCSETSTCSETSWTCSETSFTCGETATCSETATCSETAWTCSETAFTCSBRKTCXONCTCFLSHTIOCGSOFTCARTIOCSSOFTCARTIOCLINUXTIOCGSERIALTIOCEXCLTIOCNXCLTIOCSCTTYTIOCGPGRPTIOCSPGRPTIOCOUTQTIOCSTITIOCGWINSZTIOCSWINSZTIOCMGETTIOCMBISTIOCMBICTIOCMSETFIONREADTIOCCONSPOLLWRNORMPOLLWRBANDTIOCM_LETIOCM_DTRTIOCM_RTSTIOCM_STTIOCM_SRTIOCM_CTSTIOCM_CARTIOCM_RNGTIOCM_DSRTIOCM_CDTIOCM_RIO_DIRECTORYO_DIRECTO_LARGEFILEO_NOFOLLOWHUGETLB_FLAG_ENCODE_SHIFTMAP_HUGE_SHIFT// intentionally not public, only used for fd_setsafe_f__CMSG_LENcmsghdr__CMSG_NEXT__MHDR_ENDmsghdrFILEfpos_tisalnumisalphaiscntrlisdigitisgraphislowerisprintispunctisspaceisupperisxdigitisblanktolowertoupperfopenc_charfreopenfflushfcloserenametmpfilesetvbufsetbufgetcharputcharfgetcfgetsfputcfputsputsungetcfreadfwritefseekftellrewindfgetposfsetposfeofferrorperroratofc_doubleatoiatolatollstrtodstrtofc_floatstrtolstrtollstrtoulstrtoullcallocmalloc_exitatexitsystemstrcpystrncpystrcatstrncatstrcmpstrncmpstrcollstrchrstrrchrstrspnstrcspnstrdupstrpbrkstrstrstrlenstrnlenstrerrorstrtokstrxfrmwcslenwcstombswmemchrmemcmpmemcpymemmovememsetlabssrandgetpwnampasswdgetpwuidfprintfprintfsnprintfsprintffscanfscanfsscanfgetchar_unlockedputchar_unlockedsocketconnectsockaddrlistengetpeernamegetsocknamesetsockoptsocketpairsendtoshutdownchmodfchmodfstatstatmkdirpclosefdopenfilenocreatfcntlopendirreaddirdirentreaddir_rclosedirrewinddiropenatfchmodatfchownfchownatfstatatlinkatmkdiratreadlinkatrenameatsymlinkatunlinkataccessalarmchdirchownlchowndupdup2execlexecleexeclpexecv// DIFF(main): changed to `*const *mut` in e77f551de9execveexecvpforkfpathconfgetcwdgetegidgeteuidgetgidgetgroupsgetlogingetoptgetpgidgetpgrpgetpidgetppidgetuidisattylseekpathconfpauseposix_memalignrmdirseteuidsetegidsetgidsetpgidsetsidsetuidsleepnanosleeptimespectcgetpgrptcsetpgrpttynameunlinkwaitpidpreadpwriteumaskutimeutimbufkillmlockmunlockmlockallmunlockallmmapmunmapif_nametoindexif_indextonamelstatfsyncsetenvunsetenvsymlinkftruncatesignalrealpathflockgettimeofdaytimevaltimestmspthread_selfpthread_joinpthread_exitpthread_attr_initpthread_attr_tpthread_attr_destroypthread_attr_getstacksizepthread_attr_setstacksizepthread_attr_setdetachstatepthread_detachsched_yieldpthread_key_createpthread_key_deletepthread_getspecificpthread_setspecificpthread_mutex_initpthread_mutexattr_tpthread_mutex_destroypthread_mutex_lockpthread_mutex_trylockpthread_mutex_unlockpthread_mutexattr_initpthread_mutexattr_destroypthread_mutexattr_settypepthread_cond_initpthread_condattr_tpthread_cond_waitpthread_cond_timedwaitpthread_cond_signalpthread_cond_broadcastpthread_cond_destroypthread_condattr_initpthread_condattr_destroypthread_rwlock_initpthread_rwlockattr_tpthread_rwlock_destroypthread_rwlock_rdlockpthread_rwlock_tryrdlockpthread_rwlock_wrlockpthread_rwlock_trywrlockpthread_rwlock_unlockpthread_rwlockattr_initpthread_rwlockattr_destroypthread_getname_nppthread_setname_npstrerror_rgetsockoptraisesigactionutimesdlopendlerrordlsymdlclosedladdrDl_infogetaddrinfoaddrinfofreeaddrinfogai_strerrorres_initgmtime_rtmlocaltime_rmktimegmtimelocaltimemknodunameutsnamegethostnamegetservbynameserventgetprotobynameprotoentgetprotobynumberusleeprecvputenvpollfdfd_setsetlocalelocaleconvlconvsem_destroysem_waitsem_trywaitsem_postsem_initstatvfsfstatvfsreadlinksigemptysetsigset_tsigaddsetsigfillsetsigdelsetsigismembersigprocmasksigpendingtimegmgetsidsysconfmkfifopselectfseekoftellotcdraincfgetispeedtermioscfgetospeedcfmakerawcfsetispeedcfsetospeedcfsetspeedtcgetattrtcsetattrtcflowtcflushtcgetsidtcsendbreakmkstempmkdtemptmpnamopenlogcloselogsetlogmasksysloggrantptposix_openptptsnameunlockptfdatasyncclock_getresclock_gettimeclock_settimedirfdpthread_getattr_nppthread_attr_getstackmemalignsetgroupspipe2statfsfstatfsmemrchrposix_fadvisefutimensutimensatduplocalefreelocalenewlocaleuselocalefdopendirmknodatpthread_condattr_getclockpthread_condattr_setclockaccept4ptsname_rclearenvwaitidsetreuidsetregidgetresuidgetresgidacctbrksetresgidsetresuidopenptywinsizeexecvpefexecveioctllutimessetpwentendpwentgetpwentshm_openshmgetshmatshmdtshmctlshmid_dsftoksemgetsemopsembufsemctlmsgctlmsqid_dsmsggetmsgrcvmsgsndmprotect__errno_locationfallocateposix_fallocatereadaheadsignalfdtimerfd_createtimerfd_gettimeitimerspectimerfd_settimepwriteviovecpreadvquotactldup3mkostempmkostempssigtimedwaitsigwaitinfonl_langinfo_lgetnameinforebootsetfsgidsetfsuidmkfifoat// Not available now on Androidif_nameindexif_freenameindexsync_file_rangegetifaddrsifaddrsfreeifaddrsglob_tglobfreeposix_madviseshm_unlinkseekdirtelldirmadvisemsyncrecvfrommkstempsfutimesnl_langinfobindwritevreadvsendmsgrecvmsggetdomainnamesetdomainnamevhangupsendmmsgmmsghdrrecvmmsgsyscallsched_getaffinitycpu_set_tsched_setaffinityumountsched_get_priority_maxsettimeofdayeventfdsched_rr_get_intervalsem_timedwaitsem_getvaluesched_setparamsched_paramswapoffvmsplicemountpersonalitysched_getparamppollpthread_mutex_timedlocksched_getschedulerclock_nanosleeppthread_attr_getguardsizepthread_attr_setguardsizesethostnamesched_get_priority_minumount2swaponsched_setschedulersigsuspendgetgrgid_rsigaltstackstack_tsem_closegetdtablesizegetgrnam_rinitgroupspthread_sigmasksem_opengetgrnampthread_cancelpthread_killsem_unlinkdaemongetpwnam_rgetpwuid_rsigwaitpthread_atforkgetgrgidsetgrentendgrentgetgrentgetgrouplistpopenfaccessatpthread_createdl_iterate_phdrdl_phdr_info//! Definitions found commonly among almost all Unix derivatives//! More functions and definitions can be found in the more specific modules//! according to the platform in question.// PUB_TYPE// PUB_STRUCT// PUB_CONST// FIXME(#235): Include file sealing fcntls once we have a way to verify them.// LC_ALL_MASK defined per platform// PTRACE_EVENT_STOP was added to glibc in 2.26// pub const PTRACE_EVENT_STOP: c_int = 128;// netinet/in.h// NOTE: These are in addition to the constants defined in src/unix/mod.rs// END_PUB_CONST// EXTERN_FN// From psABI Calling Convention for RV64stat64R15// offsets in user_regs_structs, from sys/reg.hR14R13R12RBPRBXR11R10R9R8RDIORIG_RAXRIPEFLAGSRSPSSFS_BASEGS_BASEDSESFSGSMAP_32BITDT_WHTEAI_NODATAFUTEX_RELATIVE_TIMEOUTPOLLRDHUP"sys_alloc""sys_alloc_zeroed""sys_realloc""sys_dealloc""sys_exit""sys_abort""sys_errno"errno"sys_clock_gettime""sys_nanosleep""sys_available_parallelism"available_parallelism"sys_futex_wait"futex_wait"sys_futex_wake"futex_wake"sys_stat""sys_fstat""sys_lstat""sys_open""sys_unlink""sys_mkdir""sys_rmdir""sys_read""sys_write""sys_readv""sys_writev""sys_close""sys_dup""sys_fcntl""sys_getdents64"getdents64dirent64"sys_getaddrinfo""sys_freeaddrinfo""sys_socket""sys_bind""sys_listen""sys_accept""sys_connect""sys_recv""sys_recvfrom""sys_send""sys_sendto""sys_getpeername""sys_getsockname""sys_getsockopt""sys_setsockopt""sys_ioctl""sys_shutdown""sys_eventfd""sys_poll"//! Hermit C type definitions"libc"// Keep this order.r" Frequently-used types that are available on all platforms"r" We need to reexport the core types so this works with `rust-dep-of-std`."//! libc - Raw FFI bindings to platforms' system libraries// Attributes needed when building as part of the standard library// DIFF(1.0): The thread local references that raise this lint were removed in 1.0// Enable extra lints:// Collects all the negated `cfg`s in a list at the beginning and after the/// A macro for defining #[cfg] if-else statements./// This is similar to the `if/elif` C preprocessor macro by allowing definition/// of a cascade of `#[cfg]` cases, emitting the implementation which matches/// first./// This allows you to conveniently provide a long list #[cfg]'d blocks of code/// without having to rewrite each clause multiple times./// Create an internal crate prelude with `core` reexports and common types./// Implement `Clone` and `Copy` for a struct, as well as `Debug`, `Eq`, `Hash`, and/// `PartialEq` if the `extra_traits` feature is enabled./// Use [`s_no_extra_traits`] for structs where the `extra_traits` feature does not/// make sense, and for unions.s_paren/// Implement `Clone` and `Copy` for a tuple struct, as well as `Debug`, `Eq`, `Hash`,/// and `PartialEq` if the `extra_traits` feature is enabled./// This is the same as [`s`] but works for tuple structs./// Implement `Clone` and `Copy` for a struct with no `extra_traits` feature, as well as `Debug`/// with `extra_traits` since that can always be derived./// Most items will prefer to use [`s`].missing/// Specify that an enum should have no traits that aren't specified in the macro/// invocation, i.e. no `Clone` or `Copy`.e/// Implement `Clone` and `Copy` for an enum, as well as `Debug`, `Eq`, `Hash`, and// FIXME(#4419): Replace all uses of `e!` with `c_enum!`c_enum// Matcher for a single variant// Use a specific type if provided, otherwise default to `c_uint`/// Represent a C enum as Rust constants and a type./// C enums can't soundly be mapped to Rust enums since C enums are allowed to have duplicates or/// unlisted values, but this is UB in Rust. This enum doesn't implement any traits, its main/// purpose is to calculate the correct enum values./// See <https://github.com/rust-lang/libc/issues/4419> for more.r" Define an `unsafe` function that is const as long as `libc_const_extern_fn` is enabled."r" Define a safe function that is const as long as `libc_const_extern_fn` is enabled."r" A nonpublic function that is const as long as `libc_const_extern_fn` is enabled."const_fn// FIXME(ctest): ctest can't handle `const extern` functions, we should be able to remove this// cfg completely.// FIXME(ctest): ctest can't handle `$(,)?` so we use `$(,)*` which isn't quite correct.__itemdeprecated_mach// This macro is used to deprecate items that should be accessed via the mach2 crate// This is a pretty horrible hack to allow us to conditionally mark some functions as 'const',// without requiring users of this macro to care "libc_const_extern_fn".// When 'libc_const_extern_fn' is enabled, we emit the captured 'const' keyword in the expanded// function.// When 'libc_const_extern_fn' is disabled, we always emit a plain 'pub unsafe extern fn'.// Note that the expression matched by the macro is exactly the same - this allows// users of this macro to work whether or not 'libc_const_extern_fn' is enabled// Unfortunately, we need to duplicate most of this macro between the 'cfg_if' blocks.// This is because 'const unsafe extern fn' won't even parse on older compilers,// so we need to avoid emitting it at all of 'libc_const_extern_fn'.// Specifically, moving the 'cfg_if' into the macro body will *not* work. Doing so would cause the// '#[cfg(libc_const_extern_fn)]' to be emitted into user code. The 'cfg' gate will not stop Rust// from trying to parse the 'pub const unsafe extern fn', so users would get a compiler error even// when the 'libc_const_extern_fn' feature is disabled.c_scharint8_tint16_tint32_tint64_tuint8_tuint16_tuint32_tuint64_tr" C `__int128` (a GCC extension that's part of many ABIs)"__int128r" C `unsigned __int128` (a GCC extension that's part of many ABIs)"__uint128r" C __int128_t (alternate name for [__int128][])"__int128_tr" C __uint128_t (alternate name for [__uint128][])"__uint128_t_SIZE_128_ALIGN_128//! This module contains type aliases for C's platform-specific types//! and fixed-width integer types.//! The platform-specific types definitions were taken from rust-lang/rust in//! library/core/src/ffi/primitives.rs//! The fixed-width integer aliases are deprecated: use the Rust types instead.SceKernelVTimerHandlerSceUidSceKernelSysClockSceKernelVTimerHandlerWideSceKernelThreadEventHandlerSceKernelAlarmHandlerSceKernelCallbackFunctionSceKernelThreadEntryPowerCallbackIoPermissionsUmdCallbackSceMpegRingbufferCbGuCallbackGuSwapBuffersCallbackSceNetAdhocctlHandlerAdhocMatchingCallbackSceNetApctlHandlerHttpMallocFunctionHttpReallocFunctionHttpFreeFunctionHttpPasswordCBHttpAuthTypeAUDIO_VOLUME_MAXAUDIO_CHANNEL_MAXAUDIO_NEXT_CHANNELAUDIO_SAMPLE_MINAUDIO_SAMPLE_MAXPSP_CTRL_SELECTPSP_CTRL_STARTPSP_CTRL_UPPSP_CTRL_RIGHTPSP_CTRL_DOWNPSP_CTRL_LEFTPSP_CTRL_LTRIGGERPSP_CTRL_RTRIGGERPSP_CTRL_TRIANGLEPSP_CTRL_CIRCLEPSP_CTRL_CROSSPSP_CTRL_SQUAREPSP_CTRL_HOMEPSP_CTRL_HOLDPSP_CTRL_NOTEPSP_CTRL_SCREENPSP_CTRL_VOLUPPSP_CTRL_VOLDOWNPSP_CTRL_WLAN_UPPSP_CTRL_REMOTEPSP_CTRL_DISCPSP_CTRL_MSUSB_CAM_PIDUSB_BUS_DRIVER_NAMEUSB_CAM_DRIVER_NAMEUSB_CAM_MIC_DRIVER_NAMEUSB_STOR_DRIVER_NAMEACTIVATEDCONNECTEDESTABLISHEDUSB_CAM_FLIPUSB_CAM_MIRRORTHREAD_ATTR_VFPUTHREAD_ATTR_USERTHREAD_ATTR_USBWLANTHREAD_ATTR_VSHTHREAD_ATTR_SCRATCH_SRAMTHREAD_ATTR_NO_FILLSTACKTHREAD_ATTR_CLEAR_STACKEVENT_WAIT_MULTIPLEEVENT_WAIT_ANDEVENT_WAIT_OREVENT_WAIT_CLEARPOWER_INFO_POWER_SWITCHPOWER_INFO_HOLD_SWITCHPOWER_INFO_STANDBYPOWER_INFO_RESUME_COMPLETEPOWER_INFO_RESUMINGPOWER_INFO_SUSPENDINGPOWER_INFO_AC_POWERPOWER_INFO_BATTERY_LOWPOWER_INFO_BATTERY_EXISTPOWER_INFO_BATTERY_POWERFIO_S_IFLNKFIO_S_IFDIRFIO_S_IFREGFIO_S_ISUIDFIO_S_ISGIDFIO_S_ISVTXFIO_S_IRUSRFIO_S_IWUSRFIO_S_IXUSRFIO_S_IRGRPFIO_S_IWGRPFIO_S_IXGRPFIO_S_IROTHFIO_S_IWOTHFIO_S_IXOTHFIO_SO_IFLNKFIO_SO_IFDIRFIO_SO_IFREGFIO_SO_IROTHFIO_SO_IWOTHFIO_SO_IXOTHPSP_O_RD_ONLYPSP_O_WR_ONLYPSP_O_RD_WRPSP_O_NBLOCKPSP_O_DIRPSP_O_APPENDPSP_O_CREATPSP_O_TRUNCPSP_O_EXCLPSP_O_NO_WAITUMD_NOT_PRESENTUMD_PRESENTUMD_CHANGEDUMD_INITINGUMD_INITEDUMD_READYPLAY_PAUSEFORWARDBACKVOL_UPVOL_DOWNHOLDGU_PIGU_TEXTURE_8BITGU_TEXTURE_16BITGU_TEXTURE_32BITFGU_COLOR_5650GU_COLOR_5551GU_COLOR_4444GU_COLOR_8888GU_NORMAL_8BITGU_NORMAL_16BITGU_NORMAL_32BITFGU_VERTEX_8BITGU_VERTEX_16BITGU_VERTEX_32BITFGU_WEIGHT_8BITGU_WEIGHT_16BITGU_WEIGHT_32BITFGU_INDEX_8BITGU_INDEX_16BITGU_WEIGHTS1GU_WEIGHTS2GU_WEIGHTS3GU_WEIGHTS4GU_WEIGHTS5GU_WEIGHTS6GU_WEIGHTS7GU_WEIGHTS8GU_VERTICES1GU_VERTICES2GU_VERTICES3GU_VERTICES4GU_VERTICES5GU_VERTICES6GU_VERTICES7GU_VERTICES8GU_TRANSFORM_2DGU_TRANSFORM_3DGU_COLOR_BUFFER_BITGU_STENCIL_BUFFER_BITGU_DEPTH_BUFFER_BITGU_FAST_CLEAR_BITGU_AMBIENTGU_DIFFUSEGU_SPECULARGU_UNKNOWN_LIGHT_COMPONENTSYSTEM_REGISTRYREG_KEYNAME_SIZEUTILITY_MSGDIALOG_ERRORUTILITY_MSGDIALOG_TEXTUTILITY_MSGDIALOG_YES_NO_BUTTONSUTILITY_MSGDIALOG_DEFAULT_NOUTILITY_HTMLVIEWER_OPEN_SCE_START_PAGEUTILITY_HTMLVIEWER_DISABLE_STARTUP_LIMITSUTILITY_HTMLVIEWER_DISABLE_EXIT_DIALOGUTILITY_HTMLVIEWER_DISABLE_CURSORUTILITY_HTMLVIEWER_DISABLE_DOWNLOAD_COMPLETE_DIALOGUTILITY_HTMLVIEWER_DISABLE_DOWNLOAD_START_DIALOGUTILITY_HTMLVIEWER_DISABLE_DOWNLOAD_DESTINATION_DIALOGUTILITY_HTMLVIEWER_LOCK_DOWNLOAD_DESTINATION_DIALOGUTILITY_HTMLVIEWER_DISABLE_TAB_DISPLAYUTILITY_HTMLVIEWER_ENABLE_ANALOG_HOLDUTILITY_HTMLVIEWER_ENABLE_FLASHUTILITY_HTMLVIEWER_DISABLE_LRTRIGGERsceAudioChReserveAudioFormatsceAudioChReleasesceAudioOutputsceAudioOutputBlockingsceAudioOutputPannedsceAudioOutputPannedBlockingsceAudioGetChannelRestLensceAudioGetChannelRestLengthsceAudioSetChannelDataLensceAudioChangeChannelConfigsceAudioChangeChannelVolumesceAudioOutput2ReservesceAudioOutput2ReleasesceAudioOutput2ChangeLengthsceAudioOutput2OutputBlockingsceAudioOutput2GetRestSamplesceAudioSRCChReserveAudioOutputFrequencysceAudioSRCChReleasesceAudioSRCOutputBlockingsceAudioInputInitsceAudioInputInitExAudioInputParamssceAudioInputBlockingAudioInputFrequencysceAudioInputsceAudioGetInputLengthsceAudioWaitInputEndsceAudioPollInputEndsceAtracGetAtracIDsceAtracSetDataAndGetIDsceAtracDecodeDatasceAtracGetRemainFramesceAtracGetStreamDataInfosceAtracAddStreamDatasceAtracGetBitratesceAtracSetLoopNumsceAtracReleaseAtracIDsceAtracGetNextSamplesceAtracGetMaxSamplesceAtracGetBufferInfoForResetingAtrac3BufferInfosceAtracGetChannelsceAtracGetInternalErrorInfosceAtracGetLoopStatussceAtracGetNextDecodePositionsceAtracGetSecondBufferInfosceAtracGetSoundSamplesceAtracResetPlayPositionsceAtracSetDatasceAtracSetHalfwayBuffersceAtracSetHalfwayBufferAndGetIDsceAtracSetSecondBuffersceCtrlSetSamplingCyclesceCtrlGetSamplingCyclesceCtrlSetSamplingModeCtrlModesceCtrlGetSamplingModesceCtrlPeekBufferPositiveSceCtrlDatasceCtrlPeekBufferNegativesceCtrlReadBufferPositivesceCtrlReadBufferNegativesceCtrlPeekLatchSceCtrlLatchsceCtrlReadLatchsceCtrlSetIdleCancelThresholdsceCtrlGetIdleCancelThresholdsceDisplaySetModeDisplayModesceDisplayGetModesceDisplaySetFrameBufDisplayPixelFormatDisplaySetBufSyncsceDisplayGetFrameBufsceDisplayGetVcountsceDisplayWaitVblanksceDisplayWaitVblankCBsceDisplayWaitVblankStartsceDisplayWaitVblankStartCBsceDisplayGetAccumulatedHcountsceDisplayGetCurrentHcountsceDisplayGetFramePerSecsceDisplayIsForegroundsceDisplayIsVblanksceGeEdramGetSizesceGeEdramGetAddrsceGeEdramSetAddrTranslationsceGeGetCmdsceGeGetMtxGeMatrixTypesceGeGetStackGeStacksceGeSaveContextGeContextsceGeRestoreContextsceGeListEnQueueGeListArgssceGeListEnQueueHeadsceGeListDeQueuesceGeListUpdateStallAddrsceGeListSyncGeListStatesceGeDrawSyncsceGeBreakGeBreakParamsceGeContinuesceGeSetCallbackGeCallbackDatasceGeUnsetCallbacksceKernelExitGamesceKernelRegisterExitCallbacksceKernelLoadExecSceKernelLoadExecParamsceKernelAllocPartitionMemorySceSysMemPartitionIdSceSysMemBlockTypessceKernelGetBlockHeadAddrsceKernelFreePartitionMemorysceKernelTotalFreeMemSizesceKernelMaxFreeMemSizesceKernelDevkitVersionsceKernelSetCompiledSdkVersionsceKernelGetCompiledSdkVersionsceKernelLibcTimesceKernelLibcClocksceKernelLibcGettimeofdaysceKernelDcacheWritebackAllsceKernelDcacheWritebackInvalidateAllsceKernelDcacheWritebackRangesceKernelDcacheWritebackInvalidateRangesceKernelDcacheInvalidateRangesceKernelIcacheInvalidateAllsceKernelIcacheInvalidateRangesceKernelUtilsMt19937InitSceKernelUtilsMt19937ContextsceKernelUtilsMt19937UIntsceKernelUtilsMd5DigestsceKernelUtilsMd5BlockInitSceKernelUtilsMd5ContextsceKernelUtilsMd5BlockUpdatesceKernelUtilsMd5BlockResultsceKernelUtilsSha1DigestsceKernelUtilsSha1BlockInitSceKernelUtilsSha1ContextsceKernelUtilsSha1BlockUpdatesceKernelUtilsSha1BlockResultsceKernelRegisterSubIntrHandlersceKernelReleaseSubIntrHandlersceKernelEnableSubIntrsceKernelDisableSubIntrQueryIntrHandlerInfoIntrHandlerOptionParamsceKernelCpuSuspendIntrsceKernelCpuResumeIntrsceKernelCpuResumeIntrWithSyncsceKernelIsCpuIntrSuspendedsceKernelIsCpuIntrEnablesceKernelLoadModuleSceKernelLMOptionsceKernelLoadModuleMssceKernelLoadModuleByIDsceKernelLoadModuleBufferUsbWlansceKernelStartModuleSceKernelSMOptionsceKernelStopModulesceKernelUnloadModulesceKernelSelfStopUnloadModulesceKernelStopUnloadSelfModulesceKernelQueryModuleInfoSceKernelModuleInfosceKernelGetModuleIdListsceKernelVolatileMemLocksceKernelVolatileMemTryLocksceKernelVolatileMemUnlocksceKernelStdinsceKernelStdoutsceKernelStderrsceKernelGetThreadmanIdTypeSceKernelIdListTypesceKernelCreateThreadSceKernelThreadOptParamsceKernelDeleteThreadsceKernelStartThreadsceKernelExitThreadsceKernelExitDeleteThreadsceKernelTerminateThreadsceKernelTerminateDeleteThreadsceKernelSuspendDispatchThreadsceKernelResumeDispatchThreadsceKernelSleepThreadsceKernelSleepThreadCBsceKernelWakeupThreadsceKernelCancelWakeupThreadsceKernelSuspendThreadsceKernelResumeThreadsceKernelWaitThreadEndsceKernelWaitThreadEndCBsceKernelDelayThreadsceKernelDelayThreadCBsceKernelDelaySysClockThreadsceKernelDelaySysClockThreadCBsceKernelChangeCurrentThreadAttrsceKernelChangeThreadPrioritysceKernelRotateThreadReadyQueuesceKernelReleaseWaitThreadsceKernelGetThreadIdsceKernelGetThreadCurrentPrioritysceKernelGetThreadExitStatussceKernelCheckThreadStacksceKernelGetThreadStackFreeSizesceKernelReferThreadStatusSceKernelThreadInfosceKernelReferThreadRunStatusSceKernelThreadRunStatussceKernelCreateSemaSceKernelSemaOptParamsceKernelDeleteSemasceKernelSignalSemasceKernelWaitSemasceKernelWaitSemaCBsceKernelPollSemasceKernelReferSemaStatusSceKernelSemaInfosceKernelCreateEventFlagSceKernelEventFlagOptParamsceKernelSetEventFlagsceKernelClearEventFlagsceKernelPollEventFlagsceKernelWaitEventFlagsceKernelWaitEventFlagCBsceKernelDeleteEventFlagsceKernelReferEventFlagStatusSceKernelEventFlagInfosceKernelCreateMbxSceKernelMbxOptParamsceKernelDeleteMbxsceKernelSendMbxsceKernelReceiveMbxsceKernelReceiveMbxCBsceKernelPollMbxsceKernelCancelReceiveMbxsceKernelReferMbxStatusSceKernelMbxInfosceKernelSetAlarmsceKernelSetSysClockAlarmsceKernelCancelAlarmsceKernelReferAlarmStatusSceKernelAlarmInfosceKernelCreateCallbacksceKernelReferCallbackStatusSceKernelCallbackInfosceKernelDeleteCallbacksceKernelNotifyCallbacksceKernelCancelCallbacksceKernelGetCallbackCountsceKernelCheckCallbacksceKernelGetThreadmanIdListsceKernelReferSystemStatusSceKernelSystemStatussceKernelCreateMsgPipesceKernelDeleteMsgPipesceKernelSendMsgPipesceKernelSendMsgPipeCBsceKernelTrySendMsgPipesceKernelReceiveMsgPipesceKernelReceiveMsgPipeCBsceKernelTryReceiveMsgPipesceKernelCancelMsgPipesceKernelReferMsgPipeStatusSceKernelMppInfosceKernelCreateVplSceKernelVplOptParamsceKernelDeleteVplsceKernelAllocateVplsceKernelAllocateVplCBsceKernelTryAllocateVplsceKernelFreeVplsceKernelCancelVplsceKernelReferVplStatusSceKernelVplInfosceKernelCreateFplSceKernelFplOptParamsceKernelDeleteFplsceKernelAllocateFplsceKernelAllocateFplCBsceKernelTryAllocateFplsceKernelFreeFplsceKernelCancelFplsceKernelReferFplStatusSceKernelFplInfosceKernelUSec2SysClocksceKernelUSec2SysClockWidesceKernelSysClock2USecsceKernelSysClock2USecWidesceKernelGetSystemTimesceKernelGetSystemTimeWidesceKernelGetSystemTimeLowsceKernelCreateVTimerSceKernelVTimerOptParamsceKernelDeleteVTimersceKernelGetVTimerBasesceKernelGetVTimerBaseWidesceKernelGetVTimerTimesceKernelGetVTimerTimeWidesceKernelSetVTimerTimesceKernelSetVTimerTimeWidesceKernelStartVTimersceKernelStopVTimersceKernelSetVTimerHandlersceKernelSetVTimerHandlerWidesceKernelCancelVTimerHandlersceKernelReferVTimerStatusSceKernelVTimerInfosceKernelRegisterThreadEventHandlersceKernelReleaseThreadEventHandlersceKernelReferThreadEventHandlerStatusSceKernelThreadEventHandlerInfosceKernelReferThreadProfilerDebugProfilerRegssceKernelReferGlobalProfilersceUsbStartsceUsbStopsceUsbActivatesceUsbDeactivatesceUsbGetStatesceUsbGetDrvStatesceUsbCamSetupStillUsbCamSetupStillParamsceUsbCamSetupStillExUsbCamSetupStillExParamsceUsbCamStillInputBlockingsceUsbCamStillInputsceUsbCamStillWaitInputEndsceUsbCamStillPollInputEndsceUsbCamStillCancelInputsceUsbCamStillGetInputLengthsceUsbCamSetupVideoUsbCamSetupVideoParamsceUsbCamSetupVideoExUsbCamSetupVideoExParamsceUsbCamStartVideosceUsbCamStopVideosceUsbCamReadVideoFrameBlockingsceUsbCamReadVideoFramesceUsbCamWaitReadVideoFrameEndsceUsbCamPollReadVideoFrameEndsceUsbCamGetReadVideoFrameSizesceUsbCamSetSaturationsceUsbCamSetBrightnesssceUsbCamSetContrastsceUsbCamSetSharpnesssceUsbCamSetImageEffectModeUsbCamEffectModesceUsbCamSetEvLevelUsbCamEvLevelsceUsbCamSetReverseModesceUsbCamSetZoomsceUsbCamGetSaturationsceUsbCamGetBrightnesssceUsbCamGetContrastsceUsbCamGetSharpnesssceUsbCamGetImageEffectModesceUsbCamGetEvLevelsceUsbCamGetReverseModesceUsbCamGetZoomsceUsbCamAutoImageReverseSWsceUsbCamGetAutoImageReverseStatesceUsbCamGetLensDirectionsceUsbstorBootRegisterNotifysceUsbstorBootUnregisterNotifysceUsbstorBootSetCapacityscePowerRegisterCallbackscePowerUnregisterCallbackscePowerIsPowerOnlinescePowerIsBatteryExistscePowerIsBatteryChargingscePowerGetBatteryChargingStatusscePowerIsLowBatteryscePowerGetBatteryLifePercentscePowerGetBatteryLifeTimescePowerGetBatteryTempscePowerGetBatteryElecscePowerGetBatteryVoltscePowerSetCpuClockFrequencyscePowerSetBusClockFrequencyscePowerGetCpuClockFrequencyscePowerGetCpuClockFrequencyIntscePowerGetCpuClockFrequencyFloatscePowerGetBusClockFrequencyscePowerGetBusClockFrequencyIntscePowerGetBusClockFrequencyFloatscePowerSetClockFrequencyscePowerLockscePowerUnlockscePowerTickPowerTickscePowerGetIdleTimerscePowerIdleTimerEnablescePowerIdleTimerDisablescePowerRequestStandbyscePowerRequestSuspendsceWlanDevIsPowerOnsceWlanGetSwitchStatesceWlanGetEtherAddrsceWlanDevAttachsceWlanDevDetachsceRtcGetTickResolutionsceRtcGetCurrentTicksceRtcGetCurrentClockScePspDateTimesceRtcGetCurrentClockLocalTimesceRtcConvertUtcToLocalTimesceRtcConvertLocalTimeToUTCsceRtcIsLeapYearsceRtcGetDaysInMonthsceRtcGetDayOfWeeksceRtcCheckValidsceRtcSetTicksceRtcGetTicksceRtcCompareTicksceRtcTickAddTickssceRtcTickAddMicrosecondssceRtcTickAddSecondssceRtcTickAddMinutessceRtcTickAddHourssceRtcTickAddDayssceRtcTickAddWeekssceRtcTickAddMonthssceRtcTickAddYearssceRtcSetTime_tsceRtcGetTime_tsceRtcSetTime64_tsceRtcGetTime64_tsceRtcSetDosTimesceRtcGetDosTimesceRtcSetWin32FileTimesceRtcGetWin32FileTimesceRtcParseDateTimesceRtcFormatRFC3339sceRtcFormatRFC3339LocalTimesceRtcParseRFC3339sceRtcFormatRFC2822sceRtcFormatRFC2822LocalTimesceIoOpensceIoOpenAsyncsceIoClosesceIoCloseAsyncsceIoReadsceIoReadAsyncsceIoWritesceIoWriteAsyncsceIoLseekIoWhencesceIoLseekAsyncsceIoLseek32sceIoLseek32AsyncsceIoRemovesceIoMkdirsceIoRmdirsceIoChdirsceIoRenamesceIoDopensceIoDreadSceIoDirentsceIoDclosesceIoDevctlsceIoAssignIoAssignPermssceIoUnassignsceIoGetstatSceIoStatsceIoChstatsceIoIoctlsceIoIoctlAsyncsceIoSyncsceIoWaitAsyncsceIoWaitAsyncCBsceIoPollAsyncsceIoGetAsyncStatsceIoCancelsceIoGetDevTypesceIoChangeAsyncPrioritysceIoSetAsyncCallbacksceJpegInitMJpegsceJpegFinishMJpegsceJpegCreateMJpegsceJpegDeleteMJpegsceJpegDecodeMJpegsceUmdCheckMediumsceUmdGetDiscInfoUmdInfosceUmdActivatesceUmdDeactivatesceUmdWaitDriveStatsceUmdWaitDriveStatWithTimersceUmdWaitDriveStatCBsceUmdCancelWaitDriveStatsceUmdGetDriveStatsceUmdGetErrorStatsceUmdRegisterUMDCallBacksceUmdUnRegisterUMDCallBacksceUmdReplacePermitsceUmdReplaceProhibitsceMpegInitsceMpegFinishsceMpegRingbufferQueryMemSizesceMpegRingbufferConstructSceMpegRingbuffersceMpegRingbufferDestructsceMpegRingbufferAvailableSizesceMpegRingbufferPutsceMpegQueryMemSizesceMpegCreateSceMpegsceMpegDeletesceMpegQueryStreamOffsetsceMpegQueryStreamSizesceMpegRegistStreamSceMpegStreamsceMpegUnRegistStreamsceMpegFlushAllStreamsceMpegMallocAvcEsBufsceMpegFreeAvcEsBufsceMpegQueryAtracEsSizesceMpegInitAuSceMpegAusceMpegGetAvcAusceMpegAvcDecodeModeSceMpegAvcModesceMpegAvcDecodesceMpegAvcDecodeStopsceMpegGetAtracAusceMpegAtracDecodesceMpegBaseYCrCbCopyVmesceMpegBaseCscInitsceMpegBaseCscVmeSceMpegYCrCbBuffersceMpegbase_BEA18F91SceMpegLLIsceHprmPeekCurrentKeysceHprmPeekLatchsceHprmReadLatchsceHprmIsHeadphoneExistsceHprmIsRemoteExistsceHprmIsMicrophoneExistsceGuDepthBuffersceGuDispBuffersceGuDrawBuffersceGuDrawBufferListsceGuDisplaysceGuDepthFuncDepthFuncsceGuDepthMasksceGuDepthOffsetsceGuDepthRangesceGuFogsceGuInitsceGuTermsceGuBreaksceGuContinuesceGuSetCallbackGuCallbackIdsceGuSignalSignalBehaviorsceGuSendCommandfGeCommandsceGuSendCommandisceGuGetMemorysceGuStartGuContextTypesceGuFinishsceGuFinishIdsceGuCallListsceGuCallModesceGuCheckListsceGuSendListGuQueueModesceGuSwapBufferssceGuSyncGuSyncModeGuSyncBehaviorsceGuDrawArrayGuPrimitivesceGuBeginObjectsceGuEndObjectsceGuSetStatusGuStatesceGuGetStatussceGuSetAllStatussceGuGetAllStatussceGuEnablesceGuDisablesceGuLightLightTypeScePspFVector3sceGuLightAttsceGuLightColorsceGuLightModeLightModesceGuLightSpotsceGuClearsceGuClearColorsceGuClearDepthsceGuClearStencilsceGuPixelMasksceGuColorsceGuColorFuncColorFuncsceGuColorMaterialsceGuAlphaFuncAlphaFuncsceGuAmbientsceGuAmbientColorsceGuBlendFuncBlendOpBlendSrcBlendDstsceGuMaterialsceGuModelColorsceGuStencilFuncStencilFuncsceGuStencilOpStencilOperationsceGuSpecularsceGuFrontFaceFrontFaceDirectionsceGuLogicalOpLogicalOperationsceGuSetDitherScePspIMatrix4sceGuShadeModelShadingModelsceGuCopyImagesceGuTexEnvColorsceGuTexFilterTextureFiltersceGuTexFlushsceGuTexFuncTextureEffectTextureColorComponentsceGuTexImageMipmapLevelsceGuTexLevelModeTextureLevelModesceGuTexMapModeTextureMapModesceGuTexModeTexturePixelFormatsceGuTexOffsetsceGuTexProjMapModeTextureProjectionMapModesceGuTexScalesceGuTexSlopesceGuTexSyncsceGuTexWrapGuTexWrapModesceGuClutLoadsceGuClutModeClutPixelFormatsceGuOffsetsceGuScissorsceGuViewportsceGuDrawBeziersceGuPatchDividesceGuPatchFrontFacesceGuPatchPrimPatchPrimitivesceGuDrawSplinesceGuSetMatrixMatrixModeScePspFMatrix4sceGuBoneMatrixsceGuMorphWeightsceGuDrawArrayNsceGumDrawArraysceGumDrawArrayNsceGumDrawBeziersceGumDrawSplinesceGumFastInversesceGumFullInversesceGumLoadIdentitysceGumLoadMatrixsceGumLookAtsceGumMatrixModesceGumMultMatrixsceGumOrthosceGumPerspectivesceGumPopMatrixsceGumPushMatrixsceGumRotateXsceGumRotateYsceGumRotateZsceGumRotateXYZsceGumRotateZYXsceGumScalesceGumStoreMatrixsceGumTranslatesceGumUpdateMatrixsceMp3ReserveMp3HandleSceMp3InitArgsceMp3ReleaseMp3HandleMp3HandlesceMp3InitResourcesceMp3TermResourcesceMp3InitsceMp3DecodesceMp3GetInfoToAddStreamDatasceMp3NotifyAddStreamDatasceMp3CheckStreamDataNeededsceMp3SetLoopNumsceMp3GetLoopNumsceMp3GetSumDecodedSamplesceMp3GetMaxOutputSamplesceMp3GetSamplingRatesceMp3GetBitRatesceMp3GetMp3ChannelNumsceMp3ResetPlayPositionsceRegOpenRegistryRegHandlesceRegFlushRegistrysceRegCloseRegistrysceRegOpenCategorysceRegRemoveCategorysceRegCloseCategorysceRegFlushCategorysceRegGetKeyInfoKeyTypesceRegGetKeyInfoByNamesceRegGetKeyValuesceRegGetKeyValueByNamesceRegSetKeyValuesceRegGetKeysNumsceRegGetKeyssceRegCreateKeysceRegRemoveRegistrysceOpenPSIDGetOpenPSIDOpenPSIDsceUtilityMsgDialogInitStartUtilityMsgDialogParamssceUtilityMsgDialogShutdownStartsceUtilityMsgDialogGetStatussceUtilityMsgDialogUpdatesceUtilityMsgDialogAbortsceUtilityNetconfInitStartUtilityNetconfDatasceUtilityNetconfShutdownStartsceUtilityNetconfUpdatesceUtilityNetconfGetStatussceUtilityCheckNetParamsceUtilityGetNetParamNetParamUtilityNetDatasceUtilitySavedataInitStartSceUtilitySavedataParamsceUtilitySavedataGetStatussceUtilitySavedataShutdownStartsceUtilitySavedataUpdatesceUtilityGameSharingInitStartUtilityGameSharingParamssceUtilityGameSharingShutdownStartsceUtilityGameSharingGetStatussceUtilityGameSharingUpdatesceUtilityHtmlViewerInitStartUtilityHtmlViewerParamsceUtilityHtmlViewerShutdownStartsceUtilityHtmlViewerUpdatesceUtilityHtmlViewerGetStatussceUtilitySetSystemParamIntSystemParamIdsceUtilitySetSystemParamStringsceUtilityGetSystemParamIntsceUtilityGetSystemParamStringsceUtilityOskInitStartSceUtilityOskParamssceUtilityOskShutdownStartsceUtilityOskUpdatesceUtilityOskGetStatussceUtilityLoadNetModuleNetModulesceUtilityUnloadNetModulesceUtilityLoadAvModuleAvModulesceUtilityUnloadAvModulesceUtilityLoadUsbModuleUsbModulesceUtilityUnloadUsbModulesceUtilityLoadModulesceUtilityUnloadModulesceUtilityCreateNetParamsceUtilitySetNetParamsceUtilityCopyNetParamsceUtilityDeleteNetParamsceNetInitsceNetTermsceNetFreeThreadinfosceNetThreadAbortsceNetEtherStrtonsceNetEtherNtostrsceNetGetLocalEtherAddrsceNetGetMallocStatSceNetMallocStatsceNetAdhocctlInitSceNetAdhocctlAdhocIdsceNetAdhocctlTermsceNetAdhocctlConnectsceNetAdhocctlDisconnectsceNetAdhocctlGetStatesceNetAdhocctlCreatesceNetAdhocctlJoinSceNetAdhocctlScanInfosceNetAdhocctlGetAdhocIdsceNetAdhocctlCreateEnterGameModesceNetAdhocctlJoinEnterGameModesceNetAdhocctlGetGameModeInfoSceNetAdhocctlGameModeInfosceNetAdhocctlExitGameModesceNetAdhocctlGetPeerListsceNetAdhocctlGetPeerInfoSceNetAdhocctlPeerInfosceNetAdhocctlScansceNetAdhocctlGetScanInfosceNetAdhocctlAddHandlersceNetAdhocctlDelHandlersceNetAdhocctlGetNameByAddrsceNetAdhocctlGetAddrByNamesceNetAdhocctlGetParameterSceNetAdhocctlParamssceNetAdhocInitsceNetAdhocTermsceNetAdhocPdpCreatesceNetAdhocPdpDeletesceNetAdhocPdpSendsceNetAdhocPdpRecvsceNetAdhocGetPdpStatSceNetAdhocPdpStatsceNetAdhocGameModeCreateMastersceNetAdhocGameModeCreateReplicasceNetAdhocGameModeUpdateMastersceNetAdhocGameModeUpdateReplicasceNetAdhocGameModeDeleteMastersceNetAdhocGameModeDeleteReplicasceNetAdhocPtpOpensceNetAdhocPtpConnectsceNetAdhocPtpListensceNetAdhocPtpAcceptsceNetAdhocPtpSendsceNetAdhocPtpRecvsceNetAdhocPtpFlushsceNetAdhocPtpClosesceNetAdhocGetPtpStatSceNetAdhocPtpStatsceNetAdhocMatchingInitsceNetAdhocMatchingTermsceNetAdhocMatchingCreateAdhocMatchingModesceNetAdhocMatchingDeletesceNetAdhocMatchingStartsceNetAdhocMatchingStopsceNetAdhocMatchingSelectTargetsceNetAdhocMatchingCancelTargetsceNetAdhocMatchingCancelTargetWithOptsceNetAdhocMatchingSendDatasceNetAdhocMatchingAbortSendDatasceNetAdhocMatchingSetHelloOptsceNetAdhocMatchingGetHelloOptsceNetAdhocMatchingGetMemberssceNetAdhocMatchingGetPoolMaxAllocsceNetAdhocMatchingGetPoolStatAdhocPoolStatsceNetApctlInitsceNetApctlTermsceNetApctlGetInfoApctlInfoSceNetApctlInfosceNetApctlAddHandlersceNetApctlDelHandlersceNetApctlConnectsceNetApctlDisconnectsceNetApctlGetStateApctlStatesceNetInetInitsceNetInetTermsceNetInetAcceptsceNetInetBindsceNetInetConnectsceNetInetGetsockoptsceNetInetListensceNetInetRecvsceNetInetRecvfromsceNetInetSendsceNetInetSendtosceNetInetSetsockoptsceNetInetShutdownsceNetInetSocketsceNetInetClosesceNetInetGetErrnosceSslInitsceSslEndsceSslGetUsedMemoryMaxsceSslGetUsedMemoryCurrentsceHttpInitsceHttpEndsceHttpCreateTemplatesceHttpDeleteTemplatesceHttpCreateConnectionsceHttpCreateConnectionWithURLsceHttpDeleteConnectionsceHttpCreateRequestHttpMethodsceHttpCreateRequestWithURLsceHttpDeleteRequestsceHttpSendRequestsceHttpAbortRequestsceHttpReadDatasceHttpGetContentLengthsceHttpGetStatusCodesceHttpSetResolveTimeOutsceHttpSetResolveRetrysceHttpSetConnectTimeOutsceHttpSetSendTimeOutsceHttpSetRecvTimeOutsceHttpEnableKeepAlivesceHttpDisableKeepAlivesceHttpEnableRedirectsceHttpDisableRedirectsceHttpEnableCookiesceHttpDisableCookiesceHttpSaveSystemCookiesceHttpLoadSystemCookiesceHttpAddExtraHeadersceHttpDeleteHeadersceHttpsInitsceHttpsEndsceHttpsLoadDefaultCertsceHttpDisableAuthsceHttpDisableCachesceHttpEnableAuthsceHttpEnableCachesceHttpEndCachesceHttpGetAllHeadersceHttpGetNetworkErrnosceHttpGetProxysceHttpInitCachesceHttpSetAuthInfoCBsceHttpSetProxysceHttpSetResHeaderMaxSizesceHttpSetMallocFunctionsceNetResolverInitsceNetResolverCreatesceNetResolverDeletesceNetResolverStartNtoAin_addrsceNetResolverStartAtoNsceNetResolverStopsceNetResolverTerm//! PSP C type definitions//! These type declarations are not enough, as they must be ultimately resolved//! by the linker. Crates that use these definitions must, somewhere in the//! crate graph, include a stub provider crate such as the `psp` crate.//! SGX C types definitiontimer_t__caddr_t// sys/ansi.h__gid_t__in_addr_t__in_port_t__mode_t__off_t__pid_t__sa_family_t__socklen_t__uid_t__fsblkcnt_t__fsfilcnt_t// locale.h// nl_types.h__va_list// sys/types.hu_int8_tu_int16_tu_int32_tu_int64_tu_charu_shortu_intu_longuncharushortulongu_quad_tquad_tqaddr_tlonglong_tu_longlong_tcaddr_tdaddr_tfixpt_tlwpid_tsegsz_tswblk_tcpuid_tpsetid_tO_TEXTO_BINARY_LC_LASTEFTYPE// signal codesSIGEMTSIGINFO// ctype.h__get_stdio_file// stdio.hclearerrgetcputcvfprintfvprintfgetsvsprintfasiprintffiprintffiscanfiprintfiscanfsiprintfsiscanfsniprintfvasiprintfvfiprintfvfiscanfviprintfviscanfvsiprintfvsiscanfvsniprintfvdiprintfdiprintfflockfileftrylockfilefunlockfilegetc_unlockedputc_unlockedvsnprintfgetwputwtempnam// stdlib.hdrand48erand48strtoldstrtod_lstrtof_lstrtold_l_Exitltoaultoabsearchdiv_tldivldiv_tqsortmblenmbstowcswctombmbtowcrand_rjrand48lcong48lrand48mrand48nrand48seed48srand48a64ll64asetstateinitstatesrandommktempllabslldivlldiv_taligned_allocat_quick_exitquick_exithumanize_numberdehumanize_numbergetenv_rheapsortmergesortradixsortsradixsortgetprognamesetprognameqabsstrtoqstrtouqstrsuftollstrsuftollxl64a_rqdivqdiv_tstrtol_lstrtoul_lstrtoll_lstrtoull_lstrtoq_lstrtouq_l_mb_cur_max_lmblen_lmbstowcs_lwctomb_lmbtowc_lwcstombs_l// string.hstrtok_rmemccpystpcpystpncpystrcasestrstrlcatstrlcpystrsepstresepstrndupexplicit_memsetconsttime_memequalstrcoll_lstrxfrm_lstrerror_lbcmp// strings.hbcopybzeroffspopcountpopcountlpopcountllpopcount32popcount64rindexstrcasecmpstrncasecmp// signal.hasctime// time.hctimedifftimeasctime_rctime_r// sys/stat.h// fcntl.htellgetwdoptargopterroptindoptresetsuboptarggetsuboptlocaleconv_l// langinfo.h// malloc.h//! Interface to the [SOLID] C library//! [SOLID]: https://solid.kmckk.com///! Switch C type definitionsc_boolc_longdouble_CLongDouble// long double in C means A float point value, which has 128bit length.// but some bit maybe not used, so the real length of long double could be 80(x86) or 128(power pc/IEEE)// this is different from f128(not stable and not N*  Y    